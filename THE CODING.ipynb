{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7138f831",
   "metadata": {},
   "source": [
    "# Art Price Prediction Belgian Paintings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59da2938",
   "metadata": {},
   "source": [
    "Using different Machine Learning algorithms, the price of paintings for a selected group of belgian painters will be forecasted.\n",
    "\n",
    "Through web scraping the website of the biggest auction house turnover wise Christie's, the data is gathered ranging from artist, title, style, ... to the hue contrast in the painting, ... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44f0eb0",
   "metadata": {},
   "source": [
    "## Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c340210f",
   "metadata": {},
   "source": [
    "The estimated price of a painting that is to be sold in these auction houses is not accurate enough. By using Machine Learning algorithms, the accuracy of the forecast of the art price is tried to be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc0cb84",
   "metadata": {},
   "source": [
    "The estimated price of paintings set to be sold at these auction houses lacks sufficient accuracy. Machine learning algorithms are being employed in an attempt to enhance the precision of art price forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43464c1",
   "metadata": {},
   "source": [
    "## Data exploration and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5241f1",
   "metadata": {},
   "source": [
    "- How many data instances do you have?\n",
    "- Do you have duplicates?\n",
    "- How many features? What type are they?\n",
    "- If they are categorical, what categories they have, what is their frequency?\n",
    "- If they are numerical, what is their distribution?\n",
    "- What is the distribution of the target variable?\n",
    "- If you have a target, you can also check the relationship between the target and the variables.\n",
    "- Do you have missing data? If yes, how are you going to handle it?\n",
    "- Can you use the features in their original form, or do you need to alter them in some way?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1c2700",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a250b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import warnings\n",
    "import requests\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b873ace",
   "metadata": {},
   "source": [
    "#### import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7de2cd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>artist</th>\n",
       "      <th>img_name</th>\n",
       "      <th>collection</th>\n",
       "      <th>title</th>\n",
       "      <th>details</th>\n",
       "      <th>provenance</th>\n",
       "      <th>exhibit</th>\n",
       "      <th>further_details</th>\n",
       "      <th>price_realized</th>\n",
       "      <th>estimated_price</th>\n",
       "      <th>faces</th>\n",
       "      <th>heigth</th>\n",
       "      <th>width</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>dominant_color_hex</th>\n",
       "      <th>hue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>James Ensor</td>\n",
       "      <td>2021_CKS_20068_0032_000(james_ensor_pierrot_et...</td>\n",
       "      <td>JAMES ENSOR (1860-1949)</td>\n",
       "      <td>Pierrot et squelettes</td>\n",
       "      <td>JAMES ENSOR (1860-1949)Pierrot et squelettessi...</td>\n",
       "      <td>Private collection, Antwerp.Galeries Breckpot,...</td>\n",
       "      <td>Ostend, Kursaal, Salon des Beaux-Arts, July - ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GBP 2,542,500</td>\n",
       "      <td>GBP 1,200,000 – GBP 1,800,000</td>\n",
       "      <td>True</td>\n",
       "      <td>2743.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>38.917535</td>\n",
       "      <td>117.077205</td>\n",
       "      <td>#77746d</td>\n",
       "      <td>0.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>James Ensor</td>\n",
       "      <td>2022_NYR_21605_0124_000(james_ensor_petit_th23...</td>\n",
       "      <td>JAMES ENSOR (1860-1949)</td>\n",
       "      <td>Petit théâtre</td>\n",
       "      <td>JAMES ENSOR (1860-1949)Petit théâtresigned 'En...</td>\n",
       "      <td>(probably) Augusta Boogaerts, Brussels (by 192...</td>\n",
       "      <td>(probably) Antwerp, Kunst van Heden, April-May...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD 453,600</td>\n",
       "      <td>USD 200,000 – USD 400,000</td>\n",
       "      <td>True</td>\n",
       "      <td>2626.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>46.936813</td>\n",
       "      <td>153.851332</td>\n",
       "      <td>#999b91</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index       artist  \\\n",
       "0           0      0  James Ensor   \n",
       "1           1      1  James Ensor   \n",
       "\n",
       "                                            img_name               collection  \\\n",
       "0  2021_CKS_20068_0032_000(james_ensor_pierrot_et...  JAMES ENSOR (1860-1949)   \n",
       "1  2022_NYR_21605_0124_000(james_ensor_petit_th23...  JAMES ENSOR (1860-1949)   \n",
       "\n",
       "                   title                                            details  \\\n",
       "0  Pierrot et squelettes  JAMES ENSOR (1860-1949)Pierrot et squelettessi...   \n",
       "1          Petit théâtre  JAMES ENSOR (1860-1949)Petit théâtresigned 'En...   \n",
       "\n",
       "                                          provenance  \\\n",
       "0  Private collection, Antwerp.Galeries Breckpot,...   \n",
       "1  (probably) Augusta Boogaerts, Brussels (by 192...   \n",
       "\n",
       "                                             exhibit further_details  \\\n",
       "0  Ostend, Kursaal, Salon des Beaux-Arts, July - ...             NaN   \n",
       "1  (probably) Antwerp, Kunst van Heden, April-May...             NaN   \n",
       "\n",
       "  price_realized                estimated_price faces  heigth   width  \\\n",
       "0  GBP 2,542,500  GBP 1,200,000 – GBP 1,800,000  True  2743.0  3200.0   \n",
       "1    USD 453,600      USD 200,000 – USD 400,000  True  2626.0  3200.0   \n",
       "\n",
       "    contrast  brightness dominant_color_hex       hue  \n",
       "0  38.917535  117.077205            #77746d  0.116667  \n",
       "1  46.936813  153.851332            #999b91  0.200000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_twee.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79d8fdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51a14ee",
   "metadata": {},
   "source": [
    "#### managing the artists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9783757e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15 different artists in 1167 samples and the frequency of each different artist is:\n",
      "artist\n",
      "Rene Magritte               206\n",
      "Pierre Alechinsky           185\n",
      "James Ensor                 146\n",
      "Anthony Van Dyck            130\n",
      "Paul Delvaux                 98\n",
      "Felicien Rops                73\n",
      "Theo Van Rysselberghe        60\n",
      "Jacob Jordaens               54\n",
      "Eugene Verboeckhoven         51\n",
      "Jan Breughel II              51\n",
      "Rysselberghe                 47\n",
      "Breughel                     35\n",
      "Jan Breughel I               18\n",
      "Jan Breughel the elder        7\n",
      "Jan Breughel the younger      6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# looking how much different artists we have to work with\n",
    "artist_freq = df['artist'].value_counts()\n",
    "print(f\"There are {len(artist_freq)} different artists in {len(df)} samples and the frequency of each different artist is:\")\n",
    "print(artist_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f13ac0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11 different artists in 1132 samples and the frequency of each different artist is:\n",
      "artist\n",
      "Rene Magritte               206\n",
      "Pierre Alechinsky           185\n",
      "James Ensor                 146\n",
      "Anthony Van Dyck            130\n",
      "Theo Van Rysselberghe       107\n",
      "Paul Delvaux                 98\n",
      "Felicien Rops                73\n",
      "Jan Breughel the younger     57\n",
      "Jacob Jordaens               54\n",
      "Eugene Verboeckhoven         51\n",
      "Jan Breughel the elder       25\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# some painters are the same and we are going to put them under one name \n",
    "replace_artists = {'Jan Breughel I': 'Jan Breughel the elder', 'Jan Breughel II': 'Jan Breughel the younger', 'Rysselberghe': 'Theo Van Rysselberghe'}\n",
    "df['artist'] = df['artist'].replace(replace_artists)\n",
    "\n",
    "# drop all the columns with Breughel because we dont know which one it is ( there are more Breughels such as Pieter B. the younger and elder, ...)\n",
    "df = df[df['artist'] != 'Breughel']\n",
    "\n",
    "# print frequention of the artists \n",
    "artist_freq = df['artist'].value_counts()\n",
    "print(f\"There are {len(artist_freq)} different artists in {len(df)} samples and the frequency of each different artist is:\")\n",
    "print(artist_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7967bac4",
   "metadata": {},
   "source": [
    "what do we need to do here with the Jan Breughel the elder ? drop or keep "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f58b5",
   "metadata": {},
   "source": [
    "#### information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d0a34ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1132 entries, 0 to 1163\n",
      "Data columns (total 19 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Unnamed: 0          1132 non-null   int64  \n",
      " 1   index               1132 non-null   int64  \n",
      " 2   artist              1132 non-null   object \n",
      " 3   img_name            842 non-null    object \n",
      " 4   collection          1085 non-null   object \n",
      " 5   title               885 non-null    object \n",
      " 6   details             1132 non-null   object \n",
      " 7   provenance          678 non-null    object \n",
      " 8   exhibit             391 non-null    object \n",
      " 9   further_details     102 non-null    object \n",
      " 10  price_realized      1112 non-null   object \n",
      " 11  estimated_price     973 non-null    object \n",
      " 12  faces               842 non-null    object \n",
      " 13  heigth              842 non-null    float64\n",
      " 14  width               842 non-null    float64\n",
      " 15  contrast            842 non-null    float64\n",
      " 16  brightness          842 non-null    float64\n",
      " 17  dominant_color_hex  842 non-null    object \n",
      " 18  hue                 842 non-null    float64\n",
      "dtypes: float64(5), int64(2), object(12)\n",
      "memory usage: 176.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "479555b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the nan values of price_realized because these rows are useless\n",
    "df.dropna(subset=['price_realized'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a2d9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contains 1112 instances and 19 features.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The data contains {df.shape[0]} instances and {df.shape[1]} features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fa9436",
   "metadata": {},
   "source": [
    "#### splitsing the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e189608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new feature: year_sold \n",
    "df['year_sold'] = pd.to_numeric(df['img_name'].str[:4], errors='coerce').astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b3e956f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CKS' 'NYR' 'PAR' 'AMS' 'unknown' 'CSK' 'NYE' 'ECO' 'NYP' 'RMA' 'HGK']\n"
     ]
    }
   ],
   "source": [
    "# creating new feature: city_auction\n",
    "df['city_auction'] = df['img_name'].str[5:8]\n",
    "\n",
    "# changing some values of this column\n",
    "df['city_auction'] = np.where( df['city_auction'].isnull(), 'unknown', df['city_auction'])\n",
    "print(df['city_auction'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b1a6d9",
   "metadata": {},
   "source": [
    "later we are going to look at these cities and standardize these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5599009f",
   "metadata": {},
   "source": [
    "#### dropping the duplicate paintings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cda99e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of duplicate titles is: 396\n",
      "Number of duplicates across features title, arist and year_sold: 299\n"
     ]
    }
   ],
   "source": [
    "# dropping the duplicate paintings, it is perfect possible that the exact row is not the same \n",
    "# but the most that a painting is taken twice with an error or difference in a one feature\n",
    "\n",
    "# first we look at the different titles which is the perfect reference point to look at duplicates\n",
    "duplicate_titles = df['title'].duplicated().sum()\n",
    "print('The amount of duplicate titles is:', duplicate_titles)\n",
    "\n",
    "# secondly, we look at the different title, artist and year_sold\n",
    "duplicates_3features = df.duplicated(subset=['artist', 'title', 'year_sold'])\n",
    "df_duplicates = df[duplicates_3features]\n",
    "num_duplicates = duplicates_3features.sum()\n",
    "print(f\"Number of duplicates across features title, arist and year_sold: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cc3814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the duplicate rows BUT keeping the ones with the least nan_values\n",
    "df['nan_count'] = df.isnull().sum(axis=1)\n",
    "df_sorted = df.sort_values(by='nan_count')\n",
    "df_no_triple_duplicates = df_sorted.drop_duplicates(subset=['title','artist','year_sold'])\n",
    "df_no_triple_duplicates = df_no_triple_duplicates.drop('nan_count',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb0dab3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11 different artists in 813 samples and the frequency of each different artist is:\n",
      "\n",
      "artist\n",
      "Rene Magritte               158\n",
      "Pierre Alechinsky           137\n",
      "James Ensor                 102\n",
      "Anthony Van Dyck             95\n",
      "Paul Delvaux                 91\n",
      "Theo Van Rysselberghe        54\n",
      "Jan Breughel the younger     44\n",
      "Jacob Jordaens               43\n",
      "Felicien Rops                35\n",
      "Eugene Verboeckhoven         34\n",
      "Jan Breughel the elder       20\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "artist_freq = df_no_triple_duplicates['artist'].value_counts()\n",
    "df = df_no_triple_duplicates\n",
    "print(f\"There are {len(artist_freq)} different artists in {len(df_no_triple_duplicates)} samples and the frequency of each different artist is:\\n\")\n",
    "print(artist_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a10f055a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>artist</th>\n",
       "      <th>img_name</th>\n",
       "      <th>collection</th>\n",
       "      <th>title</th>\n",
       "      <th>details</th>\n",
       "      <th>provenance</th>\n",
       "      <th>exhibit</th>\n",
       "      <th>further_details</th>\n",
       "      <th>...</th>\n",
       "      <th>estimated_price</th>\n",
       "      <th>faces</th>\n",
       "      <th>heigth</th>\n",
       "      <th>width</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>dominant_color_hex</th>\n",
       "      <th>hue</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182</td>\n",
       "      <td>3912</td>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>2018_AMS_15910_0038_000(pierre_alechinsky_cach...</td>\n",
       "      <td>Pierre Alechinsky (b. 1927)</td>\n",
       "      <td>Cache-telé (Hidden Television)</td>\n",
       "      <td>Pierre Alechinsky (b. 1927)Cache-telé (Hidden ...</td>\n",
       "      <td>Fondation Maeght, Saint-Paul de Vence.Acquired...</td>\n",
       "      <td>Arezzo, Museo Civico d'Arte Moderna e Contempo...</td>\n",
       "      <td>Pierre Alechinsky has confirmed the authentici...</td>\n",
       "      <td>...</td>\n",
       "      <td>EUR 70,000 – EUR 100,000</td>\n",
       "      <td>True</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>52.600858</td>\n",
       "      <td>101.139904</td>\n",
       "      <td>#576d67</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>2018</td>\n",
       "      <td>AMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>523</td>\n",
       "      <td>5114</td>\n",
       "      <td>Theo Van Rysselberghe</td>\n",
       "      <td>2010_PAR_05609_0033_000(theo_van_rysselberghe_...</td>\n",
       "      <td>THEO VAN RYSSELBERGHE (1862-1926)</td>\n",
       "      <td>Jeune dame lisant</td>\n",
       "      <td>THEO VAN RYSSELBERGHE (1862-1926)Jeune dame li...</td>\n",
       "      <td>Galerie Willy D'Huysser, Bruxelles.Acquis aupr...</td>\n",
       "      <td>Bruxelles, Palais des Beaux-Arts et La Haye, G...</td>\n",
       "      <td>'YOUNG LADY READING'; SIGNED LOWER RIGHT; OIL ...</td>\n",
       "      <td>...</td>\n",
       "      <td>EUR 70,000 – EUR 100,000</td>\n",
       "      <td>True</td>\n",
       "      <td>4089.0</td>\n",
       "      <td>3275.0</td>\n",
       "      <td>49.257938</td>\n",
       "      <td>136.515970</td>\n",
       "      <td>#90837d</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>2010</td>\n",
       "      <td>PAR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                 artist  \\\n",
       "0         182   3912      Pierre Alechinsky   \n",
       "1         523   5114  Theo Van Rysselberghe   \n",
       "\n",
       "                                            img_name  \\\n",
       "0  2018_AMS_15910_0038_000(pierre_alechinsky_cach...   \n",
       "1  2010_PAR_05609_0033_000(theo_van_rysselberghe_...   \n",
       "\n",
       "                          collection                           title  \\\n",
       "0        Pierre Alechinsky (b. 1927)  Cache-telé (Hidden Television)   \n",
       "1  THEO VAN RYSSELBERGHE (1862-1926)               Jeune dame lisant   \n",
       "\n",
       "                                             details  \\\n",
       "0  Pierre Alechinsky (b. 1927)Cache-telé (Hidden ...   \n",
       "1  THEO VAN RYSSELBERGHE (1862-1926)Jeune dame li...   \n",
       "\n",
       "                                          provenance  \\\n",
       "0  Fondation Maeght, Saint-Paul de Vence.Acquired...   \n",
       "1  Galerie Willy D'Huysser, Bruxelles.Acquis aupr...   \n",
       "\n",
       "                                             exhibit  \\\n",
       "0  Arezzo, Museo Civico d'Arte Moderna e Contempo...   \n",
       "1  Bruxelles, Palais des Beaux-Arts et La Haye, G...   \n",
       "\n",
       "                                     further_details  ...  \\\n",
       "0  Pierre Alechinsky has confirmed the authentici...  ...   \n",
       "1  'YOUNG LADY READING'; SIGNED LOWER RIGHT; OIL ...  ...   \n",
       "\n",
       "            estimated_price faces  heigth   width   contrast  brightness  \\\n",
       "0  EUR 70,000 – EUR 100,000  True  2413.0  3200.0  52.600858  101.139904   \n",
       "1  EUR 70,000 – EUR 100,000  True  4089.0  3275.0  49.257938  136.515970   \n",
       "\n",
       "   dominant_color_hex       hue  year_sold  city_auction  \n",
       "0             #576d67  0.454545       2018           AMS  \n",
       "1             #90837d  0.052632       2010           PAR  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resetting the index of the dataframe\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4102b230",
   "metadata": {},
   "source": [
    "#### looking at the cities at standardize them if possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb37c2f",
   "metadata": {},
   "source": [
    "giving the cities more specific names instead of abbreviations\n",
    "\n",
    "    AMS Amsterdam\n",
    "    PAR Paris\n",
    "    NYR New York\n",
    "    CKS London\n",
    "    HGK Hong Kong\n",
    "    NYP New York - parkvenue\n",
    "    CSK London south kensigton\n",
    "    RMA Milan in a church\n",
    "    NYE New York - other site\n",
    "    ECO unknown\n",
    "    unknown unknown\n",
    "    \n",
    "done by looking up the location of 3 paintings of that city code and if 100% correct we assumed it was this city! ECO has only 4 samples and none of them had a title so I decided to put it with unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94174e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_mapping = {\n",
    "    'AMS': 'Amsterdam',\n",
    "    'PAR': 'Paris',\n",
    "    'NYR': 'New York',\n",
    "    'CKS': 'London',\n",
    "    'HGK': 'Hong Kong',\n",
    "    'NYP': 'New York',\n",
    "    'CSK': 'London',\n",
    "    'RMA': 'Milan',\n",
    "    'NYE': 'New York',\n",
    "    'ECO': 'unknown',\n",
    "    'unknown': 'unknown'\n",
    "}\n",
    "\n",
    "# Use the replace function to map the values\n",
    "df['city_auction'] = df['city_auction'].replace(city_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdec9bb",
   "metadata": {},
   "source": [
    "#### splitsing the realized price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "194001f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitsing the realized_price to currency and price\n",
    "df[['currency','price']] = df['price_realized'].str.split(' ', n=1, expand=True)\n",
    "df['price'] = df['price'].str.replace(',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83ce4bad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# splitsing the estimate_price to a low-price and high-price estimate\n",
    "df[['low_estimate','high_estimate']] = df['estimated_price'].str.split(' – ', expand=True)\n",
    "df['low_estimate'] = df['low_estimate'].str.replace(r'\\D','',regex=True)\n",
    "df['high_estimate'] = df['high_estimate'].str.replace(r'\\D','',regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6505be2b",
   "metadata": {},
   "source": [
    "###### intermezzo - not super urgent \n",
    "\n",
    "###### the under, over and correctly valued paintings \n",
    "\n",
    "###### the average estimates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd7140a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correct number of estimations are: 237\n",
      "The number of over estimations are:  363\n",
      "The number of under estimations are:  179\n",
      " \n",
      "0.33% of the estimations are correct.\n",
      "0.50% of the estimations are too high.\n",
      "0.25% of the estimations are too low.\n"
     ]
    }
   ],
   "source": [
    "# Assuming df['price'], df['low_estimate'], and df['high_estimate'] may have missing values\n",
    "valid_rows = df.dropna(subset=['price', 'low_estimate', 'high_estimate'])\n",
    "\n",
    "correct_valuation = sum(\n",
    "    (valid_rows['price'] >= valid_rows['low_estimate']) &\n",
    "    (valid_rows['price'] <= valid_rows['high_estimate'])\n",
    ")\n",
    "\n",
    "over_valuation = sum(valid_rows['price'] > valid_rows['high_estimate'])\n",
    "under_valuation = sum(valid_rows['price'] < valid_rows['low_estimate'])\n",
    "\n",
    "print('The correct number of estimations are:', correct_valuation)\n",
    "print('The number of over estimations are: ', over_valuation)\n",
    "print('The number of under estimations are: ', under_valuation)\n",
    "print(' ')\n",
    "\n",
    "# the ratio of correct, over and under valuations\n",
    "share_right = correct_valuation/len(valid_rows)\n",
    "share_over = over_valuation/len(valid_rows)\n",
    "share_under = under_valuation/len(valid_rows)\n",
    "\n",
    "print(f'{share_right:.2f}% of the estimations are correct.')\n",
    "print(f'{share_over:.2f}% of the estimations are too high.')\n",
    "print(f'{share_under:.2f}% of the estimations are too low.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3398c168",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    85000.0\n",
       "1    85000.0\n",
       "Name: average_estimate, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a new variable average_estimate to use for the sum of residuals\n",
    "# first we need to make floats and ignore the strings with NaN\n",
    "df['low_estimate'] = df['low_estimate'].replace('', np.nan)\n",
    "df['low_estimate'] = df['low_estimate'].astype(float)\n",
    "df['high_estimate'] = df['high_estimate'].replace('', np.nan)\n",
    "df['high_estimate'] = df['high_estimate'].astype(float)\n",
    "df['average_estimate'] = (df['low_estimate'] + df['high_estimate'])/2\n",
    "\n",
    "# we keep it in a variable so we can drop these columns due to human-induced bias and the risk of overfitting\n",
    "average_estimates = df['average_estimate'] \n",
    "average_estimates.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e59e453",
   "metadata": {},
   "source": [
    "##### Price converting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e9f1435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The exchange rate on 2000-01-01 from HKD to EUR was: 0.1282\n"
     ]
    }
   ],
   "source": [
    "# test with the package\n",
    "from datetime import datetime\n",
    "from forex_python.converter import CurrencyRates\n",
    "\n",
    "c = CurrencyRates()\n",
    "date_string = \"2000-01-01\"\n",
    "target_currency = \"EUR\"\n",
    "base_currency = \"HKD\"\n",
    "\n",
    "target_date = datetime.strptime(date_string, \"%Y-%m-%d\")\n",
    "\n",
    "historical_rate = c.get_rate(base_currency, target_currency, target_date)\n",
    "\n",
    "print(f\"The exchange rate on {date_string} from {base_currency} to {target_currency} was: {historical_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0890f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a function to extract the historical rate between currencies \n",
    "# this package can only go to 2000 so all the years between 1994 and 1999 are changed to 2000 to extract the rate\n",
    "from forex_python.converter import CurrencyRates\n",
    "from datetime import datetime\n",
    "\n",
    "# create a CurrencyRates object\n",
    "c = CurrencyRates()\n",
    "\n",
    "# this package can only go to 2000 so all the years between 1994 and 1999 are changed to 2000 to extract the rate\n",
    "# making a new temporary column 'year_temp' with all the years 2000 or more\n",
    "# function adjust_year to make this happen\n",
    "def adjust_years(year):\n",
    "    if pd.notna(year):\n",
    "        return max(year, 2000)\n",
    "    else:\n",
    "        return pd.NA\n",
    "\n",
    "# Apply the function to create the new 'year_temp' column\n",
    "df['year_temp'] = df['year_sold'].apply(adjust_years)\n",
    "\n",
    "# making a new column called date_string with the date always the first of the year\n",
    "df['year_string'] = pd.to_datetime(df['year_temp'], format='%Y').dt.to_period('Y').dt.start_time.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb377500",
   "metadata": {},
   "source": [
    "**Important Note**\n",
    "\n",
    "There is an important detail !! The euro is only implemented in 2002, so before that the euro is expressed in NLG, 'Nederlandse gulden'. However, from 1 jan 2000, a rate is constatated of 1NLG:0,45378 EUR. It is important to note that this exchange rate only is only a historical reference, because the euro was only an official valuata from 1 jan 2002. \n",
    "For this reason, all the years before 2000 are going to get the same exchange ratio as that valuta had on 1 jan 2000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c48b8",
   "metadata": {},
   "source": [
    "### new strategy - average for nat values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ab4d69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.8462979761343062\n",
      "1.298536694211663\n",
      "0.45378\n",
      "0.1088200060640964\n"
     ]
    }
   ],
   "source": [
    "# calculating the average exchange rates to fill in the nan values\n",
    "\n",
    "date_string_average = [datetime(year, 1, 1).strftime(\"%Y-%m-%d\") for year in range(2000, 2023 + 1)]\n",
    "\n",
    "# Euro to Euro\n",
    "average_rate_EUR = 1\n",
    "print(average_rate_EUR)\n",
    "\n",
    "# USD to Euro\n",
    "USD_to_EUR = []\n",
    "for date in date_string_average:\n",
    "    base_currency = 'USD'\n",
    "    target_currency = 'EUR'\n",
    "    target_date = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    historical_rate = c.get_rate(base_currency, target_currency, target_date)\n",
    "    USD_to_EUR.append(historical_rate)\n",
    "average_rate_USD = np.mean(USD_to_EUR)    \n",
    "print(average_rate_USD)\n",
    "\n",
    "# GBP to Euro\n",
    "GBP_to_EUR = []\n",
    "for date in date_string_average:\n",
    "    base_currency = 'GBP'\n",
    "    target_currency = 'EUR'\n",
    "    target_date = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    historical_rate = c.get_rate(base_currency, target_currency, target_date)\n",
    "    GBP_to_EUR.append(historical_rate)\n",
    "average_rate_GBP = np.mean(GBP_to_EUR)    \n",
    "print(average_rate_GBP)\n",
    "\n",
    "# NLG to Euro\n",
    "average_rate_NLG = 0.45378\n",
    "print(average_rate_NLG)\n",
    "\n",
    "# HKD to Euro\n",
    "HKD_to_EUR = []\n",
    "for date in date_string_average:\n",
    "    base_currency = 'HKD'\n",
    "    target_currency = 'EUR'\n",
    "    target_date = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    historical_rate = c.get_rate(base_currency, target_currency, target_date)\n",
    "    HKD_to_EUR.append(historical_rate)\n",
    "average_rate_HKD = np.mean(HKD_to_EUR)    \n",
    "print(average_rate_HKD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c8dfd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>artist</th>\n",
       "      <th>img_name</th>\n",
       "      <th>collection</th>\n",
       "      <th>title</th>\n",
       "      <th>details</th>\n",
       "      <th>provenance</th>\n",
       "      <th>exhibit</th>\n",
       "      <th>further_details</th>\n",
       "      <th>...</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>price</th>\n",
       "      <th>low_estimate</th>\n",
       "      <th>high_estimate</th>\n",
       "      <th>average_estimate</th>\n",
       "      <th>year_temp</th>\n",
       "      <th>year_string</th>\n",
       "      <th>exchange_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182</td>\n",
       "      <td>3912</td>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>2018_AMS_15910_0038_000(pierre_alechinsky_cach...</td>\n",
       "      <td>Pierre Alechinsky (b. 1927)</td>\n",
       "      <td>Cache-telé (Hidden Television)</td>\n",
       "      <td>Pierre Alechinsky (b. 1927)Cache-telé (Hidden ...</td>\n",
       "      <td>Fondation Maeght, Saint-Paul de Vence.Acquired...</td>\n",
       "      <td>Arezzo, Museo Civico d'Arte Moderna e Contempo...</td>\n",
       "      <td>Pierre Alechinsky has confirmed the authentici...</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>EUR</td>\n",
       "      <td>87500</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>523</td>\n",
       "      <td>5114</td>\n",
       "      <td>Theo Van Rysselberghe</td>\n",
       "      <td>2010_PAR_05609_0033_000(theo_van_rysselberghe_...</td>\n",
       "      <td>THEO VAN RYSSELBERGHE (1862-1926)</td>\n",
       "      <td>Jeune dame lisant</td>\n",
       "      <td>THEO VAN RYSSELBERGHE (1862-1926)Jeune dame li...</td>\n",
       "      <td>Galerie Willy D'Huysser, Bruxelles.Acquis aupr...</td>\n",
       "      <td>Bruxelles, Palais des Beaux-Arts et La Haye, G...</td>\n",
       "      <td>'YOUNG LADY READING'; SIGNED LOWER RIGHT; OIL ...</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>Paris</td>\n",
       "      <td>EUR</td>\n",
       "      <td>79000</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                 artist  \\\n",
       "0         182   3912      Pierre Alechinsky   \n",
       "1         523   5114  Theo Van Rysselberghe   \n",
       "\n",
       "                                            img_name  \\\n",
       "0  2018_AMS_15910_0038_000(pierre_alechinsky_cach...   \n",
       "1  2010_PAR_05609_0033_000(theo_van_rysselberghe_...   \n",
       "\n",
       "                          collection                           title  \\\n",
       "0        Pierre Alechinsky (b. 1927)  Cache-telé (Hidden Television)   \n",
       "1  THEO VAN RYSSELBERGHE (1862-1926)               Jeune dame lisant   \n",
       "\n",
       "                                             details  \\\n",
       "0  Pierre Alechinsky (b. 1927)Cache-telé (Hidden ...   \n",
       "1  THEO VAN RYSSELBERGHE (1862-1926)Jeune dame li...   \n",
       "\n",
       "                                          provenance  \\\n",
       "0  Fondation Maeght, Saint-Paul de Vence.Acquired...   \n",
       "1  Galerie Willy D'Huysser, Bruxelles.Acquis aupr...   \n",
       "\n",
       "                                             exhibit  \\\n",
       "0  Arezzo, Museo Civico d'Arte Moderna e Contempo...   \n",
       "1  Bruxelles, Palais des Beaux-Arts et La Haye, G...   \n",
       "\n",
       "                                     further_details  ... year_sold  \\\n",
       "0  Pierre Alechinsky has confirmed the authentici...  ...      2018   \n",
       "1  'YOUNG LADY READING'; SIGNED LOWER RIGHT; OIL ...  ...      2010   \n",
       "\n",
       "  city_auction currency  price  low_estimate  high_estimate  average_estimate  \\\n",
       "0    Amsterdam      EUR  87500       70000.0       100000.0           85000.0   \n",
       "1        Paris      EUR  79000       70000.0       100000.0           85000.0   \n",
       "\n",
       "  year_temp  year_string  exchange_rate  \n",
       "0      2018   2018-01-01            1.0  \n",
       "1      2010   2010-01-01            1.0  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making it through working in blocks instead of with a function\n",
    "df['exchange_rate'] = None # initialization of the new column\n",
    "for index, row in df.iterrows(): # iterating\n",
    "    c = CurrencyRates() # creating a CurrencyRates object\n",
    "    date_string = df['year_string'][index]\n",
    "    target_currency = 'EUR'\n",
    "    base_currency = df['currency'][index]\n",
    "\n",
    "    \n",
    "    if pd.isna(date_string) or date_string == 'NaT':\n",
    "        if base_currency == 'EUR':\n",
    "            historical_rate = average_rate_EUR\n",
    "        elif base_currency == 'USD':\n",
    "            historical_rate = average_rate_USD\n",
    "        elif base_currency == 'GBP':\n",
    "            historical_rate = average_rate_GBP\n",
    "        elif base_currency == 'NLG':\n",
    "            historical_rate = average_rate_NLG\n",
    "        else:\n",
    "            historical_rate = average_rate_HKD\n",
    "    else:\n",
    "        # converting date string to datetime object\n",
    "        target_date = datetime.strptime(date_string, \"%Y-%m-%d\")\n",
    "\n",
    "        if base_currency == 'NLG':\n",
    "            historical_rate =  0.45378\n",
    "        else:\n",
    "            historical_rate = c.get_rate(base_currency, target_currency, target_date)\n",
    "\n",
    "    df['exchange_rate'][index] = historical_rate\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8388ab57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>artist</th>\n",
       "      <th>img_name</th>\n",
       "      <th>collection</th>\n",
       "      <th>title</th>\n",
       "      <th>details</th>\n",
       "      <th>provenance</th>\n",
       "      <th>exhibit</th>\n",
       "      <th>further_details</th>\n",
       "      <th>...</th>\n",
       "      <th>low_estimate</th>\n",
       "      <th>high_estimate</th>\n",
       "      <th>average_estimate</th>\n",
       "      <th>year_temp</th>\n",
       "      <th>year_string</th>\n",
       "      <th>exchange_rate</th>\n",
       "      <th>price_EUR</th>\n",
       "      <th>low_estimate_EUR</th>\n",
       "      <th>high_estimate_EUR</th>\n",
       "      <th>average_estimate_EUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182</td>\n",
       "      <td>3912</td>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>2018_AMS_15910_0038_000(pierre_alechinsky_cach...</td>\n",
       "      <td>Pierre Alechinsky (b. 1927)</td>\n",
       "      <td>Cache-telé (Hidden Television)</td>\n",
       "      <td>Pierre Alechinsky (b. 1927)Cache-telé (Hidden ...</td>\n",
       "      <td>Fondation Maeght, Saint-Paul de Vence.Acquired...</td>\n",
       "      <td>Arezzo, Museo Civico d'Arte Moderna e Contempo...</td>\n",
       "      <td>Pierre Alechinsky has confirmed the authentici...</td>\n",
       "      <td>...</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>85000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index             artist  \\\n",
       "0         182   3912  Pierre Alechinsky   \n",
       "\n",
       "                                            img_name  \\\n",
       "0  2018_AMS_15910_0038_000(pierre_alechinsky_cach...   \n",
       "\n",
       "                    collection                           title  \\\n",
       "0  Pierre Alechinsky (b. 1927)  Cache-telé (Hidden Television)   \n",
       "\n",
       "                                             details  \\\n",
       "0  Pierre Alechinsky (b. 1927)Cache-telé (Hidden ...   \n",
       "\n",
       "                                          provenance  \\\n",
       "0  Fondation Maeght, Saint-Paul de Vence.Acquired...   \n",
       "\n",
       "                                             exhibit  \\\n",
       "0  Arezzo, Museo Civico d'Arte Moderna e Contempo...   \n",
       "\n",
       "                                     further_details  ... low_estimate  \\\n",
       "0  Pierre Alechinsky has confirmed the authentici...  ...      70000.0   \n",
       "\n",
       "  high_estimate average_estimate  year_temp  year_string  exchange_rate  \\\n",
       "0      100000.0          85000.0       2018   2018-01-01            1.0   \n",
       "\n",
       "   price_EUR low_estimate_EUR  high_estimate_EUR  average_estimate_EUR  \n",
       "0    87500.0          70000.0           100000.0               85000.0  \n",
       "\n",
       "[1 rows x 33 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a new column price_EUR which is the price in euro\n",
    "# convert exchange_rate and price to float\n",
    "df['exchange_rate'] = df['exchange_rate'].astype(float)\n",
    "df['price'] = df['price'].astype(float)\n",
    "\n",
    "df['price_EUR'] = (df['price'] * df['exchange_rate']).round(2)\n",
    "df['low_estimate_EUR'] = (df['low_estimate'] * df['exchange_rate']).round(2)\n",
    "df['high_estimate_EUR'] = (df['high_estimate'] * df['exchange_rate']).round(2)\n",
    "df['average_estimate_EUR'] = (df['average_estimate'] * df['exchange_rate']).round(2)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2c92e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "price_zero_count = (df['price_EUR'] == 0).sum()\n",
    "print(price_zero_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ea55336",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['price_EUR'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8201346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "price_zero_count = (df['price_EUR'] == 0).sum()\n",
    "print(price_zero_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59f9d38",
   "metadata": {},
   "source": [
    "### the sum of the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb29d615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of residuals is equal to: 131159996.63999999\n",
      "728\n",
      "The average residual is equal to: 180164.83054945053\n"
     ]
    }
   ],
   "source": [
    "# we are going to calculate the sum of residuals\n",
    "\n",
    "residuals = df['price_EUR'].dropna() - df['average_estimate_EUR'].dropna()\n",
    "sum_of_residuals = np.sum(residuals)\n",
    "average_residual = sum_of_residuals / len(residuals.dropna())\n",
    "\n",
    "# printing\n",
    "print(\"The sum of residuals is equal to:\", sum_of_residuals)\n",
    "print(len(residuals.dropna()))\n",
    "print('The average residual is equal to:', average_residual) # without the nan vlues of the avearge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77ac7c5",
   "metadata": {},
   "source": [
    "# splitsing the deeetz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2bb7fdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 811 entries, 0 to 812\n",
      "Data columns (total 33 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Unnamed: 0            811 non-null    int64  \n",
      " 1   index                 811 non-null    int64  \n",
      " 2   artist                811 non-null    object \n",
      " 3   img_name              690 non-null    object \n",
      " 4   collection            788 non-null    object \n",
      " 5   title                 759 non-null    object \n",
      " 6   details               811 non-null    object \n",
      " 7   provenance            518 non-null    object \n",
      " 8   exhibit               287 non-null    object \n",
      " 9   further_details       66 non-null     object \n",
      " 10  price_realized        811 non-null    object \n",
      " 11  estimated_price       748 non-null    object \n",
      " 12  faces                 690 non-null    object \n",
      " 13  heigth                690 non-null    float64\n",
      " 14  width                 690 non-null    float64\n",
      " 15  contrast              690 non-null    float64\n",
      " 16  brightness            690 non-null    float64\n",
      " 17  dominant_color_hex    690 non-null    object \n",
      " 18  hue                   690 non-null    float64\n",
      " 19  year_sold             690 non-null    Int64  \n",
      " 20  city_auction          811 non-null    object \n",
      " 21  currency              811 non-null    object \n",
      " 22  price                 811 non-null    float64\n",
      " 23  low_estimate          747 non-null    float64\n",
      " 24  high_estimate         728 non-null    float64\n",
      " 25  average_estimate      728 non-null    float64\n",
      " 26  year_temp             690 non-null    object \n",
      " 27  year_string           811 non-null    object \n",
      " 28  exchange_rate         811 non-null    float64\n",
      " 29  price_EUR             811 non-null    float64\n",
      " 30  low_estimate_EUR      747 non-null    float64\n",
      " 31  high_estimate_EUR     728 non-null    float64\n",
      " 32  average_estimate_EUR  728 non-null    float64\n",
      "dtypes: Int64(1), float64(14), int64(2), object(16)\n",
      "memory usage: 216.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26898b9",
   "metadata": {},
   "source": [
    "###### signed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa75da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a new column called 'signed' from output of the column 'details'\n",
    "df['signed'] = df['details'].str.contains(r'signed|signé', case=False, na=False, regex=True).astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675dc9f2",
   "metadata": {},
   "source": [
    "###### dimension --> area and circumference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4008ce1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               None\n",
       "1    67.5 x 54.3 cm.\n",
       "2               None\n",
       "Name: dimension, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a new column called 'Dimensions' from output of the column 'details'\n",
    "def extract_dimensions(text):\n",
    "    matches = re.findall(r'(\\d+\\.\\d+\\s?[xX]\\s?\\d+\\.\\d+\\s?cm\\.|\\d+\\.\\d+\\s?[xX]\\s?\\d+\\.\\d+\\s?mm\\.)', text)\n",
    "    return matches[0] if matches else None\n",
    "\n",
    "# Apply the function to the 'details' column to create the new 'dimension' column\n",
    "df['dimension'] = df['details'].apply(extract_dimensions)\n",
    "df['dimension'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8073093e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       canvas115 x 153cm.\n",
       "1      oile67.5 x 54.3 cm.\n",
       "2       toile60.4 x 73 cm.\n",
       "3      n. (99.8 x 79.5 cm.\n",
       "4       toile73.5 x 60 cm.\n",
       "              ...         \n",
       "808                   None\n",
       "809    ionP. 299 x 239 mm.\n",
       "810    on panel51 x 63 cm.\n",
       "811     ¾in. (25.5 x 35cm.\n",
       "812                   None\n",
       "Name: dimension, Length: 811, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a new column called 'dimension' from output of the column 'details'\n",
    "def extract_information(text):\n",
    "    matches = re.findall(r'(.{15}\\s?(?:cm\\.|mm\\.))', text)\n",
    "    return matches[0] if matches else None\n",
    "\n",
    "# Apply the function to the 'details' column to create the new 'X' column\n",
    "df['dimension'] = df['details'].apply(extract_information)\n",
    "df['dimension']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cabae605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               dimension unit_of_length      l      w\n",
      "0     canvas115 x 153cm.             cm  115.0  153.0\n",
      "1    oile67.5 x 54.3 cm.             cm   67.5   54.3\n",
      "2     toile60.4 x 73 cm.             cm   60.4   73.0\n",
      "3    n. (99.8 x 79.5 cm.             cm   99.8   79.5\n",
      "4     toile73.5 x 60 cm.             cm   73.5   60.0\n",
      "..                   ...            ...    ...    ...\n",
      "808                 None           None    NaN    NaN\n",
      "809  ionP. 299 x 239 mm.             mm  299.0  239.0\n",
      "810  on panel51 x 63 cm.             cm   51.0   63.0\n",
      "811   ¾in. (25.5 x 35cm.             cm   25.5   35.0\n",
      "812                 None           None    NaN    NaN\n",
      "\n",
      "[811 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# splitsing and creating\n",
    "\n",
    "# makign a column with the unit of length of the dimensions\n",
    "df['unit_of_length'] = df['dimension'].str[-3:-1]\n",
    "\n",
    "# Handling 'None' values in 'dimension'\n",
    "df.loc[df['dimension'].isna(), ['l', 'w']] = [None, None]\n",
    "\n",
    "# Splitting 'dimension' into 'length' and 'width' using str.extract\n",
    "df[['l', 'w']] = df['dimension'].str.extract(r'([\\d.]+)\\s*x\\s*([\\d.]+)')\n",
    "\n",
    "# Removing non-numeric characters and converting to float\n",
    "df['l'] = pd.to_numeric(df['l'], errors='coerce')\n",
    "df['w'] = pd.to_numeric(df['w'], errors='coerce')\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df[['dimension', 'unit_of_length', 'l', 'w']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f922498d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    unit_of_length      l      w      area  circumference\n",
      "0               cm  115.0  153.0  17595.00          536.0\n",
      "1               cm   67.5   54.3   3665.25          243.6\n",
      "2               cm   60.4   73.0   4409.20          266.8\n",
      "3               cm   99.8   79.5   7934.10          358.6\n",
      "4               cm   73.5   60.0   4410.00          267.0\n",
      "..             ...    ...    ...       ...            ...\n",
      "808           None    NaN    NaN       NaN            NaN\n",
      "809             cm   29.9   23.9    714.61          107.6\n",
      "810             cm   51.0   63.0   3213.00          228.0\n",
      "811             cm   25.5   35.0    892.50          121.0\n",
      "812           None    NaN    NaN       NaN            NaN\n",
      "\n",
      "[811 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# creating the Area and Circumference\n",
    "\n",
    "# first we need to put all in the same unit of length and we use 'cm'\n",
    "for index, row in df.iterrows():\n",
    "    if df['unit_of_length'][index] == 'mm':\n",
    "        df['l'][index] = df['l'][index]/10\n",
    "        df['w'][index] = df['w'][index]/10 \n",
    "        df['unit_of_length'][index] = 'cm'\n",
    "\n",
    "df['area'] = df['l'] * df['w']\n",
    "df['circumference'] = df['l']*2 + df['w']*2\n",
    "\n",
    "print(df[['unit_of_length', 'l', 'w','area','circumference']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ceb2c1",
   "metadata": {},
   "source": [
    "###### year_painted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1ebf51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a new column called 'year_painted' from output of the column 'details'\n",
    "def extract_last_5_characters(text):\n",
    "    return text[-5:]\n",
    "\n",
    "# Apply the function to the 'details' column to create the new 'year_painted' column\n",
    "df['year_painted_temp'] = df['details'].apply(extract_last_5_characters)\n",
    "def extract_numeric_year(text):\n",
    "    # Use regular expression to find numeric values\n",
    "    matches = re.findall(r'\\b\\d+\\b', text)\n",
    "    \n",
    "    # Return the first match if found, otherwise return None\n",
    "    return matches[0] if matches else None\n",
    "\n",
    "# Apply the function to the 'year_painted' column to create a new 'real_year' column\n",
    "df['year_painted'] = df['year_painted_temp'].apply(extract_numeric_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0825d50e",
   "metadata": {},
   "source": [
    "###### medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "748a9118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joos de Momper II (Antwerp 1564-1635) and Attributed to Jan Breughel the Younger (Antwerp 1601-1678)A winter landscapeoil on panel17 x 27 5/8 in. (43.1 x 70.1 cm.)\n",
      "\n",
      "James Ensor (1860-1949)Les Cataclysmes (Cataclysms) (D., Cr., T., E. 37)etching, 1888, on simili-Japan paper, signed, dated and titled in pencil, countersigned in pencil verso, with wide margins, soft creasing at the sheet edges, otherwise in good conditionP. 180 x 237 mm., S. 347 x 476 mm.\n",
      "\n",
      "James Ensor (1860-1949)Le Meuble hanté (The Haunted Furniture) (D. 22; Cr. 23; T., E. 22)drypoint and etching, 1888, on Japan nacré paper, third, final state, signed, dated and titled in pencil, countersigned, titled and annotated AB in pencil verso, with wide margins, a deckle edge below, the upper sheet edge verso glued to the mount, otherwise in good conditionP. 140 x 91 mm., S. 297 x 204 mm.\n",
      "\n",
      "James Ensor (Belgian, 1860-1949)Jardin d'amoursigned 'Ensor J.' (lower right), signed and inscribed 'Jardin d'amour/Ensor' (on the reverse) and signed, inscribed and dated 'Pour mon ami Ch. Sandhaus une ligne/bien encrée du peintre des tons et des valeurs des/ciels et des vagues de notre mère la mer/du corps mourant./James Ensor/Ostende 25 Mai 1939' (on a label attached to the reverse)oil on panel40½ x 18.1/8 in. (36.8 x 46 cm.)Painted in 1910\n",
      "\n",
      "James Ensor (1860-1949)Les Adieux de Napoléon (Napoleon's Farewell) (D. 111; Cr. 110; T. 111; E. 114)drypoint and etching, 1897, on simili-Japan paper, second, final state, signed, dated and titled in pencil, countersigned in pencil verso, with wide margins, a crease across the tip of the upper right sheet corner, in very good conditionP. 122 x 188 mm., S. 240 x 296 mm.\n",
      "\n",
      "James Ensor (1860-1949)Bouquet d'Arbres (Group of Trees) (D., Cr., T., E. 41)etching, 1888, on simili-Japan paper, second, final state, signed, dated and titled in pencil, countersigned in pencil verso, with wide margins, minor abrasions at the upper sheet edge, otherwise in good conditionP. 100 x 140 mm., S. 239 x 304 mm.\n",
      "\n",
      "James Ensor (1860-1949)L'Hôtel de Ville d'Audenaerde (Town Hall of Audenaerde) (D., Cr., T., E. 28)drypoint and etching, 1888, on Japan paper, third, final state, signed, dated and titled in pencil, with narrow margins, a deckle edge below, remains of old brown paper tape at the upper sheet edge verso, with a small associated abrasion, otherwise in very good conditionP. 160 x 119 mm., S. 251 x 162 mm.\n",
      "\n",
      "James Ensor (1860-1949)Fridolin and Gragapança d’Yperdamme (Fridolin and Gragapança of Yperdamme) (D. 94; Cr., T. 95; E. 97)etching, 1895, on simili-Japan paper, signed, dated and titled Fridolin et Gragapansa in pencil, countersigned in pencil verso, with wide margins, in very good conditionP. 104 x 142 mm., S. 238 x 304 mm.\n",
      "\n",
      "James Ensor (1860-1949)Le Christ aux Mendiants (Christ among the Beggars) (D. 102; Cr. 101; T. 102; E. 103)drypoint and etching, 1895, on simili-Japan paper, second, final state, signed, dated and titled in pencil, countersigned in pencil verso, with wide margins, a crease across the tip of the lower right sheet corner, otherwise in very good conditionP. 95 x 143 mm., S. 238 x 297 mm.\n",
      "\n",
      "James Ensor (1860-1949)Sentier à Groenendael (Footpath at Groenendael) (D., Cr., T., E. 48)etching, 1888, on simili-Japan paper, second, final state, signed, dated and titled in pencil, with margins, irregularly trimmed, remains of old tape at the lower sheet verso, otherwise in good conditionP. 138 x 100 mm., S. 200 x 132 mm.\n",
      "\n",
      "James Ensor (1860-1949)Nature morte au Magot-Chinoiseries, étoffessigné 'ENSOR' (en bas à droite)huile sur toile33.1 x 56 cm.Peint vers 1891signed 'ENSOR' (lower right)oil on canvas13 x 22 in.Painted circa 1891\n",
      "\n",
      "Théo van Rysselberghe (1862-1926)Fillette au panier (Elisabeth van Rysselberghe)signed with the monogram and dated '02' (lower right)coloured crayons on paper31 7/8 x 17½ (81 x 44.5cm)Executed in 1902\n",
      "\n",
      "RENE MAGRITTE (1898-1967)La voix du sangsigned ‘Magritte’ (lower right)oil on canvas31 1/8 x 23 1/8 in. (79.1 x 58.6 cm.)Painted in 1948\n",
      "\n",
      "ENTOURAGE DE JACOB JORDAENS (1593-1678)Adoration des bergersinscrit 'J. Jordans. Fe' (en bas au centre)pierre noire, sanguine, plume et encre brune, lavis brun et bleu, traces de filigrane286 x 189 mm. (11¼ x 7 3/8 in.)\n",
      "\n",
      "JACOB JORDAENS (ANVERS 1593-1678)L’Économe infidèle face aux débiteurs de son maître (?)inscrit ‘Den on[rechtvaar]digen Rentmeester/ 16[…]’ (en bas au centre) ; avec signature ‘Jordaens’ (en bas à gauche)pierre noire, sanguine, plume et encre brune, lavis brun et lavis de sanguine, rehaussé de blanc, des bandes de papier ajoutées le long des bords droit, gauche et supérieur par l'artiste24,4 x 25,7 cm (9 1/2 x 10 1/8 in.)\n",
      "\n",
      "Paul Delvaux (1887-1994)La ville des sablessigned and dated 'P.Delvaux 1-77' (lower right); signed and titled 'P. Delvaux. La ville des sables' (on the stretcher)oil on canvas59 x 102¼ in. (149.8 x 259.8 cm.)Painted in January 1977\n",
      "\n",
      "Paul Delvaux (1897-1994)Les filles de la forêtsigned and dated 'PDelvaux 11-28' (lower right)oil on canvas31½ x 39½ in. (80.3 x 100.3 cm.)Painted in November 1928\n",
      "\n",
      "Theo van Rysselberghe (Belgian, 1862-1926)Dario de Regoyos en facesigned and inscribed 'Theo van Rysselberghe/au Camarade Dario de Regoyos' (upper left)oil on panel26.5 x 36 cm.Executed circa 1882.\n",
      "\n",
      "SIR ANTHONY VAN DYCK (ANTWERP 1599-1641 LONDON)Portrait of a Carmelite monk, head and shouldersoil on panel, the reverse marked with the brand of the Antwerp panel-makers' Guild and the maker's mark of Peter de Noble24 5⁄8 x 18 7⁄8 in. (62.6 x 48 cm.)\n",
      "\n",
      "Jan Breughel II (Antwerp 1601-1678)Abundance and the Four Elementsoil on oak panel, with the original gessoed reverse25¾ x 37½ in. (65.5 x 95 cm.), including additions of ½ in. on all sides\n",
      "\n",
      "SIR ANTHONY VAN DYCK (ANTWERP 1599-1641 LONDON)Portrait of Queen Henrietta Maria, three-quarter-length, in a gold gownoil on canvas40 1/2 x 33 in. (102.9 x 83.9 cm.)\n",
      "\n",
      "Jan Breughel, the Younger (Antwerp 1601-1678)Paradiseoil on canvas22 3/8 x 33 ½ in. (56.7 x 85.1 cm.)\n",
      "\n",
      "ATTRIBUTED TO JAN BREUGHEL, THE ELDER (BRUSSELS 1568-1625 ANTWERP)A landing stage near a village with shipping and figuressigned and dated 'BRVEGHEL 160[0?]' (lower left)oil on copper10¼ x 14 1/8 in. (26 x 36 cm.)\n",
      "\n",
      "ADRIAEN VAN STALBEMT (ANVERS 1580-1662)Le Paradis terrestre avec la Création d'Adam et Eve et la Tentationhuile sur panneau59 x 94,2 cm.\n",
      "\n",
      "Jan Brueghel II Antwerp 1601-1678A river landscape with a ferry crossing near a windmill, a village beyondinscribed, 'Iean Brueghel Artem arte compensa' (lower right)oil on panel17 x 26 1/8 in. 43.4 x 66.5 cm.\n",
      "\n",
      "Jan Breughel II Antwerp 1601-1678A view of the Scheldt with Antwerp beyondwith signature and date 'BRVEGEL. 1610' (lower left)oil on marouflaged panel14¼ x 24½ in. 36.2 x 62.2 cm.\n",
      "\n",
      "Paul Delvaux (1897-1994)Le rendez-vous d'Ephèsesigned and dated 'P. Delvaux 12-67' (lower right)oil on canvas62 7/8 x 63 in. (159.9 x 160 cm.)Painted in December 1967\n",
      "\n",
      "Joos de Momper II (Antwerp 1564-1635) and Jan Breughel II (Antwerp 1601-1678)An extensive mountainous landscape with figures on a path, a river valley beyondoil on panel18 x 29¾ in. (45.5 x 75.5 cm.)\n",
      "\n",
      "Jacob Jordaens and Studio* (1593-1678)The Flight into Egyptoil on canvas31 5/8 x 45½in. (80.3 x 115.5cm.)\n",
      "\n",
      "Paul Delvaux (1897-1994)Les sirènessigned, dated twice and inscribed ‘16-7-50 P. Delvaux 7.50 St Idesbald’ (lower right)watercolour, pen and India ink on paper30 x 43 3/4 in. (76.2 x 111.2 cm.)Executed in July 1950\n",
      "\n",
      "Paul Delvaux (1897-1994)Le village des sirènessigned and dated 'P. DELVAUX 4-42' (lower right); titled 'LE VILLAGE DES SIRÈNES' (on the reverse)oil on panel41 3/8 x 50 in. (105 x 127 cm.)Painted in 1942\n",
      "\n",
      "PAUL DELVAUX (1897-1994)Squelettesigned, dated and inscribed ‘P. DELVAUX ANDERLECHT 7-45’ (lower right)oil on canvas61 7/8 x 23 1/2 in. (157 x 59.7 cm.)Painted in Anderlecht in July 1945\n",
      "\n",
      "Théo van Rysselberghe (1862-1926)Les pivoines blanchessigned with the monogram (centre right); inscribed 'Pivoines blanches' (on the stretcher)oil on canvas42 1/8 x 35 3/8 in. (107 x 90 cm.)Painted in 1913-1914\n",
      "\n",
      "Theo van Rysselberghe (1862-1926)Autoportraitstamped with the artist's monogram (lower right)black crayon and charcoal on paper22¼ x 16¾ in. (56.7 x 42.5 cm.)Drawn in 1916\n",
      "\n",
      "PAUL DELVAUX (1897-1994)Rosinesigned and dated 'P. DELVAUX ST. IDESBALD. 9-68.' (lower right); signed, titled and inscribed 'ROSINE. P. DELVAUX. 34A AV. DES CAMPANULES. BRUXELLES 17 (WAT. BOITSFORT)' (on the stretcher)oil on canvas63 1/8 x 55 1/4 in. (160 x 140.4 cm.)Painted in Saint-Idesbald in September 1968\n",
      "\n",
      "James Ensor (1860-1949)Le Diable au Moulin (The Devil at the Windmill) (D., Cr., T. 133; E. 140)soft-ground etching, 1934, on Arches laid paper, with wide margins, in very good conditionP. 147 x 192 mm., S. 224 x 283 mm.\n",
      "\n",
      "RENÉ MAGRITTE (1898-1967)La découverte du feusigned ‘Magritte’ (lower right); signed again and titled ‘”La découverte du feu” Magritte’ (on the reverse)oil on panel8 ¾ x 6 3/8 in. (22.2 x 16.1 cm.)Painted in 1936\n",
      "\n",
      "Paul Delvaux (1897-1994)Jeune fillesigned and dated 'P.Delvaux 1976' (lower right)oil, watercolour, pen and ink on panel35 5/8 x 25¼ in. (90.5 x 64.2 cm)Painted in 1976\n",
      "\n",
      "JACOB JORDAENS (ANVERS 1593-1678) OU ATELIERLe Christ chassant les marchands du Templegraphite, sanguine, aquarelle et gouache, sur papier beige25,6 x 41,4 cm.\n",
      "\n",
      "Paul Delvaux (1897-1994)Squelettesigned, dated and inscribed 'P. Delvaux 25-3-44 Musée d'Histoire Naturelle' (lower right)mixed media on board31 5/8 x 21 5/8 in. (80.3 x 55 cm.)Executed in March 1944\n",
      "\n",
      "James Ensor (1860-1949)Le Combat (The Combat) (D., Cr., T. 107; E. 109)etching, 1896, on simili-Japan paper, signed and dated in pencil, countersigned and titled in pencil verso, with wide margins, remains of old tape verso faintly showing through recto, otherwise in very good conditionP. 120 x 86 mm., S. 295 x 238 mm.\n",
      "\n",
      "James Ensor (1860-1949)Les Chaloupes (Fishing Boats) (D., Cr., T., E. 44)etching, 1888, on wove paper, a rare impression of the first state (of two), but with levelled plate edges, signed, dated and titled in pencil, a deckle edge below, with wide margins, the upper sheet corners verso glued to the mount, otherwise in very good conditionP. 180 x 237 mm., S. 253 x 326 mm.\n",
      "\n",
      "PIERRE ALECHINSKY (B. 1927)Une question d'habitudesigned, inscribed and dated 'Alechinsky 1962 III' (lower right)oil on canvas53 1/8 x 49 ½ in. (134.9 x 125.7 cm.)Painted in 1962.\n",
      "\n",
      "Paul Delvaux (1897-1994)La fin du voyagesigned and dated 'P.DELVAUX 10-68' (lower right); signed, dated and titled 'LA FIN DU VOYAGE 1968 P. DELVAUX' (on the stretcher)oil on canvas63 x 55¼in. (160 x 140.2cm.)Painted in October 1968\n",
      "\n",
      "Jacob Jordaens (Antwerp 1593-1678)Saint Ives receiving supplicantsoil on paper laid down on canvas10 x 11 7/8 in. (25.4 x 30.1 cm.)\n",
      "\n",
      "FÉLICIEN ROPS (NAMUR 1833-1898 CORBEIL-ESSONNES)Femme assise de profil à l'éventailgraphite, fusain, estompe, trace de filigrane fragmentaire, sur papier beige22,5 x 16 cm (8 7/8 x 6 ¼ in.)\n",
      "\n",
      "Rene Magritte (1898-1967)Stimulation objectivesigned 'Magritte' (upper right)gouache on paper18 1/8 x 14 ¼ in. (46 x 36.2 cm.)Painted circa 1938-1939\n",
      "\n",
      "Paul Delvaux (1897-1994)Les promeneusessigned and dated 'P. DELVAUX 4-47' (lower right)oil on panel511/8 x 707/8in. (130 x 180cm.)Painted in April 1947\n",
      "\n",
      "Paul Delvaux (1897-1994)Douce nuitsigned and dated 'P.DELVAUX 4-62' (lower right)oil on canvas51.1/8 x 72 in. (130 x 185 cm.)Painted in April, 1962\n",
      "\n",
      "Théo van Rysselberghe (1862-1926)La Fontaineporte le monogramme (en bas à gauche)huile sur toile65.2 x 81.2 cm.Peint vers 1917-22bears the monogram (lower left)oil on canvas25 ½ x 31 7/8 in.Painted circa 1917-22\n",
      "\n",
      "Théo van Rysselberghe (1862-1926)Plage à marée basse, soirsigned with the monogram and dated '1900' (lower right)oil on canvas21 ½ x 25 5/8 in. (54.6 x 65.1 cm.)Painted in 1900\n",
      "\n",
      "Théo van Rysselberghe (1862-1926)Le canal en Flandre par temps tristesigned with the artist's monogram and dated '1894' (lower left)oil on canvas23¾ x 31½ in. (60 x 80 cm.)Painted in 1894\n",
      "\n",
      "Paul Delvaux (1897-1994)Nu allongésigned 'P. DELVAUX' (lower right)pen and ink and wash on paper23½ x 31¾in. (60 x 80.7cm.)\n",
      "\n",
      "Théo van Rysselberghe (1862-1926)Portrait de Jean Kellersigned with monogram and dated '1908' (upper left)oil on canvas55 7/8 x 34 1/8 in. (142 x 86.6 cm.)Painted in 1908\n",
      "\n",
      "Théo van Rysselberghe (1862-1926)Maria et Elisabeth van Rysselberghe tricotant au jardinoil on canvas31 7/8 x 32 in. (81 x 81.3 cm.)Painted circa 1912\n",
      "\n",
      "Théo van Rysselberghe (1862-1926)Champ de course à Boulogne-sur-Mersigned with the monogram and dated ‘1900’ (lower left)oil on canvas23 x 30 1/4 in. (58.5 x 76.8 cm.)Painted in 1900\n",
      "\n",
      "SIR PETER PAUL RUBENS (SIEGEN 1577-1640 ANVERS)Étude d’homme agenouillé vu de profilpierre noire, rehaussé de blanc sur papier vélin40,6 x 29,1 cm (15 x 11 1/2 in.)\n",
      "\n",
      "ANTOON VAN DYCK (ANVERS 1599-1641 LONDRES)Le Christ portant la Croixplume et encre brune, lavis brun rehaussé de blanc200 x 160 mm. (7 7/8 x 6¼ in.)\n",
      "\n",
      "Paul Delvaux (1897-1994)Les courtisanes d'Alexandriesigned, dated and titled 'LES COURTISANES D'ALEXANDRIE P. DELVAUX St. IDESBALD 11-10-49' (lower right)watercolour and pen and india ink on paper29 x 43¼in. (73.6 x 109.8cm.)Executed on 11 October 1949\n",
      "\n",
      "Follower of Anthony Van DyckThe Betrayal of Christwith number '41'black chalk, pen and brown ink, brown wash, heightened with white and with touches of oil paint, on paper19 x 16 in. (48.3 x 40.6 cm.)\n",
      "\n",
      "THEO VAN RYSSELBERGHE (1862-1926)Vase de fleurssigné du monogramme et daté '19 VR 23' (en bas à droite)huile sur toile46.2 x 55.2 cm. (18 1/8 x 21¾ in.)Peint en 1923\n",
      "\n",
      "Théo van Rysselberghe (1862-1926)A l'ombre du buissonsigned with the artist's monogram and dated '1920' (lower right)oil on canvas39 3/8 x 31 7/8 in. (100 x 81 cm.)Painted in 1920\n",
      "\n",
      "Jacob Jordaens (Antwerp 1593-1678)The Battle of the Centaurs and the Lapithsoil on canvas30 ½ x 41 ¾ in. (77.5 x 106 cm.)\n",
      "\n",
      "Théo van Rysselberghe (1862-1926)Près des rocs de Per-Kiridec à Roscoffindistinctly signed with monogram and dated '89' (lower right)oil on canvas12 ½ x 15 7/8 in. (31.8 x 40.4 cm.)Painted in October 1889\n",
      "\n",
      "Theo van Rysselberghe (1862-1926)Villas vues à travers les eucalyptus, La Mortolabears monogramoil on canvas33 3/8 x 33 3/4 in. (85 x 85.8 cm.)Painted circa 1919-1921\n",
      "\n",
      "Circle of Jan Breughel II (Antwerp 1601-1678)The Descent into Helloil on copper17.9 x 25.6 cm.\n",
      "\n",
      "CIRCLE OF SIR ANTHONY VAN DYCK (ANTWERP 1599-1641 LONDON)The Adoration of the Shepherdsoil on panel17 x 11 1/8 in. (43.1 x 28.2 cm.)\n",
      "\n",
      "ÉCOLE FLAMANDE DU XVIIIÈME SIÈCLE, D'APRÈS ADRIAEN VAN UTRECHT ET JACOB JORDAENSLa maréehuile sur toile179,7 x 237 cm. (70 ¾ x 93 3/8 in.)\n",
      "\n",
      "Sir Anthony van Dyck (Antwerp 1599-1641 London)Portrait of Hendrick Liberti (c. 1600-1669), half-length, in black, with three gold chains, holding a sheet of music, by a columnoil on canvas45 x 34¾ in. (114.3 x 88.3 cm.)\n",
      "\n",
      "Follower of Sir Anthony van DyckPortrait of a lady, traditionally identified as Henrietta Maria, Queen Consort of England, Scotland and Ireland (1609-1669), bust-length, in a pink silk dress with a brown fur stoleoil on panel15½ x 12¼ in. (39.5 x 31 cm.)\n",
      "\n",
      "Jan Breughel II (Antwerp 1601-1678)The story of Adam and Eve: The Creation of Adam; Adam Naming the Animals; The Temptation of Adam; The Expulsion from Paradise; Adam at Work in the Field; and The Death of Abelall signed 'J. Breughel' (lower left or lower right)oil on copper inset into wooden supportseach approximately 26¼ x 33¼ in. (66.6 x 84.5 cm)a set of six (6)\n",
      "\n",
      "Circle of Anthony van Dyck (Antwerp 1599-1641 London)The Mystic Marriage of Saint Rosalia with other saintsoil on panel64.9 x 49.6 cm.\n",
      "\n",
      "Follower of Sir Anthony van DyckPortrait of a gentleman, traditionally identified as Sir Peter Paul Rubens, in a painted ovaloil on canvas26 x 19¾ in. (66 x 50.2 cm.)\n",
      "\n",
      "Eugène Joseph Verboeckhoven (Warneton 1798-1881 Schaarbeek)Et in Arcadia Egosigned with initials (lower left)black and white chalk on coloured paper248 x 304 mm.\n",
      "\n",
      "Eugène Joseph Verboeckhoven (Belgian, 1798-1881)Returning homesigned and dated 'Eugène Verboeckhoven Fe. 1866' (lower left), and further signed and dated (on the reverse)oil on panel16¾ x 28 in. (42.5 x 71.1 cm.)\n",
      "\n",
      "Marinus Adrianus Koekkoek (Dutch, 1807-1870) and Eugène Verboeckhoven (Belgian, 1798-1881)A panoramic river landscape with cattle near a bridgesigned, dated and inscribed 'MA Koekkoek.1856/E: Verboeckhoven. figuren' (lower left)oil on canvas75 x 102 cm.\n",
      "\n",
      "Sir Anthony van Dyck Antwerp 1599-1641 LondonA bearded man, a studyoil on paper laid down on panel16¾ x 15 1/8 in. 42.5 x 38.3 cm.\n",
      "\n",
      "ATTRIBUTED TO JAN BREUGHEL, THE ELDER (BRUSSELS 1568-1625 ANTWERP)A landing stage near a village with shipping and figuressigned and dated 'BRVEGHEL 160[0?]' (lower left)oil on copper10¼ x 14 1/8 in. (26 x 36 cm.)\n",
      "\n",
      "Jacob Jordaens (Antwerp 1593-1678)The Holy Family with an angeloil on canvas34 7/8 x 30 3/8 in. (87.3 x 77.2 cm.)\n",
      "\n",
      "JACOB JORDAENS (ANTWERP 1593-1678)Head study of a crying girl, with a separate study of her mouthblack chalk, heightened with white14 x 11.5 cm (5 1/2 x 4 1/2 in.)\n",
      "\n",
      "Pierre Alechinsky (b. 1927)De Loinsigned 'Alechinsky' (lower right); signed again, dated and inscribed with title 'Alechinsky 1978 De Loin' (on the reverse)acrylic on paper laid down on canvas39¾ x 60½in. (100.5 x 154cm.)Painted in 1978\n",
      "\n",
      "Eugene Joseph Verboeckhoven (Belgian, 1798-1881)Sir Anthony van Dyck; and Peter Paul Rubens: a pair of equestrian portraitsboth signed and dated 'Eugène Verboeckhoven/ft 1850.' (lower left)oil on canvas82 x 65 cm.a pair (2)\n",
      "\n",
      "‘MONSU HABE’, POSSIBLY MAXIMILIEN L’ABBE (active Mechelen 1636-1661, died 1675)An Allegory of Warred chalk, pen and brown ink, brown wash, heightened with white-yellow, on various pieces of irregularly cut paper glued together9¼ x 14½ in. (23.6 x 36.9 cm.)\n",
      "\n",
      "Jacob Jordaens (Antwerp 1593-1678)The Satyr and the Peasantsigned 'JOR' (lower left, on the foot warmer)oil on canvas53 ¼ x 54 ¼ in. (135.2 x 137.7 cm.)\n",
      "\n",
      "JAMES ENSOR (1860-1949)Les Diables Dzitts et Hihanox conduisant le Christ aux Enfers (The Devils Dzitts and Hihanox leading Christ to Hell)etching and drypoint, 1895, on Japan paper, signed, dated and titled in pencil, countersigned in pencil on the reverse, with wide margins, probably the full sheet, in very good condition, framedPlate 138 x 177 mm.Sheet 232 x 292 mm.\n",
      "\n",
      "René Magritte (1898-1967)Hommage à Shakespearesigned 'Magritte' (upper left)gouache on paper13 3/8 x 10 5/8 in. (34 x 27 cm.)Painted in September 1963\n",
      "\n",
      "Circle of Jan Breughel the Elder (Brussels 1568-1625 Antwerp)The Month of July: an extensive wooded landscape with haymakers in a meadow and travellers on a path in the foregroundindistinctly inscribed 'muius [?]' and 'julius [?]'black chalk, pen and brown ink, watercolour, heightened with touches of bodycolour, with inserted section at upper right5¾ x 8 in. (14.6 x 20.2 cm.)\n",
      "\n",
      "Circle of Jan Breughel the Elder (Brussels 1568-1625 Antwerp)A hilly wooded landscape with a windmill, a wagon and peasants in the foreground, a village beyondwith inscription 'Br 1612' on the crosspen and black ink, bodycolor, pen and brown ink framing lines, countermark IV5½ x 9 in. (140 x 228 mm.)\n",
      "\n",
      "ATTRIBUTED TO JAN BREUGHEL THE ELDER (BRUSSELS 1568-1625 ANTWERP)The Last Judgmentoil on copper, unframed10 3⁄4 x 14 1⁄2 in. (27.4 x 36.5 cm.)with the panel maker's mark of Pieter Staas (centre, to the reverse)\n",
      "\n",
      "Jan Breughel, the Elder (Brussels 1568-1625 Antwerp)Lilies, tulips, roses and other flowers in an ornamental vase on a ledge, with butterflies and beetlesoil on panel41 ¾ x 28 5/8 in. (106.1 x 72.7 cm.)\n",
      "\n",
      "Jan Breughel I (Brussels 1568-1625 Antwerp)A wooded landscape with travelers on a pathoil on panel17 7/8 x 35 in. (45.5 x 89 cm.)\n",
      "\n",
      "Jacob Jordaens (1593-1678)A woman with deep decolletage, turning to the leftblack, red and white chalk, on light brown paper, brown ink framing lines202 x 165 mm.\n",
      "\n",
      "Jacob Jordaens (1593-1678)The Incredulity of Saint Thomaswith inscription 'Jordans.'black chalk, pen and brown ink, brown wash, brown ink framing lines166 x 322 mm.\n",
      "\n",
      "Attributed to Henry Stone, called 'Old Stone' (London 1616-1653) after Sir Anthony van DyckPortrait of Montagu Bertie, Lord Willoughby, 2nd Earl of Lindsey (c.1608-1666), Colonel of the Regiment of Guards, full-length, in a buff jerkin with a breastplate and gold-embroidered red britcheswith identifying inscription and date 'Montague Lord Willoughby Colonel of the / Regiment of guard son to Robert Earl of / Lindsey Lo. Great Chamberlain of / England. / Aetat: 31.1639' (lower left)oil on canvas81 ¾ x 51 5/8 in. (207.5 x 131 cm.)in a gilt and composition pounced frame\n",
      "\n",
      "Studio of Sir Anthony van Dyck (Antwerp 1599-1641 London)Study of a head and handoil on canvas12¼ x 14 3/8 in. (31.2 x 36.5 cm.)\n",
      "\n",
      "Circle of Sir Anthony van Dyck (Antwerp 1599-1641 London)Portrait of Mrs. Thomas Carey (d. 1678), later Lady Herbert, full-length, in a white satin dress, with gold embroidery, by a column with a draped curtain, a park landscape beyondoil on canvas85½ x 47¼ in. (217.3 x 120 cm.)\n",
      "\n",
      "Follower of Sir Anthony van DyckPortrait of James, 3rd Marquess and later 1st Duke of Hamilton (1606-1649), three-quarter-length, in armour, with the Order of the Garter, holding a baton of command, his left hand resting on his helmet on a red draped table, in a rocky landscape, his groom and horse beyondoil on canvas52¼ x 42¼ in. (132.6 x 107.4 cm.)\n",
      "\n",
      "After Sir Anthony van DyckPortrait of the artist, three-quarter-length, in a brown jacket and black cloak, leaning against a ledgeoil on canvas, unlined55 7/8 x 43 in. (141.9 x 109.2 cm.)\n",
      "\n",
      "Studio of Sir Anthony van Dyck (Antwerp 1599-1641 London)Portrait of Ambrogio Spinola (1569-1630), full-length, in armour, wearing the Order of the Golden Fleece, holding a baton in his right hand, his left hand resting on the hilt of his swordoil on canvas87 1/8 x 49¾ in. (221 x 126.4 cm.)\n",
      "\n",
      "Follower of Sir Anthony van DyckPortrait of a boy, traditionally identified as Charles, Prince of Wales, later King Charles II (1660-1685), three-quarter-lengthoil on canvas39 x 30 in. (99.1 x 76.2 cm.)inscribed and dated 'ÆTATIS.SVÆ. I2. / ANNO 1641.' (upper left)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print for the medium and surface\n",
    "for i in range(200,300):\n",
    "    print(df['details'][i])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3822c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lists for each category of medium\n",
    "# we made this manuel by looking at the first 100 paintings and taking these values and put them in these categories\n",
    "\n",
    "oil_based_paintings = [\n",
    "    'huile',\n",
    "    'oil'\n",
    "]\n",
    "\n",
    "pen_and_ink_drawings = [\n",
    "    'pencil',\n",
    "    'ballpoint',\n",
    "    'pen',\n",
    "    'India ink',\n",
    "    'crayons',\n",
    "    'encre',\n",
    "    'fusain',\n",
    "    'coal',\n",
    "    'pastel',\n",
    "    'graphite',\n",
    "    'charcoal'\n",
    "]\n",
    "\n",
    "acrylic = [\n",
    "    'acrylic'\n",
    "    'acrylic paint',\n",
    "    'acrylic medium',\n",
    "    'gesso',\n",
    "    'palette knife',\n",
    "    'pouring medium',\n",
    "    'impasto gel',\n",
    "    'fluid acrylics'\n",
    "]\n",
    "\n",
    "watercolour_art = [\n",
    "    'watercolour',\n",
    "    'wash',\n",
    "    'watercolor',\n",
    "    'gouache',\n",
    "    'aquarelle',\n",
    "    'tempera',\n",
    "    'casein',\n",
    "    'Chinese watercolor',\n",
    "    'Japanese watercolor',\n",
    "    'ink wash',\n",
    "    'bodycolor',\n",
    "    'poster color'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c686c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to categorize the 'medium' with partial matches\n",
    "def categorize_medium(details):\n",
    "    details_lower = details.lower()  # Convert to lowercase for case-insensitive matching\n",
    "    for category, category_list in zip(['Oil-Based Paintings','Pen and Ink Drawings', 'acrylic', 'Watercolour Art'],\n",
    "                                      [oil_based_paintings, pen_and_ink_drawings, acrylic, watercolour_art ]):\n",
    "        for keyword in category_list:\n",
    "            if keyword.lower() in details_lower or details_lower in keyword.lower():\n",
    "                return category\n",
    "    return 'missing'\n",
    "\n",
    "# Apply the function to create the 'medium' column\n",
    "df['medium'] = df['details'].apply(categorize_medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9275cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medium\n",
      "Oil-Based Paintings     411\n",
      "Pen and Ink Drawings    251\n",
      "missing                  85\n",
      "Watercolour Art          64\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# watching the different values of medium\n",
    "medium_counts = df['medium'].value_counts()\n",
    "print(medium_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dceb6c",
   "metadata": {},
   "source": [
    "###### surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e2a5112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lists for each category of surface\n",
    "# we made this manuel by looking at the first 100 paintings and taking these values and put them in these categories\n",
    "\n",
    "canvas = [\n",
    "    'canvas',\n",
    "    'toile',\n",
    "    'map',\n",
    "    'linen',\n",
    "    'canvas board'\n",
    "]\n",
    "\n",
    "paper = [\n",
    "    'paper',\n",
    "    'papier',\n",
    "    'card',\n",
    "    'simili-japan',\n",
    "    'carton',\n",
    "    'cartonpapier',\n",
    "    'vellum',\n",
    "    'newsprint',\n",
    "    'canvas paper'\n",
    "]\n",
    "\n",
    "other = [\n",
    "    'wood',\n",
    "    'panel', \n",
    "    'glass',\n",
    "    'copper',\n",
    "    'metal',\n",
    "    'masonite',\n",
    "    'hardboard',\n",
    "    'plywood',\n",
    "    'paperboard',\n",
    "    'leather',\n",
    "    'fabric'    \n",
    "]\n",
    "# other is for all the others such as wood, ... as a surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6ac5179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_surface(details):\n",
    "    details_lower = details.lower()  # Convert to lowercase for case-insensitive matching\n",
    "    for category, category_list in zip(['canvas','paper','other'],\n",
    "                                      [canvas, paper, other]):\n",
    "        for keyword in category_list:\n",
    "            if keyword.lower() in details_lower or details_lower in keyword.lower():\n",
    "                return category\n",
    "    return 'missing'\n",
    "\n",
    "# Apply the function to create the 'medium' column\n",
    "df['surface'] = df['details'].apply(categorize_surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9ebd2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surface\n",
      "canvas     301\n",
      "paper      292\n",
      "other      114\n",
      "missing    104\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# watching the different values of medium\n",
    "surface_counts = df['surface'].value_counts()\n",
    "print(surface_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8785a2c0",
   "metadata": {},
   "source": [
    "understand what each city is, because some are latin for me x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32939e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dominantcolor_hex --> '#RRGGBB' and we are going to split it to red, green and blue\n",
    "# Convert the hexadecimal strings to integers for each color component\n",
    "df['red_hex'] = df['dominant_color_hex'].apply(lambda x: int(x[1:3], 16) if pd.notnull(x) else None)\n",
    "df['green_hex'] = df['dominant_color_hex'].apply(lambda x: int(x[3:5], 16) if pd.notnull(x) else None)\n",
    "df['blue_hex'] = df['dominant_color_hex'].apply(lambda x: int(x[5:7], 16) if pd.notnull(x) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6efbbac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>artist</th>\n",
       "      <th>img_name</th>\n",
       "      <th>collection</th>\n",
       "      <th>title</th>\n",
       "      <th>details</th>\n",
       "      <th>provenance</th>\n",
       "      <th>exhibit</th>\n",
       "      <th>further_details</th>\n",
       "      <th>...</th>\n",
       "      <th>w</th>\n",
       "      <th>area</th>\n",
       "      <th>circumference</th>\n",
       "      <th>year_painted_temp</th>\n",
       "      <th>year_painted</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>red_hex</th>\n",
       "      <th>green_hex</th>\n",
       "      <th>blue_hex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182</td>\n",
       "      <td>3912</td>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>2018_AMS_15910_0038_000(pierre_alechinsky_cach...</td>\n",
       "      <td>Pierre Alechinsky (b. 1927)</td>\n",
       "      <td>Cache-telé (Hidden Television)</td>\n",
       "      <td>Pierre Alechinsky (b. 1927)Cache-telé (Hidden ...</td>\n",
       "      <td>Fondation Maeght, Saint-Paul de Vence.Acquired...</td>\n",
       "      <td>Arezzo, Museo Civico d'Arte Moderna e Contempo...</td>\n",
       "      <td>Pierre Alechinsky has confirmed the authentici...</td>\n",
       "      <td>...</td>\n",
       "      <td>153.0</td>\n",
       "      <td>17595.00</td>\n",
       "      <td>536.0</td>\n",
       "      <td>1973</td>\n",
       "      <td>1973</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>87.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>523</td>\n",
       "      <td>5114</td>\n",
       "      <td>Theo Van Rysselberghe</td>\n",
       "      <td>2010_PAR_05609_0033_000(theo_van_rysselberghe_...</td>\n",
       "      <td>THEO VAN RYSSELBERGHE (1862-1926)</td>\n",
       "      <td>Jeune dame lisant</td>\n",
       "      <td>THEO VAN RYSSELBERGHE (1862-1926)Jeune dame li...</td>\n",
       "      <td>Galerie Willy D'Huysser, Bruxelles.Acquis aupr...</td>\n",
       "      <td>Bruxelles, Palais des Beaux-Arts et La Haye, G...</td>\n",
       "      <td>'YOUNG LADY READING'; SIGNED LOWER RIGHT; OIL ...</td>\n",
       "      <td>...</td>\n",
       "      <td>54.3</td>\n",
       "      <td>3665.25</td>\n",
       "      <td>243.6</td>\n",
       "      <td>1887</td>\n",
       "      <td>1887</td>\n",
       "      <td>Oil-Based Paintings</td>\n",
       "      <td>canvas</td>\n",
       "      <td>144.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                 artist  \\\n",
       "0         182   3912      Pierre Alechinsky   \n",
       "1         523   5114  Theo Van Rysselberghe   \n",
       "\n",
       "                                            img_name  \\\n",
       "0  2018_AMS_15910_0038_000(pierre_alechinsky_cach...   \n",
       "1  2010_PAR_05609_0033_000(theo_van_rysselberghe_...   \n",
       "\n",
       "                          collection                           title  \\\n",
       "0        Pierre Alechinsky (b. 1927)  Cache-telé (Hidden Television)   \n",
       "1  THEO VAN RYSSELBERGHE (1862-1926)               Jeune dame lisant   \n",
       "\n",
       "                                             details  \\\n",
       "0  Pierre Alechinsky (b. 1927)Cache-telé (Hidden ...   \n",
       "1  THEO VAN RYSSELBERGHE (1862-1926)Jeune dame li...   \n",
       "\n",
       "                                          provenance  \\\n",
       "0  Fondation Maeght, Saint-Paul de Vence.Acquired...   \n",
       "1  Galerie Willy D'Huysser, Bruxelles.Acquis aupr...   \n",
       "\n",
       "                                             exhibit  \\\n",
       "0  Arezzo, Museo Civico d'Arte Moderna e Contempo...   \n",
       "1  Bruxelles, Palais des Beaux-Arts et La Haye, G...   \n",
       "\n",
       "                                     further_details  ...      w      area  \\\n",
       "0  Pierre Alechinsky has confirmed the authentici...  ...  153.0  17595.00   \n",
       "1  'YOUNG LADY READING'; SIGNED LOWER RIGHT; OIL ...  ...   54.3   3665.25   \n",
       "\n",
       "  circumference  year_painted_temp  year_painted               medium  \\\n",
       "0         536.0               1973          1973              missing   \n",
       "1         243.6               1887          1887  Oil-Based Paintings   \n",
       "\n",
       "   surface red_hex  green_hex  blue_hex  \n",
       "0   canvas    87.0      109.0     103.0  \n",
       "1   canvas   144.0      131.0     125.0  \n",
       "\n",
       "[2 rows x 47 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5da994a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pierre Alechinsky' 'Theo Van Rysselberghe' 'Jan Breughel the elder'\n",
      " 'Rene Magritte' 'Anthony Van Dyck' 'Paul Delvaux' 'James Ensor'\n",
      " 'Jan Breughel the younger' 'Jacob Jordaens' 'Felicien Rops'\n",
      " 'Eugene Verboeckhoven']\n"
     ]
    }
   ],
   "source": [
    "# adding the artists year of birth and if they are dead yes or no\n",
    "unique_artists = df['artist'].unique()\n",
    "print(unique_artists)\n",
    "# Creating a DataFrame with 'artist' column\n",
    "df_y = pd.DataFrame(unique_artists, columns=['artist'])\n",
    "\n",
    "# Adding columns 'year_born' and 'dead' with manuallu\n",
    "df_y['year_born'] = [1927, 1862, 1568, 1898, 1599, 1897, 1860, 1601, 1593, 1833, 1798] \n",
    "df_y['dead'] = [False, True, True, True, True, True, True, True, True, True, True,]  \n",
    "\n",
    "# merging of the 2 dataframe that the data corespondents \n",
    "df = pd.merge(df, df_y[['artist', 'year_born', 'dead']], on='artist', how='left')\n",
    "\n",
    "# we only took the year of birth because if we would have taken death as well, these two would correlate. the feature dead (Yes or No) does not do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f673726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Theo Van Rysselberghe</td>\n",
       "      <td>1862</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jan Breughel the elder</td>\n",
       "      <td>1568</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rene Magritte</td>\n",
       "      <td>1898</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anthony Van Dyck</td>\n",
       "      <td>1599</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Paul Delvaux</td>\n",
       "      <td>1897</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>James Ensor</td>\n",
       "      <td>1860</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jan Breughel the younger</td>\n",
       "      <td>1601</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jacob Jordaens</td>\n",
       "      <td>1593</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Felicien Rops</td>\n",
       "      <td>1833</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Eugene Verboeckhoven</td>\n",
       "      <td>1798</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      artist  year_born   dead\n",
       "0          Pierre Alechinsky       1927  False\n",
       "1      Theo Van Rysselberghe       1862   True\n",
       "2     Jan Breughel the elder       1568   True\n",
       "3              Rene Magritte       1898   True\n",
       "4           Anthony Van Dyck       1599   True\n",
       "5               Paul Delvaux       1897   True\n",
       "6                James Ensor       1860   True\n",
       "7   Jan Breughel the younger       1601   True\n",
       "8             Jacob Jordaens       1593   True\n",
       "9              Felicien Rops       1833   True\n",
       "10      Eugene Verboeckhoven       1798   True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5b36ccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The title of the most expensive painting is: La voix du sang, 23596150.45\n",
      "The title of the least expensive painting is: 'Abbe Scaglia', 75.32\n",
      "The title of the biggest painting circumferencewise is: Mur d'oiseaux, 980.0\n",
      "The title of the biggest painting areawise is: Mur d'oiseaux, 57000.0\n"
     ]
    }
   ],
   "source": [
    "# looking for the most expensive and least expensive paintings\n",
    "max_price_index = df['price_EUR'].idxmax()\n",
    "min_price_index = df['price_EUR'].idxmin()\n",
    "most_expensive_painting_title = df.loc[max_price_index, 'title']\n",
    "least_expensive_painting_title = df.loc[min_price_index, 'title']\n",
    "print(f\"The title of the most expensive painting is: {most_expensive_painting_title}, {df.loc[max_price_index, 'price_EUR']}\")\n",
    "print(f\"The title of the least expensive painting is: {least_expensive_painting_title}, {df.loc[min_price_index, 'price_EUR']}\")\n",
    "\n",
    "# looking for the biggest painting\n",
    "biggest_painting_circum_index = df['circumference'].idxmax()\n",
    "biggest_painting_area_index = df['area'].idxmax()\n",
    "largest_painting_title = df.loc[biggest_painting_circum_index, 'title']\n",
    "biggest_painting_title = df.loc[biggest_painting_area_index, 'title']\n",
    "print(f\"The title of the biggest painting circumferencewise is: {largest_painting_title}, {df.loc[biggest_painting_circum_index, 'circumference']}\")\n",
    "print(f\"The title of the biggest painting areawise is: {biggest_painting_title}, {df.loc[biggest_painting_area_index, 'area']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce183b5b",
   "metadata": {},
   "source": [
    "###### dropping the columns with no meaninfull value ( splitted, too few, no variance, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bff89679",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dropping some columns \n",
    "    # due to splitting\n",
    "    # too few values\n",
    "    # no meaninfull value\n",
    "\n",
    "df.drop(['Unnamed: 0','index','img_name','collection','details','provenance','exhibit','further_details','price_realized',\n",
    "         'estimated_price','year_string','year_temp','exchange_rate','heigth','width','dominant_color_hex','hue','price','low_estimate',\n",
    "         'high_estimate','average_estimate','dimension','unit_of_length','l','w','year_painted_temp','average_estimate_EUR','low_estimate_EUR','high_estimate_EUR'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e9f04",
   "metadata": {},
   "source": [
    "# made all the columns ready after splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742f6291",
   "metadata": {},
   "source": [
    "- How many data instances do you have? OK\n",
    "- Do you have duplicates? OK\n",
    "- How many features? What type are they? OK\n",
    "- If they are categorical, what categories they have, what is their frequency? OK \n",
    "- If they are numerical, what is their distribution?\n",
    "- What is the distribution of the target variable? \n",
    "- If you have a target, you can also check the relationship between the target and the variables.\n",
    "- Do you have missing data? If yes, how are you going to handle it? OK\n",
    "- Can you use the features in their original form, or do you need to alter them in some way? Price !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e733e776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contains 811 instances and 20 features.\n"
     ]
    }
   ],
   "source": [
    "# looking at the different features, their non-null count and datatype\n",
    "print(f\"The data contains {df.shape[0]} instances and {df.shape[1]} features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4136c305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows:  0\n"
     ]
    }
   ],
   "source": [
    "df.duplicated().sum()\n",
    "print(\"Number of duplicate rows: \", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "931d22c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It contains 20 features. \n",
      "\n",
      "These are the features and its types: \n",
      " artist            object\n",
      "title             object\n",
      "faces             object\n",
      "contrast         float64\n",
      "brightness       float64\n",
      "year_sold          Int64\n",
      "city_auction      object\n",
      "currency          object\n",
      "price_EUR        float64\n",
      "signed              bool\n",
      "area             float64\n",
      "circumference    float64\n",
      "year_painted      object\n",
      "medium            object\n",
      "surface           object\n",
      "red_hex          float64\n",
      "green_hex        float64\n",
      "blue_hex         float64\n",
      "year_born          int64\n",
      "dead                bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(f\"It contains {df.shape[1]} features. \\n\")\n",
    "print(\"These are the features and its types: \\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0361a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the values to the right type\n",
    "df['year_painted'] = pd.to_numeric(df['year_painted'], errors='coerce').astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c29cbb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>contrast</th>\n",
       "      <td>690.0</td>\n",
       "      <td>47.04</td>\n",
       "      <td>17.13</td>\n",
       "      <td>5.81</td>\n",
       "      <td>34.66</td>\n",
       "      <td>45.38</td>\n",
       "      <td>57.11</td>\n",
       "      <td>98.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brightness</th>\n",
       "      <td>690.0</td>\n",
       "      <td>135.42</td>\n",
       "      <td>47.7</td>\n",
       "      <td>27.01</td>\n",
       "      <td>97.1</td>\n",
       "      <td>137.28</td>\n",
       "      <td>171.23</td>\n",
       "      <td>243.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_sold</th>\n",
       "      <td>690.0</td>\n",
       "      <td>2011.54</td>\n",
       "      <td>7.27</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2017.75</td>\n",
       "      <td>2023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_EUR</th>\n",
       "      <td>811.0</td>\n",
       "      <td>654665.18</td>\n",
       "      <td>2340433.15</td>\n",
       "      <td>75.32</td>\n",
       "      <td>4488.99</td>\n",
       "      <td>23622.05</td>\n",
       "      <td>195584.34</td>\n",
       "      <td>23596150.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area</th>\n",
       "      <td>733.0</td>\n",
       "      <td>5134.5</td>\n",
       "      <td>7381.56</td>\n",
       "      <td>0.28</td>\n",
       "      <td>689.92</td>\n",
       "      <td>2475.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>57000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>circumference</th>\n",
       "      <td>733.0</td>\n",
       "      <td>238.39</td>\n",
       "      <td>169.26</td>\n",
       "      <td>29.04</td>\n",
       "      <td>106.0</td>\n",
       "      <td>202.2</td>\n",
       "      <td>320.0</td>\n",
       "      <td>980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_painted</th>\n",
       "      <td>532.0</td>\n",
       "      <td>1188.06</td>\n",
       "      <td>1483.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>1954.25</td>\n",
       "      <td>19671.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red_hex</th>\n",
       "      <td>690.0</td>\n",
       "      <td>143.59</td>\n",
       "      <td>49.91</td>\n",
       "      <td>29.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>184.75</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>green_hex</th>\n",
       "      <td>690.0</td>\n",
       "      <td>134.14</td>\n",
       "      <td>49.07</td>\n",
       "      <td>25.0</td>\n",
       "      <td>95.25</td>\n",
       "      <td>134.0</td>\n",
       "      <td>172.75</td>\n",
       "      <td>244.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue_hex</th>\n",
       "      <td>690.0</td>\n",
       "      <td>120.32</td>\n",
       "      <td>48.8</td>\n",
       "      <td>12.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_born</th>\n",
       "      <td>811.0</td>\n",
       "      <td>1813.58</td>\n",
       "      <td>129.11</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>1798.0</td>\n",
       "      <td>1862.0</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>1927.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count       mean         std     min      25%       50%  \\\n",
       "contrast       690.0      47.04       17.13    5.81    34.66     45.38   \n",
       "brightness     690.0     135.42        47.7   27.01     97.1    137.28   \n",
       "year_sold      690.0    2011.54        7.27  1994.0   2006.0    2013.0   \n",
       "price_EUR      811.0  654665.18  2340433.15   75.32  4488.99  23622.05   \n",
       "area           733.0     5134.5     7381.56    0.28   689.92    2475.0   \n",
       "circumference  733.0     238.39      169.26   29.04    106.0     202.2   \n",
       "year_painted   532.0    1188.06     1483.19     0.0      5.0    1906.0   \n",
       "red_hex        690.0     143.59       49.91    29.0    102.0     146.0   \n",
       "green_hex      690.0     134.14       49.07    25.0    95.25     134.0   \n",
       "blue_hex       690.0     120.32        48.8    12.0     83.0     121.0   \n",
       "year_born      811.0    1813.58      129.11  1568.0   1798.0    1862.0   \n",
       "\n",
       "                     75%          max  \n",
       "contrast           57.11         98.9  \n",
       "brightness        171.23       243.21  \n",
       "year_sold        2017.75       2023.0  \n",
       "price_EUR      195584.34  23596150.45  \n",
       "area              6000.0      57000.0  \n",
       "circumference      320.0        980.0  \n",
       "year_painted     1954.25      19671.0  \n",
       "red_hex           184.75        251.0  \n",
       "green_hex         172.75        244.0  \n",
       "blue_hex           156.0        239.0  \n",
       "year_born         1898.0       1927.0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cb049d9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'artist' is categorical with 11 categories;\n",
      "Column 'title' is categorical with 714 categories;\n",
      "Column 'faces' is categorical with 2 categories;\n",
      "Column 'city_auction' is categorical with 7 categories;\n",
      "Column 'currency' is categorical with 5 categories;\n",
      "Column 'medium' is categorical with 4 categories;\n",
      "Column 'surface' is categorical with 4 categories;\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:    \n",
    "    if df[column].dtype.name == 'object': \n",
    "        \n",
    "        categories = df[column].value_counts() \n",
    "\n",
    "        print(f\"Column '{column}' is categorical with {len(categories)} categories;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c264f94",
   "metadata": {},
   "source": [
    "### handling the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed41f29",
   "metadata": {},
   "source": [
    "When handling the missing values we need to look at the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c3913cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numerical_columns = df.select_dtypes(include=['float64','int64']).columns\n",
    "numerical_columns = numerical_columns[numerical_columns != 'price_EUR']\n",
    "df[numerical_columns].hist(bins=20, figsize=(15,10))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdf8d35",
   "metadata": {},
   "source": [
    "**brightness**\n",
    "\n",
    "brightness is only the second histogram, we put it first because it's a part of contrast so than it is easier to understand.\n",
    "This value ranges from 0 to 250 and the first represents complete darkness or black, all pixels are as dark as possible. An image with a brightness score of 255 has all pixels as bright or white as possible. As a consequence 127,5 represents a balanced or neutral brightness, and there's neither an overall brith nor dark bias. The brightness is normally distributed.\n",
    "\n",
    "**contrast**\n",
    "\n",
    "A contrast of 0 means that the entire painting has the same level o brightness and there are no discernible diffferences between light and dark areas. 100 Would suggest maximum contrast, where the brightest elemetns are at their brightest and the darkest elements are at their darkest.The transition between light and dark are sharp and abrupt.\n",
    "The distribution is slightly right skewed, which means that the noticeable difference between light and dark areas is a bit under 50.\n",
    "\n",
    "**year_sold**\n",
    "\n",
    "A quasi linear function is apparent. \n",
    "\n",
    "**area** **circumference**\n",
    "\n",
    "With a histogram like this, there is a big chance there will be outliers. Because of that, we need to double check if these outliers are due to a mistake in the data manipulation from 'details' to 'dimension' to 'length and width' to area and circumference. The chance a mistake or error happened is big due to the multiple manipulations. \n",
    "\n",
    "We checked the width and length who fell out of the 3times difference inter quartile. For these values we checked the dimensions manuel and they were all right. Therefore, we will not drop these!\n",
    "\n",
    "**year_painted**\n",
    "\n",
    "This should be a graph in between the born year of the oldest ( back in history ) and 2023. The values that are not in between these values are going to be filled in with nan and afterwards going to be valued due to born_year artist + 50 and then plus a random number of this interval[-20;20]. \n",
    "\n",
    "**red_hex** **green_hex** **blue_hex**\n",
    "\n",
    "Each hex ( red, green and blue_hex ) have an intensity value ranging from 0 to 255, where 0 represents the minimum intensity (no color) and 255 represents the maximum intensity (full color).\n",
    "We see for each hex that the distribution is rather normal, which relates to the results of brightness.\n",
    "\n",
    "**year_born**\n",
    "\n",
    "For this statistic, it is better to look at it for each artist instead of all paintings because now the artists who's frequency is higher dominate in this graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "55618be3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist             0\n",
      "title             52\n",
      "faces            121\n",
      "contrast         121\n",
      "brightness       121\n",
      "year_sold        121\n",
      "city_auction       0\n",
      "currency           0\n",
      "price_EUR          0\n",
      "signed             0\n",
      "area              78\n",
      "circumference     78\n",
      "year_painted     279\n",
      "medium             0\n",
      "surface            0\n",
      "red_hex          121\n",
      "green_hex        121\n",
      "blue_hex         121\n",
      "year_born          0\n",
      "dead               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c78c342",
   "metadata": {},
   "source": [
    "now we need to see what we have to do for the missing values!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6e6a4b",
   "metadata": {},
   "source": [
    "**for the visual features**\n",
    "\n",
    "pos\n",
    "+ the original data distribution is preserved for the imputed feature\n",
    "+ no wrong assumptions about the similarity of missing values to existing categories, which is almost impossible to do with visual characteristics\n",
    "\n",
    "neg\n",
    "- may introduce bias, \n",
    "- can impact the performance of some models, they can see the 'missing' category as a meaninful feature, affecting the performance\n",
    "- increased cardinaltiy -- higher cadrinaltiy can bechallenging for certain models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d5b90c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to put the visual characteristics to the mean of that feature for each individual artist\n",
    "# numerical features --> normal distributed and no outliers --> mean\n",
    "df['contrast'] = df.groupby('artist')['contrast'].transform(lambda x: x.fillna(x.mean()))\n",
    "df['brightness'] = df.groupby('artist')['brightness'].transform(lambda x: x.fillna(x.mean()))\n",
    "df['red_hex'] = df.groupby('artist')['red_hex'].transform(lambda x: x.fillna(x.mean()))\n",
    "df['green_hex'] = df.groupby('artist')['green_hex'].transform(lambda x: x.fillna(x.mean()))\n",
    "df['blue_hex'] = df.groupby('artist')['blue_hex'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# boolean feature --> no impact on outliers, simple, intuitive, did the same for the other categories\n",
    "#                     however, we will lose variability\n",
    "df['faces'] = df.groupby('artist')['faces'].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else df['faces'].mode()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97f6f51",
   "metadata": {},
   "source": [
    "#### for the other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a8dd0cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting 'missing' when the value of 'title' is nan\n",
    "df['title'].fillna('missing', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3ab7bb",
   "metadata": {},
   "source": [
    "for title\n",
    "\n",
    "pro\n",
    "+ preserves information about missingness\n",
    "+ easy to interpret, binary nature is straightforward to interpet, and its inclusion does not introduce additional categories\n",
    "\n",
    "cons\n",
    "- increased dimensionality\n",
    "- may be redundant for some models (weigerachtig), \n",
    "- may lead to interpretability challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f29a598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year_sold  frequency    weight\n",
      "0       2014         52  0.075362\n",
      "1       2022         41  0.059420\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# missing value of year_sold\n",
    "frequency = df['year_sold'].value_counts()\n",
    "weight_dict = dict(zip(frequency.index, frequency))\n",
    "result_df = pd.DataFrame(list(weight_dict.items()), columns=['year_sold', 'frequency'])\n",
    "result_df['weight'] = result_df['frequency'] / result_df['frequency'].sum()\n",
    "print(result_df.head(2))\n",
    "\n",
    "# function to fill NaN values in Year_sold based on the weight\n",
    "def fill_nan_based_on_weight(row):\n",
    "    if pd.isna(row['year_sold']):\n",
    "        return np.random.choice(result_df['year_sold'], p=result_df['weight'])\n",
    "    else:\n",
    "        return row['year_sold']\n",
    "\n",
    "df['year_sold'] = df.apply(fill_nan_based_on_weight, axis=1)\n",
    "print(df['year_sold'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c68fb9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# area and circumference --> because skewed we do the median of each artist\n",
    "df['area'] = df.groupby('artist')['area'].transform(lambda x: x.fillna(x.median()))\n",
    "df['circumference'] = df.groupby('artist')['circumference'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b3411516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# year painted --> we take a standardization of the last x years the artist lived an then random numbers\n",
    "# Define a function to fill missing values\n",
    "\n",
    "def fill_year_painted(row):\n",
    "    if np.isnan(row['year_painted']):\n",
    "        # Calculate the range based on 'year_born_x' + 50\n",
    "        lower_bound = row['year_born'] + 50 - 20\n",
    "        upper_bound = row['year_born'] + 50 + 20\n",
    "\n",
    "        # Generate a random number in the defined range\n",
    "        random_year = np.random.randint(lower_bound, upper_bound + 1)\n",
    "\n",
    "        return random_year\n",
    "    else:\n",
    "        return row['year_painted']\n",
    "\n",
    "# Apply the function to fill missing values in 'year_painted'\n",
    "df['year_painted'] = df.apply(fill_year_painted, axis=1)\n",
    "print(df['year_painted'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e2b4e61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist           0\n",
      "title            0\n",
      "faces            0\n",
      "contrast         0\n",
      "brightness       0\n",
      "year_sold        0\n",
      "city_auction     0\n",
      "currency         0\n",
      "price_EUR        0\n",
      "signed           0\n",
      "area             0\n",
      "circumference    0\n",
      "year_painted     0\n",
      "medium           0\n",
      "surface          0\n",
      "red_hex          0\n",
      "green_hex        0\n",
      "blue_hex         0\n",
      "year_born        0\n",
      "dead             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ef1b78",
   "metadata": {},
   "source": [
    "#### adding the column called 's&p500 return per year'\n",
    "\n",
    "we add this becausee is price is slightly correlated witht the financial market.\n",
    "\n",
    "due to the fact that their is a delay we take a delay of one year so we put for each respectively year_sold, the return of the year before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "47f60016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1994</td>\n",
       "      <td>0.0997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995</td>\n",
       "      <td>0.0133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  return_sp\n",
       "0  1994     0.0997\n",
       "1  1995     0.0133"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we are going to make a dataframe with a column year and a column with the value\n",
    "# making a dataframe for each year when it was sold\n",
    "unique_years = sorted(df['year_sold'].unique())\n",
    "return_sp500 = [0.0997,0.0133,0.2268,0.3310,0.2834,0.2089,-0.0903,-0.1185,-0.2197,0.2836,0.1074,0.0483,0.1561,0.0548,-0.3655,0.2594,0.1482,0.0210,0.1589,0.3215,0.1352,0.0138,0.1177,0.2161,-0.0423,0.3121,0.1802,0.2847,-0.1801,]\n",
    "\n",
    "# creating df\n",
    "df_sp = pd.DataFrame({\n",
    "    'year' : unique_years,\n",
    "    'return_sp' : return_sp500\n",
    "})\n",
    "\n",
    "df_sp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "000c1999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>faces</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>price_EUR</th>\n",
       "      <th>signed</th>\n",
       "      <th>...</th>\n",
       "      <th>circumference</th>\n",
       "      <th>year_painted</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>red_hex</th>\n",
       "      <th>green_hex</th>\n",
       "      <th>blue_hex</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>Cache-telé (Hidden Television)</td>\n",
       "      <td>True</td>\n",
       "      <td>52.600858</td>\n",
       "      <td>101.139904</td>\n",
       "      <td>2018</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>EUR</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>536.0</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>87.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Theo Van Rysselberghe</td>\n",
       "      <td>Jeune dame lisant</td>\n",
       "      <td>True</td>\n",
       "      <td>49.257938</td>\n",
       "      <td>136.515970</td>\n",
       "      <td>2010</td>\n",
       "      <td>Paris</td>\n",
       "      <td>EUR</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>243.6</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>Oil-Based Paintings</td>\n",
       "      <td>canvas</td>\n",
       "      <td>144.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1862</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  artist                           title  faces   contrast  \\\n",
       "0      Pierre Alechinsky  Cache-telé (Hidden Television)   True  52.600858   \n",
       "1  Theo Van Rysselberghe               Jeune dame lisant   True  49.257938   \n",
       "\n",
       "   brightness  year_sold city_auction currency  price_EUR  signed  ...  \\\n",
       "0  101.139904       2018    Amsterdam      EUR    87500.0    True  ...   \n",
       "1  136.515970       2010        Paris      EUR    79000.0    True  ...   \n",
       "\n",
       "   circumference  year_painted               medium surface red_hex  \\\n",
       "0          536.0        1973.0              missing  canvas    87.0   \n",
       "1          243.6        1887.0  Oil-Based Paintings  canvas   144.0   \n",
       "\n",
       "   green_hex  blue_hex  year_born   dead  return_sp  \n",
       "0      109.0     103.0       1927  False     0.2161  \n",
       "1      131.0     125.0       1862   True     0.2594  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(df, df_sp, left_on='year_sold', right_on='year', how='left')\n",
    "merged_df = merged_df.drop('year', axis=1)\n",
    "df = merged_df\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1d5853",
   "metadata": {},
   "source": [
    "#### feedback output above\n",
    "All the values have been filled in, nonetheless, some visual features have still some none values but due to a boolean variable 'missing value visual characteristics' we try to let the algorithm know that these are special rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace1fb34",
   "metadata": {},
   "source": [
    "now we see that the only values with missing values that aren't adapted to the situation are the estimations but we don't need this for our model, only to compare the sum of residuals at the end with the sum of residuals of our algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6f47c5",
   "metadata": {},
   "source": [
    "#### distribution of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f21007",
   "metadata": {},
   "source": [
    "**target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "945b09b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count        811.000\n",
      "mean      654665.181\n",
      "std      2340433.149\n",
      "min           75.320\n",
      "25%         4488.985\n",
      "50%        23622.050\n",
      "75%       195584.345\n",
      "max     23596150.450\n",
      "Name: price_EUR, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# descriptive statistics\n",
    "stats = df['price_EUR'].describe()\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "print(stats)\n",
    "\n",
    "# gives an overall sense of the central tendency and variability of the prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "14b786f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# boxplots\n",
    "sns.boxplot(x = df['price_EUR'])\n",
    "plt.show()\n",
    "\n",
    "# outliers can be easily identified in a box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "32ebc60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['price_EUR'].dropna(), bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Prices in EURO')\n",
    "plt.xlabel('price_EUR')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# insights in shape of distribution (skewed!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "54609471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4488.985  23622.05  195584.345]\n"
     ]
    }
   ],
   "source": [
    "# percentiles\n",
    "percentiles = np.percentile(df['price_EUR'], [25, 50, 75])\n",
    "print(percentiles)\n",
    "\n",
    "# outliers may have a significant impact on the mean, but percentiles provide a more robust measure of the spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e386a5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of outliers in 'price_EUR' is: 146\n"
     ]
    }
   ],
   "source": [
    "# outliers both sides\n",
    "Q1 = df['price_EUR'].quantile(0.25)\n",
    "Q3 = df['price_EUR'].quantile(0.75)\n",
    "\n",
    "# Calculate IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Count the number of outliers\n",
    "num_outliers = ((df['price_EUR'] < lower_bound) | (df['price_EUR'] > upper_bound)).sum()\n",
    "\n",
    "print(f\"The number of outliers in 'price_EUR' is: {num_outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d1599e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of outliers above Q3 in 'price_EUR' is: 146\n"
     ]
    }
   ],
   "source": [
    "# Calculate Q3\n",
    "Q3 = df['price_EUR'].quantile(0.75)\n",
    "\n",
    "# Define the upper bound for outliers (above Q3)\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Count the number of outliers above Q3\n",
    "num_outliers_above_Q3 = (df['price_EUR'] > upper_bound).sum()\n",
    "\n",
    "print(f\"The number of outliers above Q3 in 'price_EUR' is: {num_outliers_above_Q3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3c3c3969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  6,  15,  32,  35,  87,  88,  90,  93,  95, 100, 113, 125, 212],\n",
      "      dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "# outlier detection (Z-score)\n",
    "from scipy.stats import zscore\n",
    "z_score = zscore(df['price_EUR'])\n",
    "outliers = np.where(np.abs(z_score)>3)\n",
    "print(outliers)\n",
    "# help detect observation that deviate significantl from the norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "436ea06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate analysis\n",
    "without_outliers = df[df['price_EUR'] < 0.9 * df['price_EUR'].max()]\n",
    "# one outlier that is dropped here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eb1dfd",
   "metadata": {},
   "source": [
    "Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "64bffe11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numerical_columns = df.select_dtypes(include=['float64','int64']).columns\n",
    "numerical_columns = numerical_columns[numerical_columns != 'price_EUR']\n",
    "df[numerical_columns].hist(bins=20, figsize=(15,10))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4d76b9",
   "metadata": {},
   "source": [
    "**brightness**\n",
    "\n",
    "brightness is only the second histogram, we put it first because it's a part of contrast so than it is easier to understand.\n",
    "This value ranges from 0 to 250 and the first represents complete darkness or black, all pixels are as dark as possible. An image with a brightness score of 255 has all pixels as bright or white as possible. As a consequence 127,5 represents a balanced or neutral brightness, and there's neither an overall brith nor dark bias. The brightness is normally distributed.\n",
    "\n",
    "**contrast**\n",
    "\n",
    "A contrast of 0 means that the entire painting has the same level o brightness and there are no discernible diffferences between light and dark areas. 100 Would suggest maximum contrast, where the brightest elemetns are at their brightest and the darkest elements are at their darkest.The transition between light and dark are sharp and abrupt.\n",
    "The distribution is slightly right skewed, which means that the noticeable difference between light and dark areas is a bit under 50.\n",
    "\n",
    "**year_sold**\n",
    "\n",
    "A quasi linear function is apparent. \n",
    "\n",
    "**area** **circumference**\n",
    "\n",
    "With a histogram like this, there is a big chance there will be outliers. Because of that, we need to double check if these outliers are due to a mistake in the data manipulation from 'details' to 'dimension' to 'length and width' to area and circumference. The chance a mistake or error happened is big due to the multiple manipulations. \n",
    "\n",
    "We checked the width and length who fell out of the 3times difference inter quartile. For these values we checked the dimensions manuel and they were all right. Therefore, we will not drop these!\n",
    "\n",
    "**year_painted**\n",
    "\n",
    "This should be a graph in between the born year of the oldest ( back in history ) and 2023. The values that are not in between these values are going to be filled in with nan and afterwards going to be valued due to born_year artist + 50 and then plus a random number of this interval[-20;20]. \n",
    "\n",
    "**red_hex** **green_hex** **blue_hex**\n",
    "\n",
    "Each hex ( red, green and blue_hex ) have an intensity value ranging from 0 to 255, where 0 represents the minimum intensity (no color) and 255 represents the maximum intensity (full color).\n",
    "We see for each hex that the distribution is rather normal, which relates to the results of brightness.\n",
    "\n",
    "**year_born**\n",
    "\n",
    "For this statistic, it is better to look at it for each artist instead of all paintings because now the artists who's frequency is higher dominate in this graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "53f3ef5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# looking at the unique values of year_painted becaus this needs to be in between the year of birth of the first artist and 2023.\n",
    "# we are putting nan's everywhere where the year painted is outside the possible range\n",
    "low_bound = min(df['year_born'].unique())\n",
    "high_bound = 2023\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if df['year_painted'][index] <= low_bound or df['year_painted'][index] > high_bound:\n",
    "        df.loc[index, 'year_painted'] = np.nan\n",
    "# fill in the average of that artist\n",
    "df['year_painted'] = df.groupby('artist')['year_painted'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# new histogram\n",
    "df['year_painted'].hist(bins=20, figsize=(5,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c263648d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# new histogram to look at year_born\n",
    "df_y['year_born'].hist(bins=20, figsize=(5,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fdbbca",
   "metadata": {},
   "source": [
    "**year_born** \n",
    "\n",
    "It is apparent that the paintings that are collected in this dataset are from painters that were born just before the 16th century are later than the 19th one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fc426c",
   "metadata": {},
   "source": [
    "# for data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "baea2fff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11 different artists in 811 samples and the frequency of each different artist is:\n",
      "artist\n",
      "Rene Magritte               158\n",
      "Pierre Alechinsky           137\n",
      "James Ensor                 102\n",
      "Anthony Van Dyck             95\n",
      "Paul Delvaux                 91\n",
      "Theo Van Rysselberghe        53\n",
      "Jan Breughel the younger     43\n",
      "Jacob Jordaens               43\n",
      "Felicien Rops                35\n",
      "Eugene Verboeckhoven         34\n",
      "Jan Breughel the elder       20\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# the number of paintings per painter\n",
    "# print frequention of the artists \n",
    "artist_freq = df['artist'].value_counts()\n",
    "print(f\"There are {len(artist_freq)} different artists in {len(df)} samples and the frequency of each different artist is:\")\n",
    "print(artist_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "84f7f769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The earliest painting in this dataset was sold in 1994 and the last one in 2023 which has 29 years between them.\n"
     ]
    }
   ],
   "source": [
    "# In which year was the first painting sold in this dataset\n",
    "min_year = df['year_sold'].min()\n",
    "max_year = df['year_sold'].max()\n",
    "print(f'The earliest painting in this dataset was sold in {min_year} and the last one in {max_year} which has {max_year-min_year} years between them.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb54a384",
   "metadata": {},
   "source": [
    "#### information of artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "31222d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthony Van Dyck</td>\n",
       "      <td>95</td>\n",
       "      <td>194.780</td>\n",
       "      <td>165621.720</td>\n",
       "      <td>4025443.900</td>\n",
       "      <td>15734063.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eugene Verboeckhoven</td>\n",
       "      <td>34</td>\n",
       "      <td>500.000</td>\n",
       "      <td>27034.417</td>\n",
       "      <td>156000.000</td>\n",
       "      <td>919170.180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 artist  count     min       mean         max        total\n",
       "0      Anthony Van Dyck     95 194.780 165621.720 4025443.900 15734063.420\n",
       "1  Eugene Verboeckhoven     34 500.000  27034.417  156000.000   919170.180"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a dataframe with all the important information of the artist\n",
    "# Group by 'artist' and aggregate the desired statistics\n",
    "df_artist = df.groupby('artist').agg({\n",
    "    'artist': 'count',\n",
    "    'price_EUR': ['min', 'mean', 'max', 'sum']\n",
    "})\n",
    "\n",
    "# Rename the columns for clarity\n",
    "df_artist.columns = ['count', 'min', 'mean', 'max', 'total']\n",
    "\n",
    "# Reset index to make 'artist' a regular column\n",
    "df_artist.reset_index(inplace=True)\n",
    "\n",
    "# Display the new DataFrame\n",
    "df_artist.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3838e93",
   "metadata": {},
   "source": [
    "## looking which features are correlated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "80febc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist            object\n",
       "title             object\n",
       "faces               bool\n",
       "contrast         float64\n",
       "brightness       float64\n",
       "year_sold          int64\n",
       "city_auction      object\n",
       "currency          object\n",
       "price_EUR        float64\n",
       "signed              bool\n",
       "area             float64\n",
       "circumference    float64\n",
       "year_painted     float64\n",
       "medium            object\n",
       "surface           object\n",
       "red_hex          float64\n",
       "green_hex        float64\n",
       "blue_hex         float64\n",
       "year_born          int64\n",
       "dead                bool\n",
       "return_sp        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a0846f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAssAAAIfCAYAAACGp5HiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOzdd3gU1frA8e+7m4SEVAIkISH03jsoVZCiiIJUy7Vc+/XavTYsiIL9eu0NFcWCoigKAhYERJTeQw0JECAJpPeye35/zEI6JJol4cf7eZ48sDPvzLwze/bM2TNnZsUYg1JKKaWUUqosW00noJRSSimlVG2ljWWllFJKKaUqoI1lpZRSSimlKqCNZaWUUkoppSqgjWWllFJKKaUqoI1lpZRSSimlKqCNZaXUWUFEZovI039j+UwRaVGdOZ1pInKViPz4N5b/XETGVmNKbiUii0Xk2prOoyaJSKiI7BSROjWdi1LnKm0sK+UmIhIrIjmuRlqCiHwoIn41nddfJSJeIjJNRPaKSJZr/z4QkWY1nVtpIrJcRG4sPs0Y42eM2e+GbcWKSL6INCg1fbOImMocHxFp5or1OFWcMeZTY8yIv5hnF6ArsMD1+jrXNv9TKi5ORIb8lW1UN2PMRcaYj6q6nGu/slyfvUwRSf27ubjW2ervrqeqjDEJwK/AzWd620opizaWlXKvMcYYP6AH0Bt4tDpXfrrGVTX7CrgUuBIIxGp4bQCGVXVFpfMWy9lcH8UAV5x4ISKdAZ/q3EA1vNe3AJ+akr9ElQw8KCIBf3Pd1aqaykNX1xckP2NMUHXk9XeIiP1vLP4p1vunlKoBZ/PJSamzhjHmMLAY6AQgIv1EZLWIpIrIluI9eSJyveuya4aI7BeRW4rNG+Lq+XtQROKBD0WkgYgsdK0rWUR+O9HQEJH2rl7WVBHZISKXFlvXbBF5Q0QWuba1RkRalpe/iFwIDAcuM8asM8YUGmPSjDFvGGPed8WEi8h3rhz2ichNxZafJiJficgnIpIOXOfKa4aI/A5kAy1EpJ2I/ORax24RmVRBPvVc+3xMRFJc/2/smjcDGAi87upVfN01/WTPoIgEisjHruUPiMijxY7ZdSKySkRedK07RkQuOs1bPAe4ptjra4GPS+U8WkQ2iUi6iBwSkWnFZq90/Zvqyvk8Vx6/i8jLIpIMTDuRm2t954vIcRGJdL3u6nqf21WQ40XAilLTdgJ/APeUt4CUGvpyovwVex0rIv8Rka2untz3xRo2sNhVpn4WkXrF4k9V7ssrDyWuEIjITcU+G1Ei0qOCfS2Xq4x+7XrfY0TkzmLz+ojIH67cjorI6yLi5Zp34v3Z4np/Jhd/L4qto3gZmy0ib4nIDyKSBVxQie2vd5WPBBH5b7FVr3Edj6ZV2V+lVDUxxuif/umfG/6AWOBC1/8jgR3AU0AEkARcjPWFdbjrdUNX7GigJSDAYKyGQw/XvCFAIfAcUAer9/IZ4G3A0/U30LWsJ7APeATwAoYCGUBb17pmY/Us9gE8sHqv5lawL88CK06zvyuANwFvoBtwDBjmmjcNKADGuvbZB1gOHAQ6urYfCBwCrne97gEcBzoWy/dp1//rA+OBuoA/MA/4tlguy4EbS+VngFau/3+MNRzBH2gG7AFucM27zpXrTYAduA04Asip3mdgN9DetcwhoKlrm82KvXedXfvfBUgAxrrmNXPFehRb73Wu9/oO1/HwcU1bVSxmBrDMNW8r8O8KcvR1rb9hqfWvcr1XqUCwa3ocMKT0MS+2D3Gl9v1PIBSrXCcCG4HuWOVzGfCEK/Z05X45JcuDZ/H3EZgIHMa6QiNAK6BpBft78r0uNs2GdSXkcazPQwtgPzDSNb8n0M+17WZYXyTurmidpd+LcsrYbCAN6O/adt3TbP8P4B+u//sB/UqteytwaU3Xa/qnf+fin/YsK+Ve34o1XnIVVmNyJnA18IMx5gdjjNMY8xOwHqsRgTFmkTEm2lhWAD9iNYBPcGI1QPKMMTlYDbtGWA2HAmPMb8YYg3Xi9wOeNcbkG2OWAQspNlwAmG+MWWuMKcRqLHerYD/qA0cr2klX7+YA4EFjTK4xZjMwC/hHsbA/jDHfuvY5xzVttjFmh2v7o4BYY8yHxuq53gh8DUwovT1jTJIx5mtjTLYxJgOr0Ti4ovxK5WoHJgMPG2MyjDGxwEulcj1gjHnPGOMAPsI6vqGnWfWJ3uXhwC6shl3xnJcbY7a59n8r8Hklcj5ijHnNdTxyypk/DetLxlqsBv0bFawnyPVvRukZrvfqR+DB0+RSkdeMMQnGunryG7DGGLPJGJMHfIPVcIbTlHuXk+XBGFNQajs3As8b68qGMcbsM8YcOEVeG129xKki8ipWI7uhMWa66/OwH3gPmOI6DhuMMX+6th0LvEMly9QpLDDG/G6McWJ9Uapw+1if41Yi0sAYk2mM+bPUujIoeh+VUmfQmRzvqNS5aKwx5ufiE1yXUieKyJhikz2xbuLBdcn/CaANRT1S24rFHjPG5BZ7/QJWo+lHEQF41xjzLBAOHHKdqE84gNXDd0J8sf9nYzWuy5Pkyqci4UCyq+FafFu9ir0+VM5yxac1BfpKyZuxPLAaoSWISF3gZawG9onL/P4iYnc1cE+lAVbPXvGGVoXHxRiT7Tqup7s5cw7WcIrmlBqC4cq5L1YPfSfX9utg9YifSnnH7CRjTIGIzAZeBe51fUkqT6rrX38gt5z5jwNrReTl0+RTnoRi/88p5/WJ43bKcu9yqv2NBKKrkFcPY8y+Ey/EGtITXqp82bEa+IhIG+C/WGW2LlbZ21CF7ZWndPmucPvADcB0YJeIxABPGmMWFov1p+h9VEqdQdqzrNSZdwiYY4wJKvbna4x5VqzHQ30NvAiEGuvGpB+wLjufUKJB5Oodvc8Y0wIYA9wrIsOwehojpeSNUk0o1eNZST8DfcQ1LrgcR4BgEfE/xbbKa8gVn3YIa6hH8ePiZ4y5rZzl7gPaAn2NMQHAINf0E8epokYjWEM7CrAaLxXlWmWuXs4YrJ7S+eWEfAZ8B0QaYwKxhs6cLt9T7QciEoH1xepD4CWp4PFixpgsrIZmuV94jDG7XDk/UmpWFlbD8YSwU+VzGhWW++KpnGb5csfUV2H7MaW272+MOdGz/RbWFYHWrjL1CCU/d6WVODYiUt6xKV2+K9y+MWavMeYKIARrmNVXIuLrWrcH1rCTLX9lx5VSf482lpU68z4BxojISBGxi4i368apxhT1OB4DCl29zKd8VJiIXCIircTq/kwHHK6/NVgn9AdExNN1M9UYYG5VE3b1jv8EfCMiPUXEQ0T8ReRWEfmnMeYQsBp4xrU/XbB6yj6twmYWAm1E5B+ufD1FpLeItC8n1h+r1zJVRIKxGozFJWCNCS1vXxzAl8AM1z40Be7Fel/+rhuAoa7GaXk5JxtjckWkD9ZTRU44hjW8ptLPgXa937OB913bPYo1Jr4iP3DqYQVPYo0XDyo2bTNwsYgEuxqDd1c2v3KcqtxXxizgflf5E1eZr8oNb2uBdLFujvVx5dBJRHq75vtjfX4yxbpJsvSXtNJlagvQUUS6iYg31tWdv7x9EblaRBq6rgSlupY5cZWkD9YQpVMNO1FKuYk2lpU6w1wNy8uweq6OYfU4/QewuYYx3InVmEvBalB9d5pVtsbq+c3EuknoTdf42HysR71dhNWb+iZwjasX8a+YgNXg+gLrxqXtWJesTwwzuQLrxqgjWGNVn3CNS60U176PwBrDeQRrKMSJGxlL+x/WTW3HsW4wW1Jq/ivABLGeZvFqOcvfgfVFYj/WePLPgA8qm+sp9iHaGLO+gtn/AqaLSAbWsIcviy2XjTXu+nfXGNt+ldjcnVjjqB9zDb+4HrheRAZWEP8ucJWrkV1e7jFYQ0l8i02eg9UojMUa1/xFJfIq16nKfSWXn4d1jD7DGr/7LRBche07sL4sdsO6AnAcqwEe6Aq5H+vzloE1lrj0vk4DPnK9P5OMMXuwhk38DOzFKkd/Z/ujgB0ikolVfqcUG251FdaVCKVUDZCKh7gppZT6/0REPgO+NMZ8W9O5qMoRkRCsm4O7l7pXQSl1hmhjWSmllFJKqQroMAyllFJKKVXricgHIpIoItsrmC8i8qpYP4y1Var4w0UV0cayUkoppZQ6G8zGGt9fkYuw7uNpDdyM9ZSbv00by0oppZRSqtYzxqzE+uXZilwGfOz64aI/gSARafR3t6s/SuI+OhhcKaWUUtXpVM/+PmMWebZ1SxvnksI9t2D1CJ/wrjHm3SqsIoKSPwYU55pW4S/QVoY2lt1okWfbmk6h0kYX7Oa9n08fV5vcdCE8/lF+TadRJdOv9WLG3NP9wFztMXWKnSWbz65jPKqbF8u3l/fL0LXXkE4+/LEzvabTqLTz2gfwxuKazqJqbr+Is6qOu+lCmL28prOomuuGcFaVY7DK8ivfnz19W3eNqRVtZbdxNYyr0jgurbwD9LffYG0sK6WUUkqpShPPWttojwMii71ujPXc/r9FxywrpZRSSqn/D74DrnE9FaMfkGaM+VtDMEB7lpVSSimlVBXYPGqmZ1lEPgeGAA1EJA54AvAEMMa8jfUrsxcD+4BsrF82/du0sayUUkoppWo9Y8wVp5lvgNure7vaWFZKKaWUUpUmnufWKF5tLCullFJKqUqrqWEYNeXc+mqglFJKKaVUFWjPslJKKaWUqrRa/Og4t9CeZaWUUkoppSqgPctKKaWUUqrSzrUxy9pYVkoppZRSlabDMJRSSimllFLA//OeZRFpBpxvjPmsmtZ3N/CuMSa7OtZXXJf3ZhJy8RDyE5NY2X1MuTEdXp5KyKjBOHJy2XLDQ6RvigKg4YiBdPjvVMRu49AH84h+4b3qTq9cMTtWsuyrGRink879J9J3xM0l5htjWDZvBjE7VuDh5c1F/3iW0CYdKSzIY+7LV+EozMfpcNCm+0j6X3LnGckZ4OI+dlpH2CgoNHzzu4OjyaZMTJAfTBrkgU8d4UiSk/mrHDicUMcTJgz0INAXbDb4fYeTTfucbs13RA+hZSOhwAEL1ziJTykbE+gL48634eMF8SmGBX8anE5oEgITB9hIy7LidsUZVu0ou7/VaefmVcyf/RxOp4N+Qy9n+NgbS8xPOLyfz956jEMxO7lkyp0MHXPdyXlP/nskdbzrYrPZsdnt3P/MF27N9YTtm37nyw+ex+l0MmDYOEZd/s8S8+PjYpj9xhMc2r+Ty678NyMuu/bkvJ+/n8Oqn79BRIho0ppr//0knl513Jrv1o2r+WzWSzidTgYNv4xLxl9XYv7qFYv5Yf7HAHh7+3DNrQ/RpHkbAN5/bTqb168iILAeM149M8cXIHbnSlbOn4ExTjr2m0ivC8vWFyvnzyB25wo8PL0ZfuWzhER2BODnzx4mJmo5Pn71ufqhhWcs57OtjovevpKfv5yB0+mk24CJnDeqbL4/fTGD6O0r8PTy5pLrniWsiXWM33xkKF51fBGbDZvNzvVT57s9Xzg7y7IxhlULZnBg50o8vLwZNvkZGjbuWCYuPSmOHz+5l7ycNBpEdODCK57D7uFV6eVrs3NtGMb/957lZsCV5c0Qkb/yReFuoO7fyKdCcR/NZ+0lN1Y4v+GoQfi2asby9iPYdttjdHp9mjXDZqPjq4+zdsyNrOgymvApl+DXvqU7UizB6XTw85fTGX/7LK5/bBG71i/k+NF9JWJidqwk5VgsN0z7kRFXPsVPc62c7R5eTLrzI6595DuueeRbYqJ+40jMZrfnDNA6QqjvL7zyTQHf/eFgTD97uXEjetpZHeXklW8KyM2HHq2tj0rfdjYSUw1vfl/IB0sKGdnLjt2Nn6KWjSDYT3hrkZMf1jkZ1av8jQ3tKqzdbXhrkZPcfOjWoqgiO3QMZi11Mmup0+0NZafTwbwPZnDLw2/y8H8XsPH3xcTHRZeIqesXyOXXPVyikVzcvx//gAee/+qMNZSdDgefv/cMd0x9g2n/m8+6VUs4cqhUzv6BTLnhAYZfek2J6SlJCSz74XMeef4znvjf1zidDtatWuL2fOe88zz3Pv4KM1/7kjW//cjhQ/tLxDQMDefhGe/w9Cufc+mkG5j95syT8wYMvYT7Hn/VrTmWydnpYPlX07nslllc/dAi9mxcSFJ8yfriwM6VpB6L5ZqpPzJ08lP8Om/ayXnt+17OZbfMOuM5n011nNPp4MfPpzPpjlncPG0RUesWcvxIyXyjt68kJTGWW5/6kYuufooln04rMf/K+z7ihscWnLGG8tlYlgEO7lpJ2rEDXPXQUoZMmM6Kr58sN+6PRS/SddC1XPXQUur4BLBz7ddVWl7VHrW6sSwi14jIVhHZIiJzRKSpiPzimvaLiDRxxc0WkVdFZLWI7BeRCa5VPAsMFJHNInKPiFwnIvNE5HvgRxHxc61no4hsE5HLXOvzFZFFru1uF5HJInInEA78KiK/Vve+Jq9aT0FyWoXzQy8dxuFPvgUgdc0WPAMDqBPWkKA+XciOPkBOTBymoIAjXywidMyw6k6vjPjYrdRr2JSgBpHYPbxo13M00Vt/KRGzb+svdOw7FhEhvHk38nLSyUxLRETw8vYFwOkoxOksRDgz31LbRdrYvN/qCY47bvD2Evx8ysY1D7MRdcCK2xztpH2k9VExxupdBvDyhJw8cLqxY7lNhLA11mrgHkkCb0/w8y4b1yxU2HnIitsaY2gTUTPf+g/s20bD0CY0CI3Ew8OTHudfxLZ1JT8u/oH1adqqE3Z77biwFbNvOyFhkTQMa4yHpye9Boxky7rlJWICAoNp1qoTdo+yOTsdDgry83A4CsnPzyUouKFb892/dwehjSIJceXbd8BwNq1ZUSKmdbuu+PoFANCybWeSkxJPzmvbscfJeWdKwoGtBDVoSqCrvmjdfTT7t5WsL/Zv+4V2va36olEzq77ISrPyjmjZG++6gWc057OtjjsSs5V6IU2p19DKt32v0ezZUjLfvVt+oVM/K9+IFkX51pSzsSwDxOz4hba9LkNECGvajfzcdLLSSx5HYwyH9/1Jyy4jAWjXaywx23+u9PK1ndjFLX+1Ve04W5VDRDoCU4H+xpjjIhIMfAR8bIz5SET+CbwKjHUt0ggYALQDvgO+Ah4C7jfGXOJa53XAeUAXY0yyq3d5nDEmXUQaAH+KyHfAKOCIMWa0a7lAY0yaiNwLXGCMOX4mjkFx3uGh5MTFn3ydezge74jQcqYnENSni9vzyUhNwL9e2MnXfkGhHI3dWiImMy0B/6CiGP+gMDJTE/ALDMHpdDDn2ctJPXaQboOvpFHzrm7PGSCgrpCWVdS6Tc82BNQVMnOKelzr1oHcfHC6JqVlGfxd1xPW7HJy1VAP/jPREy9PmLeiEHf21fr7COnZxfLNAX8fyMwtivHxsvI1pmTMCREN4MaRNjJz4OfNTo6nuy/ftOREguoXvedB9UM5sG/rKZYoTXhrxi0g0P/CiZx/4cTqT7KU1ORE6jUoyrlecCgxe7dVatl69UMZfuk1PHzrKDy9vOnQtR8dup3vrlQBSEk+RnCD0BI57N+7vcL4lT8voEsP9+Z0OplpCfiVqi8SDpRTX5SICSMzLQHfwJAzlmdxZ1sdl5maQECxfP3rhXIkpmS+GakJBASXzDcjxcoXYO7/bkBE6DZwMt0HTXZrvnB2lmWArLQE/IIanXztGxhGVloCvgFFZTU3OxUvnwBsrk4B36Cwk1/+KrN8bWerxQ1bd6i1jWVgKPDViYapq3F7HnC5a/4c4Pli8d8aY5xAlIiEUrGfjDHJrv8LMFNEBgFOIAIIBbYBL4rIc8BCY8xv1bZXf5FI2YJpjIFypp9sNblV2W2UztGUl4crxmazc+0jC8jNTmfBu7dz7MgeGoa3cUum5Wy+hKocrlYRwtEUw4c/FhLsD9cO9+TA9wXkFVRfjsWVm28lYk6IT4bXv3dSUGgN6Zg40MZbi9zXFV7ue16FHrW7p39MYHAIGWlJvPn0zYSEN6dVh17Vl2B5TlFOTycrM50t65Yz481F1PX1550X/8OfKxbRb/Doak6ySFWO8c5t61n583dMnXlm7mOoWGWO8enrlDPr7KrjTHn5li4Xp8j3Hw98jn9QKFnpScx95Xrqh7WgSZve7ki1WDpnY1mu4JxRuqyWe6yrsLyqVWpzY1kot4Ytofj8vFLLViSr2P+vAhoCPY0xBSISC3gbY/aISE/gYuAZEfnRGDP9tAmL3AzcDPDOO+8QcboFqiDncDw+jcM4cW+Xd0QYeUcSsXl54tO4qKfAOyKU3CPuv5xj9UgU9Wif6E0pE5NaFJORGl8mxrtuAJGt+xIb9ZvbTiR92tro2cYaRnH4uCHQt6hoBdQVMnJKFrPsPPD2AptYvcuBvkKG65bOHq3s/LbNAUByBqRkGhoECoePV98XlJ6thO4trSJ8JNnq+T6Zrw9k5pSMP5GviFUJB/hAhismv7AoLvqodVOijxfk5FdbuiUE1Q8lNanoPU9NSiCwXuV7SwKDrVj/wPp06TOMg9Hb3d5YDqofSsrxopxTkhMqPZRi19Y/aRASgX9gMADd+w1j/+7Nbm0sB9cPIfl4wsnXKUkJ1AtuUCbuUOxePnj9ae57/BX8AoLclk9l+AWGkVmqvijdi+YXWLpOia/RnrazqY47kUt6sXwzUhLwCyqVb70w0pNL5uvvivEPsvqYfAPq06bbcI7GbnV7Y/lsKsvbfv+UqDXzAAiJ7Exm6tGT87LSypZVb9965Oek43QUYrN7kFWsPPsFhZ52+dpObOdW4742j1n+BZgkIvUBXMMwVgNTXPOvAladZh0ZgP8p5gcCia6G8gVAU9e2woFsY8wnwItAj8qszxjzrjGmlzGm180331xR2F+S+P0yIq4eC0BQ364UpmeQF3+MtHXb8G3VDJ9mjRFPT8InjyZh4bJq3XZ5wpp2JiUxltTjh3AU5rNrwyJadh5aIqZll6HsWPMtxhiOxGymjo8/foEhZGckk5ttjQUoyM/lwO7VBIe2cFuua3c7eev7Qt76vpBdB510a2EV+8YNhNwCU6bxCRATb+jQ1Irr1tLGzkNWb2xqlqFFI2u6rzc0CBRSMqq3J3/DPnPyhrw9cYYuzaxKKbw+5BWUHIJxwoEEaB9pxXVpLuw9bE7meEJ4sPUt0l0NZYAmLTtxLP4ASYlxFBYWsHH1Yjr1GlKpZfNys8nNyTr5/11bV9MospX7knVp1qojiUcPcjzhMIUFBaxftZSuvQZXatngBo3Yv2cr+Xk5GGPYtW0NYY3dV5YBmrfuQMLRgxxz5btm1U907zOoREzSsXhee/YBbr7nScIimro1n8oIbdKZ1OOxpCVZ9cXeTYto0alkfdG801B2rbPqi6OxVn1RU0Mw4Oyq4wDCm5XMd+f6RbTuWjLf1l2Hsv1PK9/D+4vyzc/LJi83E4D8vGxion6nQXhrt+YLZ1dZ7tz/Kibf+y2T7/2W5h2HsXv9AowxxB/YjJe3f5nGrogQ0aov0VuXArBrvbUcQLMOQ0+7vKpdam3PsjFmh4jMAFaIiAPYBNwJfCAi/wGOAdefZjVbgUIR2QLMhpMdsyd8CnwvIuuBzcAu1/TOwAsi4gQKgNtc098FFovIUWPMBX9n/0rrNucl6g/ug1eDegyNWcHe6a8hntbbc/DduSQuXkHDiwYzZNdPOHJy2HrjIwAYh4Ptd02nz6JZiN1O3OyvyYzad6pNVQub3YNhkx7n6zduxOl00Pm88TQIb83m3z639mfgFbToOJiYHSuYNW04nl4+jLrauos5Kz2RxR8/hNPpwBhD2x6jaNm5Wg9nhfYcNrRubLj7cs+Tj4474ephHixYXUhGDvy0oZCJgz0Y1t3O0WTDxr1W3IotDsYN8OD2S6335scNDrLzyt1Utdh3FFqGG/51iY2CQuvRcSdMHmRj0VonmbmwbIuTcefbGNxZSEjh5E2M7SOFHq0EpxMKHfDNavc+5s5u92D8Px/hrZm3Wo+OGzKORpGtWPXTlwAMGD6J9NTjvPjwZHJzsrCJjeU/zOGRlxaQmZHC+y/eDVh39vfsfzHtuw1wa74ncp5y40O88tRtOJ1O+g+9jPAmrVix1OpFGjxyImkpx5n5wJXk5mQhIvyy8FOmvTKf5m060+O8C3n6/iuw2+1ENm/HwOHj3Z7v1Tc9wItP3onT4WDghZcS0aQly5ZYd9oPHTWeBV/MIjMjjY/ffu7kMtNesh6/9dZLU9m1fQOZ6ancc8Noxk65mcHDL3Nrzja7B0PGP86Ct636omPf8dRv1Jptv1v1Ref+V9Csw2Bid67go6et+uLCK4qeerDko3uJi15LbmYK7z8xiH4X3UHHfu4dz3621XE2uwfDpzzO3FduxDgddOk/nobhrdm4wsq3x+AraNlpMNHbVvD2o1a+o689kW8S89++HbBuWO3Q5xJadhpU4baqy9lYlgGath/MwV0r+fTZEXh4ejN0clFZXTjrZi6Y+BS+gaH0G30/P31yL2uWvELDiPa07zvhtMufLcSdj4GqhaT8MUOqGphFnm1rOodKG12wm/d+ruksquamC+Hxj9zYTeoG06/1YsZcx+kDa4mpU+ws2Xx2HeNR3bxYvr2cywW12JBOPvyx0413Xlaz89oH8Mbims6iam6/iLOqjrvpQpi9vKazqJrrhnBWlWOwyvIr35897aC7xtSOwc2re/V2y0E7f/26WrF/pdXanmWllFJKKVX76NMwlFJKKaWUqoDe4KeUUkoppZQCtGdZKaWUUkpVwbk2DEN7lpVSSimllKqA9iwrpZRSSqlKk3OsZ1kby0oppZRSqtLEdm4NTDi39lYppZRSSqkq0J5lpZRSSilVafroOKWUUkoppRSgPctKKaWUUqoKzrVHx2ljWSmllFJKVZoOw1BKKaWUUkoB2rOslFJKKaWq4Fx7dJwYY2o6h/+v9MAqpZRSqjrVivEPWy8e4pY2TpcflteK/StNe5bd6L2fazqDyrvpQljk2bam06iS0QW7eXtpTWdRNbeOhPvfyq7pNCrtxdvqMuaWnTWdRpV8/057Bo1bVdNpVMnKbwaQ++OHNZ1GpXmPuJ6fQjvVdBpVMjxhOz/UbVfTaVTaxdm7WNasS02nUSVDY7eeVeUYrLL88YqazqLyrhlc0xlYzrUxy9pYVkoppZRSlXauPQ3j3Bp0opRSSimlVBVoz7JSSimllKq0c20YhvYsK6WUUkopVQHtWVZKKaWUUpV2rj067tzaW6WUUkoppapAe5aVUkoppVSlnWtjlrWxrJRSSimlKu1cayzrMAyllFJKKaUqoD3LSimllFKq0rRnWSmllFJKKQVoz7JSSimllKqCc+3RcWe0sSwizYCFxphOp4mbDqw0xvx8iphpQKYx5sVS04OAK40xb/7thM+gmB0rWfbVDIzTSef+E+k74uYS840xLJs3g5gdK/Dw8uaifzxLaJOOFBbkMfflq3AU5uN0OGjTfST9L7nzjOTc5b2ZhFw8hPzEJFZ2H1NuTIeXpxIyajCOnFy23PAQ6ZuiAGg4YiAd/jsVsds49ME8ol9474zkHBu1kuXzZ+B0Oul03kT6DC97nJd/PYOYqBV4enkz4qpnCY3sSEbKUZbMeYDsjOMgNjqfP4keQ649Izlf1t+T9k3t5BfCF8vyOHzclInp38mDgV08aBBo4/EPs8nOtaY3DBImX+BF44Y2Fq8pYMWWwjOS882TQ+nZyY+8fCevzD5K9KHcMjH3/TOcVk29cTgMe2JzeeOTozicMG5EMEP6BAJgt0HjRnW4+r49ZGY73ZrznTe0oF/PeuTlOXnmtT3s2Z9VJubB21vRtqU/InDoSA7PvLaHnNyivNq18uOtZ7sy7aVdrPgjyW25/h61n+e+/hmn08m487pyw4jzSsxft/cAd787n4j61nEc2rUNt1404OR8h9PJFS/MJiTQn9dvnei2PIurf0F/2j79EGK3c/jTr4l97f0S8z0CA+j4v6fwaRaJMy+PHXc/RtaufQA0ueUfRFw5HjBk7tzLjrsexZmX7/acGwwfQIcXXPXU7K/Y/1LJesojKIAub8+gbvMmOPPy2HrrVDKj9gLQ7F//IPL6iSDCoQ/nEfvGx27PN3hwf1o//iBit3H0i/kceOuDkvkG+NP+hen4NLGO8c4HniBrz76T89o9Ow3ftq3AGHY+8DjpG7e6PeezrSxHb1/Jj19Y5+puAyZy/kVlzyE/fjGD6G3WOeSS656lUdOOAORmp7Po40c5dngPiHDJtTNp3LK723N2B5v93BqGUet6lkXEbox5/G+sIgj4F3DWNJadTgc/fzmdiXd8iH9QKJ88P4GWnYfSoFGrkzExO1aSciyWG6b9yNHYLfw0dxpXPzAPu4cXk+78CC9vXxyOAj5/6UqadxxEePNubs877qP5xL75Cd0+eK7c+Q1HDcK3VTOWtx9BUN+udHp9Gqv7TwKbjY6vPs6ai64nNy6BAX9+RcLCZWTujHZrvk6ng2XzpnP57dZx/uzFCbTsNJT6xY5zbNRKUo/Fcv1jPxIfu4VlX07jivvmITY7g8Y9RGhkR/JzM/n0hfE0bdu/xLLu0K6JjYZBNp79LJcmoTbGD/Li1fl5ZeJi4h1EHXBw26V1SkzPyTMsWFVAx+Z2t+ZZXM9OvoSHeHHLY9G0be7NbVeFcf+zsWXilq9N46UPjgBw/w3hjBgQxOKVqXzzYzLf/JgMQO8uflw2LNjtDeV+PerRONybK/+1gQ5t/Ln3llbc+uCWMnGvfRBDdo4DgNuvb87lF4fz6fw4AGw2uPWaZqzbnOLWXB1OJzPn/cg7t08hNMifK1+YzZDOrWnZqEGJuO4tG1fYePh0+XpahDYgM7dsWXILm412zz7Kxkk3kXsknr5Lv+DY0l/J2rP/ZEjzu24iY/sutlx/F3VbNafds1PZOOFG6oSF0OTGq1g98DKcuXl0fvdFQsdexNEvFrg9544vP87aS/5J7uEE+v82j8RFy8jcVVRPtfrPLaRv3cXGKXfg26a5FT/6evw6tCby+on8PmgSJr+A3gveI3HJCrKjD7g137bTH2HT1TeTF59Ar+8+59hPy8neV3SMm95+ExlRu9l2yz3UbdmMNtOnsvmqmwBo/cSDJK34ne3/ug/x9MDu4+O+XF3OtrLsdDpY8tl0rrznQwLqhfLBzAm07jqUhuFF54Ho7StJTojltqd/5EjMFpZ8Oo3rH5kHwI9fzKBFx4GMv/VVHIX5FOSX7URQtVNN9KN7iMhHIrJVRL4SkboiEisij4vIKmCiiMwWkQkAInKxiOwSkVUi8qqILCy2rg4islxE9ovIie7UZ4GWIrJZRF4QkSGumK9c6/lURMS17p4iskJENojIUhFp5Jp+p4hEuXKc65o22LXOzSKySUT8q+uAxMdupV7DpgQ1iMTu4UW7nqOJ3vpLiZh9W3+hY9+xiAjhzbuRl5NOZloiIoKXty8ATkchTmchwpn5xpe8aj0FyWkVzg+9dBiHP/kWgNQ1W/AMDKBOWEOC+nQhO/oAOTFxmIICjnyxiNAxw9yeb/yBrQQVO85te4wmelvJ4xy97Rfa97GOc6Nix9kvMITQSKt3wMvbj+DQFmSmJbg9547N7KzfbfUGH0xw4l1H8K9bNu7IcUNKRtke58wcOHTMidO9bc0S+nX1Z9mfVrnYHZOLr4+NegFlv5dv2F7Uc7s3NpcG9TzLxAzuHcDKdenuS9ZlQJ9glv6aCEDUngz8fO3ULyefEw1lgDpeNowpOubjLw5nxR9JpKQVuDXX7QeOEtmgHo0bBOHpYWdUzw4s37a30ssnpKTz245oxp3XxY1ZlhTYozPZMQfJORCHKSgk/tvFNBw1tESMb5uWJP/2JwDZ+2LwiYzAq2F9AMTugc27DmK3Y6/rQ178MbfnHNSrC9nRB8mJteqpo1/9QOglJespv/YtSfr1DwCy9sTg0zQCr5D6+LVtQeq6LThzcjEOB8mr1hF26YVuzTegWyeyDxwk99BhTEEhid8voeGIC0rE+LZuQcrvawDIjo7Fp3E4ng2Csfv5EtSnJ0e/mA+AKSikMD3DrfnC2VeWj8RsJTikKfUaWueQDr1Hs2dLyXPIns2/0OU86xwS0aIbuTnpZKQmkpeTycE96+g2YAIAdg8vvOsGnJG83UFs4pa/2qomGsttgXeNMV2AdKxeYIBcY8wAY8zcE4Ei4g28A1xkjBkANCy1rnbASKAP8ISIeAIPAdHGmG7GmP+44roDdwMdgBZAf1fsa8AEY0xP4ANghiv+IaC7K8dbXdPuB243xnQDBgI5f/tIuGSkJuBfL+zka7+gUDJSSzbEMtMS8A8qivEPCiPTFeN0Ovho5mW8+eD5NG13Po2ad62u1P4W7/BQcuLiT77OPRyPd0RoOdMT8I4IdXs+maklj6FfUGiZBm/p4+wXFFYmJi0pjmOHdxLW1P3HOdDXRmpmUYMsLdMQ6Fu7x4rVD/LgeHJRgzEptZD69Sq+iGW3wQX9AtmwI7PE9DqeQo+Ofqze6P7GcoP6dUhMKrqsfywpnwbBdcqNfejfrfn2wz40ifDh60VHreWDvRjYrz4Llh51e66JqRmE1Sv6rh4S5E9CatmGzdaYw0x85n3+9eaX7Dta1Lh8fv4v3HPZBdjO4ImpTlgIeUeKPvN5RxKoExZSIiYzajcho60GZUD3Tng3bkSdRqHkxScS+9ZsBm78mUFbf6UwPYPkFavdnrN3eCi5h4vez5zD8dQJL1lPpW/bTdhlIwAI7NUZnybheEeEkRG1l+D+vfEMDsLm403DkYPxbtzIrfnWCQ0l70hRXZV3NIE6oaWO8c49NBxlNfj9u3aiTkQjvMNC8WnSmIKkZNq/+BS9F31Bu2enYTsDPctnW1nOSE3AP7jo/BAQFEpGSkKZmIBi5/OAemFkpCaQcvwQdf2DWTj7YWY9NZaFH08lPy/7jOSt/r6aOOseMsb87vr/J8CJwUdflBPbDthvjIlxvf681PxFxpg8Y8xxIBGoqMW11hgTZ4xxApuBZliN9k7ATyKyGXgUaOyK3wp8KiJXAycGef4O/NfVgx1kjCkz+FNEbhaR9SKy/t13360glfKU7RF0dX4XRZiyMbhibDY71z6ygFtmrCA+divHjuypwrbdp/Q+gGs/yplOeftX7U5/nMvLo3hPfX5eFgvfv5PBlz9CHR+/as+wzLbLPVRn4lj9DeW+7xWH33ZlGNv3ZhO1r+T3z95d/dgZne32IRhAuddiKjrOz76+l8tvWMuBuByGDrAuF99xQwve/jj2jPTgl5dV6UPevnEYS6b/i3kP38AVg3tyz3tWj+GK7fsI9qtLhyZh5azFjcoryKX2JObVWXgEBtDvl6+IvOEqMrbtwhQ68AgMIGTUBazqPZKVXYdir+tD2PhLzkDO5aVcMuf9L76LZ70ABvz5Dc1uvZr0LTsxhYVk7d5P9H/fo8/C9+mz4D3Xvrj5foFK1BUH3nofz8AAev/wJZHXXkHmjl0YhwOx2/Hr1J7Dn3zJutGTceTk0PS2f7o3X87Cslze+aES52oRwekoJP5gFD0GX8GNj32Ll5cPq5dUpZ1Qu4jN5pa/2qomxiyXLkknXpe9m6b86qq44oOUHFS8P+XFCbDDGHNeOfGjgUHApcBjItLRGPOsiCwCLgb+FJELjTG7SuyIMe8CJ0q/ea/C2xNL8g8KIyOlqNclMzUBv8CQsjGpRTEZqfFlYrzrBhDZui+xUb/RMLxN5TbuRjmH4/FpHMaJEZzeEWHkHUnE5uWJT+OiCs47IpTcI4luz8ev1DHMTE3ANyDkNDHx+LqOs8NRwML376RdrzG07jrCbXme39GDvh2sonwo0UmQX9HHINBPSM+ufY3li4fUY+SAIAD2xubQINgToq3Gb/0gD5JTy28oTLmkAYH+HrzxdlyZeYN6BbJyrft6lcdd1IhLhlvfr3ftyySkvtfJeQ3re5GUUvENZE4nLPv9GFeMbcziZYm0a+nHE/e1BSDQ35N+PevhcBhWrU2u9rxDg/yJTynqfUtMzSAksOSoMD+fol7xgR1bMvPLpaRkZrN5fxzLt+9jVVQ0eQUOsnLzePij73nm2vJv0K0ueUcTqBNe9JmvEx5aZiiFIzOLqLsfO/l6wLql5ByMo/4F/ck5eJiCJKsmSVz0C0G9uxH/9ULcybriVdQb7BMRRt7RkvVUYUYWW2955OTrITt/ISfWKstxH31N3EdfA9DmyXvIPRyPO+XFJ5To+a7TKJT8xLLHeOd/im4JOm/VYnIOHcbu401efALpm7cBkPjDT2eksXy2lWX/emFkJBe9j+mpCfgFlTyHBNQLI73Y+Tw9xTpXiwgB9cKIaGFdkWzXcxSrF5/NjeXaO2TCHWqiGd9ERE40UK8AVp0idhfQwvUUDYDJlVh/BlCZ8cS7gYYnchERTxHpKCI2INIY8yvwANYNg34i0tIYs80Y8xywHqvXu1qENe1MSmIsqccP4SjMZ9eGRbTsXHI8X8suQ9mx5luMMRyJ2UwdH3/8AkPIzkgmN9tqUBTk53Jg92qCQ1tUV2p/S+L3y4i4eiwAQX27UpieQV78MdLWbcO3VTN8mjVGPD0JnzyahIXL3J5PWJPOpByLJS3JOs67Ny6iRanj3KLzUHautY7z0ZjNeHlbx9kYw0+fTSU4tAU9h17v1jxX7yjk5Xm5vDwvlx0xhfRqazWcm4TayM0zZNTCK3c/LE/hrqdjuOvpGP7cnMnQftad622be5Od4yQlvWxjeUT/IHp08OWFWYfLdNjU9bbRqU1d/tzivnGT3yw+yg33buaGezfz25okRl5gnfQ6tPEnK9tBUkrZsccRYd4n/9+/VzAH46w3Y/Kt65l8i/W34o/j/PedaLc0lAE6NmnEwWPJxB1PpaDQwZINUQzuXPJG0+PpmSd7uLbFHsFpIMjXh7suHcJPT93O4if/xXPXX0rvNk3d3lAGSN+0nbotmuDdJALx9CBs7EUcW/priRiPAH/E0yrrEVePJ+XPDTgys8g9fJTAHl2w+VjHPnhgX7L27i+zjeqWtmEbvq2a4tM0AvH0pNGEi0lYVLKe8gj0Rzytse2R108kedU6CjOsfh+vhsEAeDduRNilwzny5SK35puxZQd1mzXFu7F1jEPGjOL4T8tL5lvsGIdPGU/qmo04MrPIP5ZE3pEE6rZoBkBw/zNzjM+2shzerDPJxc7VUesW0aZryXNI665D2fqHdQ45vN86V/sHheAX2JCAemEkxVvHNXbnHzQMb+nWfFX1qYme5Z3AtSLyDrAXeAu4o7xAY0yOiPwLWCIix4G1p1u5MSZJRH4Xke3AYqDcGsoYk++6ifBVEQnEOhb/A/YAn7imCfCyMSZVRJ4SkQuweqajXOuuFja7B8MmPc7Xb9yI0+mg83njaRDems2/WaNOug28ghYdBxOzYwWzpg3H08uHUVfPBCArPZHFHz+E0+nAGEPbHqNo2fmCU22u2nSb8xL1B/fBq0E9hsasYO/0105WxAffnUvi4hU0vGgwQ3b9hCMnh603Wj0wxuFg+13T6bNoFmK3Ezf7azKj9rk9X5vdg6ETHmf+mzdinA469htPg0at2bLKOs5dB1xB8w6Did2xgg+nD8fDy4cRV1nH+cj+Dexct4AG4W345LnLAOh/yb007zjYrTnvPOikXVMnD13pTUEhfPFrUW/nDRfXYd7yfNKzDQM6ezCkmwf+dYX7Jnmz66CTecvz8feBuyZ44+0lGAMDu3jwwtxc8tx4D9r67Zn06uzLu0+3tB4d91HRuM8n/h3Ja3OOkpxWyL+uCiMxuYAXHmwGwB+bMpi76DgA53X3Z1NUJnn5Z6YX/c8NKZzXsx6fv9XT9ei4opuMnn+0A8+9sY/k1HweubMNvnXtIBAdk8VL77j3CS7l8bDbeHjiCG578wucxjC2XxdaNWrIl6s2ATBpQHd+2rSbL1dtwsMm1PHy5LnrLi13WNSZYhwOdj88kx5z30Hsdo58/g1Zu6NpfM0kAOI+/hLfNi3o9NpMjMNB5p79RN1j9YCmb9xGwsKf6PfTlxiHg/Rtu4ibM++M5Lzj3qfo8937YLcR9/HXZO7cR5MbrT6bg7O+wK9tS7rOehbjcJK5ax9bb3v05PI9PnsVz+AgTEEhO+6ZTmGqe8feG4eDPY/PpNvHb1nH+MtvydobTfhV1lMkjnw6j7qtmtPhJeuxZ1l7o9n1wBMnl98z7Rk6/O8ZbJ6e5ByKY+f9j1W0qWpztpVlm92DkVc8zuf/s87VXfuPp2F4azassM4hPQdfQavOg4nevoI3p1rn6kuum3ly+RFXPMa379+Ps7CAoAaRXHLdMzWyH9XhXOtZlto+/lFE/Iwxma4nWLwB7DXGvFzTeVVCpYdh1AY3XQiLPNvWdBpVMrpgN28vreksqubWkXD/W7Wwa7gCL95WlzG37KzpNKrk+3faM2jcqS5Y1T4rvxlA7o8f1nQaleY94np+Cj3l4/JrneEJ2/mhbrVdEHS7i7N3sazZmXtiSXUYGrv1rCrHYJXlj1fUdBaVd83gM/S4q9M4cPNYtzQem777ba3Yv9Jq3XOWy3GTiFwLeAGbsJ6OoZRSSimlakBtvhnPHWr93hpjXnY9Bq6DMeYqY8zZ0y2nlFJKKaWqhYiMEpHdIrJPRB4qZ36giHwvIltEZIeIVMtNRmdDz7JSSimllKolamLMsojYsYbjDgfigHUi8p0xJqpY2O1AlDFmjIg0BHaLyKfGmIofb1QJ2lhWSimllFKVVkPDMPoA+4wx+wFcv7B8GdZDF04wgL/rPjc/IJmi38v4y2r9MAyllFJKKXXOiwAOFXsd55pW3OtAe+AIsA24y/WDdH+LNpaVUkoppVTlibjlr/gvIbv+bi6+1XIyKf1UjpFYv9QcDnQDXheRgL+7uzoMQymllFJK1bhSv4RcWhwQWex1Y6we5OKuB5411nOR94lIDNaPyJ32dzpORXuWlVJKKaVUpYlN3PJ3GuuA1iLSXES8gCnAd6ViDgLDAEQkFGgL/O2fo9SeZaWUUkopVWk1cYOfMaZQRP4NLAXswAfGmB0icqtr/tvAU8BsEdmGNWzjQWPM8b+7bW0sK6WUUkqpWs8Y8wPwQ6lpbxf7/xFgRHVvVxvLSimllFKq0mriOcs1SccsK6WUUkopVQHtWVZKKaWUUpVWQz9KUmPEerqGcgM9sEoppZSqTrVi/EPCg/9wSxsn9Lk5tWL/StOeZTd6/KO/9VPkZ9T0a714e2lNZ1E1t46ERZ5tazqNKhldsJu1u9JqOo1K69MukLeW1HQWVXPbKM7KnP/33dnz/fruS+WsPMbv/VzTWVTeTReeneX4le/PnnIMcNcY4cs//vYPvJ0xk847t3p0awttLCullFJKqUrTG/yUUkoppZRSgPYsK6WUUkqpqjjHbvA7t/ZWKaWUUkqpKtCeZaWUUkopVWki59aYZW0sK6WUUkqpSjvXnrN8bu2tUkoppZRSVaA9y0oppZRSqtL00XFKKaWUUkopQHuWlVJKKaVUVZxjY5a1sayUUkoppSpNh2EopZRSSimlAO1ZLpeITAMyjTEvlpreDFhojOnkrm1f3MdO6wgbBYWGb353cDTZlIkJ8oNJgzzwqSMcSXIyf5UDhxPqeMKEgR4E+lpXSH7f4WTTPqe7UiU2aiXL58/A6XTS6byJ9Bl+c4n5xhiWfz2DmKgVeHp5M+KqZwmN7EhGylGWzHmA7IzjIDY6nz+JHkOudVueJ3R5byYhFw8hPzGJld3HlBvT4eWphIwajCMnly03PET6pigAGo4YSIf/TkXsNg59MI/oF95ze74AWzf+wZz3XsLpdDJk+GWMmVDyOP2+fAmL5n8MQB1vH6677UGaNm9D0rEE3vnfNNJSkxARLhg5jpFjppyRnGN3rmTFiXLRbyK9yykXK+a7yoWnVS5CXOVi6ScPkJVxHBEbnc+bRPczUC7OxpyNMfy+YAYHdq3Ew9OboZOfoWHjjmXi0pPj+OmTe8nLSaNBRAeGTXkOu4cXKYn7+fWLhzl2OIq+o+6m25Ab3J7z2XaMAWJ2rGTZVzMwTied+0+k74iyOS+bN4OYHSvw8PLmon88S2iTjhQW5DH35atwFObjdDho030k/S+50+35no3H2BjDqgUzOLBzJR5e3gyrqCwnxfFjsbJ84RVWWa7s8tVl79bfWPTZTIzTSc9BExh0yU1l9ueHT2eyZ+tKPL28ufzGmYQ3s/L548ePWb9iHsYYeg2eyPkjz8wxdgeRc6uv9f/d3oqIvaZz+KtaRwj1/YVXvinguz8cjOlX/q6M6GlndZSTV74pIDcferS23sa+7Wwkphre/L6QD5YUMrKXHbub3mGn08GyedMZe+ssrn1kEbs3LCTp6L4SMbFRK0k9Fsv1j/3IhZOfYtmX0wAQm51B4x7i2qmLueLeL9jy22dllnWHuI/ms/aSGyuc33DUIHxbNWN5+xFsu+0xOr1u5YvNRsdXH2ftmBtZ0WU04VMuwa99S7fn63Q4+Oid5/nPE6/w3Otf8MdvSzl8cH/JnEPDmTrzbWa++hljJ9/AB288A4DdbufKf97Fc298yRPPf8DPP8wrs6xbcnY6+HXedMbeMotrHl7E7o0LSYovWy5SjsVy3aM/MmzKU/wybxoANpudQWMf4tpHFjPlni/YsuqzMstqzpaDu1aSevwAVz64lMETprNy/pPlxv256EW6DLqWKx9cSh2fAHau/RqAOnUDGTD2UboN/qfbc4Wz8xg7nQ5+/nI642+fxfWPLWLX+oUcL1VPxeywcr5h2o+MuPIpfppr5Wz38GLSnR9x7SPfcc0j3xIT9RtHYja7Pd+z7RiDVZbTjh3gqoeWMmTCdFZ8XX5Z/mPRi3QddC1XPVSyLFd2+ergdDr4fs5TXHPvu9wx83u2rllE4uGSx2nv1pUkJRzg7ueWcNl1T/L9x9MBSIjbw/oV87jl8S+5/alv2b1lOUnxsW7LVVWvGm0si8hTInJXsdczROROEfmPiKwTka0i8mSx+d+KyAYR2SEiNxebniki00VkDXBeBdt6VkSiXOt80TWtqYj84pr2i4g0KWe5niKyRUT+AG6vzv0vrV2kjc37rZ7guOMGby/Bz6dsXPMwG1EHrLjN0U7aR1pvozFW7zKAlyfk5IHTTR3L8Qe2EtSwKUENIrF7eNG2x2iit/1SIiZ62y+07zMWEaFR827k5aSTmZaIX2AIoZHWN20vbz+CQ1uQmZbgnkSLSV61noLktArnh146jMOffAtA6poteAYGUCesIUF9upAdfYCcmDhMQQFHvlhE6Jhhbs83eu8OQsMaExIWgYenJ/0GjmDD2pUlYtq074KvXwAArdp2IiUpEYCg4AY0a9kOAJ+6voQ3bk5y8jG35xx/YCuBDZsS6CoXbcorF9t/oX1vV7lo1o38nHSy0hLxDQwhpHS5SHV/uTgbc47d8Qtte16GiBDWtBt5uelkpSeWiDHGcHjfn7TsPBKAtj3HErvjZwDq+tUnJLIzNvuZubh4Nh7j+Nit1CtWx7XrOZrorSVz3rf1Fzr2tXIOL1bHiQhe3r4AOB2FOJ2FCO4d43k2HmOAmB2/0LZXUVnOP1VZ7mKV5Xa9xhKz/edKL19d4vZvpX5oE4JDIvHw8KJz34vZuWlZiZidm5bRrb+VT2SrbuRkp5ORmsixI/uJbNkVrzo+2O0eNGvbm6iNP7slzzPCJu75q6Vqumf5feBaALH69KcACUBroA/QDegpIoNc8f80xvQEegF3ikh913RfYLsxpq8xZlXpjYhIMDAO6GiM6QI87Zr1OvCxa9qnwKvl5PghcKcxptxGeHUKqCukZRUNu0jPNgTULVl46taB3HxwusLSsgz+da3/r9nlpGGg8J+Jntx+qSeL1xZSdhBH9chMTcA/KOzka7+g0DIN3sy00jFhZWLSkuI4dngnYU27uinTyvMODyUnLv7k69zD8XhHhJYzPQHviFC355OSdIzgBkXbCa4fQkpSxQ3e5T99R5ceZYvpsYQjHNi/m1Zt3Hdp8oSsUu+5f1AoWaXe86zSZSewgnIRt5OwZu4vF2dlzukJ+AU1KpFP6Zxzs1Px8gk42SC2Pn/uaUScztl4jDNSE/CvV7KOy0g9dR3nHxR2spHpdDr4aOZlvPng+TRtdz6Nmrs357PxGIOVd/Gy7FuJsuwbFEaWqyxXZvnqkp6SSGBw0fELrBdKRkpCqZiEUjFhpKckEtK4NbG715OdmUJ+Xg57t64kLSmes5XYbG75q61qdMyyMSZWRJJEpDsQCmwCegMjXP8H8MNqPK/EaiCPc02PdE1PAhzA16fYVDqQC8wSkUXAQtf084DLXf+fAzxffCERCQSCjDErisVcVNFGXL3dNwO88847UOe6U6RU3vJlp5kqtHZbRQhHUwwf/lhIsD9cO9yTA98XkFdQpTQqqWxiZX4rvpzki/eu5OdlsfD9Oxl8+SPU8fGr9gyrqrzfujfG/P035i8y5R7j8mOjtq5n5c/f8egz75aYnpuTzavPPcRVN96LT133H2NT7nEpmXR5+1V8x/Lzslj0gatceGvO5Skv5Up9/mqo4+ZsPMaVqePK3S9XjM1m59pHFpCbnc6Cd2/n2JE9NAxv45ZMK8yl1h/jCqrSSpTlE7tWqeWrSyWOcQUfTkLCWzLw4huZ/cINeNWpS1hkO2z2s3bU6DmnNtzgNwu4DggDPgCGAc8YY94pHiQiQ4ALgfOMMdkishzwds3ONcY4KtqAMaZQRPq41j0F+DcwtLzQUq+lnGkVMsa8C5xorZjHP8o/7TJ92tro2cb6NnX4uCHQt2iTAXWFjJySm8/OA28v62qF00Cgr5CRbc3r0crOb9usw5CcASmZhgaBwuHj1d+w8wsKIyO16FtxZmoCvgEhp4mJxzfQinE4Clj4/p206zWG1l1HVHt+f0XO4Xh8GoeR4nrtHRFG3pFEbF6e+DQu6inwjggl94j7e+iC64eQfLyo1yI5KZGg4IZl4g7G7uX9N2Zw/+P/wz8g6OT0wsJCXn32Qc4fPJLe513g9nyh7HuekZpw8j2vKCYzLR6/gGLl4gOrXLQ6Q+XibMl5+++fErVmHgAhkZ3JTD1aIp+6pT5/3r71yM9Jx+koxGb3sD5/pWLOlLPlGBfnHxRGRkrJOs6vVM7+ZfYrvkyMd90AIlv3JTbqN7c2ls+mY7ztFGU5K61sOS1dlrOKlWW/oNDTLl9dAoJDSUsuOn5pKQn41wspFRNWKiaegCCr3u45eAI9B08A4KevXiagnvuvULqLPjruzPsGGIXVo7zU9fdPEfEDEJEIEQkBAoEUV0O5HdCvshtwrSvQGPMDcDfW8A6A1ViNZ4CrgBJDOIwxqUCaiAwoFlOt1u528tb3hbz1fSG7Djrp1sJ6Sxo3EHILDJk5ZZeJiTd0aGrFdWtpY+cha2ByapahRSNruq83NAgUUjLc0wMa1qQzKcdiSUs6hKMwn90bF9Gic8nvHy06D2Xn2m8xxnA0ZjNe3v74BYZgjOGnz6YSHNqCnkOvd0t+f0Xi98uIuHosAEF9u1KYnkFe/DHS1m3Dt1UzfJo1Rjw9CZ88moSFy069smrQonUH4o8eIjHhMIUFBfz524/06DOwRMzxY/G88syD3HL3kzSKaHpyujGGWa89RXhkcy66rNqLbYXCmnQmtVi52LNxES07lSwXLTsNZec6V7mItcqFr6tc/Py5VS56XHDmysXZknOn/lcx6d5vmXTvtzTvNIzdGxZgjCH+wGbqePuXaSCICOGt+hK9bSkAuzd8S7OO7h9rX56z5RiXyLlpZ1ISY0k9buW8a8MiWpaq41p2GcqONVbOR2I2U8fHquOyM5LJzU4HoCA/lwO7VxMc2sK9+Z5Fx7hz/6uYfO+3TL73W5p3HMbu9UVl2auCshzRqi/RW62yvGu9tRxAsw5DT7t8dYlo3pmkhAOkHIujsDCfbWt+oF33kh0R7bpdwObfrXwO7duMt48//kFWPpnpSQCkJh0hav1PdOk32i15qupX4z3Lxph8EfkVSHX1Dv8oIu2BP1yXvDKBq4ElwK0ishXYDfxZhc34AwtExBurt/ge1/Q7gQ9E5D/AMaC8WuJ6V0w2VkPebfYcNrRubLj7cs+Tj4474ephHixYXUhGDvy0oZCJgz0Y1t3O0WTDxr1W3IotDsYN8OD2S6239ccNDrLz3JOrze7B0AmPM//NGzFOBx37jadBo9ZsWfU5AF0HXEHzDoOJ3bGCD6cPx8PLhxFXzQTgyP4N7Fy3gAbhbfjkucsA6H/JvTTvONg9ybp0m/MS9Qf3watBPYbGrGDv9NcQT+tYHXx3LomLV9DwosEM2fUTjpwctt74CADG4WD7XdPps2gWYrcTN/trMqPcf6e43e7BNTf/hxem3YnT6WTQsDE0btKSXxZbI46GXTSeb+fOIjMjjY/eec5axmZn+n8/Zs/OLfy+fDGRTVsx9W6rsTzx6n/RrVd/t+Zss3twwfjH+eatonJRv1FrtrrKRZcBV9Csw2BiolYw+ylXubiyVLlo1IZPnneVi9HuLxdnY85N2g3mwM6VfPbsCDy8vLlg0syT8xa9fzNDJjyFb2Ao5118Pz99ei9rl7xCg4j2tO9j9Wplpx/jq1cnkJ+biYiNras+Zsr9i/By06X3s/EY2+weDJv0OF+/cSNOp4PO542nQXhrNv9m5dxt4BW06DiYmB0rmDVtOJ5ePoy62so5Kz2RxR8/hNPpwBhD2x6jaNnZvVd3zsZjDNC0/WAO7lrJp8+OcD0GsagsL5x1MxdMtMpyv9H389Mn97JmySs0jGhP+74TTrt8dbPbPbjk6kf56MUbcTqd9Bh4OaERrVm7bC4AfYZOoU3XwezZupKXHxiJZx1vLr+hKJ+5r99FdmYqNrsHl1zzGD6+gW7L1e3OsUfHSfnjnM5gAtaNfRuBicaYvTWaTPWq1DCM2mL6tV687davAtXv1pGwyLNtTadRJaMLdrN2V8VP5Kht+rQL5K0lNZ1F1dw2irMy5/99V7N1cVXcfamclcf4vbPo4QM3XXh2luNXvj97yjHAXWOEL/9w3+8RVLdJ59WO8Q9pL97lljc68P5XasX+lVajPcsi0gHrZrtv/p81lJVSSiml/l8618Ys1/TTMKKAah3IJSLfAM1LTX7QGHOW9ZsqpZRSStVCtfgxb+5Q42OWq5sxZtzpo5RSSimllDq9/3eNZaWUUkop5T7l/S7B/2fnVj+6UkoppZRSVaA9y0oppZRSqvJ0zLJSSimllFLlO9eehnFufTVQSimllFKqCrRnWSmllFJKVd459gt+59beKqWUUkopVQXas6yUUkoppSrvHBuzrI1lpZRSSilVaaLDMJRSSimllFIAYoyp6Rz+v9IDq5RSSqnqVCvGP2S996hb2ji+Nz1dK/avNB2G4UYz5jpqOoVKmzrFzv1vZdd0GlXy4m11WbsrrabTqJI+7QJZ5Nm2ptOotNEFu5m7+uz63jflfOGbtWfPZw9gXB87328orOk0Km1MTw9ufS6lptOokrcfrMcDb+fUdBqV9vytPsz84uwqx49MtvPd+rMr50t72Xnv55rOovJuurCmMzg3aWNZKaWUUkpVmpxjv+B3bu2tUkoppZRSVaA9y0oppZRSqvKkVg4tdhttLCullFJKqcrTYRhKKaWUUkop0J5lpZRSSilVFefYMAztWVZKKaWUUqoC2rOslFJKKaUq7Vx7dJw2lpVSSimlVOXJudVYPrf2VimllFJKqSrQnmWllFJKKVV5Nr3BTymllFJKKUUt71kWkenASmPMz9WwrmbATmB3scn/NcZ8LCKZxhi/YrHXAb2MMf8WkWnATcAxwAt4yhjz+d/NpyIjeggtGwkFDli4xkl8StmYQF8Yd74NHy+ITzEs+NPgdEKTEJg4wEZalhW3K86waodxV6oAXNbfk/ZN7eQXwhfL8jh8vOz2+nfyYGAXDxoE2nj8w2yyc63pDYOEyRd40bihjcVrClixpdCtuQJs3fgHc957CafTyZDhlzFmwrUl5v++fAmL5n8MQB1vH6677UGaNm9D0rEE3vnfNNJSkxARLhg5jpFjprg93y7vzSTk4iHkJyaxsvuYcmM6vDyVkFGDceTksuWGh0jfFAVAwxED6fDfqYjdxqEP5hH9wntuzxdg77bfWPzZDIzTSY9BExg4+uYS840xLP5sBnu3rsTTy5uxNzxDeLOOAKxeOpuNK79CRAhp3JqxNzyDp2cdt+e8e+tvfD/nGYzTQe8hExgy5qYS8xOP7Oer96ZyODaKkRPuYtDof56cN++9qezatAK/gGDuefY7t+cKsGvLbyz4+FmcTgd9LxjP0EtL5Xt4P1+88yhxsVFcNOkuhlxyPQAF+Xm8Of0aCgvzcTocdOk7gpET/n1GcgaYNMyHTi09yS8wfPRDNocSHGVihvSow9BedQipZ+e+V1PJyrHqlOF96tCngxcANpvQqL6N+19LIzvXvXXcpf09adfERkEhfPlrfrl13Pkd7Qxw1XHTZueUqOMmDfEioqGwZG0hK89AHTe8u3UOKXTA92udJFRwDhl7XtE55Ls1rnNIQ5hQ7ByyO86wKsq9x3fXlt/4bs4zOJ0O+gyZULYsH9nPF+9Yn71Rk+5iiOuzl5p0lLlvPUxG2nFEhL5DJzFw1D/cmitAzI6VLPvKqt86959I3xFl67dl82YQs2MFHl7eXPSPZwlt0pHCgjzmvnwVDtdnr033kfS/5E635+suco6NWa61jWURsRtjHq/m1UYbY7r9heVeNsa8KCKtgQ0i8pUxpqCac6NlIwj2E95a5CS8PozqZWP2T84ycUO7Cmt3G6IOGi7qJXRrIWzcZ1Voh47Bl7+VXcYd2jWx0TDIxrOf5dIk1Mb4QV68Oj+vTFxMvIOoAw5uu7Rkoycnz7BgVQEdm9vPSL5Oh4OP3nmeB598neD6ITx+/7X06DOQiCYtTsY0DA1n6sy38fULYMuG1XzwxjM8+eKH2O12rvznXTRr2Y6c7Cwev+8aOnXtU2JZd4j7aD6xb35Ctw+eK3d+w1GD8G3VjOXtRxDUtyudXp/G6v6TwGaj46uPs+ai68mNS2DAn1+RsHAZmTuj3Zqv0+lg0ZzpXHP/BwQEh/Lu9Im07TaUkIhWJ2P2bl1JUsIB7nx2KXH7t7BwzpPc/NiXpKcksObnOfx7xiI8vbz58s272b5mEd0HXO72nBd89DQ3PDiLwOBQXn98Mu17XEBosZzr+gYy5h+PELXhlzLL9xw4jvOHX8WXbz/k1jyL5/vNhzO4+eH3CKwfyiuPTqZDjwsIa1yUr49fIJdd+zA71i8rsayHpxe3PvoBdbx9cRQW8PqT/6Bd14E0bd3V7Xl3auFBSLCdx99Np3m4nStH1OW5ORll4qLjCtm2r4B7r/QrMf2ntXn8tNaqXzq39GRY7zpubyi3a2KjQaDw/Od5NAkRxg304vVvytZxsfFOdh7M55ZLvUpMz841LPg9/4zVcS0bQbC/8PYPrnNITxsf/VzOOaSLsG63IeqQYVRPoVtzYWO06xxyHOadoXOI0+ngm9lPc/PD1mfv1ccm07HHBYQ2LvnZG3vNI2wv9dmz2Ty45KoHaNy8A7k5Wbzy6ATadDqvxLLuyPfnL6cz8Y4P8Q8K5ZPnJ9Cy81AaNCraZsyOlaQci+WGaT9yNHYLP82dxtUPzMPu4cWkOz/Cy9sXh6OAz1+6kuYdBxHevJvb8nUrHYbhfiLSTER2ichHIrJVRL4SkboiEisij4vIKmCiiMwWkQmuZXqLyGoR2SIia0XEX0TsIvKCiKxzrecWd+ZtjNkLZAP13LH+NhHC1lirwjqSBN6e4OddNq5ZqLDzkBW3NcbQJqJmCm3HZnbW77Z6Sg4mOPGuI/jXLRt35LghJaPsSS0zBw4dc+I8M/Uy0Xt3EBrWmJCwCDw8Pek3cAQb1q4sEdOmfRd8/QIAaNW2EylJiQAEBTegWct2APjU9SW8cXOSk4+5PefkVespSE6rcH7opcM4/Mm3AKSu2YJnYAB1whoS1KcL2dEHyImJwxQUcOSLRYSOGeb2fA/v30pwSBOCQyLx8PCiU5+L2bWp5Elu16Zf6Hb+ZYgIkS27kZudTkaqdZydDgcF+bk4HIUU5OfgHxTi9pwPRW+jfmgT6rty7trvIqI2lGxk+gXWJ7JFZ2z2sv0LLdr1wsc30O15nnBw3zbqh0ZSP9TKt9t5F7Njw68lYvwD69OkZdl8RYQ63r4AOByFOB2FZ+zHBbq09uLP7VZDM+aIA586QoBv2W0fSnSQlH7qSqF3By/W78x3S57FdWhmZ+Meq/f7YKLBpw7l13FJ5ddxWbkQd8ycsTquTYSwrdQ5xLecc0jTUGFnnBW3LbbmziEHo7fRoNhnr1u/i9hR3mevZWfspcpyQL2GNG7eAQBvH19CwluQlpLo1nzjY7dSr2FTghpEYvfwol3P0URvLVm/7dv6Cx37jkVECG/ejbycdDLTEhERvFyfPaejEKezEOHcanBWBxEZJSK7RWSfiJTbQyEiQ0Rks4jsEJEV1bHdmuxHbwu8a4zpAqQD/3JNzzXGDDDGzD0RKCJewBfAXcaYrsCFQA5wA5BmjOkN9AZuEpHmp9hmS9cBPPE3sCoJi0gPYK8xxi2fSH8fIT27qMJNzwF/n5IxPl6Qmw/GlB8T0QBuHGljyiAbDQLckWWRQF8bqZlF+aZlGgJ9a++lmZSkYwQ3CD35Orh+CClJFTd4l//0HV16nFdm+rGEIxzYv5tWbTq6Jc+q8A4PJScu/uTr3MPxeEeEljM9Ae+I0PJWUa3SUxIIDG508nVgcBgZKQklYjJSEwgoFhNQL4z0lAQC6oVy/qh/8vL9Q3nx7oHU8fGnVacBZyjnsBI5p7v5pPt3pKUkEFS/6PgFBYeSlpxwiiVKcjod/Pfhy5l260Badz6Ppq26uCPNMoL8hJRijeDUDCdB/lWvLzw9oGNzDzburvaLe2UE+kqJOi410xBYTgO/tvArdQ7JqMw5JLvkF4CI+nDDSBuTz8A5JD05gaD6JT97f6XBm3zsMEcO7KRJS/eW5YzUBPzrFeXrFxRKRmrJz15mWgL+QUUx/kFhZLpinE4HH828jDcfPJ+m7c6nUXP3X9FxG7G55+9UmxSxA28AFwEdgCtEpEOpmCDgTeBSY0xHYGJ17G5NtmwOGWN+d/3/E+DEWfGLcmLbAkeNMesAjDHpxphCYARwjYhsBtYA9YHWp9hmtDGmW7G/304RW7yb4B4R2e3axrSKFhCRm0VkvYisf/fdd0+x6oqWP3USFcWcEJ8Mr3/vZNZSJ+v2Opk40L1vb7n5GvdeFv07TJmjWfHxjNq6npU/f8fka0uO58zNyebV5x7iqhvvxaeuX/kLn0FSzg4YYyp6c85ARuUolUt5aYgIOVlp7N70C3c//zP3v7ySgrwctqx2/xjgcsts7W0Pla0UKL8cVMRms3PvM/N57PVlHIrextFDe6sxuYqVm+NfKJJdWnkSfbjQ7UMwKlKLq7hKFdtTVQ3xKfDGQifvL3Wyfq+TCQPcew6pSp1ckbzcLD7+311c+o+H8XZ7nVxevqXrt3I/oID12bv2kQXcMmMF8bFbOXZkj1uy/H+sD7DPGLPfGJMPzAUuKxVzJTDfGHMQoLo6N2tyzHLpEnXidVY5sVJO/Inpdxhjlv7NXHJExMt18AGCgePF5p8Ys3w58LGItDTG5JZeiTHmXeBEK9nMmFv25pXSerYSure0PkhHkg0BdYt2NcDHGqpQXHYeeHtZnz1jrJgMV0x+sXtHoo+CzWb1IuRU49XK8zt60LeDVWwOJToJ8iuqKAL9SvZq1DbB9UNIPl7UC5CclEhQcMMycQdj9/L+GzO4//H/4R8QdHJ6YWEhrz77IOcPHknv8y44EymfVs7heHwah3HiHh7viDDyjiRi8/LEp3FR74Z3RCi5R9zfWxpQL5S05KMnX6clx5cZShFQL5T0YjHpKVbM/qg/CGrYGN+AYADa9xzOoX2b6Hr+pW7NOTA4jLTkol74tOR4As7A8I+/KjA4lNSkouOXmpxAQL2q5+vjG0DL9n3YvWUVjSJP1cfw1w3uXocBXa1xvAfiHdQLsMFhq14M8reRmln18Qm923uxLsp9QzDO62inb3tXHXesZB0XVAvruJ6trPtWoOw5xL/Y+eGEMueQukXnmdLnkJE9q/8cUlxgcBipSX/9s+coLODj/91N9/6X0Ln3cHekWIJ/UBgZKUX5ZqYm4BcYUjYmtSgmIzW+TIx33QAiW/clNuo3Goa3cW/S7nKGhm+VEgEcKvY6DuhbKqYN4CkiywF/4BVjzMd/d8M12bPcREROXOO+Alh1ithdQLiI9AZwjVf2AJYCt4mIp2t6GxHx/Qu5rACudq3DB5gE/Fo6yBgzH1gPXFt63l+1YZ9h1lKrN3hPnKFLM6sAhteHvALILNMkhwMJ0D7SiuvSXNh72KoYi49NCw+2vklUdyW3ekchL8/L5eV5ueyIKaRXW+uk0iTURm6eISO7erdXnVq07kD80UMkJhymsKCAP3/7kR59So7EOX4snleeeZBb7n6SRhFNT043xjDrtacIj2zORZdddaZTr1Di98uIuHosAEF9u1KYnkFe/DHS1m3Dt1UzfJo1Rjw9CZ88moSFy069smoQ3rwzyYkHSDkWR2FhPtvX/kC77kNLxLTrPpTNqxdgjOFQ9Ga8ffzxDwohMLgRcdFbyM/LwRjD/qg/aBDu3hsoARq36ERS/AGSE62ct/y5mA49aseXofJEtuzE8fiDJLny3fzHD3TsWbl8M9OTyclKB6AgP5e92/8gJPxUI9f+nhWb8pgxO4MZszPYvCeffp2sm3ybh9vJzTOkZ1Wt4entBa0jPdiyz31DMP7Y4eB/X+Xxv6/y2BHjoEcb6+a8JiFCTj61ro7bsM/w/o9O3v/RyZ7Dhs6lziFZ5Z1DEqF9YyuuczNhz5Gy55BGbjqHFBfZohPHi332Nv+5mA6VLMvGGL587zFCIlow+OLr3JdkMWFNO5OSGEvq8UM4CvPZtWERLTuXrN9adhnKjjXfYozhSMxm6vj44xcYQnZGMrnZRZ+9A7tXExzq/vrtbFP8Cr3rr/jjRsproZeuRDyAnsBoYCTwmIj87W8kNdmzvBO4VkTeAfYCbwF3lBdojMkXkcnAa67GbA7WuOVZQDNgo1jXQo4BY0+xzZauIRsnfGCMeRW4C3hHRO7EejM+NsasLG8FwHTgMxF5zxhTrbdt7DsKLcMN/7rEekzRwjVFq588yMaitU4yc2HZFifjzrcxuLOQkAKb91tx7SOFHq0EpxMKHfDNavfeVbLzoJN2TZ08dKU3BYXwxa9FteoNF9dh3vJ80rMNAzp7MKSbB/51hfsmebProJN5y/Px94G7Jnjj7SUYAwO7ePDC3Fzy3HQetNs9uObm//DCtDtxOp0MGjaGxk1a8svirwEYdtF4vp07i8yMND56x3r6hN1mZ/p/P2bPzi38vnwxkU1bMfVuq7E88ep/0a1Xf/ck69JtzkvUH9wHrwb1GBqzgr3TX0M8rY/twXfnkrh4BQ0vGsyQXT/hyMlh642PAGAcDrbfNZ0+i2Yhdjtxs78mM2qfW3MF6xhffNVjzHnpBpxOJ90HjickojXrfrVuQeh9wRRadxnMnq0reeXBEa5Hx80EoHHLrnToNYJ3pl2Oze5BWJP29Bo8+YzkfOk1U/nghZtwOp30GjSO0Mat+fMXK+d+w6aQkXqM1x6fRF5OJmKzsWrpHO597nu8ffz4/I372b9zLVmZqcy88wKGX/5veg8Z79Z8x103lfeevRnjdNJ7yDjCGrdi9c/WCLbzL5xMeuoxXnl0Mrk5mYjY+G3JHP7z/Hekpx5j7luPYJxOnMZJ134j6dBjiNtyLW77/kI6tXTw1M0B5BfCRz8UXUT89wQ/5izJIi3TcEHPOozo602Ar/DY9QFs31/AJ0usFmr3Nl5ExRaS7/7hygDsOuikXRPDg1fUIb8Q5i0vquP+ebEXXy3PJz0b+neyM7ibJ/514d6J3uw66OCrFQX4+cCd473x9rJ6cQd09uClL9xXx0UfhVaNDLeNdp1D1hadAyYNtPHDOusc8usWJ2PPszGos5CQCltc55B2jV3nEGOdQ779w73nELvdg7HXTeW956zPXp/B4whr3Jo/frY+e+ddOIX01GO8+ugkqyzbbKxaPIf7n/+eo4d2s3HVd4RFtuG/D48D4KLJd9O+22C35WuzezBs0uN8/caNOJ0OOp83ngbhrdn8m/U02W4Dr6BFx8HE7FjBrGnD8fTyYdTVVv2WlZ7I4o8fwul0YIyhbY9RtOxce7+Un5bNPX2tpa7QlxYHRBZ73Rg4Uk7McWNMFpAlIiuBrsDfGvMiNTHG1PXM44XGmE5nfONnTqWGYdQWU6fYuf+tWtZlchov3laXtbsqflJEbdSnXSCLPNvWdBqVNrpgN3NX167Lzqcz5Xzhm7Vnz2cPYFwfO99vcP8zeKvLmJ4e3PpcOQ/wrcXefrAeD7ydc/rAWuL5W32Y+cXZVY4fmWznu/VnV86X9rLz3t/+JYcz56YLa8cdFbnzX3HLicH78rsq3D/XiII9wDDgMLAOuNIYs6NYTHvgdaxeZS9gLTDFGLP97+RVa5+zrJRSSimlFIAxplBE/o01BNeONTpgh4jc6pr/tjFmp4gsAbYCTmDW320oQw01lo0xsYBbepVFpDMwp9TkPGNM6UHgSimllFKqqmroR0mMMT8AP5Sa9nap1y8AL1Tndv/f9SwbY7YB3Wo6D6WUUkopdfb7f9dYVkoppZRSbnSaHxD5/0Yby0oppZRSqvJq5jnLNebc+mqglFJKKaVUFWjPslJKKaWUqjw3PWe5tjq39lYppZRSSqkq0J5lpZRSSilVeefYmGVtLCullFJKqco7x56GcW7trVJKKaWUUlWgPctKKaWUUqry9AY/pZRSSimlFIAYY2o6h/+v9MAqpZRSqjrVijvrcpe+75Y2jvfIG2rF/pWmwzDcaMnm/JpOodJGdfNizC07azqNKvn+nfa8taSms6ia20bB3NVnz/eoKecLizzb1nQaVTK6YDeruvao6TSqZMCWjTz/tbOm06i0B8bbGH3j9ppOo0oWzerEZbftruk0Km3BW22ZeE9MTadRJfNebs6L88+ecgxw/+U2Zsx11HQalTZ1ir2mUzgnaWNZKaWUUkpV3jn2NAxtLCullFJKqco7x56zfG59NVBKKaWUUqoKtGdZKaWUUkpVnj46TimllFJKKQXas6yUUkopparAnGNjlrWxrJRSSimlKu8cexrGubW3SimllFJKVYH2LCullFJKqcrTnmWllFJKKaUUaM+yUkoppZSqAr3BTymllFJKqYqcY8MwtLFcS+zcvIr5s5/D6XTQb+jlDB97Y4n5CYf389lbj3EoZieXTLmToWOuOznvyX+PpI53XWw2Oza7nfuf+eKM5X3z5FB6dvIjL9/JK7OPEn0ot0zMff8Mp1VTbxwOw57YXN745CgOJ4wbEcyQPoEA2G3QuFEdrr5vD5nZTrflG7tzJSvmz8DpdNKp30R6D7+5xHxjDCvmzyAmagWent6MuOpZQiI7kpFylKWfPEBWxnFEbHQ+bxLdh1zrtjxP2LvtNxZ/NgPjdNJj0AQGji6b7+LPZrB360o8vbwZe8MzhDfrCMDqpbPZuPIrRISQxq0Ze8MzeHrWcXvOXd6bScjFQ8hPTGJl9zHlxnR4eSohowbjyMllyw0Pkb4pCoCGIwbS4b9TEbuNQx/MI/qF99yeL0DQ+efT4sH7EZudhG++Ie6D2SXm2/39aTP9CbwbR+LMz2PvE0+SvS+6KMBmo9vnn5CfeIyoO+5ye77GGP5cOJNDu1fi4eXNoPEzaRDRsUxcRnIcv869j7ycVOqHd2DwxOewe3hxIOoXNvz8KiI2bDY7fUc/TFiznm7P+5YrGtGrsx95+YaXP4gj+mDZ+uL+GxvTupkPhQ7DnpgcXp9zGIcD6vrYuP/GxjQM9sRuE+b/eJyff091e843TQqhZ0df8vINr3x8lP2H8srE3Ht9I1o19abQYdgbm8ubn8ZbddzwegzqHQCA3S40DvPimv/sc2sdd/24YHq0r0tegeGNz48RE5dfJubOqxvSMtKLQgfsO5jHu18ex1EspZaRXsy8O5yXP07kzy3ZbssVrLL8x/dFZXnwhPLLcnpyHMs+t8pyg/AODJlkleV9m75ny8pZAHh41WXA2Ceo36idW3MGGNFDaNlIKHDAwjVO4lPKxgT6wrjzbfh4QXyKYcGfBqcTmoTAxAE20rKsuF1xhlU7jNtzVn/dufXV4BRExF5T23Y6Hcz7YAa3PPwmD/93ARt/X0x8XHSJmLp+gVx+3cMlGsnF/fvxD3jg+a/OaEO5ZydfwkO8uOWxaN745Ci3XRVWbtzytWnc9sR+/j09Bi9PYcSAIAC++TGZu56O4a6nY/jo22Ns35Pt1pOI0+ng13nTGXvLLK55eBG7Ny4kKX5fiZjYqJWkHIvlukd/ZNiUp/hl3jQAbDY7g8Y+xLWPLGbKPV+wZdVnZZZ1R76L5kzn6nve4/YZC9m2ZhGJh0tuc+/WlSQlHODOZ5cy5rrpLJzzJADpKQms+XkOtzzxFbc//T3G6WT7mkVuzfeEuI/ms/aSGyuc33DUIHxbNWN5+xFsu+0xOr0+zZphs9Hx1cdZO+ZGVnQZTfiUS/Br39L9CdtstHzkQXb86w42jhtPw1Gj8GnRvERI5I03kLlrD5smTmbP1Mdp8cB/SswPv+oKsvfHuD9Xl7g9K0lPOsDE+5YwYOyTrF4wvdy4dUteomP/a5h431Lq+ASyZ/3XVr4t+zHujm8Zd8c3DLx8BqvmP+b2nHt19iM8xIubHtnLax8f5varw8uNW74mlVse3cvtT+yjjqcwcmAwAJdcUJ9DR/K448loHnohhhsnheFhd++l4J4dfWkU4smtT8Twxmfx3HZFaLlxK9am869pMdz5VCxensLwE3XcTyncM/MA98w8wJxvj7Fjr3vruO7tfWjU0JM7ZsbxzpfHuWlC/XLjftuQyV3PHOa+5w/j5SkM6+d/cp5N4OoxwWzeleO2PIs7tHslaUkHmHT/EgaMe5JV35ZfltcueYnOA65h8v1L8fIJZLerLPsHN+aSmz9m/F0L6DH0Nn6b/4Tbc27ZCIL9hLcWOflhnZNRvcpvSg3tKqzdbXhrkZPcfOjWoqi8HjoGs5Y6mbXUeXY2lEXc81dLnTONZRH5VkQ2iMgOEbnZNS1TRKaLyBrgPBG5WkTWishmEXnnRANaRN4SkfWuZZ+s7twO7NtGw9AmNAiNxMPDkx7nX8S2db+WiPEPrE/TVp2w22vPxYB+Xf1Z9mcaALtjcvH1sVEvoGx+G7Znnfz/3thcGtTzLBMzuHcAK9eluy9ZIP7AVgIbNiWwQSR2Dy/a9BhN9LZfSsREb/+F9r3HIiI0ataN/Jx0stIS8Q0MISTS6u3w8vYjOLQFmakJbs338P6tBIc0ITgkEg8PLzr1uZhdm0rmu2vTL3Q7/zJEhMiW3cjNTicjNREAp8NBQX4uDkchBfk5+AeFuDXfE5JXracgOa3C+aGXDuPwJ98CkLpmC56BAdQJa0hQny5kRx8gJyYOU1DAkS8WETpmmNvz9e/UidxDceQdPowpLOTYkqXUHzKkREzdFs1JW7sWgJzYWOqEN8Iz2GrEeYWEEDxwIAnffOv2XE84ELWMVt2t9z2kSTfyc9PJTk8sEWOM4cj+P2neaSQArXpcxoGdVvnxrOOLuE5MBQXZZ+Qk1a9bAMv+SAVg9/4cfOvaqRdYtr5Yvy3z5P/3xObQoJ4VY4zBx9s6Zfl428jIcuBwureR0aerH7/+adVLe2JyrZwDyvarbNhRqo4LKrtfA3sHsHJdhvuSBXp3qsuKddbx23sgD18fG0Hl5LtpZ1FDeN/BPOoXy3fUwAD+3JJFeqbDrbmecGDnMlq7ynLoqcpydFFZbtPjMmKjrLIc2rQ7dXysK5QhTbqSlR7v9pzbRAhbY62ydyQJvD3Bz7tsXLNQYechK25rjKFNRO1tDKpTO2cay8A/jTE9gV7AnSJSH/AFthtj+gJJwGSgvzGmG+AArnItO9UY0wvoAgwWkS7VmVhaciJB9Yt6ZYPqh5KWUpWGmPDWjFt44aFJrP55XnWmdkr1gzw4nlxw8nVSaiH161XcmLfb4IJ+gWzYkVlieh1PoUdHP1ZvdG9jOSstAf+gouPsHxRKVlrJ45yVWjLGLzCMzFIxaUlxHIvbSVizrm7NNz0lgcDgRidfBwaHkVGqXGSkJhBQLCagXhjpKQkE1Avl/FH/5OX7h/Li3QOp4+NPq04D3JpvZXmHh5ITV3RCyz0cj3dEaDnTE/COKL8nrzp5hTQkL75ou3mJiXiFlvxikbVnL/WHDQXAr1NHvBs1wivUyq3FA/cT8/Ir4HRfj2Fp2ekJ+AYWldO6AWFklWpg5GWn4uUdgM31Bds3IKxEeY/d8RNf/fdifvzoNgaOf9rtOdcP8uBYsfrieEpBiUZaaXY7XNAviA3brfpi4bJkIhvVYc6LbXljWive/fwoxs0dcvWDPDieUlj5nG0wpG8AG6OySkz38hR6dPDlj03ubSwHB3qQlFqUb1Kqg+DAii+a2m0wqJcfm3Zlu5a307dzXX5a7d48i8tKS8CvWJ3rG1h+Wa5TvCwHhpGdXvYcuXvd10S2GejehAF/HyE9u6jwpeeAv0/JGB8vyM3nZBktHRPRAG4caWPKIBsNAtyecvWz2dzzV0vV3syq350isgX4E4gEWmM1iL92zR8G9ATWichm1+sWrnmTRGQjsAnoCHQobwMicrOrB3r9u+++W+nETLk1fuW/gd49/WP+89yX3PrwW/y2dC77otZXetm/pZzeqFOdvG67Mozte7OJ2lfy8l7vrn7sjHbv5Ukrt9MfZ0M5McX2Mz8vi0Uf3Mngyx+hjrdfNWdYCaWOeXm7JCLkZKWxe9Mv3P38z9z/8koK8nLYsvq7M5TkqUm55caU37vp7taQldBptxv3wYd4BATQ7YvPCb9iCpm7doOjkHqDBlKQnEzWzp3uz7N4euWU09LHtbzyXjymWcfhTLj3By68+jU2/vRq9Sd5mvxO519XhbN9TxY79loNuR6d/Nh/KJd/3L+bO6ZHc+uV4Sd7mt2lvIxPVSJvvSKUHfvK1nF9uvixMzrH7XVcuYf4FAnfOKEBO6Nz2bXfGod93dj6fLIwBTd32Jdy6joXKld3H4lew+71X9Nn1H3VmFv5yq0yKhFzQnwyvP69NQRj3V4nEweefU0xI+KWv9qq9lzTdyMRGQJcCJxnjMkWkeWAN5BrjDlxrUmAj4wxD5datjlwP9DbGJMiIrNdy5ZhjHkXONFKNks2l72xojxB9UNJTSrq2UpNSiCwXuUvmQcGW7H+gfXp0mcYB6O306pDr0ovXxUXD6nHSNd4vL2xOTQI9oRo68RQP8iD5GK9GsVNuaQBgf4evPF2XJl5g3oFsnKte3uVAfyCwshILTrOGakJ+AaGnDImMy0evwArxuEoYOEHd9Ku1xhadR3h9nwD6oWSlnz05Ou05PgyQykC6oWSXiwmPcWK2R/1B0ENG+MbYA0VaN9zOIf2baLr+Ze6Pe/TyTkcj0/jME7cD+MdEUbekURsXp74NC7qYfKOCCX3SGL5K6lG+QmJ1Akr2m6dkBDyE4+ViHFkZbH38WknX/f6YSG5h4/QYNRIgocMpt6AAdjqeGH39aXNzKfZ88ij1Z5n1B+fsnv9VwA0iOhEVlpROc1Oj6euf8MS8d6+9cjPTcfpKMRm9yArPZ66AWXrlUbNe7My+RC5WSl4+9ar1pxHXxDMqIHWOvfE5tAwuGgIVoN6niV6QYu7YkxDAv09eH3OwZPThvevx7zF1vtyNDGfhOP5RDaqw56Y6h1be/HgIIb3ty7r7zuQe3IYyImcK6rjJo+uT4CfnTffLdvjObCXP7+td08dN7K/PxeeZ4053ncw39XzbTV+6wfZSU4vfzjFhJFBBPjZePHD4yentYz04u5rrHIU4Gune/u6OBzHWbe9em/y2/HHp+xaZ5Xlho07kVmszs1Ki8e3nLKcV7wsp5Usy0lHd7Ny/mOMuu6dai/DJ/RsJXRvaTXmjiQbAuoKJ5rIAT6QWaoYZueBt5fVaDbGislwxeQXK0LRR60OVR8vyKlck0HVgLPv68xfEwikuBrK7YB+5cT8AkwQkRAAEQkWkaZAAJAFpIlIKHBRdSfXpGUnjsUfICkxjsLCAjauXkynXkMqtWxebja5OVkn/79r62oaRbaq7hRP+mF5ysmb8v7cnMnQftZJpW1zb7JznKSklz2RjOgfRI8Ovrww63CZjsK63jY6tanLn1vcf9kvrElnUo/FkpZ0CEdhPns2LqJlp6ElYlp2GsrOdd9ijOFo7Ga8vP3xDQzBGMPPn08lOLQFPS643u25AoQ370xy4gFSjsVRWJjP9rU/0K57yXzbdR/K5tULMMZwKHoz3j7++AeFEBjciLjoLeTn5WCMYX/UHzQIb1HBls6sxO+XEXH1WACC+nalMD2DvPhjpK3bhm+rZvg0a4x4ehI+eTQJC5e5PZ+MHTvwaRJJnYhwxMODhqNGkrxiRYkYu78f4mE1mkIvH0f6xo04srI48OrrrBtxEesvvoTdDz5M2rr1bmkoA3Q47yrG3fEN4+74hqYdhrFvk/W+Jx7cjKe3f5mGsIjQqEVfYrYvBWDfxgU0aW+Vn/SkAyd7644f3oHTUUCdukHVnvOiX5O5Y3o0d0yP5s9N6Qw9z9pG2xY+ZOU4SEkrp74YWI+eHf15/t1DJeqLxOR8ura3ruYEBdiJCKtD/LHqb138sCL15E15f27J5IJ+1jXyNs29rZzLaXwO7x9Ij/a+vPRB2aEhdb1tdGxdlzVbMsssVx2W/p7Bf148wn9ePMK67VkM7m0do9ZN65CdY0gtJ9+hff3o1taHV+YcK5Hv7U/HcftT1t+fW7KY9XX1N5QBOp53FePv/Ibxd35Dsw7D2OsqywkHrTq3vLIcXqws79m4gGauspyZeoSfP7mTCyY9R1DD5mW2VV027DMnb8jbE2fo0sxqOIfXh7wCyCz7YBcOJED7SCuuS3Nh72HrYPsW624LD7Z66s66hrLY3PNXS50TPcvAEuBWEdkK7MYailGCMSZKRB4FfhQRG1AA3G6M+VNENgE7gP3A79WdnN3uwfh/PsJbM2+1Hh03ZByNIlux6qcvARgwfBLpqcd58eHJ5OZkYRMby3+YwyMvLSAzI4X3X7wbsJ6e0LP/xbTvdmbGpq7fnkmvzr68+3RL69FxHxX1cD7x70hem3OU5LRC/nVVGInJBbzwYDMA/tiUwdxFVm/Ged392RSVSV6++6/72eweXDD+cb5560aM00HHfuOp36g1W1d9DkCXAVfQrMNgYqJWMPup4Xh4+TDiypkAHNm/gZ3rFtCgURs+ef4yAPqPvpfmHQe7LV+73YOLr3qMOS/dgNPppPvA8YREtGbdr3MB6H3BFFp3GcyerSt55cERrkfHWfk2btmVDr1G8M60y7HZPQhr0p5egye7Ldfius15ifqD++DVoB5DY1awd/priKdV1Rx8dy6Ji1fQ8KLBDNn1E46cHLbe+AgAxuFg+13T6bNoFmK3Ezf7azKj3PvEEQAcDqKfeY5Ob70BNhsJ335HdvR+wiaOByB+3tfUbd6CNk9PxzgdZO+PYe8T1X6fb5VEth1M3O6VzHtpJB6e3gwcP/PkvKWzb2bA5U/jGxBC71H38evc+9jw06vUD29P214TAIjZ/iP7Ni3AZvfE7lGHC6b8t8rDJKpq3bZMenX2Z9bMNuTlO3n5w6KrTNPuasqrsw+TnFbIv68OJzGpgJcetr7crd6YzucLjzH3+2Pc88/GvDGtFQjM/jre7TehbdieRa9Ovrw9vTl5+YbXPi6q4x67PYI3PoknOc3BbVeEkphcwHP/aQLAn5sz+eKHJAD6dfNj886sM1LHbYzKoXv7urw2tTH5+YY35hZdIXn4plDe/uI4KekObp7YgGMphcy4y7rfYc3WbL76MdXt+ZUnsu1gDu1eyRcvWmV58ISisrzkw5sZON4qy30uuo9ln9/H+h9dZbm3VZY3/vImudmprHI9EcZmszPu31+5Ned9R6FluOFfl9goKLQeHXfC5EE2Fq11kpkLy7Y4GXe+jcGdhYQU2LzfimsfKfRoJTidUOiAb1afufsd1F8j5Y8FUtWg0sMwaoNR3bwYc8uZHXf5d33/TnveWlLTWVTNbaNg7uqz5zM35XxhkWfbmk6jSkYX7GZV1x41nUaVDNiykee/PntOmA+MtzH6xu01nUaVLJrVictu213TaVTagrfaMvGeM/c4wuow7+XmvDj/7CnHAPdfbmPG3DPz5I/qMHWKm5+XWEmZf37nlhOZX79La8X+lVZ7+7yVUkoppZSqYefKMAyllFJKKVUdavGTK9xBG8tKKaWUUqrSTC2+Gc8dzq29VUoppZRSqgq0Z1kppZRSSlXeOTYMQ3uWlVJKKaWUqoD2LCullFJKqco7x8Ysa2NZKaWUUkpVmtFhGEoppZRSSinQnmWllFJKKVUV59gwjHNrb5VSSimllKoC7VlWSimllFKVZji3xixrY1kppZRSSlWa/oKfUkoppZRSCgAxxtR0Dv9f6YFVSimlVHWqFeMfUjcvd0sbJ6jbkFqxf6XpMAw3Wr49p6ZTqLQhnXwYNG5VTadRJSu/GcBbS2o6i6q5bRR8s9ZR02lU2rg+dlZ17VHTaVTJgC0bWeTZtqbTqJLRBbt55suzp1w8PMnOgDErajqNKln1/WAGX766ptOotBXzz2fEPzbVdBpV8uOc7jz3lbOm06iSByfYeHR2fk2nUWlPX+dV0ymck7SxrJRSSimlKk1/lEQppZRSSikFaM+yUkoppZSqgnPtaRjaWFZKKaWUUpWnwzCUUkoppZRSoD3LSimllFKqCs61YRjn1t4qpZRSSqmzkoiMEpHdIrJPRB46RVxvEXGIyITq2K72LCullFJKqUozNfDbKCJiB94AhgNxwDoR+c4YE1VO3HPA0uratjaWlVJKKaVUpdXQMIw+wD5jzH4AEZkLXAZElYq7A/ga6F1dG9ZhGEoppZRSqsaJyM0isr7Y383FZkcAh4q9jnNNK758BDAOeLs689KeZaWUUkopVXluenScMeZd4N2KtlreIqVe/w940BjjkGrMURvLSimllFKqtosDIou9bgwcKRXTC5jraig3AC4WkUJjzLd/Z8N/qbEsIrcC2caYj//Oxqu4zc+BjsCHxpiXz9R2z5Ttm37nyw+ex+l0MmDYOEZd/s8S8+PjYpj9xhMc2r+Ty678NyMuu/bkvJ+/n8Oqn79BRIho0ppr//0knl51zkjed97Qgn4965GX5+SZ1/awZ39WmZgHb29F25b+iMChIzk889oecnKdJ+e3a+XHW892ZdpLu1jxR5Jb843duZIV82fgdDrp1G8ivYffXGK+MYYV82cQE7UCT09vRlz1LCGRHclIOcrSTx4gK+M4IjY6nzeJ7kOurWAr1Wf31t/4fs4zGKeD3kMmMGTMTSXmJx7Zz1fvTeVwbBQjJ9zFoNFF5Wbee1PZtWkFfgHB3PPsd27P9YSg88+nxYP3IzY7Cd98Q9wHs0vMt/v702b6E3g3jsSZn8feJ54ke190UYDNRrfPPyE/8RhRd9zl9ny7vDeTkIuHkJ+YxMruY8qN6fDyVEJGDcaRk8uWGx4ifZM1RK7hiIF0+O9UxG7j0AfziH7hPbfne8Lw7kLLMKHAAQvXOklILRsT6Atj+9nw9oL4FMP3aw3Ooo8ejerBNcNsfPunk91x7s/5rptbcl7P+uTmOZj5ym72RGeWiXnojja0a+0PWPXFzP/tOllfdO8UyJ03tcLDQ0hNL+COh7e4Pec7b2hO3x5BVh33+j72llPHPfCvlrRt5YcAh47m8uxre8vUcW8+05kn/7vH7XXcv/4RQe+ugeTlOXnx3QPsO5BTJubeG5vQunldBDgcn8sL7x4kN89Z6eWrkzGGNYtmcmj3Sjw8vRk4fiYNIjqWictIjuPXL+4jPyeV+uEdGDThOeweXifnH4vbxsK3pzBkyn9p3mmkW3MGGN3HTpvGNgoKDV+vcnA0uXQHJ9Tzg0mDPfCpIxxNcvLVbw4cTqjjCRMHeRDoCzaB33c42bjPWc5Wai9TM6N41wGtRaQ5cBiYAlxZIi9jmp/4v4jMBhb+3YYy/MUxy8aYt8trKIuIW3qqRSQMON8Y06WyDWV35eIOToeDz997hjumvsG0/81n3aolHDkUXSKmrn8gU254gOGXXlNiekpSAst++JxHnv+MJ/73NU6ng3WrlpyRvPv1qEfjcG+u/NcGXnhrH/fe0qrcuNc+iOGf927i+ns2kXA8j8svDj85z2aDW69pxrrNKW7P1+l08Ou86Yy9ZRbXPLyI3RsXkhS/r0RMbNRKUo7Fct2jPzJsylP8Mm+aK087g8Y+xLWPLGbKPV+wZdVnZZZ1R74LPnqa6//zDvc89z2b//iBhMMlt1nXN5Ax/3iEQRdfX2b5ngPH8c8HKrqa5SY2Gy0feZAd/7qDjePG03DUKHxaNC8REnnjDWTu2sOmiZPZM/VxWjzwnxLzw6+6guz9MWcs5biP5rP2khsrnN9w1CB8WzVjefsRbLvtMTq9Ps2aYbPR8dXHWTvmRlZ0GU34lEvwa9/yjOTcMgzq+QlvL3ayeL2TUT3Lr8ov6CKs3WN4Z7GT3ALo2rzosqQIDOliIybhjKRMv57BRIbXZcota3nhjT3cf1vrcuNenRXNdXdu4Lo7N5BwLI/xl1hDEv187dx7W2seeno7/7h9PY89W/qenurXt0cQjRt5c9Xtm3jx7WjuvblFuXGvfxjLDfdu4Z/3biHxWB7jLmp0cp7NBrf8oynrNqe6Pd/eXQOICPXm+vuj+N8HB7nz+shy497+JI7bpu7i1qm7SEwq4LLhDau0fHWK27OStOMHmHDvEvqPfZLV300vN27d0pfo1P8aJty7FC/vQPZs+PrkPKfTwfqlLxHRur/b8wVoEyHUDxBenl/At384uPQ8e7lxI3raWR3l5H/zC8jJh56trc9pv3Y2ElMNb3xXyPtLChnV2479LLuDzIi45e+U2zSmEPg31lMudgJfGmN2iMitrk5ct6nU2yMi14jIVhHZIiJzRGSaiNzvmrdcRGaKyArgLtez7Va7YteKiL+IXCcirxdb30IRGeL6f6aIPCciG0TkZxHp41rnfhG51LXIj0CIiGwWkYEi0lJElriW+U1E2rnWNVtE/isivwLPnSbuVVee+4s/h09EHhCRba78n3VNK3c91SVm33ZCwiJpGNYYD09Peg0YyZZ1y0vEBAQG06xVJ+weZb8DOB0OCvLzcDgKyc/PJSi4YXWmV6EBfYJZ+msiAFF7MvDztVO/nmeZuOwcx8n/1/GyYUzRN/DxF4ez4o8kUtIK3J5v/IGtBDZsSmCDSOweXrTpMZrobb+UiIne/gvte49FRGjUrBv5OelkpSXiGxhCSKTV2+Hl7UdwaAsyU93byjgUvY36oU2oHxKJh4cXXftdRNSGZSVi/ALrE9miMzZ72XLRol0vfHwD3Zpjaf6dOpF7KI68w4cxhYUcW7KU+kOGlIip26I5aWvXApATG0ud8EZ4BgcD4BUSQvDAgSR88+0Zyzl51XoKktMqnB966TAOf2Llk7pmC56BAdQJa0hQny5kRx8gJyYOU1DAkS8WETpm2BnJuXWEsD3W+hwdSbZ6qny9y8Y1DRF2xVlx22MNbSKKTka9Wgm7Dxuycsv2iLnDwH71WbIsHoAduzPw8/Wgfj2vMnFl6wvr/8MHh7Lyj+MkHMsDIPUM1BkD+gSzdPkxAKL2ZOLn60FwZeq4YvMuv7jRGavjzu8RyE+rkgHYFZ2Nb107wYFl64bsYr3eXl5ysk6u7PLV6eDOZbTqfhki8n/s3XdYFMcbwPHv3FGO3jsoig0Rxa6xYEw0GhM1sSSmV9OraaYYfyaamN6LMYnpscfEFlvUmKixi4IFBBSQovQOd/P7YxE4AYXIAcb5PM893N6+u/vesMzOzs4ueLeKoLQ4l8LcdLMYKSUnj20jOEzrMW7fYwzHo6vq7pit39M6bBgGBw+L5npGaCsde+O0MkzKkBhsBI52NePa+uk4mKDF7Yk1EdpKa3JJtL9ZKn4WlWB2xUepm5RypZSyg5QyREo5s+Kzz6SUNW7ok1LeIaVc1BjbPW9jWQgRBrwADJVSdgNquy7qKqWMBD4E5gOPVcReCZzvGo4DsFFK2RPIA15Fe4bedcCZU8zRQJyUMkJK+Sfa4O9HKpZ5Cvik2vo6AFdKKaecJ84PGAhcA5xpFI8ExgJ9K/J/oyL2XOu5YNmZ6bh5+lZOu7n7kH06/RxLVHHz8GHY6NuYev8InrlnGHb2jnSOuKwx06uTp4ct6adLK6czTpfi6V778I/nHm7PL1/3oVWAHYtXnNSWd7dhUD8Plv1+sknyLchJw8m1qpydXH0oyDFv8BZkm8c4uviSf1ZMzukkMpJi8A3uZtF8c7PScHGvysXF3ZfcrPrtF83FxtuLktTUyumS9HRsfLzNYgqOHMXjiqEAOHYJw+Dnh42PDwBtn3mK+Hffb1FHDoO/D0VJVd+pODkVQ4BPLZ+nYQjwaZKcnOwEuUVVTbK8InA662BtZwMlpVQ2NnMLq2Ic7bTesT1xTdNQhor64lRJ5XT66RI8PWo2lgGmPtaRX7/tT+tAexYtTwYgyN8OJ0crPpzVjS/f7cGIyy1f1p7uNmY5Z5wuwcu99pyfe7gdS7/qRasAO5ZUr+P6uvPrmtRal2lsHm7WZGRW1cmnMsvwcK/ZuAeYcm8r5n/UhSA/A8vWZjR4+cZSmJuGg0tVPefg7FujsVxSmI2NwbmyU8De2ZeCXK1eLshJIzF6HZ363GjRPKtzshfkFFT97eQWSJztzXtF7W2huBRMsnqM9n5bjAkvF8GzE615eIw1K/4pr3GXWksnhc4ir5aqPpkNBRZJKU8BSCkza4mZX/GzI3BSSrmjIja3otv8XEqBM+MGooBNUsqyivfBZwcLIRyBy4CFQoi9wOdoDd8zFlbcBXm+uF+klKaKh1mfqXWvRBsTXXjmu9ZjPdVzq3zkyZw5Dbj8LWv5M6nnXZwF+bns27GRmZ+s4I0v1lBSXMS2TSvqv+0LUOttqbV9F+D1j45y/d3/kJhUxNCBngA8cndbPvs2ocnaRbXnZv4tZG1VVrXfRWlJASu+epTI65/H1uDYyBmaqzXfpn8OfMPUtt+e9T2SvvoaK2dnIub/hP+kG8k/dBiM5bgNHkRZZiYFMTFNlGz91HZHtZSyXt+1WZ0jvSsjdPyx39Sk6da669ax/dfeP8zYO7aSmFTAFQO1K2V6vaBjiBNP/y+KJ1/ez+03tiLIv5buvEZU++++9tjXP4pl3D07SUyuVsfdFczn3yU2WR1X62Gjjnzf/uI4kx45wImUYiL7ujV4+cZSez13/nr5zO9m+8rX6HXVFHS62odCWMK/rYbPfIv2AYKTmZLZC8r4+Ncyru1rVdnTrLRM9bm+Ijj/n8uZOx7qii3HvGFe/YJhmaz6azEBJQBSSlMd4451QLaUMuI8uZwvrqTae1Ht59n5n289lc565InceKB+N0a4eviQdaqq5yErM63eQykO7d+Gp3cATi7aZezu/a7g2OG99IscVa/lG+q6kX5cM0w7tzgUm493tZ4hLw8bTmeV1rUoJhNs+CuDSWMDWbUhnU4hjrw8pSMALk7W9OvphtEo2fJPbedjF87R1Ze87KpyzstOw8HF+5wx+TmpODprMUZjGcu/epROva6lXbfhFsmxOhd3X3Iyq3LJyUzF2dX7HEs0v9K0dGx9q3qJbL29KU3PMIsxFhRwdNr0yuleK5dTnJyC54ircB8SidvAgehsbdA7ONBh1qscef7Fpkq/VkXJqdgF+nJmVL0hwJeSlHR0NtbYBVZ9V0OAD8Upluv579FOEFEx5vhklsTZrqq6crLTepfN8i4BWxut3SElONtDfrE2z88NxvTXqmR7GwjxE5hMJo6efV/5Bbr+an+uvUrrW4g5moe3Z9WVJ28PW05lnru+WP9nBpOuD2Ll+jQyTpeQk1tGcYmJ4hIT+w7k0K6NAydSGvcGtLEjfCvruMOx+RU55wHg5WHLqfPVcVtOceNYf1ZtSKdjiCPTnuwAWK6Ou/ZKT64eog0/OHyssKLnWzsMerpbczqr7uEfJgkbt2cz4Wpv1vyZyanMsgYt/29Fb/uBIzu0q+OegV0oyKmq5wpyU7F3Mj/+GezdKC3OxWQsR6e3ojA3FXsnrS48lXyAjfOnAFBcmE3Skc3odHpad76yUXPu20lHrw7a30zyKYmLQ9Xfn7ODILfQvOlQWAIGG+0GPpPUYvIKtXk92unZHKUN3cnMg6x8iaeLIPlUCzrZPo/m+A9+zak+jeX1wFIhxLtSytNCCPdzxB4C/IUQvaWUO4QQTmjDMBKAB4UQOrQHSPf5twlLKXOFEPFCiAlSyoVCO73sKqXc92/izrIGmCaE+FFKWSiEcK/oXW7oehokuF0Y6SePcyotGVd3b3Zu+Z27H59Vr2XdPf04dmQ/pSVFWNsYOBS1ndYhNe8kbixLV51k6SrtEmO/nm5cf7Uf67econMHJwoKjbVWrAG+BpJTtaP0gF7uHE/Saowb7t9ZGTP1kfb8vTPTYg1lAN9W4WRnJJBz+gSOLj4c2b2Ckbe9bRYT0mUoe//8no49RpGauA8bgxMOLt5IKVn30wu4+7Slx+U1b6azhMC2XTidmkhmehLO7t7s27aKSQ++cf4Fm1HewYPYtQrCNsCf0rR0vEZcxeGpz5vF6J0cMRUVI8vL8bn+OnJ378ZYUEDiBx+R+IF2a4NLr54E3H5bszeUAdJ/20DrB28hZf4KXPt2ozw3j5LUDEozMnFoF4xdcCDFyWn43zCKPbdOsVgeu2Mlu2O1g2mIH/RspyP6hMTfHUrKoKC45jKJ6dApUBBzQtIlWHA0WVv+05VVXZ2jegtiT8pGbygDLFmZwpKV2or793Jn3DUBrNucQVhHJ/ILy2s9uQ7wM5B8sqK+6ONRWV/8ue00T9zfDr0OrKx1dO7ozPxljf8Ij19Wp/LLaq3x1q+nG9eP9K2o4xwpKCwn8zx13GW93TierDXgb3xgd2XMcw+3Y+uurEav435bd4rf1p0CoE83Z8YM82Ljtiw6hdhTUGgkM6fmxV1/bxtS0rWy79fdmRMV5b11d069lr9QnfvdTOd+NwNw4tBGorf9SNuuV5NxYh82tk7YO5t3Cggh8Gvbl4SDv9O26yiO7l5Gq1BtKNfEp9ZVxm1eNJWgTkMavaEMsP2Qie2HtL+bDoGCfp307I83EeglKCmV5NdyzhafKgkL1hEVb6J7Ox0xx7XlswskIf46EtONOBjA01mQlXfxNJQvRedtLFfcaTgT2CSEMAJ70Bq/tcWWCiFuAD4UQtihNZSvBP4C4tGGVhwAdte2fAPcDHwqhHgRsAZ+BmprvNY37kz+q4UQEcBOIUQpsBJ4vqHraSi93oob73mO9195AJPJxIChY/Bv1Y5Nvy8EIPKqCeRknWLWMzdRXFSAEIL1y39g+vtLaNMhnB79r+TVpyah1+sJatOJQcPGNVZq57RtVxb9e7rx06c9Kx4dd7Ry3hsvdmb2x7FkZpfy/KMdcLDXg4C4+ALe/jzuHGu1HJ3eisvHTWPpp/cgTUbC+o3Dw689+7f8BEDXgZMI7hxJfPQm5r0yDCsbO4bfpJ20pBzbRcyOZXj6deD7N8YAMGDUk7QJi7RYvnq9FaNve4Gv3rwXk8lEr8HX4RPYnm3rfwag3xU3kpedwYfTJlJSlI/Q6djy+3c8Ofs3DHaO/PTxUxyL+YeC/GxmPXo5w65/mN5DLLxvGI3EvTabLp9+DDodab/8SmHcMXwnaNtNXbgY+zZt6fDqDKTJSOGxeI6+/D/L5nQeEd+9jUdkH2w83Rgav4mjMz5EWGtV4/E5P5O+ahNeIyMZcmgtxqIi9t+jNf6l0ciBx2bQZ8VchF5P0rzF5Edb9gkpZ8SdhBA/yf1X6ygrhxU7qhq/EwfpWLnDRH4xbNxvYkw/HZFdBKnZsC+++caCb92ZSf9e7syf06fy0XFnvPlyF17/8AiZWaW88HgnHOz1CCGIjc/nrU+0eiUxqZDtuzKZ92EvpITf1pwk/nihRXPetiuLfj1c+fGTHpSUGHn9o6rf7+wXQnnjk1gys8uY+mg7HOz0IARxCQW88/kxi+ZVl3/25dInwpl5b3WmpNTEW18kVs579am2vDP3OFk55Tx9X2vs7fQIAceOF/HB1yfOu7ylBHaM5MSRzSx65yrt0XHXV3UUrflmMgOvexV7Z296XTWFjT9PYdfaD/DwD6VDr/HnWKtlHUmSdAiQPHm9NaVGyZItVTd43nqlFb/8VU5eEfy+s5wbIq24sruek5mSXUe1uI37jIwbaMXDY6wQwO+7jBSW1LGxFqoljy+2BFHXGFPlgtV7GEZLMKSLHYOv29LcaTTI5qUD+bRpnpLXaB4YAUv/MZ4/sIW4ro+eLd16NHcaDTJw325WWHds7jQaZFTZYV5bcPHsF1Mn6hl47abmTqNBtvwWSeT1fzd3GvW2acllDL91T3On0SBrvuvO7EUt5+bc+nh2vI4X59U9tKalefUOmxYx/iH5SJRFGo8BHcJbxPc726V1aqAoiqIoiqIoDXDR/OMORVEURVEUpfldajf4qZ5lRVEURVEURamD6llWFEVRFEVR6u1Su8FPNZYVRVEURVGUelPDMBRFURRFURRFAVTPsqIoiqIoitIAl9owjEvr2yqKoiiKoihKA6ieZUVRFEVRFKXeLrUxy6qxrCiKoiiKotSbGoahKIqiKIqiKAqgepYVRVEURVGUBrjUhmGonmVFURRFURRFqYOQUjZ3Dv9VqmAVRVEURWlMLaJLN+7YMYu0cULatm0R3+9sahiGBW2NyW3uFOqtf6gzxWu+bu40GsQw/E7e+/XiOid5fLTgt13lzZ1GvV3b04o3FpuaO40GeWacjtcWGJs7jQaZOlHPCuuOzZ1GvY0qO0zhnwubO40GsR80geK185o7jXozDLuD4l8/bu40GsQw+iFWO4c2dxoNMiI3hs/XNHcW9Xff8ObO4NKkGsuKoiiKoihKvUnZIjuALUY1lhVFURRFUZR6k5fYLW+X1rdVFEVRFEVRlAZQPcuKoiiKoihKvalHxymKoiiKoiiKAqieZUVRFEVRFKUBLrWeZdVYVhRFURRFUertUmssq2EYiqIoiqIoilIH1bOsKIqiKIqi1JvqWVYURVEURVEUBVA9y4qiKIqiKEoDqP/gpyiKoiiKoih1uNSGYfwnG8tCiNFAZynl6+eICQYuk1L+2MB1zwOWSykXXVCSZ9m/+29+nPs2JpOJwcPGcM24O8zm/71pFSuXfAuAwWDHbfc/R6s2HQD48sMZ7N25BWcXN2Z+ML8x0zqnv6KPMXvxOkwmE9f178bdw/ubzd9xNJHH5ywhwMMFgKHdOnD/yIGV840mE5PenIe3ixMf3T+hSXKWUvLXspkkHtqMlbWBoTe8hldgWI243Mwk1n7/JCVFOXgGdOaKG2ejt7IhK/0Yf8yfSkZyNH1HPE7EkLstmu+hfX+y7NvXMZmM9L18HENH32s2Pz35GPM/f5GkhGhGTnyMIdfcCUBZaQmfzLiN8vJSTEYjXfsO56rxD1s01zOklGxbPosThzdjZWNg8LhZeAbULOO8zCT++HkKJUXZePh3JnKCVsaJ0evZte4DhNCh0+npO2oqvsE9LZ73sO6CEF9BmRGW/2MiLbtmjIsDjO2nw2ADqVmS3/6RmExV8/3c4LYrdPyyzcThJMvl2vWLWXhfPYTS9NNs7n5trTGd330B7xGRGIuK2Xf3c+TuiQbAa/ggOr/zAkKv48RXC4l78wvLJVrNXweO8OZPKzGZTIwd1JO7ro40m7/z0DGe+PgH/D3dABjaozP3XTu0XstaLOfoOGYvqqjjLouoWccdSeTxOYur6riIjjXruDfm4e3iyEcPTLR8vocSmP3rZkwmyXV9wrh7aC/zfOOSeHzecgLcnLV8w0O4f1hfEtKzeOb7VZVxSZk5PHhVP24Z1N3iOXteOZDQ2c+DXkfSN4uIf3eu2XwrV2fCP56JfZsgjCUlHHjwRfJjjgLQ+oFbCbx9AghB0jcLSfzkW4vnGx+9mY2LZ2IymQjvP4E+wyebzZdS8sfimcQf3IS1jYGrbnkdn6AwystKmP/ezRjLS5EmI+0jruKyUY9aPF+lcbSoxrIQQi+lNF7oeqSUvwK/nicsGLgJaFBj2RJMRiPfff4GT//vI9w9fPjf07fTvc9gAoLaVsZ4+fgzdebnODg6s3/XX8z7ZBbT3pwHwMCh13DF1RP54v2Xmyxno8nErIVr+PyhG/FxdeKmN+cxJLw9IX6eZnHdQwLrbAj/sHEnbX08yS8uaYqUATh+aDPZpxK56dnfSTu+j81L/se4RxfUiNu24i26Dr6d9hGj2LT4ZWL+WUyXyyZha+/CwLEvEn9gncVzNZmMLP16JpOnfoGLhw/vv3gDnXtcjm9gu8oYO0cXxtw+lYM7N5gta2Vtw/0vfoWtwQFjeRkf/e9WOnUbROv23Syed9KRzeSeTmTClNVknNjH38tmMPrBmidxO1a/TdiA2wjpNoq/fpnOkZ2LCe03Cf+QfrQKHYoQgsyTh9nw0xOMf3KlRXMO8QU3R8Fnq0z4u8OInjq+WW+qEXd5V8E/RyQxJyRX9RR0ayPYEycBEAKGdNURn2bRVAFI+mYJCZ98T8RXs2ud7zViMA7tgtkYOhzXvt3o8tF0/h4wEXQ6wj6YxvaRd1KclMbAbYtIW76B/Jg4i+ZrNJl4/Yff+PTJO/Fxc+bmVz8jMiKUEH9vs7ju7YP54NFb/9Wylsh51oI1fP7wjfi4Op+7jqujIfzDHztp6+PRJHWc0WRi1tKNfD75OnxcHLnpg/kMCWtDiI+Heb5t/PnortFmnwV7u7HgyZsq1zPsla8Y2iXE4jmj09H57ZfYMeZuipPT6L9xAekr/6DgcNX+GDJlMrlRMey5+REc2rfR4kffhWNoewJvn8DWyyciS8voueQLMn7fRGFcosXSNZmMbFg4g3EPfY2Tqw8/vDmekPChePhV1cnx0ZvJTk/grmlrOJmwj/Xzp3PTUwvRW9kw4dFvsLF1wGgsY/67NxHceTD+bSIslq8lXWo9y//6Bj8hxCtCiMeqTc8UQjwqhHhaCLFDCLFfCPG/avN/EULsEkIcFEJMrvZ5vhBihhBiO9CfWgghEoQQs4UQ/1S82lV8fq0QYrsQYo8QYp0Qwqfi8zuEEB9VvJ8nhPhACPG3EOKYEGJ8xWpfBwYJIfYKIZ4QQuiFEG9Wy/2+iuWFEOIjIUS0EGIF0Og19LGjB/HxC8LbNxAra2v6DhzGnu2bzGLad+qGg6PWGxDSMZzM0+mV8zqG9aic11QOJJ4kyNONQE9XrK30jOjZmY1RR+u9fFpWLn8ejOO6/l0tmGVNCQfX07HnGIQQ+LaOoKQ4l4LcdLMYKSXJsdsICb8KgI49x5JwUGsc2zt64B0Ujk5v+fPM47FRePgE4eEThJWVDRH9r+bgrj/MYpxcPGgVUjMfIQS2BgcAjMZyTMZyrTXXBBKjN9Cuu1bG3q0iKC3OpbCWMk45to02XbQybtdjDIkx6wGwtnVAVORaVlbYJHm3DxAcSNAavSmZYGsNDoaaca29BYeStLgDCZIOAVW59WonOJwsKSiWFs83c8tOyjJz6pzvM/oKkr//BYDs7fuwdnHG1tcL1z5dKYxLpCg+CVlWRsr8Ffhce4XF8z0Qn0SQtweBXu5YW1lxVZ9wNu6NsfiyF+JAQkpFHeem1XE9Qtm4/0i9l9fquFiuu8zyJ6gAB46nEeTpSqCHi5ZvRHs2HjzW4PVsP3qCIA8X/N0sf0xx7dWVwmPHKUrQ9sfUxSvxGTXULMahUztOb9wGQMHReOxaB2Dj5YFDx7Zk79iHqagYaTSS9dcOfK650qL5pibux9WzNa6eQeitbOjUcxRxUevNYuKi1tO5z1iEEPi3iaCkKJf8nHSEENjYanWyqaJOFk1UJysX7kKehvElcDuAEEIH3AikAe2BPkAE0FMIMbgi/i4pZU+gF/CoEOLM6a4DcEBK2VdKueUc28uVUvYBPgLeq/hsC9BPStkd+Bl4po5l/YCBwDVojWSA54A/pZQRUsp3gbuBHCllb6A3cK8Qog1wHdARCAfuBS47X8E0VFZmBu6ePpXTbh4+ZGVm1Bm/ed0yuvZo9DQaJD07D183p8ppb1cn0rLzasTtj09mwmtf8uAnC4g9WfWd3liynifGXI5O17SVRUFuGo6ufpXTji6+FOSYdwUWF2ZjY+dc2QB1dPUlP8e8sdcUcrLScPWoytXV3YeczPp3W5pMRt6Zej3T7x9E+/D+tG7XNCcmhblpOLj4Vk7bO/vWOCEpKczGxlBVxg7O5r+HhINrWfTO1az55gEGjXvV4jk72Qlyi6oauXlF4GRnHmNnAyWlICvCcgurYhztoENAVS9zczP4+1CUlFo5XZyciiHAp5bP0zAE+NS2ikaVnpWLj5tL5bSPmzMZWbk14vbHHWfi9I946L1viEtOa9CyjZ5zTj6+1RqM3m5OpOWcq46bb17HLV7HE2MvR9dEDaL03Hx8XR2r8nVxJC2noGa+ialMeOdHHpy7jNjU0zXmr953lBHdO1g01zNs/bzN98eUNGz9zffHvKhD+I4eBoBLz3AMQf4YAnzIjz6K+4BeWLu7orMz4DV8MIZAXywpPzsNJ7eqbTi6+pCXnXaeGF/yK+o2k8nId6+P4bOpl9Gq02X4BTfNiZQlSIRFXi3Vv24sSykTgNNCiO7AcGAPWiPzzPvdQCe0xjNoDeR9wDYgqNrnRmBxPTb5U7WfZ3qgA4HfhRBRwNNAzYGRml+klCYpZTRQ15FhOHCbEGIvsB3wqMhxMPCTlNIopUwBNtSxPEKIyUKInUKInXPmzKnHV9JIWdsBtvadJiZqJ5vX/crE25pm/Gldas34rJRDA31ZPeNBFk69m0mRPXniiyUAbDoQi7ujPZ1bWbZiq01tRV3j7L6WoGbpAKhPrueg0+l58rUlvPTRBk7ERXHyRP17/i+ErCXxs/OubZ+vHhMcNozxT67kyls+ZPfaDxo/yX+jlqI/8zWujNDxx35TrftXc6htP5FS1r4jN1fSZ+XSqbU/K2c/xYLpD3Pj0H488fE5Rsg1wR9krfvoWTtBaJAvq195qKqOm6MdyjZFHcXdyZ7OrfxqrMNSaq/bzKdDA7xY/fwdLHzyJiYN6MYT3yw3m19WbmTTwWMM79qeJlGP/fHYu19g5erMZVuW0Oq+W8jbH4MsN1Jw5BjH3p1Lr1++pNeSL8iNOoQsv+BRnOdx/rqt1uNHxX6j0+m59bll3PvKJlIT93Mqpf5XKpTmdaHXkucCdwC+wFfAFcBrUsrPqwcJIYYAVwL9pZSFQoiNwJmLnMX1HKcsa3n/IfCOlPLXim1Mr2PZ6gPG6qplBfCIlPL3s3K/mtrbhjUTlHIOcKaVLLfG1K/3w93Dm8xTVWenWafTcHP3rBF3IuEoX330KlOmvY+js2u91m0pPq5OpGZV9bKkZ+fh7eJkFuNoZ1v5flBYCLMW/E5WfiF7jyWx8UAsW6LjKCkzUlBcwtRvfuO122u/UelCHfjrB6K3LwTAOyic/OyTlfPyc1KxdzYfWWNwcKO0KBeTsRyd3or87FQcnC07PrI2Lu4+ZJ+uyjU7Mw1nt4bnYefgTEhoHw7v24JfkGUOgtFbf+DwTu2eV8+ALhTkVPUWFeamYu/kZRZvcHCjtLiqjAtya/4eAPza9GZz5gmKC7IwOLg1as492gki2mjVwcksibOd4MyfupOd1rtcXVEJ2Npox3cpwdke8osr8nSDMf21vgd7GwjxE5hMJo6mNGrK9VaUnIpdoC9ZFdOGAF9KUtLR2VhjV633zRDgQ3GK5a+aeLs5k5ZVNWwkLSsXL9ez64uqcS+DunbktR9+IyuvoF7LWoJWx1XV4elZeXi7OJrFmNdx7Zg1f01FHZfMxqhYthz8hJKy8oo67ldeu918rHCj5uviSGp2flW+Ofl4OzuY52uolm9oMLOW/kFWQRFuDtolki2HEugU4IWHk73F8qyuJCXNfH/096HkpPn+aMwr4MCDL1ROR0atozBRu3s2+bvFJH+nnaC0n/Y4xSmWvWHA0dWXvKyqui0/Ow1HF/N6y9Ht7JhUHM6KMdg7E9SuLwkxf+Lp3zS9+I3tUnt03IX+U5KlwAi0HuXfK153CSEcAYQQAUIIb8AFyKpoKHcC+v2Lbd1Q7efWivcuQHLF+9sbuL48oHqN+zvwgBDCuiL3DkIIB2AzcGPFmGY/4PJ/kfs5tWnfmbSTx8lIS6a8rIztW9bSvc9gs5jTGal8+PozTH7if/gGtG7sFBosrJUfxzMySTqVTVm5kdW7ookMb2cWcyo3v7J3JiohBZMEVwc7Hhs9hLWvPMSq/z3I7DtH07tDa4s1lAG6DLiZiU/+wsQnf6FNlys4vGsZUkpSE/dia3Cq0RAWQuDfri9xUdp50+FdvxAcZvlxnWcLCunCqdTjnE5Pory8lL1bVxLWs367X35uJkUF2oG+rLSYowe24u3fxmK5du5/M9c9spTrHllK685XELtHK+P043uxNjjVaAgLIfBr25f4A1oZx+5eRqtQbaxi7unEyv3mVPJBTMYybO1dGz3n3bGSr9aa+GqtiSPJki7BWuXv7w4lZVBQXHOZxHToFKjFdQkWHE3W8vx0pYlPV2ivQ0mS33c3X0MZIP23DQTcMhYA177dKM/NoyQ1g5wdUTi0C8YuOBBhbY3/DaNIW17nxbJGExYcwPG00yRnZFJWXs7v/0QxpFsns5hTOXmVv/cDx5KQUuLqaF+vZS2Sc2t/jmdkVdVxu2OIPKvHtWYdJ7U6bswQ1r76MKtmPMjsO8dU1HGWaygDhAX5cPxUNkmZOVq+e48S2bmtWcyp3IKqfI+navnaV52krNp7hJHdO1o0z+pydkVh37Y1dq0DENbW+I67mvSV5vdlWLk4IaytAQi8fQKZf+/EmKcNL7HxdAfAEOiHz+hhnFy0wqL5+rYKJzsjgZxTJzCWl3Jo1wrahpuPsQ7pMpTof37R7suI34uNwQlHF28K8zIpLqyqk48f/ht3n7a1beaiYEJY5NVSXVDPspSyVAjxB5Bd0Tu8RggRCmytuDSRD9wCrAbuF0LsBw6jDcVoKNuKmwB1wKSKz6YDC4UQyRXrbEhrYD9QXjE0ZB7wPtoTMnYLLfkMYCzaCcFQIAo4AmyqZV0XRK+34pZ7n+Gt/z2KyWhk0JWjCWgVwobV2hnz0BHjWDZ/Lvl5OXz72ezKZaa/rT0m59O3X+DQgV3k52bzxN2jGHvjZCKHjWnsNM1Y6XVMnTCcBz6Zj0lKxvbrSjs/LxZs2QPAxIHdWbvnMAu27MFKJ7C1sWb2HaOb/YaGVp0iSYzZzI+vD8fKxsDlE2dVzlvx5WSGjH8FBxcf+l/9FGt/eJJ/Vr+PZ0AooX20+0ILczNY9MF4SovzEULH/i3fcuNTK7AxONa1yX9Nr7fiujte4IvXJyNNJnoPuQ7fwHb8vU57ssRlV95AbnYG7794A8VFWj5/rv6Op9/4ldzsDH7+9HmkyYRJmujW7yo69xjS6DnWJqhjJEmHN7Pw7auwsjYwaFxVGf8+bzIDr38VB2dveo+Ywh8/T2HX2g/w8A+lYy+tjOMPrCF2zzJ0emv0VrZcfuM7Ft9v4k5CiJ/k/qt1lJXDih1VT8KYOEjHyh0m8oth434TY/rpiOwiSM2GffE1n5jRFCK+exuPyD7YeLoxNH4TR2d8iLDWqvPjc34mfdUmvEZGMuTQWoxFRey/53kApNHIgcdm0GfFXIReT9K8xeRHx1o8Xyu9nmdvuoYH3/sGk8nEmAE9CQnwYeHGfwCYMKQP63YdZOHGf9DrdBhsrHht8g0IIepc1vI565g6cRgPfPyzeR33524AJg7qwdo9h1jw5x6s9Dpsra2YfeeYZqvjrPQ6po4dwgNfLNMesdcnjHa+HizYGqXl2z+ctVGxLNgahZVOh621ntk3j6zMt6i0jG1HT/DSuKHn2kyjkkYj0U+/Sq+lcxF6HUnfLSH/UCxBd2l9Yye+mo9jxxDCP38daTSSfyiOAw+/WLl8xPfvY+PuiqmsnOgpr1Cebdmx7Dq9FZdPmMbiT+5BSiNd+o3D0689+7Zoo0S7DZxEm7BI4qM38dWMYVhZ23HVLVr9V5Cbzurvn0OajEgp6dB9BG27NHrfm2IhovbxsvVcWLuxbzcwQUppsQGRQogEoJeU8pSltmEB9R6G0RL0D3WmeM3XzZ1GgxiG38l7v7aQQaL19PhowW+7yps7jXq7tqcVbyxungbhv/XMOB2vLbD02MXGNXWinhXWTdejd6FGlR2m8M+FzZ1Gg9gPmkDx2nnNnUa9GYbdQfGvHzd3Gg1iGP0Qq51DmzuNBhmRG8Pna5o7i/q7b3jL6H7dc/SURQ6+3dt7tojvd7YLeXRcZyAWWG/JhrKiKIqiKIqiNJd/PQyj4skSjTrgRgixlJpDKZ6VUgY35nYURVEURVGUf+dSu8GvRf0HPynldc2dg6IoiqIoilK3lvxMZEu40KdhKIqiKIqiKMp/VovqWVYURVEURVFatkttGIbqWVYURVEURVGUOqieZUVRFEVRFKXeLrUxy6qxrCiKoiiKotSbGoahKIqiKIqiKAqgepYVRVEURVGUBri4/q/rhVM9y4qiKIqiKIpSB9WzrCiKoiiKotSbGrOsKIqiKIqiKAoAQkrZ3Dn8V6mCVRRFURSlMbWILt2/Y/Is0sa5LNTpnN9PCDECeB/QA3OllK+fNf9m4NmKyXzgASnlvgvNSw3DsKCPVzV3BvX30EhY69OludNokGFpB/h0dXNn0TAPjID7Z2c1dxr19tmzboy650Bzp9EgK+Z2YeC1m5o7jQbZ8lskhX8ubO406s1+0ARWWHds7jQaZFTZYTYEd23uNOptaMJ+dl0+oLnTaJCef/x1Ue3HoO3L315E1cVtkc2dgaY5hmEIIfTAx8AwIAnYIYT4VUoZXS0sHoiUUmYJIUYCc4C+F7ptNQxDURRFURRFaen6ALFSymNSylLgZ2BM9QAp5d9SyjM9UtuAwMbYsGosK4qiKIqiKPUmERZ5CSEmCyF2VntNrrbZAOBEtemkis/qcjfQKNf41TAMRVEURVEUpdlJKeegDZ2oTW1jP2odOy2EuBytsTywMfJSjWVFURRFURSl3kzN8wiDJCCo2nQgkHJ2kBCiKzAXGCmlPN0YG1aNZUVRFEVRFKXeZPM8lGMH0F4I0QZIBm4EbqoeIIRoBSwBbpVSHmmsDavGsqIoiqIoitKiSSnLhRAPA7+jPTruKynlQSHE/RXzPwOmAR7AJ0IIgHIpZa8L3bZqLCuKoiiKoij11lz/wU9KuRJYedZnn1V7fw9wT2NvVz0NQ1EURVEURVHqoHqWFUVRFEVRlHq71P75s2osK4qiKIqiKPVmahn/dbvJqGEYiqIoiqIoilIH1bOsKIqiKIqi1Ftz3eDXXP6TjWUhxHQgX0r5Vh3zNwJPSSl3NmVe55IQs5nNS2YipYmwfhPodeVks/lSSjYvmUlCzCasrA0Mu+l1vIPCAFj341Tiozdi5+jBLc8tb7KcPS4fQMdXn0Po9ST/sJiED780m2/l4kzYe69gFxyEqaSEg4+/RMGhWABa3XcrATeNAyT5MUc5+NiLmEpKLZ5zQsxmNi2Ziclkoku/CfQeVrOcNy2ZSXz0JqytDQy/WSvnvKyT/P79MxTknUIIHeH9J9J9yO0Wzxdg4hV2dAmxprRM8s3KQk6kGWvEDOlhy9Betni76ZnyQTYFRdqAsmF9bOnT2QYAnU7g56HjqQ9zKCy27ICz+yb50SvckZJSybtfJRF3vLhGzFP3BNI+2I5yo+RIfBEffZeM0Qj2djqeuicQL3dr9DrBkjWnWPdXtkXzBXhscgj9e3pQXGJk1vuHORKXXyPmuUc60Km9EwAnUoqY9d4hiopNAHTv4sKj97bDykqQnVvGI1P3WSzXvw4c4c2fVmIymRg7qCd3XR1pNn/noWM88fEP+Hu6ATC0R2fuu3ZovZa1hK5fzML76iGUpp9mc/dra43p/O4LeI+IxFhUzL67nyN3TzQAXsMH0fmdFxB6HSe+Wkjcm19YPN8z3CMH0H7aswi9jpPzl5D46Vdm862cnQh9cwZ2rbQ6LuaZlyk4Els5r9Pr03Ho2A6kJOaZaeTu3m/RfJ179yXo4cdBr+PUit9I++l7s/l6RydaPzMVW/8AZGkpCW/MojghHoDWz0zFpd8AyrOziL7rVovmWd3Fti/HHdjMmvkzkSYTEQMncNnImseQNfNnEhe1CWsbA9fc8Tp+rbVjdXFhLiu+fZGM5CMgBNfcPovAkO4Wz1m5cBdVY1loD80TUkpTc+fSmEwmIxsXzeC6B77G0dWH+e+Mp02XoXj4tquMSYzZTHZGAre9sIbUxH38sXA6Nzy5EIDQvtfTddAtrPnh2aZLWqej0+svsnvivRSnpNL39/lk/P4HBUeOVYa0eexe8g4cYt+dj2Hfrg2dXn+B3ePvwdbXm1b33Mzfg8ZgKi4hfM5b+Iwdycn5yyyasslk5I+FM7j+Qa2cf3p7PG3Dzcs5IXozWRkJ3PGiVs7rF05n0pML0en0DB77HN5BYZQW5/PjW+No1WmA2bKW0KWtFd7ueqbNyaWNv56bhtsz+7u8GnFxSeVExZbx5E2OZp+v/aeEtf+UABAeYs0VvW0t3lDuFe6Iv7cN9z5/lI5t7XjoFn+enHWsRtzG7dm8NTcJgGfuDeSqQe6s3JjJNZd7cCKlhBkfHsfZUc+cme3ZuC2HcqPl8u7X050gf3tuvO8fwjo68dQD7Zn81J4acR/MjaOwSDtZefjuEMZdE8D3i07g6KDnyQfa89T0KNIySnB1sbZYrkaTidd/+I1Pn7wTHzdnbn71MyIjQgnx9zaL694+mA8evfVfLdvYkr5ZQsIn3xPx1exa53uNGIxDu2A2hg7HtW83unw0nb8HTASdjrAPprF95J0UJ6UxcNsi0pZvID8mzqL5AqDT0XHG8+y5ZTIlqWn0+vUnMtZupDC2al9u/dC95EUfJuq+J7APCabDjBfYe/O9ALR/+VlOb/qLAw9OQVhbobezs3i+rR6bwpGnH6csI51On80l5+8tFCcmVIb43nwbRbFHOTbteWyDWtHq8SkcnfIYAKdXryR96WLaTH3JsnlWc7HtyyaTkdU/zuCmJ77G2c2Hr2aNp323oXj5Vx0H4g5sJjMtgQdeXUNK/D5W/zCdO5/XjtVr5s+kbdggxt3/AcbyUspKa3YiXCwutRv8WvyYZSFEsBAiRgjxCbAbeEkIsUMIsV8I8b9qcS8IIQ4LIdYBHeux6glCiH+EEEeEEIMq1qEXQrxZbf33VXz+pBDiq4r34UKIA0II+8b6jmmJ+3H1bI2LZxB6Kxvadx/Fsaj1ZjHHotbTqfdYhBD4BUdQUpRLQU46AAEhvTHYuzRWOvXi0iOcwvjjFCUmIcvKSf1lFV4jhprFOHQIIfPPbQAUxsZjFxSAjZcHAEJvhc5gi9Dr0dvbUZKaYfGcUxP34+JVVc4deowi7qxyjjuwntBq5VxaUc4OLt6VPfk2BkfcfdqSn51m8Zy7trdh2wGtsRufYsTOVuDsUPPy14l0I6dzz30O2buzDTtjLN973y/CmQ1bswE4fKwIB3s9bi41z8t3RlX13B5JKMLTTYuRUmJn0KomO4OOvAIjRgv/b9VB/TxYvSEVgIOH83B0sMLDzaZG3JmGMoCtja7ygDEs0ofNW0+RlqH9rrJzyiyW64H4JIK8PQj0csfayoqr+oSzcW+MxZe9EJlbdlKWmVPnfJ/RV5D8/S8AZG/fh7WLM7a+Xrj26UphXCJF8UnIsjJS5q/A59orLJ4vgHNEFwoTj1N8IhlZVk76b6vxGn65WYxD+7Zk/bUdgMK4BOwC/bH2dEfv6IBrn56cnL8EAFlWTnluzZPcxuTQKZTilCRKT6Ygy8vJ2rAe1wGDzGLsgoPJ3b0LgJITx7H18cPKTeuxzd+/D2NurkVzPNvFti+nxO/H3bs1bl7aMaRz71Ec2Wd+DDmydz1d+2vHkIC2ERQX5ZKXnU5JUT7Hj+wgYuB4APRWNhjsnS2ar9J4WnxjuUJH4FvgWSAA6ANEAD2FEIOFED3R/u1hd+B6oHc91mklpewDPA68XPHZ3UCOlLJ3xTrurfi3iu8B7YQQ1wFfA/dJKQsb56tBfk4ajm6+ldOOrj4U5KTViHEyi/ElP8fyjbW62Pp6U5KSWjldkpKGra/5GX1+9GG8R10JgHP3LhgC/bD186EkNZ2ET+cxaPc6Bu//g/LcPDI3/W3xnAty0nByrSpDp1rKuSDbPMbRpWY555xOIiMpBt/gbpZNGHB1FGRVawRn55lwdWr4n621FYS1sWL3Ycs14s7wcLUiI7NqO6eyyvBwrfsill4Pl/dzZdcBrfG8fEMmQX62fPdWRz6e3o45P520eC+Gp4ct6adKKqfTT5fg6VGzsQww9bGO/Pptf1oH2rNoeTIAQf52ODla8eGsbnz5bg9GXO5jsVzTs3Lxcas6OfZxcyYjq2YjZ3/ccSZO/4iH3vuGuOS0Bi3b1Az+PhQlVdUnxcmpGAJ8avk8DUOA5cq2OlsfH0pSqv72S06mYetzVh0XcwSvEVrj3albF2wD/DD4+mDXKpCy05mEvvUKvVfMp9Pr09FZuGfZ2tOLsvT0yunSjHSsPb3MYgrjYnEbrA1VsO8Uio2vDzZelr2qcC4X276cl52Gk3vV8cHZ1Ye8rLQaMc7VjtXObr7kZaeRdeoE9k7uLJ83lbmvjGX5ty9QWtJozYgmJxEWebVUF0tjOVFKuQ0YXvHag9bL3AloDwwClkopC6WUucCv9Vjnkoqfu4DgivfDgduEEHuB7Wj/MrF9xbCPO4DvgE1Syr9qW6EQYrIQYqcQYuecOXMa8PVqaQmIs3eamjGiRkwTqnXb5jnGfzAXKxdn+q1fRNDdN5MXdQhZbsTKxRnvEZezpfdVbO42FL29Hb7jrrF4yrLWFpf595Dn+V2UlhSw4qtHibz+eWwNjjVjG1mtv+N/0XDs2s6auORyiw/BgIbvlw/e7M+BIwUcPKodOHp0ceTYiWJufeowj8yI4/6b/Ct7mi2l1ozrKKrX3j/M2Du2kphUwBUDtcaIXi/oGOLE0/+L4smX93P7ja0I8rfwZffqzirzTq39WTn7KRZMf5gbh/bjiY9/rPeyzaG2fUZKWXtuTXX9t9ZNm2878dMvsXZxpvfKBQTdPon8g4eQRiNCr8exSyjJ3y9gx6gbMBYV0fqBuyyc7/nLKvXH79A7OhH6xTy8rxtP4dGjSGPNeyCaVUvel2vZ987ed2s7zgghMBnLST0eTY/ISdzz0i/Y2Njx9+qGtBNaFpO0zKululjGLBdU/BTAa1LKz6vPFEI8TsObEGe6kYxUlYMAHpFS/l5LfHsgH/Cva4VSyjnAmb1ffryqfok4uviSn1XVe5KfnYaDs3eNmDyzmNQaMU2p5GQatv5VZ8+2/j41hlIY8wuIfrxq/NvAHb9TdDwJj8sHUHQ8mbLTWQCkr1iPa+8IUhdb9uZER1df8rKryjAvOw0HF+9zxuTnpOJYUc5GYxnLv3qUTr2upV234RbLM7K7LQO7ab2aialG3Jx1kKwd0FyddGTnN3zIfu9QG3ZEW24IxqjL3RkxSLuceyShCC/3qjG7nm7WnM4ur3W5Sdd64eJkxUffHa/8bNgANxau0valk+mlpJ0qJcjPliPxRY2a8/VX+3PtVX4AxBzNw9vTtnKet4ctpzLrLi+TCdb/mcGk64NYuT6NjNMl5OSWUVxiorjExL4DObRr48CJlMbNGcDbzZm0rKohDWlZuXi5OpnFONoZKt8P6tqR1374jay8gnot2xyKklOxC/Qlq2LaEOBLSUo6Ohtr7AKr6hlDgA/FKem1r6SRlaSmYetf1Ytt6+dDaXrNOi7m6WmV0/23rKLoRDJ6OwMlqWnk7o0CIH3lWos3lssy0rH2rqrPbLy8KTt9yizGVFhI4huzKqe7/LSIkpMpFs3rXC62fdnJzZe8zKrjQ252Go6u5scQZzdfcqsdq3OzUnF08UYIgbObLwFttSuSnXqO4O9VF29j+VJzsfQsn/E7cJcQwhFACBEghPAGNgPXCSHshBBOQO23W9dv/Q8IIawr1t9BCOEghHAB3gcGAx5CiPEX/E2q8WkVTvapBHJOn8BYXsrRPSto28V8/G+bLkM5tOMXpJScTNiLrZ1TjYZeU8rdcwD7tq0wtApAWFvhO3YkGb//YRZj5eyEsNbOQwJuGUfWtl0Y8wsoTj6JS4+u6CoqQfdBfSk4WvMGsMbm2yqc7Iyqcj6yewUhZ5VzSJehxFQrZxuDVs5SStb99ALuPm3pcfmdFs1z054SZs7LY+a8PPYeKaVfF60R18ZfT3GJJLegYeeFBhtoH2TFvljLDcFY8Ucmj8yI45EZcWzbk8vQ/q4AdGxrR0GRkaycmo3l4YPc6BnmxBtzTph12KRnltItVOu1d3XWE+BrS2pG4zf0l6xM4c7HdnHnY7v4c9spRgzVGmVhHZ3ILyzndFbNbQb4VR24B/Tx4HiS1hv+57bTdA1zQa8DW1sdnTs6k3DCMpdYw4IDOJ52muSMTMrKy/n9nyiGdOtkFnMqJ6+yh+vAsSSklLg62tdr2eaQ/tsGAm4ZC4Br326U5+ZRkppBzo4oHNoFYxcciLC2xv+GUaQt39AkOeXtO4h9cGsMgVod533tCE6t3WgWU72O879xHNnbd2PML6A04zQlKWnYtw0GwH2A5eu4gkOHMAQEYuPrh7Cywm3oFWT/vcUsRu/giLDS8vUcdS35+/diKmy+oQAX277sHxxOZnoC2ae0Y0j0jhV06GZ+DGnfbSj7t2rHkORj2rHaydUbRxcvnN18OZ2q7QcJMVvx8g+xaL6WJKWwyKululh6lgGQUq4RQoQCWysufeQDt0gpdwsh5gN7gUTgz3+5ibloQzJ2Vzx5IwMYC7wLfCKlPCKEuBv4QwixWUrZKF0cOr0VQ8ZNY9ln92AyGQnrOw4Pv/ZE/fUTAOEDJhHcOZKEmE188+owrG3suHJSVe/A6m+eJCnuH4rzs/jy5cH0G/kIYf0mNEZqdZJGI4enzqLHz58j9HpSflpKweE4Am+bCEDStwtw6NCWLh/OQhqN5B85RvQTWg9M7u4o0pavpd/aBUijkdyoQyR9t9Ci+YJWzpePm8bST+9BmoyE9dPKef8WrZy7DtTKOT56E/NeGYaVjR3Db9LKOeXYLmJ2LMPTrwPfvzEGgAGjnqRNmGUfVXTgWDldQoy8MtmZ0nL4ZmVB5byHxzvy3eoCcvIll/e0ZXhfA84OgpfudObAsTK+X60dBLt3sCE6oZxSyw9XBmBHVD69wp2YO6sDJaUm3v06qXLe9Mda88G8ZDJzynn4Fn/ST5fx9tS2APy9O5eflmfw828ZPHFXIB9PbwcC5i1OJTffspeKt+7MpH8vd+bP6VP56Lgz3ny5C69/eITMrFJeeLwTDvZ6hBDExufz1idHAUhMKmT7rkzmfdgLKeG3NSeJP26ZRoiVXs+zN13Dg+99g8lkYsyAnoQE+LBw4z8ATBjSh3W7DrJw4z/odToMNla8NvkGhBB1LmtpEd+9jUdkH2w83Rgav4mjMz6sbGQen/Mz6as24TUykiGH1mIsKmL/Pc8DWj1z4LEZ9FkxF6HXkzRvMfnRsRbP98y2j0ybRcS3n2p13IJfKDgah//NWt2a8sNC7Nu1ofPb2mPECo7GceiZlyuXPzL9NTq/9xo6a2uKTiQR85SFnzJhMnL8g3dp/8Y7CJ2eU6uWU5wQj+e1YwE49dsvGFq3JnjqS2AyUZSQQOKbr1Uu3ubF6ThFdMfKxZXwBUtJmfclp1da9mrfxbYv6/RWXDVpGj+9px2ruw0Yh5d/e3Zt0o4hPSMn0S48krgDm/jkBe1Yfc0dVcfq4ZNe4pcvn8JUXoarZxDX3PFaXZtSWhhR+zhOpRHUexhGS/DQSFjr06W502iQYWkH+HR1c2fRMA+MgPtnZ50/sIX47Fk3Rt1zoLnTaJAVc7sw8NpNzZ1Gg2z5LZLCPy1/wthY7AdNYIV1fR461HKMKjvMhuCuzZ1GvQ1N2M+uywc0dxoN0vOPvy6q/Ri0ffnbi6i6uC2yZdwFt3J3mUUaj1f3sG4R3+9sF1XPsqIoiqIoitK8TC2jzd5k/tONZSHEx8DZp+bvSym/bo58FEVRFEVRlIvLf7qxLKV8qLlzUBRFURRF+S+51EbwXmxPw1AURVEURVGUJvOf7llWFEVRFEVRGldLfsybJajGsqIoiqIoilJvLfm/7VmCGoahKIqiKIqiKHVQPcuKoiiKoihKvakb/BRFURRFURRFAVTPsqIoiqIoitIA8hL7pySqZ1lRFEVRFEVR6qB6lhVFURRFUZR6u9SehqEay4qiKIqiKEq9XWo3+Al5qX3jpqMKVlEURVGUxtQiBgsv3GaZvuUJ/XQt4vudTfUsW9AX65o7g/q790pYad+pudNokKsLD11UZQxaOT/zWVFzp1Fvb9xvx5gHDjd3Gg2y7NOORF7/d3On0SCbllxG8dp5zZ1GvRmG3cGG4K7NnUaDDE3Yzwrrjs2dRr2NKjvMusDw5k6jQa5Mirqo9mPQ9uXvNjd3FvV36+DmzkBzqfWzqhv8FEVRFEVRFKUOqmdZURRFURRFqTeTbJGjJSxGNZYVRVEURVGUelPDMBRFURRFURRFAVTPsqIoiqIoitIAqmdZURRFURRFURRA9SwriqIoiqIoDaD+g5+iKIqiKIqi1EFeYk/DUMMwFEVRFEVRFKUOqmdZURRFURRFqTd1g5+iKIqiKIqiKIDqWVYURVEURVEaQN3gpzSL+IOb2bBoJtJkInzABPoOn2w2X0rJhoUziT+4CSsbAyNvfR2fVmGUl5Xw87s3YywvxWQ00qH7VQy45tEmydlz2EA6v/kCQq/jxLxFHHv7C7P5Vq7OdP1sJvZtWmEqKWH//S+QH30UgOAHbyXozgkgBCe+XkjCx982Sc4XYzmPHmBNp1Y6ysphwR+lJJ+qWUtdFqZnYFcrPF10TJ9XRGGx9rmXq2DiEBsCvASr/yln877yJsn53one9AxzoKRU8v63Jzl2oqRGzJN3+tGutYFyo+RoQjGf/JCK0QTXDXNjcG9nAPR6QaCvDbc9HUt+ocmiOT96dxv69nClpMTEax/FcvRYQY2YZx4MoWM7RwRw4mQxr394lKLiqrw6tXPkk9fC+d87R9i09bTFcv0rOo7Zi9ZhMpm47rII7h7e32z+jiOJPD5nMQEeLgAMjejI/SMHVs43mkxMemMe3i6OfPTARIvlWZ175ADaT3sWoddxcv4SEj/9ymy+lbMToW/OwK5VEKaSEmKeeZmCI7GV8zq9Ph2Hju1ASmKemUbu7v0WzbfrF7PwvnoIpemn2dz92lpjOr/7At4jIjEWFbPv7ufI3RMNgNfwQXR+p6Ju/GohcW9+Uevyjc1jyAA6/O9ZhF5P8k9LSPz4S7P5Vi7OdH57BnattTKOnjKNgsOx2LcNJvzTNyvj7FoFEvfWx5z48nuL53yx7ctxBzbz+8/aMSRi0AQGjKx5DFnz80xiozZhbWPg2jtfx691GADFhbks/+ZFMlKOAIJr75hFYEh3i+dsCZfaMIxLrrEshBgCPCWlvKaZU6lkMhlZt2AGEx75GidXH75/Yzwh4UPx9GtXGRN/cDNZGQncPX0NJxP2sfbn6dzyzEL0VjZMfPQbbAwOGI1l/PT2TbQJG4x/mwjLJq3TEfbuNP655i6Kk9MY8OdC0ldsIP9QXGVIu6fvI3f/IXbf+AgOHdpo8aPuxLFze4LunMBfgyciS8vovewL0ldvojAu0aIpX4zl3KmVDk8XwRs/ldDKW3DdIBs+Wlqz4ZmQaiLmeCn3jbYx+7ywWLLsr1LC2ugtmmd1PcMc8PO25v6X4+nQxsADk3x4+o3jNeI2/ZPLO1+fBGDKXX4MG+jK6s3ZLF2bxdK1WQD0Dndg9BVuFm8o9+3hSqCfgZsf2kPnDo48ObktDzwXVSPuo68TKCwyAvDQHcFcN9KPH5cmA6DTwX23tmbH3myL5mo0mZi1YA2fP3wjPq7O3PTmPIaEtyfEz9MsrntIYJ2Nhx/+2ElbHw/yi2vuSxah09FxxvPsuWUyJalp9Pr1JzLWbqQw9lhlSOuH7iUv+jBR9z2BfUgwHWa8wN6b7wWg/cvPcnrTXxx4cArC2gq9nZ3FU076ZgkJn3xPxFeza53vNWIwDu2C2Rg6HNe+3ejy0XT+HjBRqxs/mMb2kXdSnJTGwG2LSFu+gfyYuFrX02h0Ojq++gJ7bppM8clU+qz4mVNr/qDgaFUZBz9yD3kHD7H/nsexD2lDp5nPs/vGeyk8lsD2qyZUrmfQzvVkrF5v2Xy5+PZlk8nIqh9ncPMTX+Ps5sOXM8fTodtQvPyrjiFxBzaTmZ7AgzPXkHxsH6t+mM5dzy8E4PefZxLSZRDjH/gAY3kpZaXFFs9ZaRwtbsyyEOKSa8CnJuzHzas1rp5B6K1s6NRzFHH7zSuq2P3rCes7FiEE/m0iKCnKJT8nHSEENgYHAEzGckymcgSWf6SLa6+uFMYdpyghCVlWxslFK/G55gqzGMfQEE7/sRWAgiPx2LUOwMbbA8eObcnesQ9TUTHSaCRzyw58R19p8ZwvxnLuHKxn9xGtcXY8XWJnC072NeNSTkuy8mqe6hcUQ1KGxGTZtqaZPt0c+WNbLgBH4otxsNfj5lyzsb7rYFXP7dGEYjxda/7pD+rtzOYdeZZLtsLAPu78vjEDgOgj+Tg6WOHuZl0j7kxDGcDWRkf1Er/+aj82bT1NVk6ZRXM9kJBCkKcbgZ5uWFvpGdEjlI37j9R7+bSsXP48GMt1l3WzYJbmnCO6UJh4nOITyciyctJ/W43X8MvNYhzatyXrr+0AFMYlYBfoj7WnO3pHB1z79OTk/CUAyLJyynMtv09kbtlJWWZOnfN9Rl9B8ve/AJC9fR/WLs7Y+nrh2qcrhXGJFMVrdWPK/BX4XHtFnetpLC4R4RQlHKfoeBKyrJy0ZatqlLFj+xAyt5wp43gMgQHYeHqYxbgP7EtR4gmKk09aPOeLbV9Oid+Pu1dr3Ly0Y0hY71Ec2Wt+DDm8dz3h/bRjSGBIBMWFueRlp1NSlM/xIzuIGDgeAL2VDQZ75ybJ2xKktMyrpWryxrIQ4iUhxCEhxFohxE9CiKeEEBuFELOEEJuAx4QQPYUQm4QQu4QQvwsh/CqWDRFCrK74/E8hRKeKz+cJIT4QQvwthDgmhBh/njQchRCLKvL4QQghKtZTY7tCCBchxGEhRMeKmJ+EEPc2ZpnkZafh5OZblZyrD3nZaWYx+TlpOLlWxTi5+pJfEWMyGflm1hg+efYyWne6DL82lq84DP4+ZpVpUXIqtv4+ZjG5UYfxHTMcAJde4di18scQ4Ete9FHcB/TG2t0VnZ0Br6siMQT6WTzni7GcXRwE2flVNUh2vsTFoWU/39LD1YpTWVXDPU5lleFRS0P4DL0OhvR1Zne0+bAHG2tBj84ObN1j+YaRp7sN6aeqeqYyTpfg5W5Ta+xzD7dj6Ve9aBVgx5IVJyuXH9TXnV/XpFo81/ScfHzdqg6y3m5OpOXULKP98clMeO1LHvxkPrEnMyo/f2PxOp4Yezk60XT7ka2PDyUpVX9rJSfTsPXxNovJjzmC1witUenUrQu2AX4YfH2waxVI2elMQt96hd4r5tPp9enomqBn+XwM/j4UJVX9vouTUzEE+NTyeRqGAJ/aVtGobP28KT5Zbbupadj6mW83L/ow3iO1jgnniC4YAv1qxPiOHknqslUWzxcuvn05LzsNZ/dqxwe3mseQvCzzGGc3X/Ky08jKOIGDkzu/fT2VL2aMZfk3L1BaUtgkeSsXrkkby0KIXsA4oDtwPdCr2mxXKWUk8AHwITBeStkT+AqYWREzB3ik4vOngE+qLe8HDASuAV4/TyrdgceBzkBbYIAQwrq27Uopc4CHgXlCiBsBNyllrQPQhBCThRA7hRA758yZc97yqFLzdEqc9ccvazvlqojR6fTc/vwy7pu5idSE/RXjoSystrrprByPvTUHazdnBm5bSvD9t5C7LwZZXk7B4WPEvfMFfZZ/SZ9lX5AXdQhZ3hRjaS/Ccq5FSz77hjp2jXPE3z/Jh4OxhUTHFpl93qerIzFxRRYfggE19wOou5xf/yiWcffsJDG5iKEDtcvFj9wVzOffJTZJD35t++jZVzlCg3xZ/cpDLJx6N5Mie/LEnMUAbIo6iruTPZ1bWf7k9KwEazj7eyR++iXWLs70XrmAoNsnkX/wENJoROj1OHYJJfn7BewYdQPGoiJaP3BXEyVet9r3GVlZX5w1oykyOu92Ez7Wyrjv7wsJuvMm8g6Y173C2grP4UNIX77G0slWpHdx7cu1Hh9qlHvtxxmTqZyTx6PpOWQS9077BWtbO/5e1ZB2QstikpZ5tVRNPeRhILBMSlkEIIT4rdq8+RU/OwJdgLUVlZEeOCmEcAQuAxZWq6Rsqy3/i5TSBEQLIc53Gv+PlDKpIoe9QDCQXdt2AaSUa4UQE4CPgTq7E6WUc9Aa9ADyi3XnyaKCk6sveVlVPQL52Wk4unjXjMmuisnLTq0RY7B3Jqh9XxKi/8TLv0P9Nv4vab0lVZWUXYAvJSfTzWLK8wrYf9/zldNDYtZTlJAEQNI3i0n6Rqv0OvzvCYqTLd8jd7GUc/8wPX1DtT/NExkmXB2rKmNXR0FuYcurUa6OdGXYAO0GnNjEYjzdqqoWTzdrMrNrPxm6YZQHzo56PpmTVmPeoF5O/Lkz1zIJA2NH+HLNMK2qOBybj7enLaD1anl52HIqq7TOZU0m2LDlFDeO9WfVhnQ6hjgy7UltX3BxsqZfTzeMRsmWfzIbPW8fVydSs6rKJT0rD28XR7MYR7uqqnFQWDtmzV9DVn4he48lszEqli0HP6GkrJyC4hKmfvMrr90+utHzrK4kNc3sypOtnw+l6RlmMcb8AmKenlY53X/LKopOJKO3M1CSmkbuXm0MefrKtS2isVyUnIpdoC9ZFdOGAF9KUtLR2VhjF1jVs2gI8KE4Jb32lTSikpNpGPyqbdfXh5JU8+0a8wuInvJS5fSAraspOpFcOe15+SDyomIoPWW5m1Oru9j2ZWc3X3Izqx0fstJwcj3rGHJWTG6WdgwRQuDs5ktAW60JEdpjBH+vvngby5eaph6Gca5rJQXVYg5KKSMqXuFSyuFouWZX+zxCShlabfnqo/vPd02meqwR7aShru0ihNABoUAR4H7eb9lAvq3DyUpPIPvUCYzlpRzatYKQ8KFmMSFdh3Jw+y9IKUmJ34utnROOLt4U5mVSXKhVNmWlxSQe/ht3n7aNnWINObuicGjXGrvWAQhra/zGX03aig1mMVYuTghrbdxn0J0TyNyyg/I87dds46UVoyHQD9/Rw0hZsMLiOV8s5bz1oJH3FpXw3qISDsYb6dFBG+/byltQVAp5LfDK3cpN2TwxK5EnZiWybV8+l/fTLq12aGOgoMhIVq6xxjLDBrjQI9SBt786WaPjzd6gI6y9Pdv35Vss519Wp3LPlH3cM2Uff/6TyVVDvADo3MGRgsJyMrNqjj0O8DVUvr+stxvHk7Xe8Bsf2M2N92uvTVtP8+6cYxZpKAOEtfbneEYWSaeyKSs3snp3DJFd25vFnMrNr+wFi0pIwSQlrg52PDZmCGtffZhVMx5k9p1j6N2htcUbygB5+w5iH9waQ2AAwtoK72tHcGrtRrMYK2cnhLV2kuV/4ziyt+/GmF9AacZpSlLSsG8bDID7gL5mN601l/TfNhBwy1gAXPt2ozw3j5LUDHJ2ROHQLhi74ECEtTX+N4wibfmGc6+sEeTuO4Bdm9YYgrQy9hkzkoxzlfFN48jevgtjftXwJ58xTTcEAy6+fdk/OJzM9ASyMrRjyMEdK+jQzfwY0qHbUKK2aceQpLi9GOyccHL1xtHFC2c3X06navtu/KGtePqFWDRfS7rUxiw3dc/yFuBzIcRrFdseBZw9pOEw4CWE6C+l3FoxPKKDlPKgECJeCDFBSrmwYpxxVynlvkbKrc7tAk8AMcDzwFcVMY12F49Ob8UVE6ex+ON7MJmMhPcfh6d/e/b++RMAEYMm0TYskviDm5g7fRjWNnaMuGUWAAW56az69jlMJiNSSjr2GEFI+OXn2lyjkEYjB598hT6/fgl6HUnfLiY/JpZW99wAwPG583HsGEK3ua8jjSbyD8Wy/4EXK5fv8eMHWLu7IsvKOfjEDMqzLdeDeMbFWM6Hjpvo1Ery7CRbSsth4caq3s67rrZh0cZScgthQBc9kRHWONnDkxMMHDpuZNGmMhzt4NFxBgw2WkU0MNyKt+cXU2LBe9B2HSigVxcHPpvRhpJSyYffVo1tf+mhAD7+PpXMHCMPTPIhPbOM2U+3AmDb3nzmr9R6tPpFOLI3poCS0qapPbftyqJfD1d+/KQHJSVGXv8otnLe7BdCeeOTWDKzy5j6aDsc7PQgBHEJBbzzedM32qz0OqZOHMYDH/+MSUrG9utKOz8vFvy5G4CJg3qwds8hFvy5Byu9DltrK2bfOabWYQNNRRqNHJk2i4hvP0Xo9aQs+IWCo3H436w9gSHlh4XYt2tD57e1R3IVHI3j0DMvVy5/ZPprdH7vNXTW1hSdSCLmqZfq2lSjifjubTwi+2Dj6cbQ+E0cnfFhZUPz+JyfSV+1Ca+RkQw5tBZjURH773m+8rseeGwGfVbMRej1JM1bTH507Lk21Sik0cjhl2bR/YfPEDo9KfOXUnAkjoBbtDJO/n4hDu3aEvb+TKRRK+Pop6rKWGcw4D64PzHPzbB4rmdcbPuyTm/FiJum8dN792CSRiIGjMMroD27NmrHkJ5DJtEuPJLYqE18/IJ2DLn2jlmVy1816SV+mfsUxvIyXL2CuPaO15rlezSGprxpvCUQtY/BseAGhZgOTAISgQxgI3Az2uPcdlbERKCNXXZBa1S/J6X8QgjRBvgUbXyyNfCzlHKGEGIesFxKuahi+Xwppfm1nKrtD6Hao+OEEB8BO6WU82rbLrAJWAb0kVLmCSHeAfKklC/XXLuZeg/DaAnuvRJW2ndq7jQa5OrCQ1xMZQxaOT/zWdH5A1uIN+63Y8wDh5s7jQZZ9mlHIq//u7nTaJBNSy6jeO285k6j3gzD7mBDcNfmTqNBhibsZ4V1x+ZOo95GlR1mXWB4c6fRIFcmRV1U+zFo+/J3m5s7i/q7dXATPIapHj5fc85bUf61+4a3jO93tuZ4TNtbUsrpQgh7YDPw9tk3zEkp9wKDz15QShkPjKjl8zvOmq61oVwxbyNaA/3M9MPn2y7aEIwzMU/WtW5FURRFUZT/upY8ZMISmqOxPEcI0RkwAN9IKXc3Qw6KoiiKoiiKcl5N3liWUt7UFNsRQoQD3531cYmUsm9TbF9RFEVRFOW/SPUs/0dIKaOAiObOQ1EURVEU5b+kJT8T2RJa3L+7VhRFURRFUZSWQjWWFUVRFEVRlHqTUlrkdT5CiBFCiMNCiFghxHO1zBdCiA8q5u8XQvRojO+rGsuKoiiKoihKiyaE0KP9J+WRQGdgUsUDI6obCbSveE1Ge9zwBVONZUVRFEVRFKXemuk/+PUBYqWUx6SUpcDPwJizYsYA30rNNsBVCOF3od9XNZYVRVEURVGUejOZLPMSQkwWQuys9ppcbbMBwIlq00kVn9HAmAb7zz4NQ1EURVEURbl4SCnnAHPqmF3bf/c7uz+6PjENphrLiqIoiqIoSr0103OWk4CgatOBQMq/iGkwNQxDURRFURRFael2AO2FEG2EEDbAjcCvZ8X8CtxW8VSMfkCOlPLkhW5Y9SwriqIoiqIo9dYc/5RESlkuhHgY+B3QA19JKQ8KIe6vmP8ZsBK4GogFCoE7G2PbqrGsKIqiKIqitHhSypVoDeLqn31W7b0EHmrs7Yr6PARa+VdUwSqKoiiK0phqu4Gtyb39i2Uaj1PGihbx/c6mepYtaN7G5s6g/u4YAhuCuzZ3Gg0yNGE/n65u7iwa5oERMGu+sbnTqLfnb9Az4Yn45k6jQRa+24bht+5p7jQaZM133Sn+9ePmTqPeDKMfYtflA5o7jQbp+cdfrAsMb+406u3KpChWWHds7jQaZFTZ4YtqPwZtX/5uc3NnUX+3Dm7uDDTSYuMwWmRbWd3gpyiKoiiKoih1UT3LiqIoiqIoSr01xw1+zUn1LCuKoiiKoihKHVTPsqIoiqIoilJvl9qzIVRjWVEURVEURak30yU2DkMNw1AURVEURVGUOqieZUVRFEVRFKXeLrVhGKpnWVEURVEURVHqoHqWFUVRFEVRlHq71HqWVWNZURRFURRFqTfTJdZaVsMwFEVRFEVRFKUOqme5hYg7sJl1C2ZiMpmIGDiB/iMmm82XUrJ2/kziDmzC2sbANXe8jm+rMAA+eX4oNrYOCJ0OnU7PnS8saZKc3SMH0H7aswi9jpPzl5D46Vdm862cnQh9cwZ2rYIwlZQQ88zLFByJrZzX6fXpOHRsB1IS88w0cnfvt3jOCTGb2bREK+cu/SbQe1jNct60ZCbx0ZuwtjYw/ObX8Q4KIy/rJL9//wwFeacQQkd4/4l0H3K7xfMFGNZdEOInKDfCb/+YSMuqGePiAGP767CzgdQsya/bJSYTtPKC8QN15BRocYeTJFuiLd8jcOd17vQItaekTPLxTxnEJ5XWiHn0Fi9CgmwoN0Ls8RLmLDiF0VQ1PyTIhlmP+/Put+ls21do8ZwfvDWA3t1cKCkx8dacRGITi2rEPHlPK9q3sUcAyanFvDnnOMUlpnov31j+OpTA7F83YzJJrusTxt1De5nN3xGXxOPzlhPg5gzA0PAQ7h/Wl4T0LJ75flVlXFJmDg9e1Y9bBnW3WK5nOPfuS9DDj4Nex6kVv5H20/dm8/WOTrR+Ziq2/gHI0lIS3phFcUI8AK2fmYpLvwGUZ2cRfdetFs/1DI8hA+jwv2cRej3JPy0h8eMvzeZbuTjT+e0Z2LXW6rjoKdMoOByLfdtgwj99szLOrlUgcW99zIkvvz97E42q6xez8L56CKXpp9nc/dpaYzq/+wLeIyIxFhWz7+7nyN0TDYDX8EF0fucFhF7Hia8WEvfmFxbN9Yx/uy8DfLd5D0v+OYgA2vt5MmPildhaW7ZZE3dgM7//PBNpMhExaAIDRtY8hqz5eSaxUdqx+to7X8evdRinU4+x5PMnKuOyTp0gcsyj9L3yDovmaynSdP6Y/5IW1VgWQgQDy6WUXc76fCPwlJRyZyNtZzqQL6V8qzHWd6FMJiNrfprBjY9/jbObD/NeG0/7rkPx9G9XGRN3YDNZ6Qnc/8oaUuL3sfqH6dwxdWHl/JumfIO9o3vTJa3T0XHG8+y5ZTIlqWn0+vUnMtZupDD2WGVI64fuJS/6MFH3PYF9SDAdZrzA3pvvBaD9y89yetNfHHhwCsLaCr2dncVTNpmM/LFwBtc/+DWOrj789PZ42oYPxcO3qpwTojeTlZHAHS+uITVxH+sXTmfSkwvR6fQMHvsc3kFhlBbn8+Nb42jVaYDZspYQ4gfuToLPVprw94ARPXV8s65mLTW0q2DHYUn0CcmInoKINoLdcVqj+MQpWPhn09Vs3UPt8POy5pFZSbRvbcu94z14/r2TNeL+3JXPB99rDcrHbvXiin5OrPk7DwCdgFuudWfvIcs1OKvr3c2ZAB8Ddz4VTacQex69M4hHpx+pEffZ90kUFmtled9NAYwZ5sX85Wn1Xr4xGE0mZi3dyOeTr8PHxZGbPpjPkLA2hPh4mMV1b+PPR3eNNvss2NuNBU/eVLmeYa98xdAuIRbJ04xOR6vHpnDk6ccpy0in02dzyfl7C8WJCZUhvjffRlHsUY5Nex7boFa0enwKR6c8BsDp1StJX7qYNlNfsnyu1XLu+OoL7LlpMsUnU+mz4mdOrfmDgqNVdVzwI/eQd/AQ++95HPuQNnSa+Ty7b7yXwmMJbL9qQuV6Bu1cT8bq9RZPOembJSR88j0RX82udb7XiME4tAtmY+hwXPt2o8tH0/l7wETQ6Qj7YBrbR95JcVIaA7ctIm35BvJj4iya74Xsy2k5+fy4ZR9Ln74Fg7UVT3+3ktV7jzCmd2eL5WsyGVn14wxufkI7Vn85czwdug3F66xjdWZ6Ag/OXEPysX2s+mE6dz2/EA/fttz78rLK9bz/9GA6dh9msVyVxqWGYbQAKfH7cfNujZtXEHorG0J7jeLIPvOK9ei+9XTpNxYhBAFtIygpyiU/J72ZMgbniC4UJh6n+EQysqyc9N9W4zX8crMYh/ZtyfprOwCFcQnYBfpj7emO3tEB1z49OTlf6wGXZeWU5+ZZPOfUxP24eLXGxVMr5w49RhEXZV7OcQfWE9pbK2e/4AhKi3IpyEnHwcUb7yCtJ9/G4Ii7T1vys9MsnnOHAEFUgtboTTkNBmtwMNSMa+0jiEnS4qISJB0ChMVzq0vvLvZs2pEPwNHEEhzsdLg662vE7YmpagjHHi/Bw7Xq3H3EIGe27SsgN99o+YSBy3q4sHZLJgCH4gpxsNfj7lKzL+FMQxnAxkYgK8bt1Xf5xnDgeBpBnq4EerhgbaVnRER7Nh48dv4Fz7L96AmCPFzwr+ixsySHTqEUpyRRejIFWV5O1ob1uA4YZBZjFxxM7u5dAJScOI6tjx9Wbm4A5O/fhzE31+J5VucSEU5RwnGKjichy8pJW7aqRh3n2D6EzC1n6rh4DIEB2HiaN/TcB/alKPEExck1TxgbW+aWnZRl5tQ532f0FSR//wsA2dv3Ye3ijK2vF659ulIYl0hRfBKyrIyU+SvwufYKi+d7ofuy0WSipKyccqOJorJyvJwdLJitdqx296o6Vof1HsWRvebHkMN71xNecawODImguDCXvGzzY3V8zFbcvIJw9QiwaL6WJKW0yKulaomNZSshxDdCiP1CiEVCCPvqM4UQ+dXejxdCzKt47yWEWCyE2FHxGnCe7XQWQmwUQhwTQjxabZ23CCH+EULsFUJ8LoTQCyF6V+RjEEI4CCEOCiG6nGvlDZGfnYazm2/ltJObD3lnNcTystNwdq8W4+pLXlZVzM/v3c3XM69nz+b5jZXWOdn6+FCSUrX9kpNp2Pp4m8XkxxzBa4RW4Tp164JtgB8GXx/sWgVSdjqT0LdeofeK+XR6fTq6JuhZLshJw8m1ehn6UJBjXs4F2eYxji6+5J8Vk3M6iYykGHyDu1k2YcDRTpBbWFWB5BWB01lFZWcDxaVVdyfnFoJTtb+aAA+4+yodNwzW4Wn5dhHuLlaczi6vnD6dbcTdpWZj+Qy9Dgb3cmTPocKK5fX0Dbdn7d+WP4E6w8PNmozMqqEipzLL8HC3rjV2yr2tmP9RF4L8DCxbm9Hg5S9Uem4+vq6OldPeLo6knRlnU83+xFQmvPMjD85dRmzq6RrzV+87yojuHSyS49msPb0oS69qMJRmpGPt6WUWUxgXi9vgSADsO4Vi4+uDjZd5ndKUbP28KT6ZWjldnJqGrZ+PWUxe9GG8R14JaB0IhkC/GjG+o0eSumwVLYHB34eipGrfKTkVQ4BPLZ+nYQjwqW0VjepC9mUfF0duj+zBVTO/5spX5uJksOWyjq0tmm+N43Btx+os8xhnN98aMdE7VhDW5xqL5qo0rpbYWO4IzJFSdgVygQfrudz7wLtSyt7AOGDueeI7AVcBfYCXhRDWQohQ4AZggJQyAjACN0spdwC/Aq8CbwDfSykPNOxr1U1S82xKcFbPYG1nXEKLufWZn7jrxaVMfOQLdm/6geNHdjRWanWrpePy7LPCxE+/xNrFmd4rFxB0+yTyDx5CGo0IvR7HLqEkf7+AHaNuwFhUROsH7rJ4yrWftZp/kdp+F2fKGaC0pIAVXz1K5PXPY2twrBnbyOrTPyxq/V1oP1Oz4OPlJr783cTOoybGD7T8n3xt+dRWrGfcM96TmLhiDh0rAeCOsR58vzyLpvxvqg3J+e0vjjPpkQOcSCkmsq9bg5e/UOeoCiqFBnix+vk7WPjkTUwa0I0nvlluNr+s3Mimg8cY3rW9ZZI8X4JQ44uk/vgdekcnQr+Yh/d14yk8ehRpbJorC7U7f84JH2t1XN/fFxJ0503kHTiELK86URTWVngOH0L68jWWTrZeRC2/ByllvX4/lnAh+3JuYTF/HDzGyqm3s/aluykqLWP5rkMWzvf8x5Da/vCrl7uxvJQj+zYQ2mtE4ybXxEwmy7xaqhY1ZrnCCSnlXxXvvwcePVdwNVei9RafmXYWQjhJKevqnlohpSwBSoQQ6YAPcAXQE9hRsR474Ex3yAxgB1BcV05CiMnAZIDPP/8cmw6TawurwcnVl9ysqrP6vKw0HF3Ne1Sc3HzJzawWk52KU0WMk6vWA+Dg7EGHiGGcTNhPqw6967Xtf6skNQ1b/6qeB1s/H0rTM8xijPkFxDw9rXK6/5ZVFJ1IRm9noCQ1jdy9UQCkr1zbJI1lR1df8rKrl2EaDi7e54zJz0nF0VmLMRrLWP7Vo3TqdS3tug23WJ492wki2mr7cUqmxNlecKYCdrLTeperKywBg412kJESnO0hvyKmtOq4TdxJuKqn1hNdVPN+uwty1QAnruzvBEDs8dKKIRVa49fDVU9mbu2NnvFXueLsqOOtr09VfhYSZMPjt2m9js4OerqH2mM0nmLHgca9ye/aKz25eoh2yfzwsUK83G0ArVfL092a01lldS5rkrBxezYTrvZmzZ+ZnMosa9DyF8LHxZHU7MoLbKTn5ON91uVnR4Nt5ftBocHMWvoHWQVFuDlolyW2HEqgU4AXHk5mF+4spiwjHWvvqr81Gy9vyk6fMosxFRaS+MasyukuPy2i5GRKk+RXm5KTaRj8qnoIDb4+lKSaX0435hcQPaVqHPWAraspOpFcOe15+SDyomIoPVWzZ785FCWnYhfoy5l7hA0BvpSkpKOzscYusNp3DfChOMXyw/wuZF/eEZtEgLsz7o7aPnxFlxD2JZ7kmp6dLJav89nH4ay0yuPwGWcfq3OzUnGsdpyJPbAZ31ZhODp7WizPptCSh0xYQkvsWT77N3Cu6eqjN3VAfyllRMUr4BwNZThzJNcY0U4cBPBNtXV0lFJOr4hxBxwBp7O2W5WYlHOklL2klL0mT65fQxnAPzicrPQEsk+dwFheSszOFbTvNtQspn23oRzY9gtSSpKP7cXWzglHF29KSwopKdYqm9KSQuKj/8LT3/K9RXn7DmIf3BpDYADC2grva0dwau1GsxgrZydExZ3J/jeOI3v7boz5BZRmnKYkJQ37tsEAuA/oa3bTjKX4tgonOyOBnNNaOR/ZvYKQLublHNJlKDE7tHI+mbAXG4MTDi7eSClZ99MLuPu0pcfld1o0z12xki/XmPhyjYkjyZLwYK3h7O8BJWVQUFxzmcR0CA3U4sKDBUdStD+T6uOb/dy1HbyxG8oAv/+Vx9NvpfD0WynsOFBAZG+t1719a1sKiyTZtTSWh/Z1JKKjHe9/l2HWw/TQq0k89Ir22ravgLmLG7+hDPDbulM88OJhHnjxMH/vymHYQO0G2U4h9hQUGsnMKa+xjL+3TeX7ft2dOXFS+2Vs3V2/5RtDWJAPx09lk5SZQ1m5kdV7jxLZua1ZzKncgsqDWdTxVExS4mpftTOs2nuEkd07WiS/2hQcOoQhIBAbXz+ElRVuQ68g++8tZjF6B0eElVZfeI66lvz9ezEVWv4pKHXJ3XcAuzatMQRpdZzPmJFknKuOu2kc2dt3YcyvGkbgM6blDMEASP9tAwG3jAXAtW83ynPzKEnNIGdHFA7tgrELDkRYW+N/wyjSlm+weD4Xsi/7ujmx/3gqRaVlSCnZHnuCNt6WvcndPziczPQEsjK0Y8jBHSvocNaxukO3oURVHKuT4vZisHMya1Af/GcFYX1GWTRPpfG1xJ7lVkKI/lLKrcAkYAtQ/Rk4aRXDJQ4D1wFnGsRrgIeBNwGEEBFSyr0N3PZ6YJkQ4l0pZboQwh1wklImAnOAl4A2wOyKbTUKnd6KYTdO4+f370GajHQdMA4v//bs3vQTAD0iJxHSJZK4qE189uIwrG3sGHW71gNTkHuaJZ89BIDJaKRzn2sI6TK4sVKrkzQaOTJtFhHfforQ60lZ8AsFR+Pwv1m7Azzlh4XYt2tD57e1R+wUHI3j0DMvVy5/ZPprdH7vNXTW1hSdSCLmKcvf5a7TW3H5uGks/VQr57B+4/Dwa8/+LVo5dx04ieDOkcRHb2LeK8OwsrFj+E1aOacc20XMjmV4+nXg+zfGADBg1JO0CYu0aM5xJ6Gdn+SBUTrKymH5P1XXqSYO0rFyh4n8Yvhjn4mx/XUMDhekZcO+Y1pcp0BBj3YCk4RyI/yy1fLXuXZHF9E91J4PXwiktFTy8c9VVxym3uvDZ/NPkZVrZPIETzKyypn5mB8A2/cXsmhNtsXzq80/+3LpE+HMvLc6U1Jq4q0vEivnvfpUW96Ze5ysnHKevq819nZ6hIBjx4v44OsT512+sVnpdUwdO4QHvliGyWRibJ8w2vl6sGCrdqVmYv9w1kbFsmBrFFY6HbbWembfPLLyUnBRaRnbjp7gpXFDz7WZxmUycvyDd2n/xjsInZ5Tq5ZTnBCP57VjATj12y8YWrcmeOpLYDJRlJBA4puvVS7e5sXpOEV0x8rFlfAFS0mZ9yWnVy6vY2ONQxqNHH5pFt1/+Ayh05MyfykFR+IIuEWr45K/X4hDu7aEvT8TadTquOinquo4ncGA++D+xDw3w6J5Vhfx3dt4RPbBxtONofGbODrjw8rG/PE5P5O+ahNeIyMZcmgtxqIi9t/zfOV3PfDYDPqsmIvQ60mat5j86FiL53sh+3LXVr4MC2/Hje/9jF4n6BTgxfh+YRbNV6e3YsRN0/jpvXswSSMRA8bhFdCeXRu1Y0jPIZNoFx5JbNQmPn5BO1Zfe0fV1ZKykiLio//m6luabp+wlKYcJtcSiJbUlV7x6LiVwGbgMuAocGvFZ09JKXcKIcajNVZPAAcARynlHUIIT+BjIBTtJGCzlPL+OrYznWqPjhNCHACukVImCCFuAKai9VSXAQ8BHYCxUsrrhRB64G9gqpTyXKfect7Gf10UTe6OIbAhuGtzp9EgQxP28+nq5s6iYR4YAbPmN+c4zIZ5/gY9E56Ib+40GmThu20Yfuue5k6jQdZ8153iXz9u7jTqzTD6IXZdfr57qFuWnn/8xbrA8OZOo96uTIpihXXT9f43hlFlhy+q/Ri0ffm7zc2dRf3dOrhet7JY3IvzSi3SeHz1DpsW8f3O1qJ6lqWUCUBtD0kcUi1mEbColmVPod2cV5/tTD9ruku19/OBsx8psQ34tmK+Eehbn+0oiqIoiqL818hLrGu5RTWWFUVRFEVRlJatBQ1KaBL/6cayEOJO4LGzPv5LSvlQc+SjKIqiKIqiXFz+041lKeXXwNfNnYeiKIqiKMp/hekSG4bREh8dpyiKoiiKoigtwn+6Z1lRFEVRFEVpXC3pSWpNQTWWFUVRFEVRlHqTLfhfU1uCGoahKIqiKIqiKHVQPcuKoiiKoihKvZkusWEYqmdZURRFURRFUeqgepYVRVEURVGUervUbvBTPcuKoiiKoiiKUgfVs6woiqIoiqLU26X2T0lUY1lRFEVRFEWpt0tsFAbiUht30oRUwSqKoiiK0phEcycA8PiH+RZp47z3iGOL+H5nUz3LFrQ1Jre5U6i3/qHOFK/5urnTaBDD8Dt5/7eL65zksWsFv+40Nnca9Ta6l563llxcT59/6nodsxddXDk/O17HaufQ5k6j3kbkxlD458LmTqNB7AdNoHjtvOZOo94Mw+6g+NePmzuNBjGMfogV1h2bO40GGVV2mC/WNXcW9Xfvlc2dgUZeYsMw1A1+iqIoiqIoilIH1bOsKIqiKIqi1Nul9k9JVGNZURRFURRFqTc1DENRFEVRFEVRFED1LCuKoiiKoigNoHqWFUVRFEVRFEUBVM+yoiiKoiiK0gCXWMeyaiwriqIoiqIo9aeGYSiKoiiKoiiKAqieZUVRFEVRFKUB5CX2nGXVs6woiqIoiqIodVA9y4qiKIqiKEq9mS6xMcv/+cayECIB6CWlPNXcuZzL/t1/8+PctzGZTAweNoZrxt1hNv/vTatYueRbAAwGO267/zlatekAwJcfzmDvzi04u7gx84P5TZbzX9HHmL14HSaTiev6d+Pu4f3N5u84msjjc5YQ4OECwNBuHbh/5MDK+UaTiUlvzsPbxYmP7p/QJDlLKdmybCaJMZuxsjFwxQ2v4RUYViMu93QSa75/kpKiHDwDOnPlpNnorWzqvXxjObTvT3797jVMJiN9hoxn6Oh7zeanpxxj/ucvkJwQzYiJjzFk1F0AZJ8+yc+fTiUv5xRCCPoOncigEbdaLM/qpJRs/W0WJw5rZRQ5fhaeAbWUcWYSG36aQklRNp7+nRkyUSvj2D2/sW/zXACsbOwZOPZlPPw6WTzn7SsqcrY2MGhc7TnnZSbxx/wplBZl4+HfmcHjtZzPyEiKYvlnNzLkxndo0+Uqi+XreeVAQmc/D3odSd8sIv7duWbzrVydCf94JvZtgjCWlHDgwRfJjzkKQOsHbiXw9gkgBEnfLCTxk28tlmd1fx04wps/rcRkMjF2UE/uujrSbP7OQ8d44uMf8Pd0A2Boj87cd+3Qei1rsZyj45i9qKKOuyyiZh13JJHH5yyuquMiOtas496Yh7eLIx89MNHy+R5KYPavmzGZJNf1CePuob3M841L4vF5ywlwc9byDQ/h/mF9Afhu8x6W/HMQAbT382TGxCuxtbZsE6HrF7PwvnoIpemn2dz92lpjOr/7At4jIjEWFbPv7ufI3RMNgNfwQXR+5wWEXseJrxYS9+YXFs31jPiDm9mwaCbSZCJ8wAT6Dp9sNl9KyYaFM4k/uAkrGwMjb30dn1ZhlJeV8PO7N2MsL8VkNNKh+1UMuObRJslZuXD/mcayEEIvpTQ28jqtpJTljbnO2piMRr77/A2e/t9HuHv48L+nb6d7n8EEBLWtjPHy8WfqzM9xcHRm/66/mPfJLKa9OQ+AgUOv4YqrJ/LF+y9bOtVKRpOJWQvX8PlDN+Lj6sRNb85jSHh7Qvw8zeK6hwTW2RD+YeNO2vp4kl9c0hQpA3D80GZyMhK5+bnfSTu+j02L/8f4xxbUiNu64i26Db6d9t1HsXHRy8T8s5gul02q9/KNwWQysnTeq0yeOhcXdx8+eOkGwnpcjk9gu8oYewcXxt72PAd2rTdbVqez4pqbnyGwTWeKiwp4/8XxdOjS32xZSzlxeDM5pxOZ+NRq0k/sY8svMxj7UM2TuH9Wv034wNsI6TaKP5dO5/DOxXTuNwkn90CumfwttnYunDi8mT+XvFzr8o0p6chmck4lMv7J1WSc2Mffv85g9AM1t7nj97fpMuA22nYdxV+/TOfIrsWE9p0EaL+vnb+/TUD7ARbNFZ2Ozm+/xI4xd1OcnEb/jQtIX/kHBYfjKkNCpkwmNyqGPTc/gkP7Nlr86LtwDG1P4O0T2Hr5RGRpGT2XfEHG75sojEu0aMpGk4nXf/iNT5+8Ex83Z25+9TMiI0IJ8fc2i+vePpgPHr31Xy1riZxnLVjD5w/fiI+r87nruDoawj/8sZO2Ph5NUscZTSZmLd3I55Ovw8fFkZs+mM+QsDaE+HiY59vGn4/uGm32WVpOPj9u2cfSp2/BYG3F09+tZPXeI4zp3dmiOSd9s4SET74n4qvZtc73GjEYh3bBbAwdjmvfbnT5aDp/D5gIOh1hH0xj+8g7KU5KY+C2RaQt30B+TFyt62ksJpORdQtmMOGRr3Fy9eH7N8YTEj4UT7+qejX+4GayMhK4e/oaTibsY+3P07nlmYXorWyY+Og32BgcMBrL+Ontm2gTNhj/NhEWzdlS1JjlJiCEeEUI8Vi16ZlCiEeFEE8LIXYIIfYLIf5Xbf4vQohdQoiDQojJ1T7PF0LMEEJsB/pTt6eFEP9UvNpVLNtaCLG+YlvrhRCtKj6fJ4R4RwjxBzC7YvoDIcTfQohjQojxjV0ex44exMcvCG/fQKysrek7cBh7tm8yi2nfqRsOjlpvQEjHcDJPp1fO6xjWo3JeUzmQeJIgTzcCPV2xttIzomdnNkYdrffyaVm5/Hkwjuv6d7VgljXFH1xPx15jEELg2zqC0uJcCnLTzWKklCTHbiOkq9Yz2KnXWOIPrKv38o3leFwUnj6t8PAOwsrKhoh+Izm4a4NZjKOLB0Eh4ej15ue9zm5eBLbRDnQGOwe8/duSk2WZPM+WGLOB9t21MvJppZVRYS1lnBK3rbL3tUOPMSREaw1+n9bdsbXTeuq8W3WjIDfV4jkfj9lAu4qcvc+R88lj2wgO03Ju32MMx6OrTlJitn5P67BhGBzMGyeNzbVXVwqPHacoIQlZVkbq4pX4jBpqFuPQqR2nN24DoOBoPHatA7Dx8sChY1uyd+zDVFSMNBrJ+msHPtdcadF8AQ7EJxHk7UGglzvWVlZc1SecjXtjLL7shTiQkFJRx7lpdVyPUDbuP1Lv5bU6LpbrLutmwSyrHDieRpCnK4EeLlq+Ee3ZePBYvZc3mkyUlJVTbjRRVFaOl7ODBbPVZG7ZSVlmTp3zfUZfQfL3vwCQvX0f1i7O2Pp64dqnK4VxiRTFa38DKfNX4HPtFRbPNzVhP25erXH1DEJvZUOnnqOI22/eURG7fz1hfccihMC/TQQlRbnk56QjhMDGoJWpyViOyVSOQFg8Z0uRJmmRV0vVXDf4fQncDiCE0AE3AmlAe6APEAH0FEIMroi/S0rZE+gFPCqEOHM0cgAOSCn7Sim3nGN7uVLKPsBHwHsVn30EfCul7Ar8AHxQLb4DcKWUckrFtB8wELgGeP1ffeNzyMrMwN3Tp3LazcOHrMyMOuM3r1tG1x6XNXYaDZKenYevm1PltLerE2nZeTXi9scnM+G1L3nwkwXEnqz6Tm8sWc8TYy5Hp2vayqIgJw1HV7/KaQcXXwpy0sxiiguzsbFzRlfRAHVw9aUgJ73eyzeW3Mw0XD18K6dd3H3/VYM3MyOZlMQYWoU0zYmJVkZVeTu4+NY4oSgpzMbWUK2MXXwpzK1Zjod3LCaowyDLJgwU5qbh4FItZ2ffGo3lksJsbKrlbO/sS0FFzgU5aSRGr6NTnxstnqutnzdFSVUnEMUpadj6+5jF5EUdwnf0MABceoZjCPLHEOBDfvRR3Af0wtrdFZ2dAa/hgzEE+mJp6Vm5+Li5VE77uDmTkZVbI25/3HEmTv+Ih977hrjktAYt2+g55+Tj61bVCeHt5kRazrnquPnmddzidTwx9nJ0omnquPTcfHxdHavydXEkLaegZr6JqUx450cenLuM2NTTAPi4OHJ7ZA+umvk1V74yFyeDLZd1bN0keZ+Lwd/HfF9PTsUQ4FPL52kYAnxqW0WjystOw8mt6u/F0dWHvGzzeis/Jw2navWfk6sv+RUxJpORb2aN4ZNnL6N1p8vwa9M0J1LKhWuWxrKUMgE4LYToDgwH9gC9q73fDXRCazyD1kDeB2wDgqp9bgQW12OTP1X7eaYHuj/wY8X779Aaw2csPGtIxy9SSpOUMhqo8y9SCDFZCLFTCLFzzpw59UhLU/vljNor2JionWxe9ysTb3u43uu3hFozPivl0EBfVs94kIVT72ZSZE+e+GIJAJsOxOLuaE/nVpY/SJ+t9qIW5w8SDVi+kchaSrmhmyopLuDb9x5j9K1TMdg7nn+BRlFb+ZknXp99PiVuO4d3LqbPiCm1xDauWvM5O+dafx9azPaVr9HrqinodHqL5HeuvIAaO+axd7/AytWZy7YsodV9t5C3PwZZbqTgyDGOvTuXXr98Sa8lX5AbdQhZ3qij1+rvrO/RqbU/K2c/xYLpD3Pj0H488fGPdSxYc1lLqG2fOLsnMDTIl9WvPFRVx83RDkeboo7i7mRP51Z+NdZhKfXYhQkN8GL183ew8MmbmDSgG098sxyA3MJi/jh4jJVTb2ftS3dTVFrG8l2HmiDrcxO1/J6llPX6G7CMuuuAqjTq/kXodHpuf34Z983cRGrCfjJS6n+loqW51HqWm3PM8lzgDsAX+Aq4AnhNSvl59SAhxBDgSqC/lLJQCLERMFTMLq7nOGVZx/u6Ys4+Ha8+4KzOWlpKOQc400qWW2Pq1/vh7uFN5qmqs9Os02m4uXvWiDuRcJSvPnqVKdPex9HZtV7rthQfVydSs6p6WdKz8/B2cTKLcbSzrXw/KCyEWQt+Jyu/kL3Hkth4IJYt0XGUlBkpKC5h6je/8drttd/gcaGi/vqB6O0LAfAOCic/+2TlvIKcVByczcc+GhzcKC3KxWQsR6e3oiC7KsbR1ee8yzcWF3dfsk9X9Z7kZKbi7Fr/bRnLy/j2vcfpPuAawnsPs0SKlQ5u/YFDOxYB4BXYhfzsqrwLclJxcPIyizc4uFFSXK2Mc1Kxr1aOp08eZvOSlxhxx+cYHNwsknP0th84UpGzZ2AXCnKq5Zybiv3ZOdu7UVot58LcVOydtJxPJR9g43ytUV9cmE3Skc3odHpad278IQ4lKWnYVesNNvj7UHLSvBfcmFfAgQdfqJyOjFpHYWISAMnfLSb5O61R137a4xSnWObKSHXebs6kZVVdbk/LysXL9ez6wlD5flDXjrz2w29k5RXUa1lL0Oq4qjo8PSsPbxfzE07zOq4ds+avqajjktkYFcuWg59QUlZeUcf9ymu3m48VbtR8XRxJzc6vyjcnH++zhlI4GqrlGxrMrKV/kFVQxI7YJALcnXF3tAfgii4h7Es8yTU9LXtj7fkUJadiF+hLVsW0IcCXkpR0dDbW5n8DAT4Up1h+mJmTqy95WVX1RH52Go4u3jVjqtV/edmpNWIM9s4Ete9LQvSfePl3sGzSlxAhhDswHwgGEoCJUsqss2KCgG/R2p4mYI6U8v3zrbs5n7O8FBiB1qP8e8XrLiGEI4AQIkAI4Q24AFkVDeVOQL9/sa0bqv3cWvH+b7ThHwA3A+caxmFRbdp3Ju3kcTLSkikvK2P7lrV07zPYLOZ0Riofvv4Mk5/4H74BzX95LKyVH8czMkk6lU1ZuZHVu6KJDDe/eexUbn7lWXZUQgomCa4Odjw2eghrX3mIVf97kNl3jqZ3h9YWaygDhA+4mRue/IUbnvyFNmFXcHjnMqSUpCbuxcbgVKOxK4QgoF1f4vb/DsChndpyAMGdh553+cYS1LYLp1ITyUxPory8lL3bVtG55+X1WlZKyYIvXsI7oC2RV99hkfyqC+t/M+MeXcq4R5cS3PkKju7RyijtuFZG9rWUsX/bvsQf0Mr4yO5lBIdq427zs1NY9/2jXD5xNq5ebSyWc+d+NzP2kaWMfWQprUOvILYi5/Tje7GxrT1nv7Z9STio5Xx09zJaVeQ88al1THx6PROfXk9w2HD6j55mkYYyQM6uKOzbtsaudQDC2hrfcVeTvvIPsxgrFyeEtTUAgbdPIPPvnRjztD4AG093AAyBfviMHsbJRSsskmd1YcEBHE87TXJGJmXl5fz+TxRDupk3xE7l5FXWFweOJSGlxNXRvl7LWiTn1v4cz8iqquN2xxDZtb1ZTM06Tmp13JghrH31YVbNeJDZd46pqOMs11AGCAvy4fipbJIyc7R89x4lsnNbs5hTuQVV+R5P1fK1N+Dr5sT+46kUlZZpT4aJPUEbb3eL5lsf6b9tIOCWsQC49u1GeW4eJakZ5OyIwqFdMHbBgQhra/xvGEXa8g3nXlkj8G0dTlZ6AtmnTmAsL+XQrhWEhJvfLxDSdSgHt/+i3ZcRvxdbOyccXbwpzMukuFA7+SorLSbx8N+4+7StbTMXBZOUFnldoOeA9VLK9sD6iumzlQNTpJShaO3Jh4QQ572Ttdl6lqWUpRU30WVX9A6vEUKEAlsrLmvkA7cAq4H7hRD7gcNoQzEayrbiJkAdMKnis0eBr4QQTwMZwJ0X9IUugF5vxS33PsNb/3sUk9HIoCtHE9AqhA2rtd6foSPGsWz+XPLzcvj2s9mVy0x/W3vk06dvv8ChA7vIz83mibtHMfbGyUQOG2PRnK30OqZOGM4Dn8zHJCVj+3WlnZ8XC7bsAWDiwO6s3XOYBVv2YKUT2NpYM/uO0bVeVmtKrUMjOX5oMz+8PhwrawNDb5hVOW/53MlcPuEVHFx86DfqKdZ+/yTbV7+PV0AooX3Hn3f5xqbXWzH2jhf4Yva9mEwm+kReh29ge7au+xmA/lfeSG52Bh+8OJHionyETseWVd/x1Bu/cfLEYXZv+RXfoA68M/U6AEbe8DihEZZ/5FZQx0hOHN7M/Leuwspae3TcGau/nsygca/i4OxNn5FT2PDTFHau+QAP/1A69tbKePf6TyguzGbLshmAdunyuocXWTTnwI6RnDiymUXvaDkPur4q5zXfTGbgda9i7+xNr6umsPHnKexaq+XcoVej3+97XtJoJPrpV+m1dC5CryPpuyXkH4ol6C6tT+DEV/Nx7BhC+OevI41G8g/FceDhFyuXj/j+fWzcXTGVlRM95RXKsy0//tdKr+fZm67hwfe+wWQyMWZAT0ICfFi48R8AJgzpw7pdB1m48R/0Oh0GGytem3wDQog6l7V8zjqmThzGAx//bF7H/bkbgImDerB2zyEW/LkHK70OW2srZt85ptnqOCu9jqljh/DAF8u0R+z1CaOdrwcLtkZp+fYPZ21ULAu2RmGl02FrrWf2zSMRQtC1lS/Dwttx43s/o9cJOgV4Mb6f5R6JeUbEd2/jEdkHG083hsZv4uiMDxEVj6s7Pudn0ldtwmtkJEMOrcVYVMT+e54HtL+BA4/NoM+KuQi9nqR5i8mPjrV4vjq9FVdMnMbij+/BZDIS3n8cnv7t2funNtIzYtAk2oZFEn9wE3OnD8Paxo4Rt2h1SUFuOqu+fQ6TyYiUko49RhASXr/Oj5aohQ6ZGAMMqXj/DbAReLZ6gJTyJHCy4n2eECIGCACiz7Vi0VyP/6i4sW83MEFKWf/HKFw86j0MoyXoH+pM8ZqvmzuNBjEMv5P3f2uRf7B1euxawa87m2mM6L8wupeet5aYmjuNBnnqeh2zF11cOT87Xsdq59DmTqPeRuTGUPjnwuZOo0HsB02geO285k6j3gzD7qD414+bO40GMYx+iBXWHZs7H/eFTAAAMUpJREFUjQYZVXaYL9Y1dxb1d++VLeMRGrdPS7XIwffbV/zuA6o/vHpOxRDX8xJCZEspXatNZ0kp6xzHJ4QIBjYDXaSU52ywNUvPckWX93Jg6X+0oawoiqIoivKfZKmO1rPu/apBCLEObbzx2V6o5bM6VQz5XQw8fr6GMjRTY7niqRKNOlhHCLEUOHuA47NSyt8bczuKoiiKoihK05NS1nkziBAiTQjhJ6U8KYTwA2q961MIYY3WUP5BSrmkPtv9z/wHPynldc2dg6IoiqIoyn+dqWWOWf4V7X94vF7xc9nZAUK7qeBLIEZK+U59V9ycT8NQFEVRFEVRLjIt9DnLr/+/vTuPj6o6/zj++SassiOb4IIgiCiCoOKO+05bd61Ybd1abcX662JrtVWrtXa1alsV674vxYWqoFaoiiIoggIuCCgiIMq+J3l+f5w7MAkzyUQzufeG5/16zSu5N3fMl/HOzZlzz3kOcJikD4DDom0kdZX0n+iYfYEzgIMlTY4eR9f0H24wPcvOOeecc27zZGZfENbsqLp/HnB09P3LVLNeRj7eWHbOOeeccwWLq5JaXHwYhnPOOeecc3l4z7JzzjnnnCuYVaSrlv3X5T3LzjnnnHPO5eE9y84555xzrmAJLR1XNN5Yds4555xzBfMJfs4555xzzjnAe5adc84551wt1MECIqmiza0rvR75C+ucc865ulTrBTWK4aQfzypKG+eRv2yfiH9fVd6zXEQ3PJWe9vLwoeLusXGnqJ3vDIGHx6erfM3Je5dw2/NxpyjcuYfCNQ+Wxx2jVi47tZRf3bku7hi18tuzmnDL6LhTFO78w0nl9eKecXGnKNwZB6QrL4TMabq+QbjGjWq8Y9wxCnbM+vfijgBsfj3L3lh2zjnnnHMFq7B0dVR9XT7BzznnnHPOuTy8Z9k555xzzhVscxuG4T3LzjnnnHPO5eE9y84555xzrmCbW8+yN5adc84551zBNreywz4MwznnnHPOuTy8Z9k555xzzhWsosJLxznnnHPOOefwnmXnnHPOOVcLm9sEP+9Zds4555xzLo9UNJYltZV0Qdw5nHPOOec2d2YVRXkkVaKGYUgSINv0FWsLXAD8vZb/vVIzK6+jeEVnZrz8xDXMmT6ORk2accgpv6Pj1jtvctyyL+Yy+t5LWLt6KR269eXQ035PaaMmBT+/rsx8ZxyjH7oGq6hgwH4nsc9R523y7xn90DXMnDqWxk2acexZ17HVdiHPmlXLGHX3r/j80/dB4tgzr2XrnrsVLWvGB1P+x6j7r8UqKhh0wIkccOy5m2T+z33X8v6UcTRu0ozjz7mWrt1D5vGj72bi2EcwM3YfchL7HHFm0fPOenccLz4aXuN++57E4MM3fY1ffOQaZr07lkZNmnHUGdfRedudKVu/lgf/cjrlZeuoKC+n925HsO+xFxU9b8bhA0XPrcT6cnj69QrmL970mDYt4Lh9SmjeBOYvNp54zaiogG07wUn7lbB0ZThuxlzj5XeLf8vvmD1L6b11CevLjMdeLuezLzf9ne1awslDGtG8qfjsiwoe/V855RXQtDGcdEAj2rSAEsEr71bw5ofFu/DPmjaOlx67hoqKCvrtfRJ75jgv/vtYOC8aN2nGEcOuo/M24bx46K/hvLCKcnoNOIJ9jqmf8yKN14uZ74zjuQejzPufxL65Mj94DR9GmYd+t3Lmp+/6FZ/Pex8QQ88qfuavmveL+R/x+C0/3nDc4kWfMOSbFzH40LOKmhfSd43b9bZr6XT0gaxb+AXjdhua85i+f7mMTkcOoXz1Gt4++1KWvTUNgI6H70/fP1+GSkv45F+PMPMPtxU9b7H4MIx6Jqm7pOmS/g68CVwu6Q1JUyRdGR12HdBT0mRJf5B0oKSns/4bN0k6K/p+tqQrJL0MnBRtXynpTUlTJfWpJsuQ6HdMlvSWpFbR7xon6d+Spkn6p6SivG4fzxjH0s/ncPqlz3HgiVcx9rErcx43ftQf6X/AmZx+6XM0bd6a6RMeq9Xz60JFRTnP3n8Vp140gvOvHMW7bzzN5/M+rHTMzHfG8eWC2fzgt6M5+oyrefa+32z42eiHrqHHzvvz/auf5dwrnqDDVj2LljU781P3XM13LrmVH137FFNeH8XCTytn/mDKOL5YMIeLf/8s3zzrSp66+yoAFsx9n4ljH+H8Kx7mwqtH8t7bL/HF/NlFz/v8w1dxwoUj+O7lo5gx8WkWfVY576x3x7H489mc/ZvRHP7tqxnz4G8AKG3UhJMvuoszf/kk3/nlSGZN+x/zZk0uat6MnltB+5biH6Mq+M8bFRy5e+63y8H9xYT3jH+MqmDNOhjQQxt+9snnMOK5CkY8V1EvDeXe3cSWrcVfHl/PyPHlfGPv0pzHHT6olFenVfDXx9ezeh0M6hX+bXv1KWHhEuPmJ8u4/dkyjtyjlNIiXV0rKsp58ZGrOO4HIzjrslHMmPQ0X1Q9L6aNY8nC2XzvitEceurVvPDQb4BwXpx00V185xdPMuzSkcyeXj/nRVqvF8/cfxWnDR/B968axbsT8mReOJsLrgmZn8nK/NyD19Bzl/35wdXPct6vi5/56+TdsksPzv31E5z76yc4+/LHadykOTvudlhR82Yyp+0aN/eux5lw7Dl5f97xyANosUN3XtrpcKb+4HJ2uSnkpaSEnf92BROGnsPYXY+h66nH0nKn4p/Hrm7E3liO7AjcDfwc6AbsCQwABkk6ALgUmGlmA8zspwX899aY2X5m9mC0vcjMBgL/AH5SzfN+AlxoZgOA/YHV0f49gf8D+gE9geNr8W8r2Kx3X2DH3b+JJLpsN4B1a5axctnCSseYGZ9++Bo9dz0CgD67f4tZ7zxf8PPryrxZU2jfaTvaddyG0kZN6LvHMbz/9guVjnl/8gvsuve3kES3HgNYs3oZy5csZO3qFXz8/hsM2O9EIFz0mm3Ruig5s839aApbdt6W9p22oVGjJvQbfDTT33qx0jHT33qRAfuG13CbHQawelXI/Pm8j9imZ3+aNG1OaWkjuu+4B9PefL6oeefPnkK7jtvRtkN4jfsMOoaZUyq/xh9OeYGdB4fXuOv2A1i7ehkrli5EEk2atQCgoryMiooyhHL9mjrXu5uYMjs0cOd9Ac0aQ8tmmx7XvbOY/kk4bsoso3e3+smXy07bljB5ZugJnvu50ayJaNl80+N6bFXCu7PDcW99WMFO24ZLqBF6l4m+rl4LxaqsNH/OFNp2qHJeTK18Xsyc+gJ998xzXjTNOi/Kywg39IorjdeLebOm0L7jxsw773EM70+unPm9yS/Qb6+QeeueA1izKr7MXydvtlnTx9Ou4za03bJbUfNCOq9xX748kfVfLs37887fOIRP7x0JwJLX36Zxm9Y07dKRtnvuyqqZc1g9ay62fj3zHhpF56GHFD1vsViFFeWRVElpLM8xs9eAw6PHW4Re5j5Ar6/w33uoyvbj0ddJQPdqnvcK8GdJFwFtzaws2j/BzD6KhnQ8AOz3FTLVaOXSBbRsu9WG7RZturBy6YJKx6xZtYQmzVtTUhpG0LRo24WVSxcW/Py6snzJAlq177Jhu3XbzixfvGCTY1q3yzqmXReWL1nA4kWfsEWr9jx95y8YcfW3ePruy1i3dlVRcmZbtnghbbIyt2m3aeZlixdUOaYLyxYvpNPWvZj93kRWrVjMurWr+WDKOJZ+Mb+oeZcvWUCrrNevZdvOLF9SOe+KpQto1XbjMa3admFFdExFRTl3XftN/v7zfdiuzz5stX3/oubdkKG5WLZq40Vv2WpoVaXh2bwJrFkHmUWgqh7TrQOcc0QJpx5QQofit4totYVYujIr80qj9RaV//Bu0TRkzlzPwzHh+9emV9Cxjfj5yY354TcbM2pCGcW67K8o5LzY5JgurFi68by457pv8s9f7MO2ffZhq+7FPy/SeL1YvmQBrbMyt2q36eu8fHHlYzZk/vwTWrRqz1N3/ILbrvoWT99V/MxfJ2+2aW+MYuc9jy1q1g15UnqNq06zrp1ZPXfj34Y1n86nWbfOOfYvoFm3znFEdF9BUhrL0ehEBPwu6kEeYGY7mNntOY4vo3L2qv1WK6tsr42+llPNOG0zuw44B2gOvJY1ZKPq372cfwclnSdpoqSJt956a75fk1fO1SOr9vrkOki1eH5dyfHLqvZQ5VoOUxIV5WXM/3gaA4ecxjmXj6RJk+a8+mztX69ay/0C1XyMRKeuPdn/6HO48w9nc/efzqXLNn0oKc19q77ufLXXOPP/vKSklDN/+QTnXzOW+bOnRGMniy/XKVc1ZXWn5fwv4aanwhCMNz6o4KT9i3+Z+qrvksy/q1c38dmXxu8fXs/NT65n6OBGG3qa617N50XO9ycbz4szLn2Cc68ey/w5U1hUH+dFCq8XuZfzrXqm5MlcUcZnH09j0IGnce4VI2nctDmvPlPczF8nb0Z52Tref/tFdtr9yLoNl1c6r3HVyXWnxszyXBiT25NakwqrKMojqRI1wQ94Drha0n1mtkJSN2A9sBxolXXcHKCvpKaEhvIhwMtf95dL6mlmU4GpkvYm9GwvAfaUtH30e08Bcl71zOzWrJ/ZDU/V/EaY+sp9THv9EQA6bdOPFUs+2/CzlUvn06J1p0rHN2vRjnWrl1FRXkZJaSNWLtl4TMu2nWt8fl1p1a4Ly7/c+Cl52ZIFtGxb+Xe1bteFZYuzjlk8n5ZtOiGJ1u260K1H6AXoM+jIov8hAWjdvjNLszIvXbyAVu2qZG7fpcox82ndtiMAg4acyKAh4bbqmEf/Qut2xe0VaNW2C8uzXr8VSxbQsk2nTY9ZsvGY5Uvmb3JMsy1as02vwcye9j86du1dlKyDdhC79Qx/DOZ9memVDed/6+awYnXl41ethWZNwt8Ps3DM8uiYdWUbj5v5GZSUhJ7o1evqNvPgPiXs3js0xD9dZLRpkZW5ReXe8ezMJQq9y61biOVRZ+HAHUoZNzXMJf5yOSxeYXRoIz5dVPd/DFsWcF60bFf1mPm0yHVe7DCY2dP/R4cinRcZqbxetOvCsqzMyxcvoFWVzK2qHJMv804Djyx6A//r5M348J1xdNl2Z1q27lDUrBvypOgaV6jVn86n+dZdyMxpbtatC2vnLaSkSWOab72xh7xZt86smVecYZL1IclDJoohKT3LAJjZaOB+YLykqcCjQCsz+wJ4RdI7kv5gZp8ADwNTgPsIwzbqwsXR73ibMF75mWj/eMIkw3eAWcC/6+j30W/f0znlkpGccslItt/5EN6b+ARmxvw5k2nSrNUmjV1JdNthMDOnPAfAjInheQDd+x5c4/PrStfu/fhy4WyWLPqE8rJ1THtjFL37H1zpmF79D2bK+JFhnPVHk2navBWt2naiZZuOtG7XhS/mfwTA7Onj6di1+BMdum3fjy8WzGHx53MpK1vH1Nf/Q5/dDqp0TJ8BBzH5lfAafvLhZJpFmQFWLPsCgCVfzGPaxDHsutcxRc3bZbt+LM56jWdMGkXPfpVf4567Hsy7r4fXeN6s8Bq3bNOJVcu/ZM2qZQCsX7eGOe+9SvvOPYqWddKHtmFC3vtzjV27h4Zz1y1h7XpYsWbT58xZADttE47bdXvxwafh4tsi6z5R1/ahb6yuG8oAr8+o4OYny7j5yTKmfVzBgJ7hcrh1R7F2nW3SwAeYNd/YuXs4brcdSpj+cegJWbLS6Nm1ZEP+Dq3F4uXF+WPSZdt+LPl8NkuzzoseVc+LXQ5m2oSN50WTZrnPi4+LfF5kpPF6kcm8+POQ+d0cmXv3P5ipr4XMc2duvF5UzTxrxviiT/D7Onkz3p0wip33LO51LVuarnGFWvjUi3Qb9i0A2g7uT9my5ayd/zlL35hKix2607z71qhxY7qecgwLnn6x+v+YS4zYe5bNbDawS9b2DcANOY77dpXtnwE/y3Fc93zbZjYROLCaLD+qui+6pbLKzE7J97y6st1OQ/h4xjjuu+5wGjVuxsGnXLvhZ0+POI+DTrqaFm06s9cxP2HMvZfw+rM30LHbTuw0+MQan1/XSkobccRpV/DAX8+hoqKc/vueQMeuvZg09gEABg05jR36DWHmO2P5+2WH0bhJc449a2Oew0+7nJG3/4SKsvW07bANx571u6JlzSgtbcSxw37FXX88h4qKCgbufzydu/ViwothHuieB59K7/5DeH/KOP7ysyNo3LQZx5+9MfODNw1n1YollJQ24tjvXE7zFm2KmrektBGHnHwFj90cXuN+e59Ah669mPy/8BoP2P80euw8hFnvjmXEb8JrfOSwkHflsoU8c/elVFSUY2bsOPBIevY7qLpfV2c+/Ax6djUuOLaE9WWhdFzGKQeUMGpCBSvWwItvV3DcPiUM6ScWLIbJH4XjdtpGDNxBVFRAWTn8+9Xi35p7f67Ru5txyfGNWVduPP7yxoqTZxzaiJGvlLF8NTw3sYxThjTi0N1K+exLY9IH4biX3i7nhP0a8cNvNkLAc5PKWbU2zy/7mkpKG3HQSVfw2N/PwaycXfY6gQ5b9eLtl8N50X+/09h+5yHMmjaWf111GI0aN+eIrPPi2XsvxaLzovduR9Jjl+KfF2m8XpSUNuLIb0eZrZwB+55Ax269mPRSlPnAkPnDqWO5Oco8NCvzEaddzsgRP6G8bD1tO27D0CJn/rp5169dzaxpr3L0sKuKmrNq5rRd4wbc8ye2HLInTTq04+BZY/ngqhtR49CU+vjWB1n4zFg6HjWEA2eMoXz1aqac80sArLycd4ZfxZ6jRqDSUube+Rgrpn1Y3a9KNCvWDOaEUu5xTi5D0oHAT8ystjMeChqGkRTDh4q7x8adona+MwQeHp+uN+zJe5dwW3GLaNSpcw+Fax5MTalyAC47tZRf3VmErugi+u1ZTbhldNwpCnf+4aTyenHPuLhTFO6MA9KVF0LmNF3fIFzjRjXeMe4YBTtm/XvxlQ3Kctjpk4rSwBlz36BE/Puqir1nOQ6SvgsMr7L7FTO7sOqxZvYS8FI9xHLOOeecS7zNbczyZtlYNrM7gDvizuGcc845lzZJXpq6GBI1wc8555xzzrkk2Sx7lp1zzjnn3FdTsZkNw/CeZeecc8455/LwnmXnnHPOOVewza10nPcsO+ecc845l4f3LDvnnHPOuYJ56TjnnHPOOefy8NJxzjnnnHPOOcB7lp1zzjnnXC1sbsMwvGfZOeecc865PLxn2TnnnHPOFWxzKx0ns82rKz3tJJ1nZrfGnaM20pY5bXnBM9eHtOUFz1wf0pYX0pc5bXkhnZldfj4MI33OizvAV5C2zGnLC565PqQtL3jm+pC2vJC+zGnLC+nM7PLwxrJzzjnnnHN5eGPZOeecc865PLyxnD5pHAOVtsxpywueuT6kLS945vqQtryQvsxpywvpzOzy8Al+zjnnnHPO5eE9y84555xzzuXhjWXnnHPOOefy8Mayc84555xzeXhj2TnnnHPOuTx8uesUkPSCmR1S074kkdQCWG1mFZJ6A32AZ8xsfczRGgRJpUA7M1sUbTcBzgJ+bGY7xZmtOpJ2AfoCzTL7zOzu+BI1HJKOr+7nZvZ4fWWpLUnNzGxNlX0dMud30kg628xuz9ouBX5lZlfGGKtakvqa2bQq+w40s5diitTgRO/B/QADXjazf8ccydUR71lOMEnNJLUHOkhqJ6l99OgOdI05Xk3GAc0kdQNeAL4L3BlrohwkTZU0Jd8j7ny5SDoV+BKYImmspIOAj4CjgNNjDVcNSb8GboweBwHXA9+INVQNJPWW9IKkd6LtXSX9Ku5ceQyNHmcDtxPOhdOBEcCwGHMV4g1Je2U2JJ0AvBpjnpocIuk/kraKPgC+BrSKO1QNHpb0cwXNJd0I/C7uUPlIOl7SB5KWSlomabmkZXHnykfS34HvA1OBd4DzJd0cbypXV7x0XIJJGg5cTGgYfwoo+tEy4DYzuymmaDWS9KaZDZT0I6C5mV0v6S0z2y3ubNkkbRd9e2H09Z7o6+nAKjO7qv5TVS9quH3LzD6UNBAYD5ya9F4MSVOB/sBbZtZfUmdghJkNjTlaXpLGAj8Fbsmcu5LeMbNd4k2Wn6SngXPN7LNoeyvgZjOrtuc5TpL6Af8CXiJc77YEzjGzuXHmqo6kU4CbgVXAaWb2SsyRqhXd7fs9MIjQsL8P+L2ZVcQaLA9JHwJDzWx63FkKIeldYBeLGlWSSoCpZrZzvMlcXfBhGAlmZjcAN0j6kZndGHeeWpKkvQmNzrOjfYk738xsDoCkfc1s36wfXSrpFSBxjWVgnZl9CGBmb0qalfSGciQzLKdMUmtgIdAj7lA12MLMJkjK3lcWV5gCdc80lCMLgN5xhSmEmU2VdA3hw+py4ICEN5R7AcOBx4CdgDOizoBV8Sar1npgNdCcMAxqVlIbypEFaWkoR94DtgXmRNvbAIm8O+lqL3GNF5fTfEmtzGx5dAt4IPBbM3sz7mDVuBj4BfBvM3tXUg/gv/FGqlYLSfuZ2csAkvYBWsScKZ9Oki7J2m6ZvW1mf44hUyEmSmoL3AZMAlYAE2JNVLNFknoSxiAi6UTgs+qfEruXJD0HPEDIfSrJfu8h6XagJ7AroWH/lKSbzCypt7GfAn5oZs8rfJK6BHgDSHIv4hvAE8AehJ77WySdaGYnxhsrr4mSHgJGAmszOxM89n5LYLqkzDVtD2C8pCcBzCzRQ85c9XwYRgpImmJmu0rajzDG7I/AL81scMzRChLdjmppZkkebzaIcBu4TbRrCfC9JH4gicb+5pXkSUYZ0bj71maW6J6X6EPercA+wGJgFjDMzGbHmasmko4DDog2xyX9zoOkHwN/zbqF3Qb4s5mdXf0z4yGpddXrmaReZvZBXJlqIml3M5tYZd8ZZnZPvufESdIdOXabmX2v3sMUQNKQ6n5uZmPrK4ure95YToHMWF9JvyOMgbo/ieN/s0m6nzDZoZzQi5j54/eHWIPVIBoeIDNbGneWhibqgTsd6GFmV0naFuhiZknvXc6M9ywxs+VxZylENBa/V9TzuQVQmvTsVTI3BxolNXM03v5aoJuZHSmpL7B3doWMpEnT+0+hush1ZvbTuLMUSl4BqkHzxnIKRBN2PgUOJUzOWA1MMLP+sQarhqTJZjZA0umEzD8HJpnZrjFHq6TKcIZNJHFIg6S/VdllwCLgv5lhJEkk6R9ABXCwme0kqR0w2sz2iDlaXpKuBa43syXRdjvg/8wsqRUxkHQucB7Q3sx6RuNr/5nwUpOpyizpGeAO4LJosmojwsTVfjFHyytt7z8lvDxqVZImAfsD7QjVUSYSJokntkKRK5yXjkuHk4HngCOjP9rtCTP0k6yxpMbAt4Anok/XSfxk1qqGRxJNqvJ4kzD+9w+SLo4xV00Gm9mFwBoAM1sMNIk3Uo2OyjSUYUPmo+OLU5ALgX0JVXOIhgZ0ijVRzdKWuYOZPUxofGJmZYS7aEmWtvffZElPSjojKiN3vGqoJR4zRRM8jwduNLPjSPYYdlcLPsEvBaI34OOSOkW3zgBmxJmpALcAs4G3gXHRLdbEjVlOw/jeqszsrlz7Jf2TUJv2r/UaqHDro9urmXGpHYkaGwlWKqmpma0FiIYHNI05U03Wmtm6TAWPqNcziR9Us6Ut80pJW7LxXN4LSPrQrbS9/9oDXwAHZ+0zIKkT/HJVgCqNMY+rQ95YTgFJ3wD+RKg/upBQnmYGCf7UamZ/A7KHC8xRWDwjkSRtTVgsY1+i1ZeA4UkuX1WVma2uUuIsaf4G/JtQzeMa4EQgscMZIvcCL0STjQz4HpDzw0qCjJX0S6C5pMOACwjVG5IsbZkvAZ4EekYlJjsSzuckS9X7z8y+G3eGWhpOuipAuVrwMcspIOltwqfr56OJfgcRiuCfF3O0vLImwHQ1s6OSPgFG0hjgfjYuSjIMON3MDosvVeGinrgzgOMtgYt8RBVR9iKsPHgIYYGdF9JQR1XSUWzMPNrMnos5UrWi1/ps4HBC5ufM7LZ4U1UvV2bCgjWJ/QMVved2JOR9Lw0TuST1ISXvv4bQgZFN0o1m9qO4c7ivxhvLKSBpopntHjWad4tm204wsz3jzpZP2ibAZCYk1rQvCSQtZ9Nb1KuBscDFZjav/lPVTNJ4M9s77hwNnaThFhY0qnaf+3oUarF3J+sOrZndHVugAkTDMDpTOfPH8SXKL+0dGFUpWtU27hzuq/EJfumwRFJLYBxwn6QbSP4qYmmbALNI0jBJpdFjGGG8XOKYWSsza13l0dnMTk5qQzkyWtIJSvhYkWzRpKIPJC2VtEzSckmJG3tfxZk59p1V3yFqQ9K+ksZIel/SR5JmSfoo7lz5SLqHUO9+P8LiE3sAu8caqgaSfkRYzXEM8DQwKvqaVB3N7A4zK4sedxKGuzhX73zMcjp8k9Bz+GPC5IE2JHMZ5mxpmwDzPeAm4C/R9ivRvsSRNMzM7o2+39fMXsn62Q/N7Kb40lXrEsKqiGWS1hBuBZuZtY43VrWuB4Ym+XZ1hqTTgG8D2ytaNSzSioR+8MtyO+H6Nolkf6jO2B3om+RhIjkMB3Y0s6SfCxmLok6LB6Lt00j+eewaKG8sJ1x02+wJMzuU0Eub9MlFGamaABPdikzLcqSXECaeQRjTl31rL9PoTxwzayWpPdALaBZ3ngItSENDOfIqYSnuDoQJwRnLgUSvlAgsNbNn4g5RC+8AXUj+0ufZPiHZHRZVpaYDo0CpuaPmNuWN5YQzs3JJqyS1sRStKmdmbyos/5mKCTCSrgd+S+jBfxboTxj/e2+1T4yH8nyfazsxJJ1D6N3aGphMmPD3KmHCUVJNlPQQMBJYm9lpZokrX2Vmc4A5QGrGhUvKfND7r6Q/EMqCZb/OiVpuXtJThLtlrYBpkiZQOW/iPnBr48JLHwEvSRpF5cyJW3gJUteBUQifM5Bi3lhOhzXA1GjCw8rMTjO7KL5IBdmTjRNgBkpK8gSYw83sZ5KOA+YCJxHK/iSxsWx5vs+1nSTDCWM7XzOzg6KZ+Umvc90aWEWo0pCR5FqvRAs3/J6wqIdI9nCXP1XZzh73a1SusZsEf4w7wFeQWVzp4+jRhGQvRgJAVHrtBsKHagPGAz82s0SOZVdY4vqnwHZUnkB5cPT1zniSubrgjeV0GBU9siW5UZSZANOT0IOYGYNoQFIby42jr0cDD5jZlwmeh9ZH0hRCI6hn9D3Rdo/4YtVojZmtkUS00McMSTvGHao6Kaz1CikaZ21mBdVel3RmvsV46pOZjS3kuCRVfil04aUElja7H7gZOC7aPpUwfnlwbImq9wjwT+A20jHu3tWCN5bToW2uUlBxhSlQ2ibAPCVpBmEYxgXR6lZrYs6Uz05xB/iK5kpqSxjSMEbSYiDJ1TsyvUX/ADqb2S6SdgW+YWa/jTladdI0zrpQw0nPfA1Iz5j8bPvGHaAKmdk9Wdv3SvphbGlqVmZm/4g7hCsOr7OcArnqM0p6y8x2iytTTSQ9AlxkZqmZACOpHbAsGifeAmhlZvOjnx1mZmPiTVg7Serdqioaz94GeNbM1sWdJx9JYwm3Vm/JvN8kvWNmu8SbLL+otGQXUjDOulBJv95VlcaauknJHE0CBvgZsAR4kHBX8hSgqZldHVO0akn6DWGF3X9T+X33ZVyZXN3xnuUES3kpqA6kZAJMhpktzvp+JVnjwwljQFPVWCbBvVuF3s5OgC3MbEKVITlJr3GeunHWBfBenc3HJML/78yb7vysnxmQyMYyG+ub/zRrn5HsoXGuQN5YTrY0l4L6TdwB6lhiBzBXwxsYX98iST3ZWC/8RBJeLiyl46xrkrb3X9ryQkIym9n2hRyXpLt90XLtl5rZQ3FnccXhjeUES2MpqCxHm9nPs3dI+j1hSeY08obn5ulC4FbCpMpPgVmEhYESR9LPzOx6STeS43xNQfWc6rxS8yGJckbcAfKR1CK6c1ZV2kqbJeZun5lVSLoQ8MZyA+WN5RRIWSmojMOAn1fZd1SOfa54EtFTlFbRgkA/MLNDozHsJWa2PO5c1chM6psYa4payKoBnFOmBrCZJWpiV03XZDN7J8Z4OUnaBxgBtAS2ldQfON/MLoBUljZL2vVtjKSfEBrM2SVefcxyA+CN5XRITSkoST8ALgB6ZJU0gzDO+tV4UlUvuoW2l5lVl292PcWpFUnbAb3M7HlJzYFGWQ26xPZupUE00XNQ9H2unrhEMbOnoq9pqhqRqQG8I6EGd2ZuxlBgXCyJCpOaa3KWvwBHEL3GZva2pAPijfS1JO1uX2Z1wQuz9vmY5QbCG8vpkKZSUPcDzwC/Ay7N2r88qZ+wo1tof6Ka4S5mdnw9RiqIpHOB84D2hJrWWxPqfB4CyezdSqG3osm1j1C5tyixk+Wisoc/B/qSNckzszhCkmRqAEsaDQzMfNCLKgs8EmO0mqTpmryBmX1SZbKq1wOuI4WOtXbp5I3ldEjTkrtLgaXAadFt7M6E86ylpJbREqZJNFrSCcDjKaoNfSFhlcTXAczsA0md4o3U4LQnVJ7JbmgmvbLEfYRbwccA3yfM0v881kQ12xbILiG4jrD6Z1Kl5pqc5ZNoKIZJagJcxMahO4mSxrt9kr6Ta3+CV611teCN5XRIXSmoqHj8b4AFQEW024Bd48pUg0uAFkCZpDWkY1z4WjNbl+kpktSI5N2aTLWUVpbY0sxulzQ8KtE3NqoXnWT3ABMk/ZtwDh9Hclf7hBRekwkfnG4AugFzgdFUHjKQGCm927dH1vfNCHf43iTZ57ErkC9K4opC0ofAYDNLej3o1JJ0PaFo/3eAHxHGik8zs8vizNWQpHEFP0mvmdlekp4D/kZYJfFRM+sZc7RqSRoI7B9tjjOzt+LM4+Il6UpCidQ03e3bQFIb4J4kry3gCueN5RSQtDVwI2E5UgNeBoab2dxYg1VD0n+Bw8ws6Qs4bBCt4NeLyuM8EzvJKLpVeTahd0vAc8CINP5hSaqUruB3LPA/YBvCdaM1cKWZPVntE2MmaT/CZNU7onHXLc1sVty5cknph6g7yF1S8Hs5Do+dpOVEd/uAtNzt20BSY2CKme0Udxb39XljOQUkjSFMnLsn2jUMON3MDosvVW5ZpaB2JsxwH0XlMX1/jiNXTSSdAwwnTJKbDOwFjE/ipKiMqJzZGjMrj7ZLCcvBroo3WcMh6Q0z2yN7uWVJk81sQMzRGhRJvwZ2B3Y0s96SugKPmNm+MUfLKaUfok7I2mxGGOoyL+X1txND0lNs/DBSQphg+0jV9QZcOvmY5XToaGZ3ZG3fKeniuMLUIFMK6uPo0SR6JN1wwpiz18zsIEl9gCtjzlSTF4BDgRXRdnPCOMR9YkvU8KRuBT9JPQhjU/cmzBcYD/zYzD6KNVj1jgN2I4zxxMzmSWpV/VNilbpl0M3ssextSQ8Az8cUpyApu9v3x6zvy4A5Sb7762rHG8vpsEjSMOCBaPs0wgz9xMmUgkqhNWa2RhKSmprZDEk7xh2qBs3MLNNQxsxWSNoizkANUGpW8MtyP3AzoQEKcCrh2jE4tkQ1W2dmJinzoaRF3IFqkLoPUTn0IlQhSaR8d/uoXJkmSXKuWus9yw2DN5bT4XvATYSi8kZY3CPRs/Sr3JLKWEpYXewWM1tT/6mqNVdSW0IpqDGSFhMmRiXZSkkDzexNgGgBjdUxZ2oQokoSNwBbpWgFvwyZ2T1Z2/dG1WkSSaF79mlJtwBto/rh3wNuizdZtXJ9iBoWb6TqRWOAjWjsLzCfZK+omra7fb5qbQPmY5ZTQNJdwMVmtjjabg/8MakTMwAk3QB0ZGNv+CmEi3NzoLWZJXZ1OUlDgDbAs2a2rqbj4yJpD+BBNjbqtwJOMbNJ8aVqGDLjkiW9aWYD485TG5KuI1RJeZDQKDoFaErobU7k8ruS3iQ0KjZMVjWzMfGmqlnKPkSlStZ8gcmEykprkzhfIHvVWmBm1o9aAa+YWaI/RLnCeGM5BbInF1W3L0kkjTOzA3Ltk/Sume0cV7Z80jQbPyOacb0joYExw8zWxxypQYjGc+5N+MCX/QcwMyM/qfXCkVTdOWtmlrjldyXdDNxpZm/EnaUQkjoD1wJdzewoSX2Bvc3s9pijbSIqyZdX5s5U0kQ1t78LXEwYerEYaGxmR8eZq6qoRFw7UrRqras9byyngKS3gQOr9CyPNbN+8SbLT9J04IjMin2StiX01PZNYkM/TbPxJR1sZi9KylmUP+GriKWGpC6Ecnyb1Ek1szn1n6huSDosab22kqYBvYE5VF5WPJEfSiQ9A9wBXGZm/aMFgd5K4jU5KuOZkf0HP/PBL6ljgDdI0d2+7A6XDkCrpHe4uML4mOV0+BPwqqRHCRe7k4Fr4o1Uo/8DXpY0k3BR3h64ILpteVesyXJL02z8IcCLwNAcP0v6KmKpYWbzgf5x5yiC3wOJaiwTxnamSQcze1jSLwDMrExSedyhcjGzgwAkNScMF9iPcJ34H6FWdGLluNvXjTA+PHGyO1wIH6SaAPcS1kdwKeeN5RQws7slTSTcihJwvJlNizlWtczsP5J6AX3YOEQgM6nvr7EFyy81s/HN7NfRgiTPmNnDcedpyKIFPq4GtiNcL1O1MEIeqvmQ+pXCnvqVkrZkYzWMvQgTmJPsLmAZYVVHCFWV7iZ0viROjsZnY5Ld+ExTh4urJW8sp0TUOE50AxmqHSLQQ1KShwg8nKbZ+GZWEVU48MZycf0VOB6Yag1nzFpD+XfE6RLgSaCnpFcIY9tPjDdSjXY0s+w7Jf+NhvglVdoan6npcHG1541lV9fSOkRgLaFA/zJCT8YVSRvXmcMYST8BHqLyOE+fVFJ3PgHeaUANZfc1RStlDokemcm176Vgcu1bkvYys9cAJA0GXok5U3VS0/hMaflDVws+wc/VuWiIwIlpGiIg6beExRveBP5FKF2V6DdHVPVgk4xJrHaQVlF5vquBsaRj2fYSYC8ze7WaYx43s5yTQ11hJL1kZgfGnaMQkqYSrhOZyjkfR9vbAdMsoUt0Rx0BvQj1i39HaHzeb2Y3xhosj7SWP3SF8cayK4pcpeOSLuodOJxQrmh3whCH281sZrVPjEmeCTv/NDNfmKSOSBpNWE58KmHpaCDZK1VKGm9me8edoyGTdA2hOkPVuzqJK8Mmabvqfp7U8eKSfkSozb8nKWh8pq38oasdbyy7opB0OWE1uVQNEZDUn9BYPhL4L2GJ1TFm9rNYg+Ug6WHCsJH7ol2nAW3NLJETdtJI0kQz2z3uHLUh6UpgCvB40u+OpFVWObbM65uaMmxpkba7fWkrf+hqxxvLrijSNkRA0kXAmcAiYAQw0szWR7e1PzCznrEGzEHS21Um7OTc5766aDW8F81sdNxZChUta9wCKAPW0DAqeCSKpP9j49LRRN8vAyaa2eS4cjU0abrbl68HP6k99652fIKfK5a+5BgiEGui6nUglOSrdGGLqk4cG1OmmqRtwk4aXQj8TNJaYD0paHiaWZIrBjQUgwiNtycJ58QxwBvA+ZIeMbPr4wzXUEQT/OYThmOUEVbKe1RS4u72eaO4YfOeZVcUPkSg+KJVEjMTdgC2BaYTxtYmeklmV1yS2hEmRzXL7DOzcfElalgkPQecYGYrou2WwKOEcmeTzKxvnPkagjTe7XMNl/csu2JJW03PNDoy7gANnaSck1ST3PCUdA4wHNgamEwYdz+esKiRqxvbAtnLLq8HtjOz1dFdCPf1pfFun2ugvLHsisWHCBSZ3/arFz/N+r4ZYWb+JJLd8BwO7AG8ZmYHSeoDJLZ6R0rdD7wm6YloeyjwQFQLOPGLR6WBmV1Rzc+m12cW53wYhqtTaa3p6VwhJG0DXG9mp8WdJR9Jb5jZHpImA4PNbK2kyWY2IOZoDYqkQYQ5GQJeNrOJMUdyzhWJ9yy7uua3x1xDNhdI+ge+uZLaAiMJqzwuBubFmqgBMrNJhLsMzrkGznuWnXMuD0k3srEEYgkwAJhtZsNiC1ULkoYQFs941szW1XS8c865TXlj2Tnn8pB0ZtZmGaGhnPix95L2A3qZ2R2SOgItzWxW3Lmccy6NvLHsnHN5RBO21phZebRdCjQ1s1XxJstP0q8JNYB3NLPekroCj5jZvjFHc865VCqJO4BzziXYC0DzrO3mwPMxZSnUccA3iJbcNbN5gC9U4pxzX5E3lp1zLr9mmYUnAKLvt4gxTyHWWbhlaLChd9w559xX5I1l55zLb6WkgZmNqFzY6hjzFOJhSbcAbSWdS+gJvy3mTM45l1peOs455/IbDjwiKVN6bSvglBjzFGItoYG8jFDr/AozGxNvJOecSy9vLDvnXA7RZL79gT6ERqeAGWa2PtZgNetMaOS/CfyL5I+xds65RPNqGM45l4ekl8zswLhz1JYkAYcD3yVUxngYuN3MZsYazDnnUsjHLDvnXH6vSLpJ0v6SBmYecYeqSTTBb370KAPaAY9Kuj7WYM45l0Les+ycc3lI+m+O3WZmB9d7mAJJugg4E1gEjABGmtl6SSXAB2bWM9aAzjmXMj5m2Tnn8jCzg+LO8BV0AI43sznZO82sQtKxMWVyzrnU8p5l55yrQtIwM7tX0iW5fm5mf67vTM455+LhPcvOObepzEIeuVa+8x4G55zbjHhj2TnnqjCzW6JvewDDzWwJgKR2wJ/iyuWcc67+eTUM55zLb9dMQxnAzBYDu8UXxznnXH3zxrJzzuVXEvUmAyCpPX5HzjnnNit+0XfOufz+BLwq6VHCWOWTgWvijeScc64+eTUM55yrhqS+wMGE5a5fMLNpMUdyzjlXj7yx7JxzzjnnXB4+Ztk555xzzrk8vLHsnHPOOedcHt5Yds4555xzLg9vLDvnnHPOOZfH/wNfLNRSdBdIjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# correlationmatrix, Pearson correlation, only for numeric features\n",
    "numeric_features = df.select_dtypes(include=['float64','int64'])\n",
    "\n",
    "corr_matrix = numeric_features.corr()\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Pearson Correlation Matrix (Numeric Features)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c444a4",
   "metadata": {},
   "source": [
    "**feedback**\n",
    "\n",
    "By working with a heatmap, it is easier to see when there are highly correlated values.\n",
    "\n",
    "There is no strict rule for what correlation coefficient consitutes \"high\" multicollinearity, but a commonly threshold is around 0.8 or higher. if two or more features have a corr coefficient close to +1 r -1, it indicates a high degree of correlation. In this case of multicollinearity, yyou may consider dropping one of the variables to mitigate redundancy.\n",
    "\n",
    "Firstly, it is apparent that brightness is highly ( almost perfectly ) correlated with the different color_hex blue, green and red. Due to this reason, we shall need to drop some features. There has been chosen to keep brightness because this is one features and we can drop 3 others gives us a better dimensionality.\n",
    "\n",
    "Secondly, there is a correlation of 0.51 of brightness and year_born. On the first look, this seems unlogical, nonetheless, the year when the artist was born influence the movement and this can be correlated with the brightness of paintings is that movement. Different aristic styles and eras may be associated with specific levels of brightness in paintings. We keep both features and see later if we will drop one. Also because this is underneath the common threshold of 0.8.\n",
    "\n",
    "Thirdly, we observe an almost perfect positive correlation between the 'year_painted' and 'year_born' columns. This correlation is expected as, with a small deviation, the values are nearly identical. However, we choose to retain the 'year_born' column because it represents information that is 100% accurate. Additionally, we have filled in some values in the 'year_painted' column, leading to potential data leakage in this context.\n",
    "\n",
    "\"Finally, the 'area' and 'circumference' exhibit a strong positive correlation, scoring 0.94. Following univariate testing, we can determine which variable has the strongest relationship with the target feature, 'price in euros.' The variable demonstrating the most robust relationship will be retained.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "61758767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-test for contrast: p-value = 3.0777957755013894e-15\n",
      "T-test for brightness: p-value = 3.1034721954045874e-15\n",
      "T-test for year_sold: p-value = 3.706133136667523e-15\n",
      "T-test for price_EUR: p-value = 1.0\n",
      "T-test for area: p-value = 4.901436470863685e-15\n",
      "T-test for circumference: p-value = 3.133551549488896e-15\n",
      "T-test for year_painted: p-value = 3.655245499314833e-15\n",
      "T-test for red_hex: p-value = 3.1059119617018645e-15\n",
      "T-test for green_hex: p-value = 3.103078107600885e-15\n",
      "T-test for blue_hex: p-value = 3.0990032406782313e-15\n",
      "T-test for year_born: p-value = 3.637462564271004e-15\n",
      "T-test for return_sp: p-value = 3.0641406314390914e-15\n",
      "ANOVA for artist: p-value = 3.1838311844635605e-29\n",
      "ANOVA for title: p-value = 0.14513140689042411\n",
      "ANOVA for faces: p-value = 0.04921331077964482\n",
      "ANOVA for city_auction: p-value = 1.9426780681993403e-05\n",
      "ANOVA for currency: p-value = 0.0005587610396531135\n",
      "ANOVA for signed: p-value = 9.754589761545304e-05\n",
      "ANOVA for medium: p-value = 3.116470699146709e-08\n",
      "ANOVA for surface: p-value = 3.5558839511786155e-10\n",
      "ANOVA for dead: p-value = 0.0007927333454695502\n"
     ]
    }
   ],
   "source": [
    "# univariate testing, to see the relationship of all features seperately with the output\n",
    "from scipy.stats import ttest_ind, f_oneway\n",
    "\n",
    "# List of numeric columns\n",
    "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Perform t-test for each numeric column\n",
    "for column in numeric_columns:\n",
    "    statistic, p_value = ttest_ind(df[column], df['price_EUR'])\n",
    "    print(f\"T-test for {column}: p-value = {p_value}\")\n",
    "    \n",
    "# List of categorical columns\n",
    "categorical_columns = df.select_dtypes(include=['object','bool']).columns\n",
    "\n",
    "# Perform ANOVA for each categorical column\n",
    "for column in categorical_columns:\n",
    "    groups = df.groupby(column)['price_EUR'].apply(list)\n",
    "    statistic, p_value = f_oneway(*groups)\n",
    "    print(f\"ANOVA for {column}: p-value = {p_value}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de795be7",
   "metadata": {},
   "source": [
    "**feedback**\n",
    "\n",
    "p-value of 1 --> **price_EUR** --> suggests that there's no signficant difference in means between groups. \n",
    "\n",
    "p-value close to 0 --> **year_sold, area, circumference, year_painted, year_born, return_sp, artist, city_auction, currency, signed, medium, surface, dead, contrast, birhtness, red green and blue_hex** --> indicate that there is significant evidence to reject teh null hypothesis. This means that these features are likely to be associated with variations in the target variable or with other means are likely to be associated to influence the price of the painting.\n",
    "\n",
    "high p-value --> **title (0.1313), faces(0.047 and 0.1869 when we did it for only the non missing values)** --> These p-values suggests that there is not enough evidence to reject the null hypothesis that the means of \"price_EUR\" are the same acorss different levels of the 'title' of 'face' feature.\n",
    "\n",
    "Given that **'area' and 'circumference'** have a high correlation (0.94), it suggests that these two features are strongly correlated, meaning they provide similar information. In such cases, you might want to consider dropping one of the two features to avoid multicollinearity in your model. Multicollinearity can lead to unstable coefficient estimates ad make it challenging to interpret the individual effects of each feature. When deciding which one to drop, you could cosider factors such as the interpretability of the feature, domain knowledge, or the p-values from the T-tests. In the context of the T-tests, a lower p-value generally indicates stronger evidence against the null ypothesis. In this case, both 'area' and 'circumference' have extremely low p-values, nevertheless, the one of 'circumference' is a bit smaller so we keep that one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "997911d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>price_EUR</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>52.601</td>\n",
       "      <td>101.140</td>\n",
       "      <td>2018</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>EUR</td>\n",
       "      <td>87500.000</td>\n",
       "      <td>True</td>\n",
       "      <td>536.000</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Theo Van Rysselberghe</td>\n",
       "      <td>49.258</td>\n",
       "      <td>136.516</td>\n",
       "      <td>2010</td>\n",
       "      <td>Paris</td>\n",
       "      <td>EUR</td>\n",
       "      <td>79000.000</td>\n",
       "      <td>True</td>\n",
       "      <td>243.600</td>\n",
       "      <td>Oil-Based Paintings</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1862</td>\n",
       "      <td>True</td>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  artist  contrast  brightness  year_sold city_auction  \\\n",
       "0      Pierre Alechinsky    52.601     101.140       2018    Amsterdam   \n",
       "1  Theo Van Rysselberghe    49.258     136.516       2010        Paris   \n",
       "\n",
       "  currency  price_EUR  signed  circumference               medium surface  \\\n",
       "0      EUR  87500.000    True        536.000              missing  canvas   \n",
       "1      EUR  79000.000    True        243.600  Oil-Based Paintings  canvas   \n",
       "\n",
       "   year_born   dead  return_sp  \n",
       "0       1927  False      0.216  \n",
       "1       1862   True      0.259  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping the features that have no significant influence or are correlated with others.\n",
    "df.drop(['year_painted','red_hex','green_hex','blue_hex','title','faces','area'], axis=1, inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3711f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature engineering\n",
    "Creating good features is probably the most important step in the machine learning process. \n",
    "This might involve doing:\n",
    "- transformations\n",
    "- aggregating over data points or over time and space, or finding differences (for example: differences between two monthly bills, time difference between two contacts with the client) \n",
    "- creating dummy (binary) variables\n",
    "- discretization\n",
    "\n",
    "Business insight is very relevant in this process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ce96f",
   "metadata": {},
   "source": [
    "#### Checking if types are categorical and transforming it to numerical & transforming binary columns to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "18ef19fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist            object\n",
       "contrast         float64\n",
       "brightness       float64\n",
       "year_sold          int64\n",
       "city_auction      object\n",
       "currency          object\n",
       "price_EUR        float64\n",
       "signed              bool\n",
       "circumference    float64\n",
       "medium            object\n",
       "surface           object\n",
       "year_born          int64\n",
       "dead                bool\n",
       "return_sp        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6b6987ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 811 entries, 0 to 810\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   artist         811 non-null    object  \n",
      " 1   contrast       811 non-null    float64 \n",
      " 2   brightness     811 non-null    float64 \n",
      " 3   year_sold      811 non-null    int64   \n",
      " 4   city_auction   811 non-null    object  \n",
      " 5   currency       811 non-null    object  \n",
      " 6   price_EUR      811 non-null    float64 \n",
      " 7   signed         811 non-null    category\n",
      " 8   circumference  811 non-null    float64 \n",
      " 9   medium         811 non-null    object  \n",
      " 10  surface        811 non-null    object  \n",
      " 11  year_born      811 non-null    int64   \n",
      " 12  dead           811 non-null    category\n",
      " 13  return_sp      811 non-null    float64 \n",
      "dtypes: category(2), float64(5), int64(2), object(5)\n",
      "memory usage: 77.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# create a figure with subplots for each column\n",
    "# Convert boolean columns to categorical ( help maintain consistency in the encoding process. \n",
    "# It makes the interpretation of the encoded features more straightforward)\n",
    "df['signed'] = df['signed'].astype('category')\n",
    "df['dead'] = df['dead'].astype('category')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be371e96",
   "metadata": {},
   "source": [
    "We convert the binary categorical variables from float to integer. This will make it easier to work witht them later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b0bea0",
   "metadata": {},
   "source": [
    "# DESCRIPTIVE MOMENT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aaff534e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>price_EUR</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>52.601</td>\n",
       "      <td>101.140</td>\n",
       "      <td>2018</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>EUR</td>\n",
       "      <td>87500.000</td>\n",
       "      <td>True</td>\n",
       "      <td>536.000</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Theo Van Rysselberghe</td>\n",
       "      <td>49.258</td>\n",
       "      <td>136.516</td>\n",
       "      <td>2010</td>\n",
       "      <td>Paris</td>\n",
       "      <td>EUR</td>\n",
       "      <td>79000.000</td>\n",
       "      <td>True</td>\n",
       "      <td>243.600</td>\n",
       "      <td>Oil-Based Paintings</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1862</td>\n",
       "      <td>True</td>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  artist  contrast  brightness  year_sold city_auction  \\\n",
       "0      Pierre Alechinsky    52.601     101.140       2018    Amsterdam   \n",
       "1  Theo Van Rysselberghe    49.258     136.516       2010        Paris   \n",
       "\n",
       "  currency  price_EUR signed  circumference               medium surface  \\\n",
       "0      EUR  87500.000   True        536.000              missing  canvas   \n",
       "1      EUR  79000.000   True        243.600  Oil-Based Paintings  canvas   \n",
       "\n",
       "   year_born   dead  return_sp  \n",
       "0       1927  False      0.216  \n",
       "1       1862   True      0.259  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ba1284bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['city_auction'].isin(['Hong Kong','Milan'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b77ac5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataset had 809 features and 14 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f'the dataset had {df.shape[0]} features and {df.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4c9ecbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809\n",
      "1994\n",
      "2023\n"
     ]
    }
   ],
   "source": [
    "# Information about the samples\n",
    "samples = len(df)\n",
    "print(samples)\n",
    "min_date = df['year_sold'].min()\n",
    "max_date = df['year_sold'].max()\n",
    "print(min_date)\n",
    "print(max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fbd57eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524772518.60999936\n",
      "75.32\n",
      "23596150.45\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Target feature\n",
    "min_price = df[df['price_EUR'] > 0]['price_EUR'].min()\n",
    "max_price = df['price_EUR'].max()\n",
    "total = sum(df['price_EUR'])\n",
    "print(total)\n",
    "print(min_price)\n",
    "print(max_price)\n",
    "number = len(df[df['price_EUR']==0])\n",
    "print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fd5e367a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            artist   count     average  \\\n",
      "artist                                                                   \n",
      "Anthony Van Dyck                  Anthony Van Dyck  95.000  165621.720   \n",
      "Eugene Verboeckhoven          Eugene Verboeckhoven  34.000   27034.417   \n",
      "Felicien Rops                        Felicien Rops  35.000   10203.283   \n",
      "Jacob Jordaens                      Jacob Jordaens  43.000  203264.717   \n",
      "James Ensor                            James Ensor 102.000  111794.619   \n",
      "Jan Breughel the elder      Jan Breughel the elder  20.000  470298.059   \n",
      "Jan Breughel the younger  Jan Breughel the younger  43.000  195599.899   \n",
      "Paul Delvaux                          Paul Delvaux  91.000  276618.521   \n",
      "Pierre Alechinsky                Pierre Alechinsky 136.000   44883.927   \n",
      "Rene Magritte                        Rene Magritte 157.000 2638164.809   \n",
      "Theo Van Rysselberghe        Theo Van Rysselberghe  53.000  459124.620   \n",
      "\n",
      "                             std dev      min        25%        50%  \\\n",
      "artist                                                                \n",
      "Anthony Van Dyck          634614.587  194.780   1665.825   6782.070   \n",
      "Eugene Verboeckhoven       31428.591  500.000   8221.802  14075.000   \n",
      "Felicien Rops              12545.987  720.000   3821.505   5565.390   \n",
      "Jacob Jordaens            564498.401   75.320   2764.500  10000.000   \n",
      "James Ensor               382355.100  525.370   3475.255   7196.830   \n",
      "Jan Breughel the elder    954108.497  685.630  11298.307  44751.495   \n",
      "Jan Breughel the younger  263047.475 2000.000  18915.795  64339.710   \n",
      "Paul Delvaux              664544.333  785.040   3472.240  10173.100   \n",
      "Pierre Alechinsky         132582.129  299.000   2731.533   8809.520   \n",
      "Rene Magritte            4668681.682 1118.930 167685.820 994441.500   \n",
      "Theo Van Rysselberghe    1352078.316 2169.520  32169.440  58600.000   \n",
      "\n",
      "                                 75%          max         total  \n",
      "artist                                                           \n",
      "Anthony Van Dyck           25046.110  4025443.900  15734063.420  \n",
      "Eugene Verboeckhoven       33657.997   156000.000    919170.180  \n",
      "Felicien Rops              10751.505    58600.000    357114.890  \n",
      "Jacob Jordaens             48696.500  2462887.590   8740382.810  \n",
      "James Ensor                35592.910  2828048.010  11403051.170  \n",
      "Jan Breughel the elder    502653.605  4067434.600   9405961.180  \n",
      "Jan Breughel the younger  298484.315  1256135.520   8410795.650  \n",
      "Paul Delvaux              160508.385  3593870.450  25172285.410  \n",
      "Pierre Alechinsky          45046.268  1387500.000   6104214.110  \n",
      "Rene Magritte            2477745.510 23596150.450 414191874.940  \n",
      "Theo Van Rysselberghe     248654.540  8125333.810  24333604.850  \n"
     ]
    }
   ],
   "source": [
    "# artist\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your original DataFrame\n",
    "# Grouping by 'artist' and aggregating price statistics\n",
    "grouped_data = df.groupby('artist')['price_EUR'].describe()\n",
    "\n",
    "# Creating the new DataFrame\n",
    "result_df = pd.DataFrame({\n",
    "    'artist': grouped_data.index,\n",
    "    'count': grouped_data['count'],\n",
    "    'average': grouped_data['mean'],\n",
    "    'std dev': grouped_data['std'],\n",
    "    'min': grouped_data['min'],\n",
    "    '25%': grouped_data['25%'],\n",
    "    '50%': grouped_data['50%'],\n",
    "    '75%': grouped_data['75%'],\n",
    "    'max': grouped_data['max'],\n",
    "    'total': grouped_data['count'] * grouped_data['mean']  # Total = count * average\n",
    "})\n",
    "\n",
    "# Displaying the result DataFrame\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ea60b4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              count   total_spent     average\n",
      "city_auction                                 \n",
      "New York        144 159090598.830 1104795.825\n",
      "London          345 316731867.800  918063.385\n",
      "Paris            91  33845986.000  371933.912\n",
      "unknown         125  11371555.730   90972.446\n",
      "Amsterdam       104   3732510.250   35889.522\n"
     ]
    }
   ],
   "source": [
    "# location and most money per location\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your original DataFrame\n",
    "# Grouping by 'city_auction' and aggregating count and sum\n",
    "city_stats = df.groupby('city_auction').agg({'city_auction': 'count', 'price_EUR': 'sum'})\n",
    "\n",
    "# Renaming columns for clarity\n",
    "city_stats = city_stats.rename(columns={'city_auction': 'count', 'price_EUR': 'total_spent'})\n",
    "city_stats['average'] = city_stats['total_spent'] / city_stats['count']\n",
    "city_stats = city_stats.sort_values(by='average', ascending=False)\n",
    "\n",
    "# Displaying the result DataFrame\n",
    "print(city_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ebebdfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we dropped the rows of 'milan' and 'hong kong' because there were only 1 row each and it was 'annoying' the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8eab8ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          count   total_spent    average\n",
      "currency                                \n",
      "USD         169 165137381.590 977144.270\n",
      "GBP         418 321968556.920 770259.706\n",
      "EUR         180  37082906.000 206016.144\n",
      "NLG          42    583674.100  13897.002\n"
     ]
    }
   ],
   "source": [
    "# currency and most money per currency\n",
    "\n",
    "# Assuming df is your original DataFrame\n",
    "# Grouping by 'city_auction' and aggregating count and sum\n",
    "currency_stats = df.groupby('currency').agg({'currency': 'count', 'price_EUR': 'sum'})\n",
    "\n",
    "# Renaming columns for clarity\n",
    "currency_stats = currency_stats.rename(columns={'currency': 'count', 'price_EUR': 'total_spent'})\n",
    "currency_stats['average'] = currency_stats['total_spent'] / currency_stats['count']\n",
    "currency_stats = currency_stats.sort_values(by='average', ascending=False)\n",
    "\n",
    "# Displaying the result DataFrame\n",
    "print(currency_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "df729831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         count   total_spent     average\n",
      "surface                                 \n",
      "canvas     300 407095665.510 1356985.552\n",
      "other      114  35691807.100  313086.027\n",
      "paper      292  74849470.160  256333.802\n",
      "missing    103   7135575.840   69277.435\n"
     ]
    }
   ],
   "source": [
    "# currency and most money per currency\n",
    "\n",
    "# Assuming df is your original DataFrame\n",
    "# Grouping by 'city_auction' and aggregating count and sum\n",
    "surface_stats = df.groupby('surface').agg({'surface': 'count', 'price_EUR': 'sum'})\n",
    "\n",
    "# Renaming columns for clarity\n",
    "surface_stats = surface_stats.rename(columns={'surface': 'count', 'price_EUR': 'total_spent'})\n",
    "surface_stats['average'] = surface_stats['total_spent'] / surface_stats['count']\n",
    "surface_stats = surface_stats.sort_values(by='average', ascending=False)\n",
    "\n",
    "# Displaying the result DataFrame\n",
    "print(surface_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c55a324c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      count   total_spent     average\n",
      "medium                                               \n",
      "Oil-Based Paintings     410 443763371.760 1082349.687\n",
      "Watercolour Art          64  60163076.320  940048.068\n",
      "missing                  84   7996315.110   95194.227\n",
      "Pen and Ink Drawings    251  12849755.420   51194.245\n"
     ]
    }
   ],
   "source": [
    "# currency and most money per currency\n",
    "\n",
    "# Assuming df is your original DataFrame\n",
    "# Grouping by 'city_auction' and aggregating count and sum\n",
    "medium_stats = df.groupby('medium').agg({'medium': 'count', 'price_EUR': 'sum'})\n",
    "\n",
    "# Renaming columns for clarity\n",
    "medium_stats = medium_stats.rename(columns={'medium': 'count', 'price_EUR': 'total_spent'})\n",
    "medium_stats['average'] = medium_stats['total_spent'] / medium_stats['count']\n",
    "medium_stats = medium_stats.sort_values(by='average', ascending=False)\n",
    "\n",
    "# Displaying the result DataFrame\n",
    "print(medium_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d6223386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count   total_spent    average\n",
      "signed                                \n",
      "True      580 490829549.760 846257.844\n",
      "False     229  33942968.850 148222.571\n"
     ]
    }
   ],
   "source": [
    "# currency and most money per currency\n",
    "\n",
    "# Assuming df is your original DataFrame\n",
    "# Grouping by 'city_auction' and aggregating count and sum\n",
    "signed_stats = df.groupby('signed').agg({'signed': 'count', 'price_EUR': 'sum'})\n",
    "\n",
    "# Renaming columns for clarity\n",
    "signed_stats = signed_stats.rename(columns={'signed': 'count', 'price_EUR': 'total_spent'})\n",
    "signed_stats['average'] = signed_stats['total_spent']/signed_stats['count']\n",
    "signed_stats = signed_stats.sort_values(by='average', ascending=False)\n",
    "\n",
    "# Displaying the result DataFrame\n",
    "print(signed_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "da69be45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>price_EUR</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>52.601</td>\n",
       "      <td>101.140</td>\n",
       "      <td>2018</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>EUR</td>\n",
       "      <td>87500.000</td>\n",
       "      <td>True</td>\n",
       "      <td>536.000</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Theo Van Rysselberghe</td>\n",
       "      <td>49.258</td>\n",
       "      <td>136.516</td>\n",
       "      <td>2010</td>\n",
       "      <td>Paris</td>\n",
       "      <td>EUR</td>\n",
       "      <td>79000.000</td>\n",
       "      <td>True</td>\n",
       "      <td>243.600</td>\n",
       "      <td>Oil-Based Paintings</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1862</td>\n",
       "      <td>True</td>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  artist  contrast  brightness  year_sold city_auction  \\\n",
       "0      Pierre Alechinsky    52.601     101.140       2018    Amsterdam   \n",
       "1  Theo Van Rysselberghe    49.258     136.516       2010        Paris   \n",
       "\n",
       "  currency  price_EUR signed  circumference               medium surface  \\\n",
       "0      EUR  87500.000   True        536.000              missing  canvas   \n",
       "1      EUR  79000.000   True        243.600  Oil-Based Paintings  canvas   \n",
       "\n",
       "   year_born   dead  return_sp  \n",
       "0       1927  False      0.216  \n",
       "1       1862   True      0.259  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46de74fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "f930b8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>target</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>72.213</td>\n",
       "      <td>133.827</td>\n",
       "      <td>1994</td>\n",
       "      <td>London</td>\n",
       "      <td>GBP</td>\n",
       "      <td>40694.870</td>\n",
       "      <td>True</td>\n",
       "      <td>507.800</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>62.101</td>\n",
       "      <td>174.389</td>\n",
       "      <td>1995</td>\n",
       "      <td>New York</td>\n",
       "      <td>USD</td>\n",
       "      <td>9730.240</td>\n",
       "      <td>True</td>\n",
       "      <td>322.600</td>\n",
       "      <td>Watercolour Art</td>\n",
       "      <td>paper</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist  contrast  brightness  year_sold city_auction currency  \\\n",
       "0  Pierre Alechinsky    72.213     133.827       1994       London      GBP   \n",
       "1  Pierre Alechinsky    62.101     174.389       1995     New York      USD   \n",
       "\n",
       "     target signed  circumference           medium surface  year_born   dead  \\\n",
       "0 40694.870   True        507.800          missing  canvas       1927  False   \n",
       "1  9730.240   True        322.600  Watercolour Art   paper       1927  False   \n",
       "\n",
       "   return_sp  \n",
       "0      0.100  \n",
       "1      0.013  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436aab03",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "f25fbb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>target</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>72.213</td>\n",
       "      <td>133.827</td>\n",
       "      <td>1994</td>\n",
       "      <td>London</td>\n",
       "      <td>GBP</td>\n",
       "      <td>40694.870</td>\n",
       "      <td>True</td>\n",
       "      <td>507.800</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>62.101</td>\n",
       "      <td>174.389</td>\n",
       "      <td>1995</td>\n",
       "      <td>New York</td>\n",
       "      <td>USD</td>\n",
       "      <td>9730.240</td>\n",
       "      <td>True</td>\n",
       "      <td>322.600</td>\n",
       "      <td>Watercolour Art</td>\n",
       "      <td>paper</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist  contrast  brightness  year_sold city_auction currency  \\\n",
       "0  Pierre Alechinsky    72.213     133.827       1994       London      GBP   \n",
       "1  Pierre Alechinsky    62.101     174.389       1995     New York      USD   \n",
       "\n",
       "     target signed  circumference           medium surface  year_born   dead  \\\n",
       "0 40694.870   True        507.800          missing  canvas       1927  False   \n",
       "1  9730.240   True        322.600  Watercolour Art   paper       1927  False   \n",
       "\n",
       "   return_sp  \n",
       "0      0.100  \n",
       "1      0.013  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### here we are making feature called dataframe with df as dataframe to always have the standard df somewhere\n",
    "dataframe = df\n",
    "dataframe.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7424f283",
   "metadata": {},
   "source": [
    "We are working with a time series dataset because the collected datapoints are measured over a series of time intervals. Each data point is associated with a specific timestamp of time period, and the sequence of observations is ordered chronologically. \n",
    "\n",
    "Time series datasets are commonly used in various fields to analyze and understand trends, patterns, and behaviours over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "05f543f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>price_EUR</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>52.601</td>\n",
       "      <td>101.140</td>\n",
       "      <td>2018</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>EUR</td>\n",
       "      <td>87500.000</td>\n",
       "      <td>True</td>\n",
       "      <td>536.000</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Theo Van Rysselberghe</td>\n",
       "      <td>49.258</td>\n",
       "      <td>136.516</td>\n",
       "      <td>2010</td>\n",
       "      <td>Paris</td>\n",
       "      <td>EUR</td>\n",
       "      <td>79000.000</td>\n",
       "      <td>True</td>\n",
       "      <td>243.600</td>\n",
       "      <td>Oil-Based Paintings</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1862</td>\n",
       "      <td>True</td>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  artist  contrast  brightness  year_sold city_auction  \\\n",
       "0      Pierre Alechinsky    52.601     101.140       2018    Amsterdam   \n",
       "1  Theo Van Rysselberghe    49.258     136.516       2010        Paris   \n",
       "\n",
       "  currency  price_EUR signed  circumference               medium surface  \\\n",
       "0      EUR  87500.000   True        536.000              missing  canvas   \n",
       "1      EUR  79000.000   True        243.600  Oil-Based Paintings  canvas   \n",
       "\n",
       "   year_born   dead  return_sp  \n",
       "0       1927  False      0.216  \n",
       "1       1862   True      0.259  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cbfd6de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'price_EUR': 'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "91e039a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>target</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>52.601</td>\n",
       "      <td>101.140</td>\n",
       "      <td>2018</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>EUR</td>\n",
       "      <td>87500.000</td>\n",
       "      <td>True</td>\n",
       "      <td>536.000</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Theo Van Rysselberghe</td>\n",
       "      <td>49.258</td>\n",
       "      <td>136.516</td>\n",
       "      <td>2010</td>\n",
       "      <td>Paris</td>\n",
       "      <td>EUR</td>\n",
       "      <td>79000.000</td>\n",
       "      <td>True</td>\n",
       "      <td>243.600</td>\n",
       "      <td>Oil-Based Paintings</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1862</td>\n",
       "      <td>True</td>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  artist  contrast  brightness  year_sold city_auction  \\\n",
       "0      Pierre Alechinsky    52.601     101.140       2018    Amsterdam   \n",
       "1  Theo Van Rysselberghe    49.258     136.516       2010        Paris   \n",
       "\n",
       "  currency    target signed  circumference               medium surface  \\\n",
       "0      EUR 87500.000   True        536.000              missing  canvas   \n",
       "1      EUR 79000.000   True        243.600  Oil-Based Paintings  canvas   \n",
       "\n",
       "   year_born   dead  return_sp  \n",
       "0       1927  False      0.216  \n",
       "1       1862   True      0.259  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "efed88f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Time Range: 1994 2019\n",
      "Testing Set Time Range: 2019 2023\n"
     ]
    }
   ],
   "source": [
    "#  When dealing with time series data, it's important to split the dataset in a way that respects the temporal\n",
    "# order to avoid data leakage and to simulate a more realistic scenario where you train on past data and \n",
    "# evaluate on future data.\n",
    "\n",
    "# step 1: sort your data in ascending order 'year_sold'\n",
    "df = df.sort_values(by='year_sold')\n",
    "\n",
    "# step 2: define a split point. We opt for 80%\n",
    "split_percentage = 0.80\n",
    "split_point = int(len(df) * split_percentage)\n",
    "\n",
    "# step 3: Split the data in a training and test set\n",
    "train_set = df[:split_point]\n",
    "test_set = df[split_point:]\n",
    "\n",
    "# Check the time range in each set\n",
    "print(\"Training Set Time Range:\", train_set['year_sold'].min(), train_set['year_sold'].max())\n",
    "print(\"Testing Set Time Range:\", test_set['year_sold'].min(), test_set['year_sold'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "13df492a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>target</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>72.213</td>\n",
       "      <td>133.827</td>\n",
       "      <td>1994</td>\n",
       "      <td>London</td>\n",
       "      <td>GBP</td>\n",
       "      <td>40694.870</td>\n",
       "      <td>True</td>\n",
       "      <td>507.800</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>62.101</td>\n",
       "      <td>174.389</td>\n",
       "      <td>1995</td>\n",
       "      <td>New York</td>\n",
       "      <td>USD</td>\n",
       "      <td>9730.240</td>\n",
       "      <td>True</td>\n",
       "      <td>322.600</td>\n",
       "      <td>Watercolour Art</td>\n",
       "      <td>paper</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist  contrast  brightness  year_sold city_auction currency  \\\n",
       "0  Pierre Alechinsky    72.213     133.827       1994       London      GBP   \n",
       "1  Pierre Alechinsky    62.101     174.389       1995     New York      USD   \n",
       "\n",
       "     target signed  circumference           medium surface  year_born   dead  \\\n",
       "0 40694.870   True        507.800          missing  canvas       1927  False   \n",
       "1  9730.240   True        322.600  Watercolour Art   paper       1927  False   \n",
       "\n",
       "   return_sp  \n",
       "0      0.100  \n",
       "1      0.013  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "5bc69255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting training and test into X features and Y\n",
    "\n",
    "# splitting the training set into features X and target variable Y\n",
    "x_train = train_set.drop(columns=['target'])\n",
    "y_train = train_set['target']\n",
    "\n",
    "#splitting the test set into  features X and target variable Y\n",
    "x_test = test_set.drop(columns=['target'])\n",
    "y_test = test_set['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bef3d84",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Pipeline including Column Transformer**\n",
    "\n",
    "The pipeline consists of four main steps:\n",
    "\n",
    "1) We use the OneHotEncoder transformer from the category_encoders library to convert categorical features represented as strings into numerical features. This is applied to the columns specified in the one_hot_cols list.\n",
    "\n",
    "2) Transformers are defined for each column type. For categorical columns, TargetEncoder() from the category_encoders library is used to perform target encoding on region and state columns. This helps us to capture the relationship between the categorical feature and the target variable.\n",
    "\n",
    "3) For continuous features, we first impute missing values using the median value of the feature and then standardize them using the StandardScaler transformer from the sklearn library. This is applied to the columns specified in the continuous_cols list. Scaling ensures that all continuous features are on the same scale, facilitating the algorithm in learning the correct weights and biases for each feature.\n",
    "\n",
    "4) We use a feature selector to choose the best features with f_regression scoring function via SelectKBest. We set k to \"all\" to include all features, reducing dataset dimensionality, preventing overfitting, and retaining the most informative features. f_regression is used to select continuous features based on their correlation with the target variable.We chose the f_regression scoring function as it is a suitable method for selecting continuous features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "103347e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import category_encoders as ce\n",
    "from category_encoders import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "a88514cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the columns to encode and scale(min-max)\n",
    "one_hot_cols = ['artist', 'city_auction', 'currency', 'medium', 'surface', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
    "        ('num', continuous_transformer, continuous_cols)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9418a9",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "We are going to see different approaches and tune hyperparameters of each approach. Model selection and tuning using CV is on training set, avoiding data leakage. \n",
    "\n",
    "We perform hyperparameter tuning using grid search with cross-validation. The training data is dived into 5folds and the model is trained on 4 folds and validated on the remaining fold. This process is repeated 5 times, with each fold being the validation test once.\n",
    "\n",
    "For testing the model we only use the training set. As the metric to estimate the model's performance on the unseen data we use the MAE (mean absolute error). It is robust to outliers, which is important with some painings being significant more expensive that others. This is for the test-sets!\n",
    "\n",
    "This approach is used to prevent overfitting to the test set and obtain optimistic estimates of the model's preformance on unseen data during the hyperparameter tuning process. \n",
    "\n",
    "The test dataset will only be used as a final evaluation of the model after the hyperparameters have been tunes and the model has been trained on the entire training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ea559c",
   "metadata": {},
   "source": [
    "### linear regression, Lasso and Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1432ca3d",
   "metadata": {},
   "source": [
    "We used Linear regression, Lasso and Ridge as our initial models for prediciting painting prices because they can handle both categorical annd continiuous features. \n",
    "\n",
    "**Linear Regression** serves as a simple and straightforward model thaht sets a baseline performance for painting price prediction. However, it might overfit the model if there are too many features or if the features are highly correlated.\n",
    "\n",
    "On the other hand, **Lasso and Ridge regression**£ are regularized linear regression models that can adress overfitting by adding a penalty term to the objective function. Ridge regression can mitigate the impact of highly correlated features by shrinking their coefficients towards each other. We chose these models for painting price prediction because they can provide more stable and understandable results compared to other complex models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "249440b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for the models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "78c07a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'estimator': Lasso(), 'estimator__alpha': 0.01}\n",
      "Best score: 1704557384399.0605\n",
      "Best R2: 0.26463577040396113\n",
      " \n",
      "All the metrics for Linear Regression.\n",
      "Linear Regression CV R-squared: -2.1017343597313747e+20\n",
      "Linear Regression CV MSE: 2.58498262984527e+31\n",
      "Linear Regression CV RMSE: 5084272445340896.0\n",
      "Linear Regression CV MAE: 505271.2283780633\n",
      " \n",
      "All the metrics for the Ridge Regression.\n",
      "Ridge Regression CV R-squared: 0.180099308007401\n",
      "Ridge Regression CV MSE: 1705855230682.1257\n",
      "Ridge Regression CV RMSE: 1306083.9294172965\n",
      "Ridge Regression CV MAE: 503849.80246479233\n",
      " \n",
      "All the metrics for the Lasso Regression.\n",
      "Lasso Regression CV R-squared: 0.1727429932672306\n",
      "Lasso Regression CV MSE: 1704570857361.9192\n",
      "Lasso Regression CV RMSE: 1305592.1481695266\n",
      "Lasso Regression CV MAE: 505268.2310321579\n"
     ]
    }
   ],
   "source": [
    "# define the models\n",
    "linear = LinearRegression()\n",
    "# alpha is the regularization term, the larger the stronger the regularization. If 0 you have a linear regression\n",
    "# choosing the right alpha is crucial: to small --> overfitting, to large --> shrinkage of coefficient #underfitting\n",
    "ridge = Ridge(alpha=0.5)\n",
    "lasso = Lasso(alpha=0.5)\n",
    "\n",
    "# define the pipelines\n",
    "pipeline_linear = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', linear)\n",
    "])\n",
    "\n",
    "pipeline_ridge = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', ridge)\n",
    "])\n",
    "\n",
    "pipeline_lasso = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', lasso)\n",
    "])\n",
    "\n",
    "# define the hyperparameters to search\n",
    "# purpose = explore different combinations of these hyperparameters to find the \n",
    "# set that results in the best model performance. \n",
    "param_grid = [{'estimator': [Ridge()],\n",
    "              'estimator__alpha': [0.01, 0.1, 1, 10, 100]\n",
    "              },\n",
    "              {'estimator': [Lasso()],\n",
    "              'estimator__alpha': [0.01, 0.1, 1, 10, 100]\n",
    "              }\n",
    "]\n",
    "\n",
    "# create gridsearchcv to perform this lookout for the best hyperparameters\n",
    "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline_linear, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# git the grid search to the training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# evaluate each model using cross-validation\n",
    "scores_linear = cross_val_score(pipeline_linear, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
    "scores_ridge = cross_val_score(pipeline_ridge, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
    "scores_lasso = cross_val_score(pipeline_lasso, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
    "\n",
    "# compute the mean squared error of each model\n",
    "mse_linear = -cross_val_score(pipeline_linear, x_train, y_train, cv=time_serie_split, scoring='neg_mean_squared_error').mean()\n",
    "mse_ridge = -cross_val_score(pipeline_ridge, x_train, y_train, cv=time_serie_split, scoring='neg_mean_squared_error').mean()\n",
    "mse_lasso = -cross_val_score(pipeline_lasso, x_train, y_train, cv=time_serie_split, scoring='neg_mean_squared_error').mean()\n",
    "\n",
    "# compute the root mean squared error of each model\n",
    "rmse_linear = sqrt(mse_linear)\n",
    "rmse_ridge = sqrt(mse_ridge)\n",
    "rmse_lasso = sqrt(mse_lasso)\n",
    "\n",
    "# Ensure the entire pipeline is fitted before predicting\n",
    "grid_search.best_estimator_.fit(x_train, y_train)\n",
    "pipeline_ridge.fit(x_train, y_train)\n",
    "pipeline_lasso.fit(x_train, y_train)\n",
    "\n",
    "# Compute the mean absolute error of each model\n",
    "mae_linear = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
    "mae_ridge = mean_absolute_error(y_train, pipeline_ridge.predict(x_train))\n",
    "mae_lasso = mean_absolute_error(y_train, pipeline_lasso.predict(x_train))\n",
    "\n",
    "# printing all\n",
    "# print best parameters and best score\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "print('Best score:', -grid_search.best_score_)\n",
    "print('Best R2:', grid_search.best_estimator_.score(x_train, y_train))\n",
    "print(' ')\n",
    "\n",
    "# printing all for linear regression\n",
    "print('All the metrics for Linear Regression.')\n",
    "print(\"Linear Regression CV R-squared:\", scores_linear.mean())\n",
    "print(\"Linear Regression CV MSE:\", mse_linear)\n",
    "print(\"Linear Regression CV RMSE:\", rmse_linear)\n",
    "print(\"Linear Regression CV MAE:\", mae_linear)\n",
    "print(' ')\n",
    "\n",
    "# printing all for Ridge regression\n",
    "print('All the metrics for the Ridge Regression.')\n",
    "print(\"Ridge Regression CV R-squared:\", scores_ridge.mean())\n",
    "print(\"Ridge Regression CV MSE:\", mse_ridge)\n",
    "print(\"Ridge Regression CV RMSE:\", rmse_ridge)\n",
    "print(\"Ridge Regression CV MAE:\", mae_ridge)\n",
    "print(' ')\n",
    "\n",
    "\n",
    "# printing all for Lasso regression\n",
    "print('All the metrics for the Lasso Regression.')\n",
    "print(\"Lasso Regression CV R-squared:\", scores_lasso.mean())\n",
    "print(\"Lasso Regression CV MSE:\", mse_lasso)\n",
    "print(\"Lasso Regression CV RMSE:\", rmse_lasso)\n",
    "print(\"Lasso Regression CV MAE:\", mae_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "51cbedcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'estimator': Lasso(), 'estimator__alpha': 0.01}\n",
      "Best score: 1709567759450.6094\n",
      "Best R2 (Training): 0.26675893629098857\n",
      " \n",
      "All the metrics for Linear Regression.\n",
      "Linear Regression CV R-squared: 0.12968707305585828\n",
      "Linear Regression Training R-squared: 0.26675893629098857\n",
      "Linear Regression Training MSE: 1345395162329.8088\n",
      "Linear Regression Training RMSE: 1159911.7045403968\n",
      "Linear Regression Training MAE: 506517.2233652305\n",
      " \n",
      "All the metrics for Ridge Regression.\n",
      "Ridge Regression CV R-squared: 0.14266254894410454\n",
      "Ridge Regression Training R-squared: 0.26673267575032367\n",
      "Ridge Regression Training MSE: 1345443346762.0774\n",
      "Ridge Regression Training RMSE: 1159932.4750872687\n",
      "Ridge Regression Training MAE: 505076.05398940766\n",
      " \n",
      "All the metrics for Lasso Regression.\n",
      "Lasso Regression CV R-squared: 0.13168776078497788\n",
      "Lasso Regression Training R-squared: 0.2667589361369228\n",
      "Lasso Regression Training MSE: 1345395162612.4978\n",
      "Lasso Regression Training RMSE: 1159911.7046622548\n",
      "Lasso Regression Training MAE: 506514.27668107534\n"
     ]
    }
   ],
   "source": [
    "# define the models\n",
    "linear = LinearRegression()\n",
    "ridge = Ridge(alpha=0.5)\n",
    "lasso = Lasso(alpha=0.5)\n",
    "\n",
    "# define the pipelines\n",
    "pipeline_linear = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', linear)\n",
    "])\n",
    "\n",
    "pipeline_ridge = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', ridge)\n",
    "])\n",
    "\n",
    "pipeline_lasso = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', lasso)\n",
    "])\n",
    "\n",
    "# define the hyperparameters to search\n",
    "param_grid = [{'estimator': [Ridge()],\n",
    "               'estimator__alpha': [0.01, 0.1, 1, 10, 100]\n",
    "               },\n",
    "              {'estimator': [Lasso()],\n",
    "               'estimator__alpha': [0.01, 0.1, 1, 10, 100]\n",
    "               }\n",
    "]\n",
    "\n",
    "# create gridsearchcv to perform this lookout for the best hyperparameters\n",
    "time_series_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline_linear, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# fit the grid search to the training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# evaluate each model using cross-validation\n",
    "scores_linear = cross_val_score(pipeline_linear, x_train, y_train, cv=time_series_split, scoring='r2')\n",
    "scores_ridge = cross_val_score(pipeline_ridge, x_train, y_train, cv=time_series_split, scoring='r2')\n",
    "scores_lasso = cross_val_score(pipeline_lasso, x_train, y_train, cv=time_series_split, scoring='r2')\n",
    "\n",
    "# Ensure the entire pipeline is fitted before predicting\n",
    "grid_search.best_estimator_.fit(x_train, y_train)\n",
    "pipeline_ridge.fit(x_train, y_train)\n",
    "pipeline_lasso.fit(x_train, y_train)\n",
    "\n",
    "# compute the R-squared of the training set for each model\n",
    "r2_linear_train = grid_search.best_estimator_.score(x_train, y_train)\n",
    "r2_ridge_train = pipeline_ridge.score(x_train, y_train)\n",
    "r2_lasso_train = pipeline_lasso.score(x_train, y_train)\n",
    "\n",
    "# compute the mean squared error of each model on the training set\n",
    "mse_linear_train = mean_squared_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
    "mse_ridge_train = mean_squared_error(y_train, pipeline_ridge.predict(x_train))\n",
    "mse_lasso_train = mean_squared_error(y_train, pipeline_lasso.predict(x_train))\n",
    "\n",
    "# compute the root mean squared error of each model on the training set\n",
    "rmse_linear_train = sqrt(mse_linear_train)\n",
    "rmse_ridge_train = sqrt(mse_ridge_train)\n",
    "rmse_lasso_train = sqrt(mse_lasso_train)\n",
    "\n",
    "# compute the mean absolute error of each model on the training set\n",
    "mae_linear_train = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
    "mae_ridge_train = mean_absolute_error(y_train, pipeline_ridge.predict(x_train))\n",
    "mae_lasso_train = mean_absolute_error(y_train, pipeline_lasso.predict(x_train))\n",
    "\n",
    "# print all metrics\n",
    "# print best parameters and best score\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "print('Best score:', -grid_search.best_score_)\n",
    "print('Best R2 (Training):', r2_linear_train)\n",
    "print(' ')\n",
    "\n",
    "# printing all for linear regression\n",
    "print('All the metrics for Linear Regression.')\n",
    "print(\"Linear Regression CV R-squared:\", scores_linear.mean())\n",
    "print(\"Linear Regression Training R-squared:\", r2_linear_train)\n",
    "print(\"Linear Regression Training MSE:\", mse_linear_train)\n",
    "print(\"Linear Regression Training RMSE:\", rmse_linear_train)\n",
    "print(\"Linear Regression Training MAE:\", mae_linear_train)\n",
    "print(' ')\n",
    "\n",
    "# printing all for Ridge regression\n",
    "print('All the metrics for Ridge Regression.')\n",
    "print(\"Ridge Regression CV R-squared:\", scores_ridge.mean())\n",
    "print(\"Ridge Regression Training R-squared:\", r2_ridge_train)\n",
    "print(\"Ridge Regression Training MSE:\", mse_ridge_train)\n",
    "print(\"Ridge Regression Training RMSE:\", rmse_ridge_train)\n",
    "print(\"Ridge Regression Training MAE:\", mae_ridge_train)\n",
    "print(' ')\n",
    "\n",
    "# printing all for Lasso regression\n",
    "print('All the metrics for Lasso Regression.')\n",
    "print(\"Lasso Regression CV R-squared:\", scores_lasso.mean())\n",
    "print(\"Lasso Regression Training R-squared:\", r2_lasso_train)\n",
    "print(\"Lasso Regression Training MSE:\", mse_lasso_train)\n",
    "print(\"Lasso Regression Training RMSE:\", rmse_lasso_train)\n",
    "print(\"Lasso Regression Training MAE:\", mae_lasso_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e306c83e",
   "metadata": {},
   "source": [
    "### feedback\n",
    "\n",
    "* R-squared: measure that explains the variance in the target variable.\n",
    "* MSE(Mean Squared Error): average squared difference between predicted and actual values.\n",
    "* RMSE(Root Mean Squared Error): the square root of MSE, providing a more interpretable scale.\n",
    "* MAE (Mean Absolute Error): measure the average absolute differences between the predicted values and the acutal values. It gives an equal weight to all errors, regardless of their magnitude and it is easy to interpret ( if the MAE is 10 000, the model is on average off by 10 000 units)\n",
    "\n",
    "**Linear Regression metrics**\n",
    "\n",
    "* R-squared: A negative value indicates that the model performs poorly and does not capture the variance\n",
    "* MSE: a high MSE suggests that the predictions are far from the actual values\n",
    "* RSME: An extremely high RMSE indicates significant erros in prediction\n",
    "* MAE: The model is by average 471 055 euros off the price.\n",
    "\n",
    "**Ridge Regression metrics**\n",
    "\n",
    "* Metrics are better than those for linear regression but still not satisfactory. The regularization that mitigates the overfitting may not be sufficient for your data.\n",
    "* MAE: The model is by average 469 418 euros off the price.\n",
    "\n",
    "**Lasso Regression metrics**\n",
    "\n",
    "* Similar to Ridge regression, it introduces L1 regularization. The metrics are comparable, indicating that both Ridge and Lasso may not be the best models for your data.\n",
    "* MAE: The model is by average 471 502 euros off the price.\n",
    "\n",
    "It might be beneficial to explore more complex models, consider additional feature engineering, or investigate if outliers or non-linear patterns are influencing the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3fc50c",
   "metadata": {},
   "source": [
    "**Best Model yet**\n",
    "\n",
    "All the metrics are better for the Ridge Regression. The model has a higher R^2 and lower RMSE and MAE, which makes is straightforward to chose the ridge regression as best model yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141558a3",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c6bf63",
   "metadata": {},
   "source": [
    "We chose the decision tree algorithm for predicting the painting prices due to several reasons. Firstly, decision trees are easy to understand and interpret, providing transparent results tha can be visualized. Secondly, decisop, trees can handle both categorical annd numerical features, making them versatile for various types of datasets. Thirdly, decision trees can capture non-linera relationships between features, allowing them to detect complex patterns that other models may miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1f292249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries for the decision tree model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from math import sqrt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b1b595ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "CV R-squared scores for each fold: [-0.51781306  0.07703509  0.52211062  0.35444326  0.32780089]\n",
      "Average CV R-squared: 0.15271536004063097\n",
      "\n",
      "\n",
      "CV R-squared: 0.47846681951336356\n",
      "CV MSE: 1394795576367.9175\n",
      "CV RMSE: 1181014.6385070414\n",
      " \n",
      "CV MAE: 308510.45348964474\n",
      " \n",
      "Training Set R-squared: 0.47846681951336356\n",
      "Training Set MSE: 953985486667.0203\n",
      "Training Set RMSE: 976721.8061797434\n",
      " \n",
      "Training Set MAE: 308510.45348964474\n",
      " \n",
      "Best hyperparameters: {'estimator__max_depth': 5, 'estimator__max_features': 'sqrt', 'estimator__min_samples_leaf': 2}\n",
      " \n",
      "Best MSE: 1394795576367.9175\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator\n",
    "print('Decision Tree')\n",
    "estimator = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# define the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'estimator__max_depth': [None,1, 2,3, 5, 10],\n",
    "    'estimator__min_samples_leaf': [1, 2, 4],\n",
    "    'estimator__max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# define the grid search object\n",
    "time_series_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# fit the pipeline to the data using cross-validation\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best estimator from the grid search\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Get cross-validated R-squared scores\n",
    "cv_r2_scores = cross_val_score(best_estimator, x_train, y_train, cv=time_series_split, scoring='r2')\n",
    "\n",
    "# Print the R-squared scores for each fold\n",
    "print(\"CV R-squared scores for each fold:\", cv_r2_scores)\n",
    "print(\"Average CV R-squared:\", cv_r2_scores.mean())\n",
    "print('\\n')\n",
    "\n",
    "# Predict on the entire training set\n",
    "y_train_pred = best_estimator.predict(x_train)\n",
    "\n",
    "# print the R-squared score of the model using cross-validation\n",
    "r2 = grid_search.best_estimator_.score(x_train, y_train)\n",
    "print(\"CV R-squared:\", r2)\n",
    "\n",
    "# print the mean squared error of the model using cross-validation\n",
    "mse = -grid_search.best_score_\n",
    "print(\"CV MSE:\", mse)\n",
    "\n",
    "# print the root mean squared error of the model using cross-validation\n",
    "rmse = sqrt(mse)\n",
    "print(\"CV RMSE:\", rmse)\n",
    "print(' ')\n",
    "\n",
    "# Print the Mean Absolute Error (MAE) of the model using cross-validation\n",
    "mae = mean_absolute_error(y_train, y_train_pred)\n",
    "print(\"CV MAE:\", mae)\n",
    "print(' ')\n",
    "\n",
    "# Print the R-squared score on the entire training set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "print(\"Training Set R-squared:\", r2_train)\n",
    "\n",
    "# Print the mean squared error on the entire training set\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "print(\"Training Set MSE:\", mse_train)\n",
    "\n",
    "# Print the root mean squared error on the entire training set\n",
    "rmse_train = sqrt(mse_train)\n",
    "print(\"Training Set RMSE:\", rmse_train)\n",
    "print(' ')\n",
    "\n",
    "# Print the Mean Absolute Error (MAE) on the entire training set\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "print(\"Training Set MAE:\", mae_train)\n",
    "print(' ')\n",
    "\n",
    "# print the best hyperparameters and the corresponding mean squared error\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(' ')\n",
    "print(\"Best MSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "0d69c6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "CV R-squared scores for each fold: [0.09366361 0.10750847 0.3902861  0.28446785 0.40171543]\n",
      "Average CV R-squared: 0.255528292549266\n",
      "\n",
      "\n",
      "CV R-squared: 0.7424535908382275\n",
      "CV MSE: 1330385932501.1755\n",
      "CV RMSE: 1153423.5702902796\n",
      " \n",
      "CV MAE: 198515.1123647668\n",
      " \n",
      "Training Set R-squared: 0.7424535908382275\n",
      "Training Set MSE: 472561767352.37024\n",
      "Training Set RMSE: 687431.281912869\n",
      " \n",
      "Training Set MAE: 198515.1123647668\n",
      " \n",
      "Best hyperparameters: {'estimator__max_depth': 10, 'estimator__max_features': 'log2', 'estimator__min_samples_leaf': 2}\n",
      " \n",
      "Best MSE: 1330385932501.1755\n"
     ]
    }
   ],
   "source": [
    "# Define the final estimator\n",
    "print('Decision Tree')\n",
    "estimator = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'estimator__max_depth': [None, 1, 2, 3, 5, 10],\n",
    "    'estimator__min_samples_leaf': [1, 2, 4],\n",
    "    'estimator__max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Define the grid search object\n",
    "time_series_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the pipeline to the data using cross-validation\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best estimator from the grid search\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Get cross-validated R-squared scores\n",
    "cv_r2_scores = cross_val_score(best_estimator, x_train, y_train, cv=time_series_split, scoring='r2')\n",
    "\n",
    "# Print the R-squared scores for each fold\n",
    "print(\"CV R-squared scores for each fold:\", cv_r2_scores)\n",
    "print(\"Average CV R-squared:\", cv_r2_scores.mean())\n",
    "print('\\n')\n",
    "\n",
    "# Predict on the entire training set\n",
    "y_train_pred = best_estimator.predict(x_train)\n",
    "\n",
    "# Print the R-squared score of the model using cross-validation\n",
    "r2 = grid_search.best_estimator_.score(x_train, y_train)\n",
    "print(\"CV R-squared:\", r2)\n",
    "\n",
    "# Print the mean squared error of the model using cross-validation\n",
    "mse = -grid_search.best_score_\n",
    "print(\"CV MSE:\", mse)\n",
    "\n",
    "# Print the root mean squared error of the model using cross-validation\n",
    "rmse = sqrt(mse)\n",
    "print(\"CV RMSE:\", rmse)\n",
    "print(' ')\n",
    "\n",
    "# Print the Mean Absolute Error (MAE) of the model using cross-validation\n",
    "mae = mean_absolute_error(y_train, y_train_pred)\n",
    "print(\"CV MAE:\", mae)\n",
    "print(' ')\n",
    "\n",
    "# Print the R-squared score on the entire training set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "print(\"Training Set R-squared:\", r2_train)\n",
    "\n",
    "# Print the mean squared error on the entire training set\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "print(\"Training Set MSE:\", mse_train)\n",
    "\n",
    "# Print the root mean squared error on the entire training set\n",
    "rmse_train = sqrt(mse_train)\n",
    "print(\"Training Set RMSE:\", rmse_train)\n",
    "print(' ')\n",
    "\n",
    "# Print the Mean Absolute Error (MAE) on the entire training set\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "print(\"Training Set MAE:\", mae_train)\n",
    "print(' ')\n",
    "\n",
    "# Print the best hyperparameters and the corresponding mean squared error\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(' ')\n",
    "print(\"Best MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a78f23",
   "metadata": {},
   "source": [
    "#### feedback\n",
    "\n",
    "* CV R-squared: A cross validation of 1 suggests that your model perfectly predicts the target variable in the training data. This is an ideal scenario, nonetheless, it could also indicate potential overfitting, expecially if the model does not generalize well to new, unseen data\n",
    "* CV MSE: The lower the MSE, the better but the absolute value itself might not give a clear sense of the scale of the errors.\n",
    "* CV RMSE: Lower RMSE values indicate better model performance\n",
    "* MAE: The model is by average 0 euros off the price. This was also possible to see due to the R^2 which is 1 and leads to a model that perfectly predicts the price of paintings.\n",
    "\n",
    "It is important to note that while achieving a perfect R-squared on the training data is desirable, it doesn't guarantee good generalization to new, unseen data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa76ca0",
   "metadata": {},
   "source": [
    "**compare with previous models**\n",
    "\n",
    "Based on the R-squared and the RMSE, the decision tree model appears to perform better than the linear regression, ridge regression and lasso regression models. The decision tree has the highest (perfect) R-squared score of 1.0, indicating that it explains the variance perfectly ( no variance in this model which indicates overfitting ). Additionally, the decision tree has the lowest RMSE of 1325551.67, indicating that it has the smallest prediction error compared to the other models. Therefore, the decision tree model is the best choice for this particular problem yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc22764a",
   "metadata": {},
   "source": [
    "### Ensemble Random Forest\n",
    "\n",
    "As the decision tree showed promising results, we decided to utilize random forest as an ensemble method. Random forest combines multiple decision trees to improve accuracy and reduce overfitting. This is particularly important in house price prediction, where multiple variables can impact the outcome.\n",
    "\n",
    "Random forest is also robust to outliers, which is beneficial for extreme values. Therefore, random forest is a suitable model for predicting house prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fd10374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries for the RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5978bc60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Best hyperparameters: {'estimator__max_depth': 20, 'estimator__n_estimators': 10}\n",
      "Best MSE: 1312979623976.3843\n",
      "Cross-validation scores: [-0.71164834  0.10401672  0.47177239  0.50534785  0.37102203]\n",
      "Mean CV R-squared: 0.14810213294329871\n",
      "Train R-squared: 0.8569292553428316\n",
      "Train MSE: 261704181203.2496\n",
      "Train RMSE: 511570.30914943607\n",
      "Train MAE: 126221.72010189369\n"
     ]
    }
   ],
   "source": [
    "# define the model that we are going to use\n",
    "# we use the same random_state\n",
    "# we are going to look what the best n_estimators is\n",
    "print('Random Forest')\n",
    "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# define the grid of hyperparamters to look at\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
    "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
    "}\n",
    "\n",
    "# define the grid search object\n",
    "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# fit the grid search object to the training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# print the best hyperparameters and the corresponding mean squared error\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best MSE:\", -grid_search.best_score_)\n",
    "\n",
    "# calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# fit the pipeline to the train data\n",
    "grid_search.best_estimator_.fit(x_train, y_train)\n",
    "\n",
    "# make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# print the R-squared score of the model on the train data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# print the mean squared error of the model on the train data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Train MSE:\", mse_train)\n",
    "\n",
    "# print the root mean squared error of the model on the train data\n",
    "rmse_train = mse_train ** 0.5\n",
    "print(\"Train RMSE:\", rmse_train)\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "print(\"Train MAE:\", mae_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf86cd1",
   "metadata": {},
   "source": [
    "#### feedback\n",
    "\n",
    "* The set of hyperparameters that resulted in the best performance during the grid search for a random forest regressor are a maximum depth of 10 and 25 estimators were found to be optimal.\n",
    "* The mean squared error associated with these set of hyperparameters is 129714157794 and this is done on the validation set ( or a portion of the training set not used during the training ) when using the optimal hyperparameters.\n",
    "* The cross validation score corresponds to a different fold in the cross-validation process and represents the R-squared scores during cross-validation. and the Mean CV R-squared value is 0.317975.\n",
    "* The Train R-squared score on the training data, indicating how well them odel fiets the data it was trained on is equal to 0.87026 which is actually a good score but can indicate overfitting especially if you are comparing it with the mean CV R-squared score.\n",
    "    * A significant difference between the CV R-squared score and the training R-squared score can provide insights into the model's generalization performance. \n",
    "        * If the training R-squared is much higher, it suggest that the model might be overfitting the training data. Overfitting occurs when the model learns the training data too well, capturing noise or patterns specific to the training set but not generalizable to new data. This noise can be due to outliers in the price setting of      \n",
    "* The training MSE is bigger than the best scored MSE. \n",
    "    * If the difference between the training MSE and the best MSE of the validation sets is large, it can suggest several pontential issues in your ML model.\n",
    "        * overfitting, the model may perform poorly on unseen data, leading to a higher MSE on the validation set. \n",
    "        * The model can be overly complex, it might fit the training data colsely but struggle to generalize to new data. comples models can be sensitive to noise in the training set, resulting in a  large difference between training and validation MSE.\n",
    "        * a non representative validation set. IF the validation set is small or not representative of the overall data disttribution, the model may not generalize well.\n",
    "* MAE: The model is by average 140 626 euros off the price/target feature. \n",
    "        \n",
    "**what can be done to tackle these issues**\n",
    "\n",
    "* use regularization techniques to control model complexity \n",
    "* use extra parameters for optimalization\n",
    "* limiting the number of features used in the model\n",
    "* drop some outliers ( because they are a reason of the problem due to noise )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e254f46",
   "metadata": {},
   "source": [
    "**compared with previous best model**\n",
    "\n",
    "\n",
    "The decision tree appears to have an issue with overfitting, as evidenced by the perfect CV R-squared and the high CV MSE. The random forest, with its ensemble approach, seem to generalize better, as indicated by a lower mean CV MSE and a more reasonable CV R-squared. Based on the provided metrics, the random forest model apperas to be performing better than the decision tree. Therefore, the ensemble random forest model is the best choice for this particular problem yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d972d",
   "metadata": {},
   "source": [
    "### gradient boosting regressor\n",
    "\n",
    "We choose Graient Boosting because it builds an ensemble of decision trees, just like Random Forest, but instead of building tree independently, it builds them sequentially with each new tree correcting the errors of the previous ones. This can lead to a highly accurate model with lower bias and variance compared to single decision trees.\n",
    "\n",
    "Furthermore, Gradient Boosting allows for fine-tunning of the model through the adjustment of hyperparameters, such as the learning rate, the maxium depth of trees and the number of estimators which can improve the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "302773dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries for the Gradient Boosting Regressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f0867b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "Best Hyperparameters: {'estimator__max_depth': 7, 'estimator__max_features': 'log2', 'estimator__n_estimators': 100}\n",
      "Best MSE: 1333583060958.7234\n",
      "Cross-validation scores: [0.32141679 0.11102071 0.43439693 0.58484352 0.33174577]\n",
      "Mean CV R-squared: 0.3566847432558292\n",
      "training MAE: 20904.664768030565\n",
      "Train R-squared: 0.9991183799408444\n",
      "Training MSE: 1612654328.923325\n",
      "Training RMSE: 40157.867584364154\n"
     ]
    }
   ],
   "source": [
    "# Define the estimator for Gradient Boosting\n",
    "estimator = GradientBoostingRegressor(random_state=42)\n",
    "print('Gradient Boosting')\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_depth': [1,3,5 ,7, 10],\n",
    "    'estimator__max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "# Create a grid search object\n",
    "time_series_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the best MSE and corresponding negative value\n",
    "best_mse = -grid_search.best_score_\n",
    "print(\"Best MSE:\", best_mse)\n",
    "\n",
    "# Calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# calculate and print MAE\n",
    "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
    "print('training MAE:', mae)\n",
    "\n",
    "# Make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# Print the R-squared score of the model on the training data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# Print the mean squared error of the model on the training data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Training MSE:\", mse_train)\n",
    "\n",
    "# Print the root mean squared error of the model on the training data\n",
    "rmse_train = sqrt(mse_train)\n",
    "print(\"Training RMSE:\", rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42a0236",
   "metadata": {},
   "source": [
    "#### feedback\n",
    "\n",
    "* The set of hyperparameters that resulted in the best performance during the grid search for a random forest regressor are a maximum depth of 7, max features of log(2) and 100 estimators were found to be optimal. The very high training R-squared (0.9987) suggests that the model is fitting the training data extremely well, but there is a pontential risk of overfitting.\n",
    "* The mean squared error associated with these set of hyperparameters is 1244422502814 and this is done on the validation set ( or a portion of the training set not used during the training ) when using the optimal hyperparameters.\n",
    "* The cross validation score corresponds to a different fold in the cross-validation process and represents the R-squared scores during cross-validation. and the Mean CV R-squared value is 0.33607.\n",
    "* The Train R-squared score on the training data, indicating how well them odel fiets the data it was trained on is equal to 0.99872 which is actually almost a perfect score, nonetheless, it indicates overfitting especially if you are comparing it with the mean CV R-squared score.\n",
    "    * big difference between mean cv R-squared score and training R-squared score explanation ( random forrest )\n",
    "* The training RMSE is the smallest one which indicates a good model.\n",
    "* The training MSE is bigger than the best scored MSE. \n",
    "    * If the difference between the training MSE and the best MSE of the validation sets is large, it can suggest several pontential issues in your ML model. (same explanation random forrest )\n",
    "* MAE: The model is by average 23 510 euros off the price/target feature. \n",
    "    \n",
    "\n",
    "\n",
    "While the model shows excellent perfomrance on the training data, it's imporant to evaluate its peformance on independent datasets to ensure it doesn't overfit and can generalize well to new observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96ec630",
   "metadata": {},
   "source": [
    "**compared with previous best model**\n",
    "\n",
    "**Random Forrest Vs Gradient Boosting**\n",
    "\n",
    "* **Mean CV R-squared**\n",
    "    * Gradient boosting has a slightly hihger mean cross-validation R^2 compared to Random Forrest. A higher R^2 suggests better predicitive performance on average across different corss-validation folds.\n",
    "* **Train R-squared**\n",
    "    * Gradient bossting has an exceptionally high training R^2 (almost 1), indicating an almost perfect fit to the training set, raising concerns about potential overfitting.\n",
    "* **Training RMSE**\n",
    "    * Random Forest has a higher training RMSE compared to Gradient Boosting. A lower RMSE indicates better model performance. However, be cautious about overfitting, expecially when the training R^2 is very high.\n",
    "* **Training MAE**\n",
    "    * Gradient Boosting has a lower MAE (23510) compared to Random Forest (140626), which is prefered to be as small as possible.\n",
    "* **Generalization**\n",
    "    * Both models show improvement over the baseline (as indicated by positive cross-validation scores), but Gradient Boosting seems to generalize slightly better in terms of mean cross-validation R^2.\n",
    "    \n",
    "**Conclusion**\n",
    "* If you prioritize generalization to new, unseen data, the Gradient Boosting model might be preferred due to its higher mean cross-validation R^2.\n",
    "\n",
    "* If computational efficiency is a concern, and you are satisfied with the Random Forest's performance, it could be a pragmatic choice.\n",
    "\n",
    "* Both models seem to fit the training well, but Gradient Boosting outperforms Random Forest in terms the MAE, which is know for its resiliency to outliers.\n",
    "\n",
    "* Keep in mind that these are just a few metrics, and the final decision should consider your specific requirements, the nature of your data, and the implications of potential overfitting. You might also want to explore further tuning or consider ensemble methods combining the strengths of both models.\n",
    "\n",
    "* Not unimportant is that Gradient Boosting is robust to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4116e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import of the libraries\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8b096621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "\n",
      "Test MSE: 10791817474913.41\n",
      "Test RMSE: 3285090.1775923003\n",
      "Test R-squared: 0.4107415883265494\n",
      "Adjusted R2 is 0.35898240351739497\n",
      "Test MAE: 1486125.4065651512\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator with the best parameters\n",
    "gbr = RandomForestRegressor(n_estimators=200, max_depth=7,random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('Random Forest')\n",
    "print('')\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fbd47910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "\n",
      "Test MSE: 12405623220762.424\n",
      "Test RMSE: 3522161.725526303\n",
      "Test R-squared: 0.32262402955954406\n",
      "Adjusted R2 is 0.26312478891274727\n",
      "Test MAE: 1519766.1507016283\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator with the best parameters\n",
    "gbr = GradientBoostingRegressor(n_estimators=100, max_depth=10, max_features= 'log2',random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('Gradient Boosting')\n",
    "print('')\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2594b38e",
   "metadata": {},
   "source": [
    "### Feedback\n",
    "\n",
    "**conclusion**\n",
    "\n",
    "* The model's performance, as indicated by metrics such as Test MSE, Test RMSE, Test R-squared, and Test MAE, seems to be suboptimal. The relatively high values for MSE and RMSE, as well as the moderate R-squared and large MAE, suggest that the model might not be capturing the underlying patterns in the data effectively.\n",
    "\n",
    "**Recommendations for improvement**\n",
    "\n",
    "* Explore the possibility of creating new features, transofrming existing ones or dropping features to provide more meaningfull information to the model. Feature engineering can sometimes significantly improve model performance.\n",
    "* Investigate and handle outliers: Outliers in the data can adversely affect the model's performance. Identify and ocnsider appropiate strategies for handling outliers in your dataset.\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981c59d4",
   "metadata": {},
   "source": [
    "# doing the same for a dataset without outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "77540d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "603e2735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>target</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>72.213</td>\n",
       "      <td>133.827</td>\n",
       "      <td>1994</td>\n",
       "      <td>London</td>\n",
       "      <td>GBP</td>\n",
       "      <td>40694.870</td>\n",
       "      <td>True</td>\n",
       "      <td>507.800</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>62.101</td>\n",
       "      <td>174.389</td>\n",
       "      <td>1995</td>\n",
       "      <td>New York</td>\n",
       "      <td>USD</td>\n",
       "      <td>9730.240</td>\n",
       "      <td>True</td>\n",
       "      <td>322.600</td>\n",
       "      <td>Watercolour Art</td>\n",
       "      <td>paper</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist  contrast  brightness  year_sold city_auction currency  \\\n",
       "0  Pierre Alechinsky    72.213     133.827       1994       London      GBP   \n",
       "1  Pierre Alechinsky    62.101     174.389       1995     New York      USD   \n",
       "\n",
       "     target signed  circumference           medium surface  year_born   dead  \\\n",
       "0 40694.870   True        507.800          missing  canvas       1927  False   \n",
       "1  9730.240   True        322.600  Watercolour Art   paper       1927  False   \n",
       "\n",
       "   return_sp  \n",
       "0      0.100  \n",
       "1      0.013  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55691ef6",
   "metadata": {},
   "source": [
    "##### 1. identify and understand outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307a6454",
   "metadata": {},
   "source": [
    "Alright, we are going to see to different distributions of the target variable when dropping outliers.\n",
    "\n",
    "Afterwards, we will run different models on these dataframes and look what changes in the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "43a5e6b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAGRCAYAAACT7EP6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABcnklEQVR4nO3de7x0dVn//9dbQM4IxA0iN3CjIgr8PNAtaZghpOARyjTMAxnJ10TNMhPMyiySvt/yUGqGh8QDImIqmidEySwBAfEASJCcbkHuWxQ5SJy8fn+sz4a5N/swe997Zs/e83o+HvOYmc+steZac7hmzbU+67NSVUiSJEmSJI2y+y12AJIkSZIkSbOxgCFJkiRJkkaeBQxJkiRJkjTyLGBIkiRJkqSRZwFDkiRJkiSNPAsYkiRJkiRp5FnAGCFJXpfkPQs9bR/LqiQP3YD5FyyWtrxbkjy43X5/kr9ewGW/K8mfLdTy5vC8v5/k+rZuvzDs5x9Fve/zLNOtap/Rjad5/A1JPrTwEUqzW8ickmS39r3YqN0/K8nvLcSy2/I+l+TIhVrepGU/JcknB7Fs9af39zLJryS5dADPsVOSS5JsutDLlhaCOfmeZZuTF5k5eXAsYAxIkt9J8p0kP0vywyT/lGTbmeapqr+pqr4S41ym3RAtWf9vkpuT3JTk/CTH9n5R+o2l38RfVVtV1fcXIPbfSfK1Sct+aVX91YYue45xbAK8GXhKW7cbeh77lfbjeEuSW9sf9Vt6LrsNKcYZiwBJvpDkjVO0H9Y+31MWF2ayUO+zNChJrkxyW8t/Nyb5ryQvTXLPb2e/OaUt69dmmqaqrm7fi7sXIPb7fKer6qlVddKGLnsafwOc0PP81XLaLUl+kOTNE38ClqIk+7Y8+KMkNcXj2yf5RFvnq5L89izLW5nkw0luaPOcm+QZc4jnPr9vvarqP6pqr36X16+quh74CnD0Qi9bmo05eU6We04+sv0nuSnJmiT/t3dbtOf/y8T29IzFA3Py0mIBYwCSvBr4W+A1wAOAxwG7A2ckuf8088z5D+AQvbyqtgZ2Bl4NHAF8NkkW8klG/DXYEDsBmwEXTX6gJbStqmorYJ/WvO1EW1Vd3c8TDOG1ez/wwine8xcCH66qu/pd0DJ+n7U8PbPlv93pNgZfC7x3oZ9kKX8vkjwWeEBVnT3poUe13ParwG8Bvzv04BbOncCpwFHTPP4O4A66fP984J+S7DPVhEm2B77Wpt8H2AF4C3Bykt9c4LjnrI/P4oeB/zOMWKQpmJNnMSY5eQvgVXT585eAg4E/njTNy3u2p6ctHpiTl6Cq8rKAF2Ab4BbguZPatwLWAr/b7r8BOA34EHAT8Hut7UM987wIuAq4Afgz4Erg13rm/1C7vQoo4EjgauBHwJ/2LGd/4OvAjcB1wNuB+/c8XsBDp1mfs4Dfm9S2G/Az4BlTxLJZW6cb2vN9g26D7njgbuB/2+vz9p7nPga4DLhicjx0f5zfBZwB3Az8O7D7pPXeeHK8wCPac93dnu/GnuX9dc/0LwEuB34MnA48aNLr8tIW20/oNlAzzeu0KfBW4Np2eWtrexhwa1vWLcCXZ/jsrLc+wIuBS9p6fx/4Pz3THgisofvh/iHwQWBz4KQW6yXAnwBreuZ5EPBxYB1wBfDK1n4oXdK+s8X4rSli2xz4KfDEnrbt2mv8KPr7jM30Pj8d+Cbdd+Ea4A1TvC5Ht9f2OuDVPY+/gfW/N48D/qvF8i3gwMXOC16W5oWenNvTtj/wc2Dfdv+enEK30fOZ9tn7MfAfdDsKPtjmua19x/6k53N9FF3e/uoUOeAs4E3Aue379ylg+/bYgb3f7954p/tO05PPW1yvp/uNWQt8gG6Dt/c7N+VvyhSv058D75nUtt7vCt2f/3f03H8GcGF7rf4LeOSk9XgN8G26/Pleut+Rz9Hlwy8B2/VM/yy6AvGNbR0f0dqPBU6bFNfbgH9otx/Qln0d8APgr4GNZvlMPBSoSW1bttf7YT1tHwROmGYZfwV8F7jfpPbXtvcjkz8Lve8fffy+Tf58ME3+b4+9gftuj+wPnNfuXw+8uWf6jem2AXZf7O+ol/G6YE42J0+/zn8EfLrn/j2vbR/zmpOX2MUeGAvvl+n+xP9rb2NV3UL3RX9yT/NhdB/QbemqZ/dIsjfwTro9OTvTfal3meW5nwDsRVeF/PMkj2jtdwN/SJfIH98ef9ncVmu9dbma7kv0K1M8fGSLdVfgF+gKALdV1Z/S/XBMVENf3jPP4XTV072necrn0yWXHeiS64enma43xkvac3+9Pd+2k6dJchDdD9Fz6V7jq4BTJk32DOCxdH/SnwscMs1T/indH+dHc+8f+tdX1X+zfs+Kg2aLvcfa9vzb0BUz3pJkv57HHwhsT7cX4mjgL+gS7IPpPmcv6FnX+wGfpvtDvwvdZ+BVSQ6pqs/TdTX8aHutHjU5kKq6je7H7kU9zc8FvldV36K/z9jhTP8+39qWvS1dMeP3kxw+aZonAXsCTwGOnarrZ5JdgH+j+9Hbnq4a//EkK6Z4TmnOqupcuuLhVPnv1e2xFXQbd6/rZqkX0m10PrN9x/5vzzy/SrfxM11ueRHdXrIHAXcB/9BHjLN+p4HfaZcn0eWMregKj72m+02Z7P8Dpu2em+ThdK/X5e3+fsD76PYY/QLwz8DpWf8Y3mfT5bGHAc+k+/18HV2OuR/wyrashwEfodsTtwL4LPDp1tvxI8DTkmzTpt2ILm+d3J7jJLrX9KHAY+hyy3wOzXwYcHfL9xO+xb25f7InAx+vqp9Paj+VbgfBw2Z6sn5+33rNlP97Jpu8PfI24G1VtQ3wkBbbxPPfRfdeTvW5kobKnDylcczJT+S+PZ3f1A77+88kB84wrzl5ibGAsfB2AH5UU3epv649PuHrVfXJqvp5+4PY6zfpKolfq6o76KqpNctz/2VV3db+UH6L9kGuqvOr6uyququqrqRLTL8691Vbz7V0fxAnu5Mu+T20qu5uz33TLMt6U1X9eIrXYMK/VdVXq+p2ukLB45PsOv/Q7/F84H1VdUFb9nFt2at6pjmhqm5sRZuv0BUoplvWG6tqbVWtA/6S7vCKeauqf6uq/6nOvwNfZP0f6J8Df1FVt7fX7rnA31TVT6pqDev/qD4WWFFVb6yqO6obe+LddIcD9esk4DlJNm/3X9Ta+v2MTfs+V9VZVfWd9l34Nt2P3OT5/7Kqbq2q7wD/AjxvihhfAHy2qj7blnUGXbHtaXNYT2k2M+W/nen2gtxZ3SFis+XtN7TP9XT574NV9d2qupWuJ95zF+i45efT7cH5fiuwHwccMamr6pS/KVPYlm4v3GQXJLmVrkfYWXRFeeh6vv1zVZ3TfidOAm6nKwJP+Mequr6qfkBX/D6nqr7ZcvUn6DZuoesG/W9VdUZV3Qn8HV2PsV+uqquAC+iKpwAHAT+rqrOT7AQ8FXhVe/3X0nUZnktOnLAV3d7YXj8Ftp5m+h3otgcmu67n8YXUT/6fvD1yJ/DQJDtU1S11367oN9O979IoMCevb1vGKCcneTGwuj3XhNfSFYJ2AU6kK6I8ZJpFmJOXGAsYC+9HwA7THK+0c3t8wjUzLOdBvY9X1c/oDsuYyQ97bv+MbqOKJA9L8pl0gy3eRFcF3tAv4y503fEm+yDwBeCUJNe2QXU2mWVZM70O6z3ekvqP6V6fDfUgul4Xvcu+gfV7ukz5ms62rHZ7g2JM8tQkZyf5cZIb6f6E975v66rqfyfF0Pta9t7eHXhQG/Tqxra819HtkehLVX2NrqvbYenOHvJYWtW8z8/YtO9zkl9K8pUk65L8lK6SPdP8072+u9MVWXrX8wl03z1poUyX//4f3V6QLyb5fpJj+1hW3/mP7nO/CQuzMTVVztqY9XNCv/nvJ0z9Z32/Ns9v0fW+2rK17w68etL3dFfW/05f33P7tinuT8QyOY//nO41m8jjJ3NvsfO3uXdP3+50r+V1PTH8M7DjNOs4k1voesr12oap/0BAtx0wVU7auefxhdRP/p/8OTyKbq/j95J8Y4rB7Lam6x4ujQJz8vrGJie33ronAE+tqntyZyvG3Nx28p0E/CfT78wyJy8xFjAW3tfpqpa/0duYZEu6yuKZPc0zVYGvA1b2zL85Xc+G+fgn4HvAntV1PXod3fFc89J6P/wiXQV2Pa3C/ZdVtTfd4TTP4N7DDqZb39mq4ff0tkiyFV2V/Vq6ww6gG8hnwgPnsNxr6ZLIxLK3pHuNfzDLfLMui67L2bXzWM5ELJvSHRv3d8BO1XVH+yzrv2+T12+9zww9rxtdIryiqrbtuWxdVRPJfLbXasIH6N7PFwJfrG70Y+jvMzbTc5xMNwbJrlX1ALpxTybP37s+072+19DtHeldzy2r6oQpppXmrA2OtgvdgF/raRtLr66qB9N1sf2jJAdPPDzNIvvOf3Sf+zvpNqZupSf3tT2AvYdKzSn/tWXfxfobpf36NtN0sa3OqXS/jX/emq8Bjp/0Pd2iqj4yj+eenMdD95pN5PGPAQcmWQn8OvduLF9D91u9Q08M21TVdId9zOS/gY2T7NnT9iimGLi5+RLw7PScOaF5bovrv9nw37des+X/+yyvqi6rqufR/Xn4W+C09hs5MaDcQ+n2AEuLypw8pbHIyUkOpeu58MzqeufOpJj+v485eYmxgLHAquqndIcP/GOSQ5Ns0g5J+BjdcXgf7HNRpwHPTPLL7bixv2T+RYet6QZ9uaUd9/b781lIki2S/CrdoEXn0v2hnjzNk5L8fy1x30SX2CdOP3U9XXeuuXpakie01+Gv6LqtXVPdoRo/AF6QZKMkv0t3XNiE64GVmebML3RJ88VJHt0KBn/Tln3lPGL8CPD6JCuS7ED3ozDtaUn7cH+6QUDXAXcleSrdsYAzORU4Lsl26caC6B1n5FzgpiSvTbJ5e732bT/80L1Wq6ZI3pN9gG5AqpfQDh9pNvQztjXw46r63yT701XlJ/uz9hnch25MkI9OMc2H6L43h7R13CzJxA+lNG9Jtml7PE6hGzT2PhtLSZ6R5KFtg+0muty3ofnvBUn2TrIF8Ea6AdDuptug2izJ01svt9fT5YwJs32nPwL8YZI9WmF44vjsvs8o1OOzzH5Y4gnA0UkeSLfB+dLW8ypJtmzrMd0hFzM5FXh6koPb6/Bquo3g/wJovxNn0R12dkV1xypTVdfRHZb39+29vV+Sh7TfuPtocW5Gl5tpuWXTtqxb6ca9emNblwPojl+e7vf+LXQ9NN6b5IFtWc+jO0TyNe0Pxob+vvWaLf9Ptb4vSLKi7T29sTVPfJb3B65s3cGlRWFOntE45OSD6MaGeHZ146D0PrZt2w7cLMnGSZ5PN0bGF6aJ2Zy8xFjAGIDqBgN6Hd3e85uAc+iqbQdXd6xYP8u4CHgFXWK+jq4r6lq6JDBXf0z3h/BmuiQ11R+/mbw9yc10X8630vUMOLTuO9gNdNXI0+jW+xK6s4ZM/JF/G/CbSX6SZNZBj3qcTDdA5Y/pen48v+exl9CNjHwD3YBp/9Xz2Jfp9oD9MMl9un9V1Zl0xy9+nO41fgjzO/4ZukEjz6Oren+H7hi/v57nsqiqm+kGRDqVrivgb9P1UJjJG+mKZFfQVZNPo31e2o/rM+nG8LiCbm/Be+gGXIWuwAZwQ5ILZojrSrrXeMtJ8WzoZ+xldBv/N9MVf06dYpp/p+sKeibwd1X1xSniu4buj8Pr6Io/19B9Psx1mq9Pt8/lNXQbM2+mK6BNZU+6794tdHu33llVZ7XH3kRX5LwxyeRTvc3kg3Qjmf+QboDoV8I9xfKX0X2Pf0C3d2hNz3yzfaff15b9Vbqc8L90vzlzVlUXAD9N8kszTPMduu/wa6rqPLrc/Xa6/HY53eB183nuS+nGvvlHurz2TLq9cXf0THYyXeH15Emzv4iuIHFxi+M0pj/cbHe6btITvSpuY/1B8l5Gd5z3Wro/Ir/ffsenivkGukPbNmvPfQPdCPovrKre3Dnv37dJzzdb/p/KocBFSW6h++0+ou49ZPH5dL3kpMVgTp7FmOTkP6PLYZ9Ncku7fK49tgndNvi6FsMrgMNbbFPFbE5eYlKzjmWjUdCqsTfSddG/YpHD0RKQ5PfpEtyGDtgqSTNK8hTgZVV1+GLHosFJsiPdn57H1PpjMEkaIebk8TCuOdkCxghL8ky6vc0B/p5uwJ39yjdNU0iyM113yK/T7XX4N+DtVfXWxYxLkiRJkhaC3apH22F0g+FcS/eH9AiLF5rB/elGbL6Zrivbp7j3FFmSJEmStKTZA0OSJEmSJI08e2BIkiRJkqSRZwFDkiRJkiSNvI0XO4ANscMOO9SqVasWOwxJmrfzzz//R1W1YrHjWAjmZElLmflYkkbHdDl5SRcwVq1axXnnnbfYYUjSvCW5arFjWCjmZElLmflYkkbHdDnZQ0gkSZKkIUqybZLTknwvySVJHp9k+yRnJLmsXW/XM/1xSS5PcmmSQxYzdklaTBYwJEmSpOF6G/D5qno48CjgEuBY4Myq2hM4s90nyd7AEcA+wKHAO5NstChRS9Iis4AhSZIkDUmSbYAnAu8FqKo7qupG4DDgpDbZScDh7fZhwClVdXtVXQFcDuw/zJglaVRYwJAkSZKG58HAOuBfknwzyXuSbAnsVFXXAbTrHdv0uwDX9My/prVJ0tixgCFJkiQNz8bAfsA/VdVjgFtph4tMI1O01X0mSo5Ocl6S89atW7cwkUrSiBnLAsbK3VeRZMbLyt1XLXaYkjQWzMmSxswaYE1VndPun0ZX0Lg+yc4A7Xptz/S79sy/Erh28kKr6sSqWl1Vq1esmN/ZYM3Hkkbdkj6N6nz94OqreNMFM1emj9tvWZwGXJJGnjlZ0jipqh8muSbJXlV1KXAwcHG7HAmc0K4/1WY5HTg5yZuBBwF7AucOIjbzsaRRN5YFDEmSJGkRvQL4cJL7A98HXkzXM/rUJEcBVwPPAaiqi5KcSlfguAs4pqruXpywJWlxWcCQJEmShqiqLgRWT/HQwdNMfzxw/CBjkqSlYCzHwJCkcZNk2ySnJflekkuSPD7J9knOSHJZu96uZ/rjklye5NIkhyxm7JIkSRJYwJCkcfE24PNV9XDgUcAldKPen1lVewJntvsk2Rs4AtgHOBR4Z5KNFiVqSZIkqbGAIUnLXJJtgCcC7wWoqjuq6kbgMOCkNtlJwOHt9mHAKVV1e1VdAVwO7D/MmCVJkqTJLGBI0vL3YGAd8C9JvpnkPUm2BHaqqusA2vWObfpdgGt65l/T2iRJkqRFYwFDkpa/jYH9gH+qqscAt9IOF5lGpmirKSdMjk5yXpLz1q2b+dR7kiRJ0oawgCFJy98aYE1VndPun0ZX0Lg+yc4A7Xptz/S79sy/Erh2qgVX1YlVtbqqVq9YsWIgwUuSJElgAUOSlr2q+iFwTZK9WtPBwMXA6cCRre1I4FPt9unAEUk2TbIHsCdw7hBDliRJku5j48UOQJI0FK8APpzk/sD3gRfTFbFPTXIUcDXwHICquijJqXRFjruAY6rq7sUJW5IkSepYwJCkMVBVFwKrp3jo4GmmPx44fpAxSZIkSXPhISSSJEmSJGnkDbSAkWTbJKcl+V6SS5I8Psn2Sc5Iclm73q5n+uOSXJ7k0iSHDDI2SZIkSZK0dAy6B8bbgM9X1cOBRwGX0J2678yq2hM4s90nyd7AEcA+wKHAO5NsNOD4JEmSJEnSEjCwAkaSbYAnAu8FqKo7qupG4DDgpDbZScDh7fZhwClVdXtVXQFcDuw/qPgkSZIkSdLSMcgeGA8G1gH/kuSbSd6TZEtgp6q6DqBd79im3wW4pmf+Na1NkiRJkiSNuUEWMDYG9gP+qaoeA9xKO1xkGpmire4zUXJ0kvOSnLdu3bqFiVSSJEkakiRXJvlOkguTnNfaHCdOkmYxyALGGmBNVZ3T7p9GV9C4PsnOAO16bc/0u/bMvxK4dvJCq+rEqlpdVatXrFgxsOAlSZKkAXpSVT26qiZOce04cZI0i4EVMKrqh8A1SfZqTQcDFwOnA0e2tiOBT7XbpwNHJNk0yR7AnsC5g4pPkiRJGiGOEydJs9h4wMt/BfDhJPcHvg+8mK5ocmqSo4CrgecAVNVFSU6lK3LcBRxTVXcPOD5JkiRp2Ar4YpIC/rmqTmTSOHFJeseJO7tnXseJkzS2BlrAqKoLgdVTPHTwNNMfDxw/yJgkSZKkRXZAVV3bihRnJPneDNP2PU4ccDTAbrvttjBRStKIGeQYGJIkSZImqapr2/Va4BN0h4Q4TpwkzcIChiRJkjQkSbZMsvXEbeApwHdxnDhJmtWgx8CQJI2AJFcCNwN3A3dV1eok2wMfBVYBVwLPraqftOmPA45q07+yqr6wCGFL0nK0E/CJJNBti59cVZ9P8g0cJ06SZmQBQ5LGx5Oq6kc99ydO2XdCkmPb/ddOOmXfg4AvJXmYG8yStOGq6vvAo6ZovwHHiZOkGXkIiSSNL0/ZJ0mSpCXDAoYkjYeJU/ad30aqh0mn7AN6T9l3Tc+8nrJPkiRJi85DSCRpPCz4KfvA0/ZJkiRpeOyBIUljYBCn7GvL87R9kiRJGgoLGJK0zHnKPkmSJC0HHkIiScufp+yTJEnSkmcBQ5KWOU/ZJ0mSpOXAQ0gkSZIkSdLIs4AhSZIkSZJGngUMSZIkSZI08ixgSJIkSZKkkWcBQ5IkSZIkjby+ChhJ9h10IJKk/piTJWk0mI8labj67YHxriTnJnlZkm0HGZAkaVbmZEkaDfPKx0k2SvLNJJ9p97dPckaSy9r1dj3THpfk8iSXJjlkAOsgSUtGXwWMqnoC8HxgV+C8JCcnefJAI5MkTcmcLEmjYQPy8R8Al/TcPxY4s6r2BM5s90myN3AEsA9wKPDOJBst4CpI0pLS9xgYVXUZ8HrgtcCvAv+Q5HtJfmNQwUmSpmZOlqTRMNd8nGQl8HTgPT3NhwEntdsnAYf3tJ9SVbdX1RXA5cD+C74SkrRE9DsGxiOTvIWuUnwQ8MyqekS7/ZYBxidJmsScLEmjYZ75+K3AnwA/72nbqaquA2jXO7b2XYBreqZb09okaSz12wPj7cAFwKOq6piqugCgqq6lqzhLkobHnCxJo2FO+TjJM4C1VXV+n8vPFG015YTJ0UnOS3LeunXr+ly8JC0tG/c53dOA26rqboAk9wM2q6qfVdUHBxadJGkq5mRJGg1zzccHAM9K8jRgM2CbJB8Crk+yc1Vdl2RnYG2bfg3d+BoTVgLXThVIVZ0InAiwevXqKYsckrTU9dsD40vA5j33t2htkqThm1dOdtR7SVpwc8rHVXVcVa2sqlV0g3N+uapeAJwOHNkmOxL4VLt9OnBEkk2T7AHsCZy7sKsgSUtHvwWMzarqlok77fYWgwlJkjSL+eZkR72XpIW1UNvIJwBPTnIZ8OR2n6q6CDgVuBj4PHDMRG8PSRpH/RYwbk2y38SdJL8I3DaYkCRJs5hzTnbUe0kaiHlvI1fVWVX1jHb7hqo6uKr2bNc/7pnu+Kp6SFXtVVWfW/A1kKQlpN8xMF4FfCzJxDF3OwO/NZCIJEmzeRVzz8lvpRv1fuuetvVGvU/SO+r92T3TOeq9JE3tVbiNLElD01cBo6q+keThwF50oyF/r6ruHGhkkqQpzTUn9456n+TAPp5iTqPeA0cD7Lbbbn0sWpKWD7eRJWm4+u2BAfBYYFWb5zFJqKoPDCQqSdJs5pKTHfVekgbHbWRJGpK+ChhJPgg8BLgQmBg4qACTsyQN2VxzclUdBxzX5j0Q+OOqekGS/0c32v0J3HfU+5OTvBl4EI56L0lTchtZkoar3x4Yq4G9q2rOe9fayPXnAT+oqmck2R74KF2l+krguVX1kzbtccBRdD8Ar6yqL8z1+SRpDMw7J09yAnBqkqOAq4HnQDfqfZKJUe/vwlHvJWk6C5WPJUl96PcsJN8FHjjP5/C0fZK0sOadkx31XpIW1IZsI0uS5qjfHhg7ABcnORe4faKxqp4100w9p+07Hvij1nwYcGC7fRJwFvBaek7bB1yRZOK0fV/vM0ZJGhfzysmSpAVnPpakIeq3gPGGeS7/rSzwafsc8V6S5p2TJUkL6w2LHYAkjZO+DiGpqn+nG69ik3b7G8AFM83Te9q+PmPp67R9VXViVa2uqtUrVqzoc9GStHzMJydLkhae+ViShquvAkaSlwCnAf/cmnYBPjnLbBOn7bsSOAU4qPe0fW258zptnySNs3nmZEnSAjMfS9Jw9TuI5zF0BYmbAKrqMmDHmWaoquOqamVVraIbnPPLVfUCutPzHdkmm3zaviOSbJpkDzxtnyRNZ845WZI0EOZjSRqifsfAuL2q7ki6ozySbMwUh3f0ydP2SdKGWcicLEmaP/OxJA1RvwWMf0/yOmDzJE8GXgZ8ut8nqaqz6M42QlXdABw8zXTH052xRJI0vQ3KyZKkBWM+lqQh6vcQkmOBdcB3gP8DfBZ4/aCCkiTNyJwsSaPBfCxJQ9RXD4yq+jnw7naRJC0ic7IkjYb55OMkmwFfBTal2xY/rar+Isn2wEeBVXRnNnluVf2kzXMccBRwN/DKqvrCAq6GJC0ZfRUwklzB1Kc0ffCCRyRJmpE5WZJGwzzz8e3AQVV1S5JNgK8l+RzwG8CZVXVCkmPpene8NsnedAPi7wM8CPhSkoc5VpykcdTvGBire25vRjfw5vYLH44kqQ/mZEkaDXPOx1VVwC3t7ibtUsBhwIGt/SS68eNe29pPqarbgSuSXA7sD3x9QdZAkpaQvsbAqKobei4/qKq3AgcNNjRJ0lTMyZI0Guabj5NslORCYC1wRlWdA+xUVde15V7Hvadj3QW4pmf2Na1NksZOv4eQ7Ndz93501eatBxKRJGlGc83JHm8tSYMx323kdvjHo5NsC3wiyb4zPc1Ui5gilqOBowF222232UKQpCWp30NI/r7n9l20Dd0Fj0aS1I+55mSPt5akwdigbeSqujHJWcChwPVJdq6q65LsTNc7A7oeF7v2zLYSuHaKZZ0InAiwevXq+xQ4JGk56PcsJE8adCCSpP7MNSd7vLUkDcZ8tpGTrADubMWLzYFfA/4WOB04EjihXX+qzXI6cHKSN9MVlfcEzl2A8CVpyen3EJI/munxqnrzwoQjSZrNfHJyko2A84GHAu+oqnOSrHe8dZLe463P7pnd460laQrz3EbeGTip5eX7AadW1WeSfB04NclRwNV0A4JSVRclORW4mK6XxzH2iJM0ruZyFpLH0lWAAZ5Jdzz1NdPOIUkalDnn5EEcbw0ecy1p7M0nH38beMwU7TcAB08zz/HA8RsarCQtdf0WMHYA9quqmwGSvAH4WFX93qACkyRNa945eSGPt27L85hrSePMbWRJGqK+TqMK7Abc0XP/DrpR6yVJwzennJxkRet5Qc/x1t/j3uOt4b7HWx+RZNMke+Dx1pI0HbeRJWmI+u2B8UHg3CSfoOtG/OvABwYWlSRpJnPNyR5vLUmD4TayJA1Rv2chOb6dcu9XWtOLq+qbgwtLkjSdueZkj7eWpMFwG1mShqvfQ0gAtgBuqqq3AWtat2JJ0uIwJ0vSaDAfS9KQ9FXASPIXwGuB41rTJsCHBhWUJGl65mRJGg3mY0karn57YPw68CzgVoCquhbYelBBSZJmZE6WpNFgPpakIeq3gHFHVRXd4EQk2XJwIUmSZmFOlqTRYD6WpCHqt4BxapJ/BrZN8hLgS8C7BxeWJGkG5mRJGg3mY0kaolnPQpIkwEeBhwM3AXsBf15VZww4NknSJOZkSRoN5mNJGr5ZCxhVVUk+WVW/CJiQJWkRmZMlaTSYjyVp+Po9hOTsJI8daCSSpH6ZkyVpNJiPJWmIZu2B0TwJeGmSK+lGWQ5d4fmRgwpMkjQtc7IkjQbzsSQN0YwFjCS7VdXVwFOHFI8kaRrmZEkaDRuSj5PsCnwAeCDwc+DEqnpbku3pxtRYBVwJPLeqftLmOQ44CrgbeGVVfWEh1kOSlprZDiH5JEBVXQW8uaqu6r0MPDpJUq9PgjlZkkbAJ2He+fgu4NVV9QjgccAxSfYGjgXOrKo9gTPbfdpjRwD7AIcC70yy0SBWSpJG3WwFjPTcfvAgA5EkzcqcLEmjYd75uKquq6oL2u2bgUuAXYDDgJPaZCcBh7fbhwGnVNXtVXUFcDmw//xDl6Sla7YCRk1zW5I0fPPKyUl2TfKVJJckuSjJH7T27ZOckeSydr1dzzzHJbk8yaVJDlnAdZCk5WBBtpGTrAIeA5wD7FRV10FX5AB2bJPtAlzTM9ua1iZJY2e2QTwfleQmuirz5u023DtA0TYDjU6S1Gu+OXmiu/IFSbYGzk9yBvA7dN2VT0hyLF135ddO6q78IOBLSR5WVXcPbtUkaUnZ4G3kJFsBHwdeVVU3JZl20ina7lM0SXI0cDTAbrvtNvsaSNISNGMBo6o8vk6SRsR8c3LbkzexV+/mJL3dlQ9sk50EnAW8lp7uysAVSSa6K399Q+KXpOViQ7eRk2xCV7z4cFX9a2u+PsnOVXVdkp2Bta19DbBrz+wrgWuniOlE4ESA1atX23Na0rI02yEk82aXZUkaPXZXlqTFla6rxXuBS6rqzT0PnQ4c2W4fCXyqp/2IJJsm2QPYEzh3WPFK0igZWAEDR1iWpJEyubvyTJNO0Tbl3rwkRyc5L8l569atW4gwJWm5OwB4IXBQkgvb5WnACcCTk1wGPLndp6ouAk4FLgY+DxzjIX2SxtVsY2DMm12WJWl0DKK7MthlWZLmqqq+xtSFYoCDp5nneOD4gQUlSUvEIHtg3MMuy5K0eOyuLEmSpOVgYD0wJjjCsiQtuonuyt9JcmFrex1d9+RTkxwFXA08B7ruykkmuivfhd2VJUmSNAIGWsBwhGVJWnx2V5YkSdJyMMizkNhlWZIkSZIkLYhB9sCwy7IkSZIkSVoQgzwLiV2WJUmSJEnSghjKWUgkSZIkSZI2hAUMSZIkSZI08ixgSJIkSZKkkWcBQ5IkSZIkjTwLGJIkSZIkaeRZwJAkSZIkSSPPAoYkSZIkSRp5FjAkSZIkSdLIs4AhSZIkDUmS9yVZm+S7PW3bJzkjyWXteruex45LcnmSS5McsjhRS9JosIAhSWPADWZJGhnvBw6d1HYscGZV7Qmc2e6TZG/gCGCfNs87k2w0vFAlabRYwJCk8fB+3GCWpEVXVV8Ffjyp+TDgpHb7JODwnvZTqur2qroCuBzYfxhxStIosoAhSWPADWZJGmk7VdV1AO16x9a+C3BNz3RrWpskjSULGJI0vtxglqTRlinaasoJk6OTnJfkvHXr1g04LElaHBYwJEmTucEsScN1fZKdAdr12ta+Bti1Z7qVwLVTLaCqTqyq1VW1esWKFQMNVpIWiwUMSRpfbjBL0mg4HTiy3T4S+FRP+xFJNk2yB7AncO4ixCdJI8EChiSNLzeYJWnIknwE+DqwV5I1SY4CTgCenOQy4MntPlV1EXAqcDHweeCYqrp7cSKXpMW38WIHIEkavLbBfCCwQ5I1wF/QbSCf2jaerwaeA90Gc5KJDea7cINZkhZMVT1vmocOnmb644HjBxeRJC0dFjAkaQy4wSxJkqSlzkNIJEmSJEnSyLOAIUmSJEmSRp4FDEmSJEmSNPIsYEiSJEmSpJFnAUOSJEmSJI08CxiSJEmS+rLx/TclyayXlbuvWuxQJS1DnkZVkiRJUl/uuuN23nTBulmnO26/FUOIRtK4sQeGJEmSJEkaeRYwpmH3OEkaHf3kZPOxJEnS8uYhJNOwe5wkjY5+crL5WJIkaXmzB4YkSZKkBWXPOUmDYA8MSZIkSQvKnnOSBmHkemAkOTTJpUkuT3LsYsczG6vLkpar5ZiPN91iS8c3krTkLLV8LEmDMlI9MJJsBLwDeDKwBvhGktOr6uLFjWx6/VSX/+xxK0ky4zS77LY7a666cgEjk6T5W675+Lj9VvQ1vpF5W9KoWIr5uF8TheeZ3H/zLbjjtp/NOI35WBofI1XAAPYHLq+q7wMkOQU4DFjSCdoudJKWoGWZj/u1UHl75e6r+MHVV804Tb8b3gu5LElLyrLNxwtVeO6n6Az9FUMWahrzsTQYo1bA2AW4puf+GuCXFimWoVqoCnS/05l4Jc1ibPNxv/rJ28CCbXgv1LIW6jei3+mW6m+JBSONEPPxLOZy9sCFKJgs1aLKsP9LjOJvxLBzu78lCy9Vtdgx3CPJc4BDqur32v0XAvtX1St6pjkaOLrd3Qu4dB5PtQPwow0Md6lwXZcn13X52L2qRq4LVj/5uLWbkzec6+/6u/6jwXw8Wu/HQnK9lo7luE7ges3HlDl51HpgrAF27bm/Eri2d4KqOhE4cUOeJMl5VbV6Q5axVLiuy5PrqiGYNR+DOXkhuP6uv+s/vuvfJ/PxBnK9lo7luE7gei2kUTsLyTeAPZPskeT+wBHA6YsckySNI/OxJI0G87EkNSPVA6Oq7krycuALwEbA+6rqokUOS5LGjvlYkkaD+ViS7jVSBQyAqvos8NkBP80Gda9bYlzX5cl11cANKR+D77HrP95cf83KfLzBXK+lYzmuE7heC2akBvGUJEmSJEmayqiNgSFJkiRJknQfy7qAkeTQJJcmuTzJsVM8niT/0B7/dpL9FiPOhdDHuh6Y5KdJLmyXP1+MODdUkvclWZvku9M8vpze09nWdbm8p7sm+UqSS5JclOQPpphm2byvutdseWs56+dzPw6SbJTkm0k+s9ixDFuSbZOcluR77XPw+MWOaZiS/GH77H83yUeSbLbYMY2z5ZqPZ9uWWoqW6+9Hks2SnJvkW229/nKxY1ooy/G3LsmVSb7T/oOcN8znXrYFjCQbAe8AngrsDTwvyd6TJnsqsGe7HA3801CDXCB9rivAf1TVo9vljUMNcuG8Hzh0hseXxXvavJ+Z1xWWx3t6F/DqqnoE8DjgmOX6XdW95pC3lqt+Pvfj4A+ASxY7iEXyNuDzVfVw4FGM0euQZBfglcDqqtqXbmDKIxY3qvG1zPPx+5l9W2qpWa6/H7cDB1XVo4BHA4cmedzihrRglutv3ZPaf5CxPo3qQtofuLyqvl9VdwCnAIdNmuYw4APVORvYNsnOww50AfSzrstCVX0V+PEMkyyX97SfdV0Wquq6qrqg3b6ZLsHvMmmyZfO+6h5jk7em0ufnfllLshJ4OvCexY5l2JJsAzwReC9AVd1RVTcualDDtzGweZKNgS2Aaxc5nnG2bPPxctyWWq6/H20b75Z2d5N2WfKDNY7zb92gLOcCxi7ANT3313DfL3c/0ywF/a7H41u3rM8l2Wc4oQ3dcnlP+7Ws3tMkq4DHAOdMemjc3tdx4HvazPC5X+7eCvwJ8PNFjmMxPBhYB/xL61b8niRbLnZQw1JVPwD+DrgauA74aVV9cXGjGmvm4yVquf1+tEMtLgTWAmdU1XJYr7eyPH/rCvhikvOTHD3MJ17OBYxM0Ta5itfPNEtBP+txAbB765b1j8AnBx3UIlku72k/ltV7mmQr4OPAq6rqpskPTzHLcn1fx4XvKbN+7petJM8A1lbV+YsdyyLZGNgP+KeqegxwK7Bsxh2YTZLt6Pbw7wE8CNgyyQsWN6qxZj5egpbj70dV3V1VjwZWAvsn2XeRQ9ogy/y37oCq2o/u0LNjkjxxWE+8nAsYa4Bde+6v5L7dE/uZZimYdT2q6qaJblntXOKbJNlheCEOzXJ5T2e1nN7TJJvQ/Qh/uKr+dYpJxuZ9HSNj/5728blfzg4AnpXkSrru6gcl+dDihjRUa4A1PXsXT6MraIyLXwOuqKp1VXUn8K/ALy9yTONs7PPxUrPcfz/aIXVnsfTHL1m2v3VVdW27Xgt8gu5QtKFYzgWMbwB7Jtkjyf3pBoc6fdI0pwMvamc4eBxdF8brhh3oAph1XZM8MEna7f3p3vsbhh7p4C2X93RWy+U9bevwXuCSqnrzNJONzfs6RvrJ0ctWn5/7ZauqjquqlVW1iu69/3JVjc0e+Kr6IXBNkr1a08HAxYsY0rBdDTwuyRbtu3Awy3OAu6VirPPxUrNcfz+SrEiybbu9OV2h83uLGtQGWq6/dUm2TLL1xG3gKcDQzvSz8bCeaNiq6q4kLwe+QDe69fuq6qIkL22Pvwv4LPA04HLgZ8CLFyveDdHnuv4m8PtJ7gJuA46oqiXXPTDJR4ADgR2SrAH+gm6Qn2X1nkJf67os3lO66vQLge+04x4BXgfsBsvvfVVnury1yGEN05Sf+9abSuPhFcCH2x/G7zNGea2qzklyGt2hkHcB3wROXNyoxtdyzsdTbUtV1XsXN6oNtlx/P3YGTmpnxbkfcGpVLZvTji4zOwGfaPtRNwZOrqrPD+vJszT/70iSJEmSpHGynA8hkSRJkiRJy4QFDEmSJEmSNPIsYEiSJEmSpJFnAUOSJEmSJI08CxiSNA9J3pdkbZJZTxuV5C1JLmyX/05y4xBClKSxMJd83KZ/bpKLk1yU5ORBxydJ42TQOdkChpa9JNsmedkQnufwJHsP+nk0Mt4PHNrPhFX1h1X16Kp6NPCPwL8OMC5pZJmPNSDvp898nGRP4DjggKraB3jV4MKSRps5WQPyfgaYky1gaBxsC/SdnNOZz3fjcMDkPCaq6qvAj3vbkjwkyeeTnJ/kP5I8fIpZnwd8ZChBSqNnW8zHWmBzzMcvAd5RVT9p864dcrjSKNkWc7IW2KBzsgUMjYMTgIe07vtvSXJmkguSfCfJYQBJViW5JMk7gQuAXZP8WZLvJTkjyUeS/HGb9j5fwCS/DDwL+H/teR6yaGurxXQi8Iqq+kXgj4F39j6YZHdgD+DLixCbNArMxxqW6fLxw4CHJfnPJGcn6WsvobRMmZM1LAuWkzceYJDSqDgW2LeqHp1kY2CLqropyQ7A2UlOb9PtBby4ql6WZDXwbOAxdN+TC4Dz23QnAi+tqsuS/BLwzqo6qC3nM1V12jBXTqMhyVbALwMfSzLRvOmkyY4ATququ4cZmzRCzMcauFny8cbAnsCBwErgP5LsW1U3DjlMaRSYkzVwC52TLWBo3AT4myRPBH4O7ALs1B67qqrObrefAHyqqm4DSPLpdt3Pn1SNp/sBN7ZxLqZzBHDMcMKRRp75WIMyUz5eA5xdVXcCVyS5lG7j+RtDjE8aReZkDcqC5mQPIdG4eT6wAvjF9iW6HtisPXZrz3Rhavd8AXsujxhYtFoyquomusT7HLjnONFHTTyeZC9gO+DrixSiNGrMxxqIWfLxJ4EntfYd6Lovf38x4pRGjDlZA7HQOdkChsbBzcDW7fYDgLVVdWeSJwG7TzPP14BnJtmsVZSfDrN+AXufR8tcko/QFSP2SrImyVF0P/5HJfkWcBFwWM8szwNOqaoafrTSyDAfa8HNMR9/AbghycXAV4DXVNUNixG3NALMyVpwg87JcVta4yDdOYUfSdcd6eHAJsCFwAHAU9tkn6mqfXvmeQPdn86rgHXAWVX17iR7AP8E7NyWc0pVvTHJAcC7gduB36yq/xnCqknSkmI+lqTRYU7WUmMBQ5pGkq2q6pYkWwBfBY6uqgsWOy5JGjfmY0kaHeZkLSYH8ZSmd2KSvemO/zvJxCxJi8Z8LEmjw5ysRWMPDEmSJEmSNPIcxFOSJEmSJI08CxiSJEmSJGnkWcCQJEmSJEkjzwKGJEmSJEkaeRYwJEmSJEnSyLOAIUmSJEmSRp4FDEmSJEmSNPIsYEiSJEmSpJFnAUOSJEmSJI08CxiSJEmSJGnkWcBYgpK8K8mfLdCydktyS5KN2v2zkvzeQiy7Le9zSY5cqOVNWvZTknxyEMtWf5K8P8lft9u/kuTSATzHTkkuSbLpQi9bmivz7z3LNv+OuCSV5KHt9oJ9bic9xyuTnLDQy5UkaToWMEZMkiuT3Jbk5iQ3JvmvJC9Ncs97VVUvraq/6nNZvzbTNFV1dVVtVVV3L0Dsb0jyoUnLf2pVnbShy57G3wD3bDi1jbVb2x+CHyR588Qfg6WobXDe0nO5PcnNPY+fleR/ex6fsXiQZGWSDye5ob1O5yZ5xhzi+Z0kX5vu8ar6j6raq9/l9auqrge+Ahy90MuWepl/52S55999k3whyY+S1AzT7dny8IcmtW+R5J1t/p8m+eosz/eMlpNvbTn6w0lWziHeGYtf/X5u5+FE4AVJdhzAsiVJug8LGKPpmVW1NbA73Qbia4H3LvSTJNl4oZc5LEkeCzygqs6e9NCjqmor4FeB3wJ+d+jBLZC2wbnVxAX4CPCxSZO9vGeaaYsHSbYHvgbcAewD7AC8BTg5yW8OaBX61sdn8cPA/xlGLBp75t9ZjEP+Be4ETgWOmmW6dwDfmKL9RGB74BHt+g+nW0DLwScDb6PLzfsAtwNfS7LdnCNfQLN9Tqvqf4HPAS8aTkSSpHFnAWOEVdVPq+p0ug3BI5PsC/fptr9Dks+0vYU/TvIfSe6X5IPAbsCn2x6xP0myqu0lOyrJ1cCXe9p6N1Ie0vYE/TTJp9qfX5IcmGRNb4wTexmTHAq8Dvit9nzfao/fs1eoxfX6JFclWZvkA0ke0B6biOPIJFe3vVZ/OsPL81Tg32d47S4H/hN4dE+sz0hyYc+e1UdOWo/XJPl22wP23nSHLnyu7Y39Uu+GZJJnJbmoLeusJI9o7ccmOW3Sa/S2JP/Qbj+gLfu6tpfyr/vZS5lkS+DZwHz3pv4hcAtwVFX9sKpuq6qPAMcDf5/OfT4LE+9fW793AY9v7++NU8S43ucjyYOSfDzJuiRXJHllz2NvSHJakg8luQn4nST7JzkvyU1Jrk/y5p7FnwM8OMnu81x/aU7Mv+Odf6vq0qp6L3DRdOuZ5AjgRuDMSe17Ac8Cjq6qdVV1d1WdP80yAvw98NdV9eGWm38I/B5dzv7DNt16PWx6PztJjgd+BXh7e//fPsXz3PO5bfdnez9em+TbwK3tOV7bXrObk1ya5OCexZ8FPH2610mSpIVkAWMJqKpzgTV0GyiTvbo9tgLYiW4jtqrqhcDVdHsTt6qq/9szz6/S7RU6ZJqnfBHdnrMHAXcB/9BHjJ+n61L80fZ8j5pist9plycBDwa2AiZvaD0B2As4GPjziQ3TKfx/wLSHTCR5ON3rdXm7vx/wPrq9+L8A/DNwetYfV+HZwJOBhwHPpNur9Dq6PWL3A17ZlvUwut4Qr6J73T9L90fl/q39aUm2adNuBDyXbu8adAWIu4CHAo8BnkK3oTqbZwPrgMndkN/U/mz8Z5IDZ5j/ycDHq+rnk9pPpfuj9bCZnryqLgFeCny9vb/bzjR9ui73nwa+BexC936+KknvZ+4w4DRgW7oeFm8D3lZV2wAPabFNPP9ddO/lVJ8raWDMv1Mat/w71TpuA7yR7jMw2S8BVwF/2fLzd5I8e5pF7UWXg9frXddy9cfpXpMZVdWfAv/BvT3yXj5L7P28H8+jK0psS5ePXw48tvVOOgS4smfaSzA3S5KGxALG0nEtXTfUye4EdgZ2r6o72zgE0x6v27yhqm6tqtumefyDVfXdqroV+DPgudPtpZqj5wNvrqrvV9UtwHHAEZP2Pv5l2wP1Lbo/v9NtFG0L3DxF+wVJbqXboDoLeGdrfwnwz1V1TtsbdhJdF93H9cz7j1V1fVX9gG5j8Jyq+mZV3Q58gm6DF7o9sv9WVWdU1Z3A3wGbA79cVVcBFwCHt2kPAn5WVWcn2Yluz+Wr2uu/lu4wjiNmfNU6RwIfmPTevpbuj8gudN2VP53kIdPMvwNw3RTt1/U8vpAeC6yoqjdW1R1V9X3g3ay/rl+vqk9W1c/bZ/FO4KFJdqiqW6bonn4z3fsuDZv5d33bMl75dyp/Bby3qq6Z4rGVwL7AT+kKUS8HTpqmIDSRe6fLzwudm6G/9+Mfquqa9jm9G9gU2DvJJlV1ZVX9T8+0NwMPGECckiTdhwWMpWMX4MdTtP8/ur1cX0zy/STH9rGsqTa4pnv8KmATFmYj6kFteb3L3phuz+WEH/bc/hndXsKp/ATYeor2/do8v0W3F2zL1r478OrWXfbGdIdA7NpimnB9z+3bprg/Ect669H2lF1D9x5Bt7fvee32b3Pv3r/d6V7L63pi+GdgxsHPkuxKt9f2A73tbePz5qq6vW2A/ifwtGkW8yO6P1qT7dzz+ELaHXjQpNf7daz/Xk/+HB5Ft/f1e0m+kfsOMLo1XXdtadjMv+sbm/w7lSSPBn6NrgAylYmC7F+3Au6/0w1E/JQppp3IvdPl54XOzdDf+3HP57AdEvQq4A3A2iSnJOmddmu6Yo0kSQNnAWMJSDdg2i50gzCup/2BfXVVPZiu2+0f9RybOt2ewNn2EO7ac3s3ug2xHwG3Alv0xLURXRfefpd7Ld2GU++y72L9DdV+fZtpDnuozqnA14E/b83XAMdX1bY9ly2qGwdirtZbj3YM867AD1rTx4AD040g/+vcuwF9Dd1erh16YtimqvaZ5fleBPxX68UwkwIyzWNfAp6dnrMpNM9tcf033fsLPe8x8MBJy+/XNcAVk17vrauqt8Cy3vKq6rKqeh7dH4q/BU5LN/bHxEByD6XbKywNjfl3SuOUf6dyILAKuDrJD4E/psuvF7THvz2HZV1KdxjSc3obW65+NveOr7He+8/6uRnmnp9nez8m5+eTq+oJdK990eXoCY/A3CxJGhILGCMsyTZtL/QpwIeq6jtTTPOMJA9tG3E30XX1nDgl3/V0hxjM1QuS7J1kC7pjfE+r7jR//w1sluTpSTYBXk/XrXTC9cCqKf4kT/gI8IdJ9kiyFfces33XPGL8LF2vhJmcAByd5IF0hy+8NMkvpbNlW4+p9iLO5lTg6UkObq/Dq+k2jP8LoKrW0XWf/he6P/GXtPbrgC/SDZq5TbpB9R6SZLb1eBHw/t6GJNsmOSTJZm2AtecDTwS+MM0y3gJsA7w3yQPbfM8D/hR4TfvTsY7uT8ALkmyU5Hfpjn2ecD2wsh1rPptzgZvSDfy2eVvevu3P4JSSvCDJirZH9cbWPPFZ3h+4snURlwbO/DujZZ9/W5ybAfdv9zfLvWNEnEiXGx/dLu8C/o17xzX5Kt0YKMe1/HwAXdHjPvm5HXL0x8Drk/x2y5cPBN5Dl7MnenlcCDwxyW7pBl89btKi5vJ5m9P7kWSvJAe19f9fuh4mvaf+/VW6MUskSRo4Cxij6dNJbqbbS/KnwJuBF08z7Z50e9dvodvj9c6qOqs99ia6jaIbk/zxHJ7/g3R/mH8IbEYbPK2qfgq8jG7D6gd0e4R6R8WfGITshp49Ub3e15b9VeAKug2hV8whrntU1QXAT5P80gzTfIdupPzXVNV5dMf9vp2u+/PldAPazee5LwVeAPwj3Z7RZ9IN1ndHz2Qn03UxPnnS7C+i2yC+uMVxGlN3HQYgyePpjqeefPrUTYC/phvY80d0r+PhLbapYr6BboC+zdpz3wD8EfDCqvpoz6QvAV7THt+H9qeg+TLdiPw/TDJjt+b2h+uZdBv3V7QY38PMx0kfClyU5Ba6AT2PqO4UfdAdv/+umZ5TWiDm31mMSf7dne6P+sRZSG6jDVxaVT+r7mxOP6zujCG3AP/biie0sTkOozuk76d0BYMXVdX3plmnjwIvpDvjyI9afJsDB7TcTVWdAXyUrnfH+cBnJi3mbcBvJvlJ2llXpjOP92NTuoLUj+g+lzvSHRJIK/I8jfmfIUuSpDlJzTremDSakjwFeFlVHb7YsWhwkuxI90foMT0FDUmLyPwrgCSvAHatqj9Z7FgkSePBAoYkSZIkSRp5HkIiSZIkSZJGngUMSZIkSZI08ixgSJIkSZKkkWcBQ5IkSZIkjbyNFzuADbHDDjvUqlWrFjsMSZq3888//0dVtWKx41gI5mRJS9lyyseStFwt6QLGqlWrOO+88xY7DEmatyRXLXYMC8WcLGkpW075WJKWKw8hkSRJkiRJI88ChiRJkiRJGnkDLWAkuTLJd5JcmOS81rZ9kjOSXNaut+uZ/rgklye5NMkhg4xNkiRJkiQtHcPogfGkqnp0Va1u948FzqyqPYEz232S7A0cAewDHAq8M8lGQ4hPkiRJkiSNuMU4hOQw4KR2+yTg8J72U6rq9qq6Argc2H/44UmSJEmSpFEz6AJGAV9Mcn6So1vbTlV1HUC73rG17wJc0zPvmta24FbuvookM15W7r5qEE8tSZrEnCxJkqR+DPo0qgdU1bVJdgTOSPK9GabNFG11n4m6QsjRALvtttu8gvrB1VfxpgvWzTjNcft5GnBJGgZzsiRJkvox0B4YVXVtu14LfILukJDrk+wM0K7XtsnXALv2zL4SuHaKZZ5YVauravWKFW7QSpIkSZI0DgZWwEiyZZKtJ24DTwG+C5wOHNkmOxL4VLt9OnBEkk2T7AHsCZw7qPgkSZIkSdLSMchDSHYCPpFk4nlOrqrPJ/kGcGqSo4CrgecAVNVFSU4FLgbuAo6pqrsHGJ8kSZIkSVoiBlbAqKrvA4+aov0G4OBp5jkeOH5QMUmSJEmSpKVpMU6jKkmSJEmSNCcWMCRJkiRJ0sizgCFJkiRJkkaeBQxJkiRJkjTyLGBIkiRJkqSRZwFDkiRJkiSNPAsYkiRJkiRp5FnAkCRJkiRJI88ChiRJkiRJGnkWMCRJkiRJ0sizgCFJkiRJkkaeBQxJkiRJkjTyLGBIkiRJkqSRZwFDkpa5JJslOTfJt5JclOQvW/v2Sc5Iclm73q5nnuOSXJ7k0iSHLF70kiRJUscChiQtf7cDB1XVo4BHA4cmeRxwLHBmVe0JnNnuk2Rv4AhgH+BQ4J1JNlqMwCVJkqQJFjAkaZmrzi3t7ibtUsBhwEmt/STg8Hb7MOCUqrq9qq4ALgf2H17EkiRJ0n1ZwJCkMZBkoyQXAmuBM6rqHGCnqroOoF3v2CbfBbimZ/Y1rU2SJElaNBYwJGkMVNXdVfVoYCWwf5J9Z5g8Uy1iygmTo5Ocl+S8devWLUCkkiRJ0tQGXsBoe/2+meQz7b6DxknSIqmqG4Gz6Ma2uD7JzgDtem2bbA2wa89sK4Frp1neiVW1uqpWr1ixYlBhS5IkSUPpgfEHwCU99x00TpKGKMmKJNu225sDvwZ8DzgdOLJNdiTwqXb7dOCIJJsm2QPYEzh3qEFLkiRJkwy0gJFkJfB04D09zQ4aJ0nDtTPwlSTfBr5BNwbGZ4ATgCcnuQx4crtPVV0EnApcDHweOKaq7l6UyCVJkqRm4wEv/63AnwBb97StN2hckt5B487umc5B4yRpAVTVt4HHTNF+A3DwNPMcDxw/4NAkSZKkvg2sB0aSZwBrq+r8fmeZou0+g8Y5YJwkSZIkSeNnkIeQHAA8K8mVwCnAQUk+xAYOGueAcZIkSZIkjZ+BFTCq6riqWllVq+gG5/xyVb0AB42TJEmSJElzNOgxMKZyAnBqkqOAq4HnQDdoXJKJQePuwkHjJEmSJElSM5QCRlWdBZzVbjtonCRJkiRJmpOBnkZVkiRJkiRpIVjAkCRJkiRJI88ChiRJkiRJGnkWMCRJkiRJ0sizgCFJkiRJkkaeBQxJkiRJkjTy+ipgJNl30IFIkvpjTpYkSdI46rcHxruSnJvkZUm2HWRAkqRZmZMlSZI0dvoqYFTVE4DnA7sC5yU5OcmTBxqZJGlK5mRJkiSNo77HwKiqy4DXA68FfhX4hyTfS/IbgwpOkjQ1c7IkSZLGTb9jYDwyyVuAS4CDgGdW1SPa7bcMMD5J0iTmZEmSJI2jjfuc7u3Au4HXVdVtE41VdW2S1w8kMknSdMzJkiRJGjv9FjCeBtxWVXcDJLkfsFlV/ayqPjiw6CRJUzEnS5Ikaez0OwbGl4DNe+5v0dokScNnTpYkSdLY6beAsVlV3TJxp93eYjAhSZJmYU6WJEnS2Om3gHFrkv0m7iT5ReC2GaaXJA2OOVmSJEljp98xMF4FfCzJte3+zsBvDSQiSdJsXoU5WZIkSWOmrwJGVX0jycOBvYAA36uqO2eaJ8lmwFeBTdvznFZVf5Fke+CjwCrgSuC5VfWTNs9xwFHA3cArq+oL81kpSVrO5pOTJUmSpKWu3x4YAI+lKzpsDDwmCVX1gRmmvx04qKpuSbIJ8LUknwN+Azizqk5IcixwLPDaJHsDRwD7AA8CvpTkYROj7EuS1jPXnCxJkiQtaX0VMJJ8EHgIcCFd7wiAAqbdWK6qAiYGmdukXQo4DDiwtZ8EnAW8trWfUlW3A1ckuRzYH/h6vysjSeNgPjlZkiRJWur67YGxGti7FSX6lmQj4HzgocA7quqcJDtV1XUAVXVdkh3b5LsAZ/fMvqa1SZLWN6+cLEmSJC1l/Z6F5LvAA+e68Kq6u6oeDawE9k+y7wyTZ6pF3Gei5Ogk5yU5b926dXMNSZKWg3nlZEmSJGkp67cHxg7AxUnOpRvbAoCqelY/M1fVjUnOAg4Frk+yc+t9sTOwtk22Bti1Z7aVwLVMUlUnAicCrF692r2PksbRBuVkSZIkaSnqt4DxhrkuOMkK4M5WvNgc+DXgb4HTgSOBE9r1p9ospwMnJ3kz3SCeewLnzvV5JWkMvGEuEyfZlW58jAcCPwdOrKq3eVYoSZIkLSX9nkb135PsDuxZVV9KsgWw0Syz7Qyc1MbBuB9walV9JsnXgVOTHAVcDTynPcdFSU4FLgbuAo7xDCSSdF/zyMl3Aa+uqguSbA2cn+QM4HfwrFCSJElaIvo9C8lLgKOB7elGvt8FeBdw8HTzVNW3gcdM0X7DdPNV1fHA8f3EJEnjaq45uQ2cPDF48s1JLmnzeFYoSZIkLRn9DuJ5DHAAcBNAVV0G7DjjHJKkQZl3Tk6yiq64fA6w3lmhepaxC3BNz2yeFUqSJEmLrt8Cxu1VdcfEnSQbM8UZQiRJQzGvnJxkK+DjwKuq6qaZJp2ibcrle2YoSZIkDUu/BYx/T/I6YPMkTwY+Bnx6cGFJkmYw55ycZBO64sWHq+pfW/P17WxQzOesUNCdGaqqVlfV6hUrVsx7hSRJkqTZ9FvAOBZYB3wH+D/AZ4HXDyooSdKM5pSTkwR4L3BJVb2556GJs0LBfc8KdUSSTZPsgWeFkiRJ0gjo9ywkPwfe3S6SpEU0j5x8APBC4DtJLmxtr6M7nbVnhZIkSdKS0O9ZSK5giuOfq+rBCx6RJGlGc83JVfU1ph7XAjwrlCRJkpaIvgoYwOqe25vR7aXbfuHDkST1wZwsSZKksdPXGBhVdUPP5QdV9VbgoMGGJkmaijlZkiRJ46jfQ0j267l7P7q9f1sPJCJJ0ozMyZIkSRpH/R5C8vc9t+8CrgSeu+DRSJL6YU6WJEnS2On3LCRPGnQgkqT+mJMlSZI0jvo9hOSPZnq8qt68MOFIkmZjTpYkSdI4mstZSB4LnN7uPxP4KnDNIIKSJM3InCxJkqSx028BYwdgv6q6GSDJG4CPVdXvDSowSdK0zMmSJEkaO32dRhXYDbij5/4dwKoFj0aS1A9zsiRJksZOvz0wPgicm+QTQAG/DnxgYFFJkmZiTpYkSdLY6fcsJMcn+RzwK63pxVX1zcGFJUmajjlZkiRJ46jfQ0gAtgBuqqq3AWuS7DGgmCRJszMnS5Ikaaz0VcBI8hfAa4HjWtMmwIdmmWfXJF9JckmSi5L8QWvfPskZSS5r19v1zHNcksuTXJrkkPmtkiQtb/PJyZIkSdJS128PjF8HngXcClBV1wJbzzLPXcCrq+oRwOOAY5LsDRwLnFlVewJntvu0x44A9gEOBd6ZZKO5rY4kjYX55GRJkiRpSeu3gHFHVRXdYHEk2XK2Garquqq6oN2+GbgE2AU4DDipTXYScHi7fRhwSlXdXlVXAJcD+/cZnySNkznnZEmSJGmp67eAcWqSfwa2TfIS4EvAu/t9kiSrgMcA5wA7VdV10BU5gB3bZLsA1/TMtqa1SZLWt0E5WZIkSVqKZj0LSZIAHwUeDtwE7AX8eVWd0c8TJNkK+Djwqqq6qVvc1JNO0VZTLO9o4GiA3XbbrZ8QJGnZ2NCcLEmSJC1VsxYwqqqSfLKqfhGY0wZykk3oihcfrqp/bc3XJ9m5qq5LsjOwtrWvAXbtmX0lcO0U8ZwInAiwevXq+xQ4JGk525CcLEmSJC1l/R5CcnaSx85lwW0v4XuBS6rqzT0PnQ4c2W4fCXyqp/2IJJu20wHuCZw7l+eUpDEx55wsSZIkLXWz9sBongS8NMmVdKPeh25H4CNnmOcA4IXAd5Jc2NpeB5xAd/z2UcDVwHPoFnZRklOBi+nOYHJMVd09t9WRpLEwn5wsSZIkLWkzFjCS7FZVVwNPneuCq+prTD2uBcDB08xzPHD8XJ9LksbBhuRkSZIkaambrQfGJ4H9quqqJB+vqmcPISZJ0tQ+iTlZkiRJY2q2MTB6e1A8eJCBSJJmZU6WJEnS2JqtgFHT3JYkDZ85WZIkSWNrtkNIHpXkJrq9fpu323DvgHHbDDQ6SVIvc7IkSZLG1owFjKraaFiBSJJmZk6WJEnSOJvtEBJJkiRJkqRFZwFDkiRJkiSNPAsYkjQGkrwvydok3+1p2z7JGUkua9fb9Tx2XJLLk1ya5JDFiVqSJEm6lwUMSRoP7wcOndR2LHBmVe0JnNnuk2Rv4AhgnzbPO5M4/oYkSZIWlQUMSRoDVfVV4MeTmg8DTmq3TwIO72k/papur6orgMuB/YcRpyRJkjQdCxiSNL52qqrrANr1jq19F+CanunWtDZJkiRp0VjAkCRNlinaasoJk6OTnJfkvHXr1g04LEmSJI0zCxiSNL6uT7IzQLte29rXALv2TLcSuHaqBVTViVW1uqpWr1ixYqDBSpIkabxZwJCk8XU6cGS7fSTwqZ72I5JsmmQPYE/g3EWIT5IkSbrHxosdgCRp8JJ8BDgQ2CHJGuAvgBOAU5McBVwNPAegqi5KcipwMXAXcExV3b0ogUuSJEmNBQxJGgNV9bxpHjp4mumPB44fXESSJEnS3HgIiSRJkiRJGnkDK2AkeV+StUm+29O2fZIzklzWrrfreey4JJcnuTTJIYOKS5IkSZIkLT2D7IHxfuDQSW3HAmdW1Z7Ame0+SfYGjgD2afO8M8lGA4xNkiRJkiQtIQMrYFTVV4EfT2o+DDip3T4JOLyn/ZSqur2qrgAuB/YfVGySJEmSJGlpGfYYGDtV1XUA7XrH1r4LcE3PdGtamyRJkiRJ0sgM4pkp2mrKCZOjk5yX5Lx169YNOCxJkiRJkjQKhl3AuD7JzgDtem1rXwPs2jPdSuDaqRZQVSdW1eqqWr1ixYqBBitJkiRJkkbDsAsYpwNHtttHAp/qaT8iyaZJ9gD2BM4dcmySpBG18f03JcmMl5W7r1rsMCVJkjRAGw9qwUk+AhwI7JBkDfAXwAnAqUmOAq4GngNQVRclORW4GLgLOKaq7h5UbJKkpeWuO27nTRfMfNjgcfvZK0+SJGk5G1gBo6qeN81DB08z/fHA8YOKR5IkSZIkLV2jMoinJEmSJEnStCxgSJIkSZKkkWcBQ5K0LDjQpyRJ0vI2sDEwJEkaJgf6lCRJWt7sgSFJkiRJkkaeBQxJkiRJkjTyLGBMo59jqT2eWpIkSZKk4XAMjGn0cyw1eDy1JEmSJEnDYA8MSZIkSZI08ixgSJLGhocHSpIkLV0eQiJJGhseHihJkrR02QNDkiRJkiSNPAsYkiRJkiRp5FnAkCRpkn7GynCcDEmSpOFyDIwNNLGRO5NddtudNVddOZyAJEkbrJ+xMhwnQ5IkabgsYGwgN3IlSZIkSRo8DyEZArsiS5IkSZK0YeyBMQT20pCk5cdDCCVJkoZr5AoYSQ4F3gZsBLynqk5Y5JCGYiE3hFfuvoofXH3VgixL0vga13zcr4UqTveTs8G8LUmSNFIFjCQbAe8AngysAb6R5PSqunhxIxu8fjaE/+xxK2ctckywx4ekDTHO+XjYfnD1VbPmbOjvN6CfIsdCFrktmEuSpGEaqQIGsD9weVV9HyDJKcBhgBvM9FfkgP6KE8Pu8XH/zbfgjtt+tiDPN0xLdUN/Ke/R9Q/RyDAfL4B+cm2/FrLQPcyCeT/LWsjfiIX6TVqoaWA0c7u5VpK0FI1aAWMX4Jqe+2uAX1qkWJa1xejxMayN3H6n62fDrJ89o8Pe0F+ouGHhurcv5IY+LEwPIjfON5j5eAEMewykhXq+hSyY9xvTqP0mLdQ0sLC/bwv1fP0sa9i/yws1jbldkpavVNVix3CPJM8BDqmq32v3XwjsX1Wv6JnmaODodncv4NJ5PNUOwI82MNxhMM6FtRTiXAoxgnEupN2rauSO6eonH7f2ccrJC2kc1xlc73Gz1NZ7JPOxJOleo9YDYw2wa8/9lcC1vRNU1YnAiRvyJEnOq6rVG7KMYTDOhbUU4lwKMYJxjolZ8zGMV05eSOO4zuB6L3Ycwzau6y1JGpz7LXYAk3wD2DPJHknuDxwBnL7IMUnSODIfS5IkaaSMVA+MqrorycuBL9Cdtu99VXXRIoclSWPHfCxJkqRRM1IFDICq+izw2QE/zQZ1dx4i41xYSyHOpRAjGOdYGFI+hvF8n8ZxncH1Hjfjut6SpAEZqUE8JUmSJEmSpjJqY2BIkiRJkiTdx7IrYCQ5NMmlSS5PcuwUjyfJP7THv51kv37nHWKMz2+xfTvJfyV5VM9jVyb5TpILk5w3qBj7jPPAJD9tsVyY5M/7nXfIcb6mJ8bvJrk7yfbtsaG8nknel2Rtku9O8/iify77jHNUPpuzxTkSn03NbCm+F1N99pJsn+SMJJe16+16Hjuurd+lSQ7paf/F9n25vH3309o3TfLR1n5OklU98xzZnuOyJEcOaZUnnnvXJF9JckmSi5L8QWtf1uueZLMk5yb5VlvvvxyH9W7PvVGSbyb5TLu/7NdZkrQEVNWyudANNPc/wIOB+wPfAvaeNM3TgM8BAR4HnNPvvEOM8ZeB7drtp07E2O5fCewwIq/lgcBn5jPvMOOcNP0zgS8vwuv5RGA/4LvTPL6on8s5xLnon80+41z0z6aXWd/DJfleTPXZA/4vcGy7fSzwt+323m29NgX2aOu7UXvsXODx7Tv/OeCprf1lwLva7SOAj7bb2wPfb9fbtdvbDXG9dwb2a7e3Bv67rd+yXvcW41bt9ibAOS1HL+v1bs//R8DJtFw6DuvsxYsXL15G/7LcemDsD1xeVd+vqjuAU4DDJk1zGPCB6pwNbJtk5z7nHUqMVfVfVfWTdvdsYOUA4pjNhrwew3ot5/NczwM+MqBYplVVXwV+PMMki/257CvOEfls9vN6Tmeor6dmtCTfi2k+e4cBJ7XbJwGH97SfUlW3V9UVwOXA/u27vU1Vfb2qCvjApHkmlnUacHDba30IcEZV/bh9B88ADl3o9ZtOVV1XVRe02zcDlwC7sMzXveXkW9rdTdqlWObrnWQl8HTgPT3Ny3qdJUlLw3IrYOwCXNNzf01r62eafuYdVoy9jqLbazGhgC8mOT/J0QOIb0K/cT6+da39XJJ95jjvQuj7uZJsQbch9PGe5mG9nrNZ7M/lfCzWZ7Nfi/3Z1MyW03uxU1VdB90ffWDH1j7T93rNFO3rzVNVdwE/BX5hhmUNXevu/xi63gjLft3boRQXAmvp/lyPw3q/FfgT4Oc9bct9nSVJS8DInUZ1A2WKtsmnWZlumn7mXQh9P0+SJ9H9SXxCT/MBVXVtkh2BM5J8r+0RXIw4LwB2r6pbkjwN+CSwZ5/zLpS5PNczgf+sqt69p8N6PWez2J/LOVnkz2Y/RuGzqZmNw3sxn+/1SOeCJFvRFYFfVVU3tSENppx0irYlue5VdTfw6CTbAp9Isu8Mky/59U7yDGBtVZ2f5MB+ZpmibUmtsyRp6VhuPTDWALv23F8JXNvnNP3MO6wYSfJIuq6bh1XVDRPtVXVtu14LfIKuG/YgzBpnVd000bW2qj4LbJJkh37mHWacPY5g0uEjQ3w9Z7PYn8u+jcBnc1Yj8tnUzJbTe3F96y5Pu17b2mf6Xq+con29eZJsDDyA7pCVRX+9kmxCV7z4cFX9a2sei3UHqKobgbPoevIt5/U+AHhWkivpDu06KMmHWN7rLElaIpZbAeMbwJ5J9khyf7o/rKdPmuZ04EXpPA74aesK2c+8Q4kxyW7AvwIvrKr/7mnfMsnWE7eBpwBTnoVhSHE+sGdE8f3pPk839DPvMONs8T0A+FXgUz1tw3w9Z7PYn8u+jMhnc1Yj8tnUzJbTe3E6cGS7fST35pnTgSPSnXFhD7peQOe27/bNSR7XPqcvmjTPxLJ+k27Q4QK+ADwlyXbpzv7wlNY2FC3O9wKXVNWbex5a1uueZEXreUGSzYFfA77HMl7vqjquqlZW1Sq67+WXq+oFLON1liQtITUCI4ku5IXubA7/TTcK9p+2tpcCL223A7yjPf4dYPVM8y5SjO8BfgJc2C7ntfYH0430/S3gokHG2GecL29xfItuQMdfHvZr2U+c7f7v0A0y1jvf0F5Pup4f1wF30u1hOmrUPpd9xjkqn83Z4hyJz6aXWd/HJfdeTPPZ+wXgTOCydr19z/R/2tbvUtoZGFr7aroi3/8AbwfS2jcDPkY3EOK5wIN75vnd1n458OIhr/cT6Lryf7vn+/+05b7uwCOBb7b1/i7w5619Wa93z/MfyL1nIRmLdfbixYsXL6N9mfghkSRJkiRJGlnL7RASSZIkSZK0DFnAkCRJkiRJI88ChiRJkiRJGnkWMCRJkiRJ0sizgCFJ85DkfUnWJunrdLFJnpvk4iQXJTl50PFJkiRJy40FDC17SbZN8rIhPM/hSfYe9PNoZLwfOLSfCZPsCRwHHFBV+wCvGlxY0ugyH0uSpA1hAUPjYFug7w3mdObz3TgccIN5TFTVV4Ef97YleUiSzyc5P8l/JHl4e+glwDuq6idt3rVDDlcaFdtiPpYkSfOUqlrsGKSBSnIKcBhwKfAV4JHAdsAmwOur6lNJVgGfa48/nm7j90XA84FrgB8B51fV3yV5CPAOYAXwM7o/p9sDnwF+2i7Prqr/GdIqapG0z81nqmrfdv9M4KVVdVmSXwLeVFUHJfkk8N/AAcBGwBuq6vOLFLa0aMzHkiRpQ2y82AFIQ3AssG9VPTrJxsAWVXVTkh2As5Oc3qbbC3hxVb0syWrg2cBj6L4nFwDnt+lOZP0/qe9sf1JPp/sze9owV06jIclWwC8DH0sy0bxpu94Y2BM4EFgJ/EeSfavqxiGHKS0287EkSZo3CxgaNwH+JskTgZ8DuwA7tceuqqqz2+0nAJ+qqtsAkny6Xc/0J1Xj7X7AjVX16CkeWwOcXVV3AlckuZSuoPGNIcYnjRrzsSRJmhMLGBo3z6fravyLVXVnkiuBzdpjt/ZMl8kzNjP9SdUYa3uRr0jynKr6WLp/VI+sqm8BnwSeB7y/7Wl+GPD9RQxXGgXmY0mSNCcO4qlxcDOwdbv9AGBt21h+ErD7NPN8DXhmks3aXr6nQ/cnlW4P+nPgngHmHjXF82iZS/IR4OvAXknWJDmK7g/ZUUm+BVxEd6w/wBeAG5JcTHdc/2uq6obFiFtaZOZjSZI0bw7iqbGQ5GS6weK+ATycbsC4C+kGVXxqm+yewRjbPG+g22t+FbAOOKuq3p1kD+CfgJ3bck6pqjcmOQB4N3A78JsOGidJ92U+liRJ82UBQ5pGkq2q6pYkWwBfBY6uqgsWOy5JGjfmY0mSBI6BIc3kxCR70x2TfZIby5K0aMzHkiTJHhiSJEmSJGn0OYinJEmSJEkaeRYwJEmSJEnSyLOAIUmSJEmSRp4FDEmSJEmSNPIsYEiSJEmSpJFnAUOSJEmSJI28/x89eRPmmdgw9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x576 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the number of outliers to drop for each scenario\n",
    "outlier_counts = [10, 25, 75, 146]\n",
    "\n",
    "# Visual inspection for different outlier removal scenarios\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Before outlier removal\n",
    "plt.subplot(3, 3, 1)\n",
    "plt.hist(df['target'].dropna(), bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Original Distribution of Target Variable')\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Iterate through different outlier removal scenarios\n",
    "for i, outlier_count in enumerate(outlier_counts):\n",
    "    # Remove the top outliers based on the specified count\n",
    "    target_without_outliers = df['target'].sort_values().iloc[:-outlier_count]\n",
    "    \n",
    "    # Visualize the distribution after outlier removal\n",
    "    plt.subplot(3, 3, i + 2)\n",
    "    plt.hist(target_without_outliers, bins=30, color='skyblue', edgecolor='black')\n",
    "    plt.title(f'Distribution (Remove {outlier_count} Outliers)')\n",
    "    plt.xlabel('target')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5968d77",
   "metadata": {},
   "source": [
    "### 10 biggest outliers of set dropping out of the training only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a2405ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_values_indices = df['target'].nlargest(10).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6c2745d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>target</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>72.213</td>\n",
       "      <td>133.827</td>\n",
       "      <td>1994</td>\n",
       "      <td>London</td>\n",
       "      <td>GBP</td>\n",
       "      <td>40694.870</td>\n",
       "      <td>True</td>\n",
       "      <td>507.800</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>62.101</td>\n",
       "      <td>174.389</td>\n",
       "      <td>1995</td>\n",
       "      <td>New York</td>\n",
       "      <td>USD</td>\n",
       "      <td>9730.240</td>\n",
       "      <td>True</td>\n",
       "      <td>322.600</td>\n",
       "      <td>Watercolour Art</td>\n",
       "      <td>paper</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist  contrast  brightness  year_sold city_auction currency  \\\n",
       "0  Pierre Alechinsky    72.213     133.827       1994       London      GBP   \n",
       "1  Pierre Alechinsky    62.101     174.389       1995     New York      USD   \n",
       "\n",
       "     target signed  circumference           medium surface  year_born   dead  \\\n",
       "0 40694.870   True        507.800          missing  canvas       1927  False   \n",
       "1  9730.240   True        322.600  Watercolour Art   paper       1927  False   \n",
       "\n",
       "   return_sp  \n",
       "0      0.100  \n",
       "1      0.013  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e0cc045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitsing in 80% and then you are going to look at the indexes of the outliers --> later we are going to drop the outliers but only out of the training set\n",
    "split_percentage = 0.80\n",
    "split_point = int(len(df) * split_percentage)\n",
    "\n",
    "train_set = df[:split_point]\n",
    "test_set = df[split_point:]\n",
    "\n",
    "range_train = len(train_set)\n",
    "\n",
    "filtered_indices = [index for index in top_values_indices if index <= range_train]\n",
    "\n",
    "# splitting the training set into features X and target variable Y\n",
    "x_train = train_set.drop(columns=['target'])\n",
    "y_train = train_set['target']\n",
    "\n",
    "# dropping the rows based on the indices\n",
    "x_train = x_train.drop(index=filtered_indices)\n",
    "y_train = y_train.drop(index=filtered_indices)\n",
    "\n",
    "#splitting the test set into  features X and target variable Y\n",
    "x_test = test_set.drop(columns=['target'])\n",
    "y_test = test_set['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fe88f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the columns to encode and scale(min-max)\n",
    "one_hot_cols = ['artist', 'city_auction', 'currency', 'medium', 'surface', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
    "        ('num', continuous_transformer, continuous_cols)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "53e0d8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forst\n",
      "\n",
      "Best hyperparameters: {'estimator__max_depth': None, 'estimator__n_estimators': 100}\n",
      "Best MSE: 537643176903.85\n",
      "Cross-validation scores: [-0.34839672  0.11243334  0.52832668  0.58067014  0.36830978]\n",
      "Mean CV R-squared: 0.24826864434244852\n",
      "Train R-squared: 0.9288443066587951\n",
      "Train MSE: 59896518850.66587\n",
      "Train RMSE: 244737.65311178798\n",
      "Train MAE: 96480.97201271313\n"
     ]
    }
   ],
   "source": [
    "# define the model that we are going to use\n",
    "# we use the same random_state\n",
    "# we are going to look what the best n_estimators is\n",
    "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "print('Random Forst')\n",
    "print('')\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# define the grid of hyperparamters to look at\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
    "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
    "}\n",
    "\n",
    "# define the grid search object\n",
    "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# fit the grid search object to the training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# print the best hyperparameters and the corresponding mean squared error\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best MSE:\", -grid_search.best_score_)\n",
    "\n",
    "# calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# fit the pipeline to the train data\n",
    "grid_search.best_estimator_.fit(x_train, y_train)\n",
    "\n",
    "# make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# print the R-squared score of the model on the train data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# print the mean squared error of the model on the train data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Train MSE:\", mse_train)\n",
    "\n",
    "# print the root mean squared error of the model on the train data\n",
    "rmse_train = mse_train ** 0.5\n",
    "print(\"Train RMSE:\", rmse_train)\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "print(\"Train MAE:\", mae_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b4d915a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "\n",
      "Best Hyperparameters: {'estimator__max_depth': 20, 'estimator__max_features': 'log2', 'estimator__n_estimators': 200}\n",
      "Best MSE: 539738704162.9201\n",
      "Cross-validation scores: [0.31295054 0.13051063 0.35691415 0.63378066 0.4423248 ]\n",
      "Mean CV R-squared: 0.3752961585027528\n",
      "training MAE: 0.00032373148818633636\n",
      "Train R-squared: 1.0\n",
      "Training MSE: 4.1925530563418296e-07\n",
      "Training RMSE: 0.0006474992707595762\n"
     ]
    }
   ],
   "source": [
    "# Define the estimator for Gradient Boosting\n",
    "estimator = GradientBoostingRegressor(random_state=42)\n",
    "print('Gradient Boosting')\n",
    "print('')\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_depth': [7, 10, 20],\n",
    "    'estimator__max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "# Create a grid search object\n",
    "time_series_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the best MSE and corresponding negative value\n",
    "best_mse = -grid_search.best_score_\n",
    "print(\"Best MSE:\", best_mse)\n",
    "\n",
    "# Calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# calculate and print MAE\n",
    "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
    "print('training MAE:', mae)\n",
    "\n",
    "# Make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# Print the R-squared score of the model on the training data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# Print the mean squared error of the model on the training data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Training MSE:\", mse_train)\n",
    "\n",
    "# Print the root mean squared error of the model on the training data\n",
    "rmse_train = sqrt(mse_train)\n",
    "print(\"Training RMSE:\", rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6662708b",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d25f16b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 13251261671404.254\n",
      "Test RMSE: 3640228.244410542\n",
      "Test R-squared: 0.27645019726173625\n",
      "Adjusted R2 is 0.21289514702121315\n",
      "Test MAE: 1999268.133930006\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator with the best parameters\n",
    "gbr = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dde2629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 12965912822988.672\n",
      "Test RMSE: 3600821.131768235\n",
      "Test R-squared: 0.2920309101102515\n",
      "Adjusted R2 is 0.22984443599831406\n",
      "Test MAE: 1952348.2622706606\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator with the best parameters\n",
    "gbr = GradientBoostingRegressor(n_estimators=200, max_depth=7, max_features= 'sqrt',random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dea91c0",
   "metadata": {},
   "source": [
    "##  25 biggest outliers of set dropping out of the training only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "475c1cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_values_indices = df['target'].nlargest(25).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "022d6949",
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitsing in 80% and then you are going to look at the indexes of the outliers --> later we are going to drop the outliers but only out of the training set\n",
    "split_percentage = 0.80\n",
    "split_point = int(len(df) * split_percentage)\n",
    "\n",
    "train_set = df[:split_point]\n",
    "test_set = df[split_point:]\n",
    "\n",
    "range_train = len(train_set)\n",
    "\n",
    "filtered_indices = [index for index in top_values_indices if index <= range_train]\n",
    "\n",
    "# splitting the training set into features X and target variable Y\n",
    "x_train = train_set.drop(columns=['target'])\n",
    "y_train = train_set['target']\n",
    "\n",
    "# dropping the rows based on the indices\n",
    "x_train = x_train.drop(index=filtered_indices)\n",
    "y_train = y_train.drop(index=filtered_indices)\n",
    "\n",
    "#splitting the test set into  features X and target variable Y\n",
    "x_test = test_set.drop(columns=['target'])\n",
    "y_test = test_set['target']\n",
    "\n",
    "\n",
    "# define the columns to encode and scale(min-max)\n",
    "one_hot_cols = ['artist', 'city_auction', 'currency', 'medium', 'surface', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
    "        ('num', continuous_transformer, continuous_cols)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ec467266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "\n",
      "Best hyperparameters: {'estimator__max_depth': 30, 'estimator__n_estimators': 200}\n",
      "Best MSE: 284199234267.597\n",
      "Cross-validation scores: [-0.36273885  0.21738978  0.15806762  0.36478531  0.15380625]\n",
      "Mean CV R-squared: 0.10626202211175968\n",
      "Train R-squared: 0.9017325925708932\n",
      "Train MSE: 33030613999.634483\n",
      "Train RMSE: 181743.26397320614\n",
      "Train MAE: 76534.52766084037\n"
     ]
    }
   ],
   "source": [
    "# define the model that we are going to use\n",
    "# we use the same random_state\n",
    "# we are going to look what the best n_estimators is\n",
    "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "print('Random Forest')\n",
    "print('')\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# define the grid of hyperparamters to look at\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
    "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
    "}\n",
    "\n",
    "# define the grid search object\n",
    "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# fit the grid search object to the training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# print the best hyperparameters and the corresponding mean squared error\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best MSE:\", -grid_search.best_score_)\n",
    "\n",
    "# calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# fit the pipeline to the train data\n",
    "grid_search.best_estimator_.fit(x_train, y_train)\n",
    "\n",
    "# make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# print the R-squared score of the model on the train data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# print the mean squared error of the model on the train data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Train MSE:\", mse_train)\n",
    "\n",
    "# print the root mean squared error of the model on the train data\n",
    "rmse_train = mse_train ** 0.5\n",
    "print(\"Train RMSE:\", rmse_train)\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "print(\"Train MAE:\", mae_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2cab6173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "\n",
      "Best Hyperparameters: {'estimator__max_depth': 10, 'estimator__max_features': 'log2', 'estimator__n_estimators': 50}\n",
      "Best MSE: 250016806748.61743\n",
      "Cross-validation scores: [0.3715299  0.2854667  0.22577799 0.38637331 0.21590233]\n",
      "Mean CV R-squared: 0.2970100473074126\n",
      "training MAE: 7144.794955086738\n",
      "Train R-squared: 0.9994154965215121\n",
      "Training MSE: 196469096.7685143\n",
      "Training RMSE: 14016.743443771606\n"
     ]
    }
   ],
   "source": [
    "# Define the estimator for Gradient Boosting\n",
    "estimator = GradientBoostingRegressor(random_state=42)\n",
    "print('Gradient Boosting')\n",
    "print('')\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_depth': [7, 10, 20],\n",
    "    'estimator__max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "# Create a grid search object\n",
    "time_series_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the best MSE and corresponding negative value\n",
    "best_mse = -grid_search.best_score_\n",
    "print(\"Best MSE:\", best_mse)\n",
    "\n",
    "# Calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# calculate and print MAE\n",
    "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
    "print('training MAE:', mae)\n",
    "\n",
    "# Make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# Print the R-squared score of the model on the training data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# Print the mean squared error of the model on the training data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Training MSE:\", mse_train)\n",
    "\n",
    "# Print the root mean squared error of the model on the training data\n",
    "rmse_train = sqrt(mse_train)\n",
    "print(\"Training RMSE:\", rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07b41a3",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2c34d7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 17077662860761.107\n",
      "Test RMSE: 4132512.8990435237\n",
      "Test R-squared: 0.06751976524626035\n",
      "Adjusted R2 is -0.014387282401027601\n",
      "Test MAE: 1603773.0835302467\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator with the best parameters\n",
    "gbr = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "232d0d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 18028854404255.11\n",
      "Test RMSE: 4246039.849583976\n",
      "Test R-squared: 0.015582487821079294\n",
      "Adjusted R2 is -0.07088661797842044\n",
      "Test MAE: 1619647.7671426479\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator with the best parameters\n",
    "gbr = GradientBoostingRegressor(n_estimators=200, max_depth=20, max_features= 'log2',random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f568df03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffb1b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07291eee",
   "metadata": {},
   "source": [
    "##  75 biggest outliers of set dropping out of the training only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c805833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_values_indices = df['target'].nlargest(75).index\n",
    "## splitsing in 80% and then you are going to look at the indexes of the outliers --> later we are going to drop the outliers but only out of the training set\n",
    "split_percentage = 0.80\n",
    "split_point = int(len(df) * split_percentage)\n",
    "\n",
    "train_set = df[:split_point]\n",
    "test_set = df[split_point:]\n",
    "\n",
    "range_train = len(train_set)\n",
    "\n",
    "filtered_indices = [index for index in top_values_indices if index < range_train]\n",
    "\n",
    "# splitting the training set into features X and target variable Y\n",
    "x_train = train_set.drop(columns=['target'])\n",
    "y_train = train_set['target']\n",
    "\n",
    "# dropping the rows based on the indices\n",
    "x_train = x_train.drop(index=filtered_indices)\n",
    "y_train = y_train.drop(index=filtered_indices)\n",
    "\n",
    "#splitting the test set into  features X and target variable Y\n",
    "x_test = test_set.drop(columns=['target'])\n",
    "y_test = test_set['target']\n",
    "\n",
    "\n",
    "# define the columns to encode and scale(min-max)\n",
    "one_hot_cols = ['artist', 'city_auction', 'currency', 'medium', 'surface', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
    "        ('num', continuous_transformer, continuous_cols)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "89bd188d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "\n",
      "Best hyperparameters: {'estimator__max_depth': 15, 'estimator__n_estimators': 100}\n",
      "Best MSE: 52191698219.15645\n",
      "Cross-validation scores: [0.25589651 0.31566848 0.35166    0.48157188 0.354502  ]\n",
      "Mean CV R-squared: 0.3518597744975098\n",
      "Train R-squared: 0.9288684851246327\n",
      "Train MSE: 5990911085.615955\n",
      "Train RMSE: 77400.97599911745\n",
      "Train MAE: 38762.76887664405\n"
     ]
    }
   ],
   "source": [
    "# define the model that we are going to use\n",
    "# we use the same random_state\n",
    "# we are going to look what the best n_estimators is\n",
    "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "print('Random Forest')\n",
    "print('')\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# define the grid of hyperparamters to look at\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
    "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
    "}\n",
    "\n",
    "# define the grid search object\n",
    "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# fit the grid search object to the training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# print the best hyperparameters and the corresponding mean squared error\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best MSE:\", -grid_search.best_score_)\n",
    "\n",
    "# calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# fit the pipeline to the train data\n",
    "grid_search.best_estimator_.fit(x_train, y_train)\n",
    "\n",
    "# make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# print the R-squared score of the model on the train data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# print the mean squared error of the model on the train data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Train MSE:\", mse_train)\n",
    "\n",
    "# print the root mean squared error of the model on the train data\n",
    "rmse_train = mse_train ** 0.5\n",
    "print(\"Train RMSE:\", rmse_train)\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "print(\"Train MAE:\", mae_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "59a29b76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "\n",
      "Best Hyperparameters: {'estimator__max_depth': 7, 'estimator__max_features': 'log2', 'estimator__n_estimators': 100}\n",
      "Best MSE: 49930627963.83559\n",
      "Cross-validation scores: [0.34115123 0.43966748 0.3578388  0.49102457 0.32771277]\n",
      "Mean CV R-squared: 0.39147897088328965\n",
      "training MAE: 9325.554865309192\n",
      "Train R-squared: 0.9972196428287093\n",
      "Training MSE: 234170080.99211988\n",
      "Training RMSE: 15302.616802106751\n"
     ]
    }
   ],
   "source": [
    "# Define the estimator for Gradient Boosting\n",
    "estimator = GradientBoostingRegressor(random_state=42)\n",
    "print('Gradient Boosting')\n",
    "print('')\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_depth': [7, 10, 20],\n",
    "    'estimator__max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "# Create a grid search object\n",
    "time_series_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the best MSE and corresponding negative value\n",
    "best_mse = -grid_search.best_score_\n",
    "print(\"Best MSE:\", best_mse)\n",
    "\n",
    "# Calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# calculate and print MAE\n",
    "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
    "print('training MAE:', mae)\n",
    "\n",
    "# Make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# Print the R-squared score of the model on the training data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# Print the mean squared error of the model on the training data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Training MSE:\", mse_train)\n",
    "\n",
    "# Print the root mean squared error of the model on the training data\n",
    "rmse_train = sqrt(mse_train)\n",
    "print(\"Training RMSE:\", rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf09575",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7baba6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 19414079264495.656\n",
      "Test RMSE: 4406141.085405193\n",
      "Test R-squared: -0.06005402130756221\n",
      "Adjusted R2 is -0.1531668745305237\n",
      "Test MAE: 1646144.0353834857\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator with the best parameters\n",
    "gbr = RandomForestRegressor(n_estimators=20, max_depth=10, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "690b9c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 19617774292297.965\n",
      "Test RMSE: 4429195.671033056\n",
      "Test R-squared: -0.07117624505046605\n",
      "Adjusted R2 is -0.16526605035895292\n",
      "Test MAE: 1630806.8123636812\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator with the best parameters\n",
    "gbr = GradientBoostingRegressor(n_estimators=50, max_depth=20, max_features= 'log2',random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33e7e79",
   "metadata": {},
   "source": [
    "## 146 biggest outliers of set dropping out of the training only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "05f962e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>target</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>72.213</td>\n",
       "      <td>133.827</td>\n",
       "      <td>1994</td>\n",
       "      <td>London</td>\n",
       "      <td>GBP</td>\n",
       "      <td>40694.870</td>\n",
       "      <td>True</td>\n",
       "      <td>507.800</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>62.101</td>\n",
       "      <td>174.389</td>\n",
       "      <td>1995</td>\n",
       "      <td>New York</td>\n",
       "      <td>USD</td>\n",
       "      <td>9730.240</td>\n",
       "      <td>True</td>\n",
       "      <td>322.600</td>\n",
       "      <td>Watercolour Art</td>\n",
       "      <td>paper</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist  contrast  brightness  year_sold city_auction currency  \\\n",
       "0  Pierre Alechinsky    72.213     133.827       1994       London      GBP   \n",
       "1  Pierre Alechinsky    62.101     174.389       1995     New York      USD   \n",
       "\n",
       "     target signed  circumference           medium surface  year_born   dead  \\\n",
       "0 40694.870   True        507.800          missing  canvas       1927  False   \n",
       "1  9730.240   True        322.600  Watercolour Art   paper       1927  False   \n",
       "\n",
       "   return_sp  \n",
       "0      0.100  \n",
       "1      0.013  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "82dccf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_values_indices = df['target'].nlargest(146).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "61469596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 809 entries, 0 to 808\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   artist         809 non-null    object  \n",
      " 1   contrast       809 non-null    float64 \n",
      " 2   brightness     809 non-null    float64 \n",
      " 3   year_sold      809 non-null    int64   \n",
      " 4   city_auction   809 non-null    object  \n",
      " 5   currency       809 non-null    object  \n",
      " 6   target         809 non-null    float64 \n",
      " 7   signed         809 non-null    category\n",
      " 8   circumference  809 non-null    float64 \n",
      " 9   medium         809 non-null    object  \n",
      " 10  surface        809 non-null    object  \n",
      " 11  year_born      809 non-null    int64   \n",
      " 12  dead           809 non-null    category\n",
      " 13  return_sp      809 non-null    float64 \n",
      "dtypes: category(2), float64(5), int64(2), object(5)\n",
      "memory usage: 77.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b2fba4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitsing in 80% and then you are going to look at the indexes of the outliers --> later we are going to drop the outliers but only out of the training set\n",
    "split_percentage = 0.80\n",
    "split_point = int(len(df) * split_percentage)\n",
    "\n",
    "train_set = df[:split_point]\n",
    "test_set = df[split_point:]\n",
    "\n",
    "range_train = len(train_set)\n",
    "\n",
    "filtered_indices = [index for index in top_values_indices if index < range_train]\n",
    "\n",
    "# splitting the training set into features X and target variable Y\n",
    "x_train = train_set.drop(columns=['target'])\n",
    "y_train = train_set['target']\n",
    "\n",
    "# dropping the rows based on the indices\n",
    "x_train = x_train.drop(index=filtered_indices)\n",
    "y_train = y_train.drop(index=filtered_indices)\n",
    "\n",
    "#splitting the test set into  features X and target variable Y\n",
    "x_test = test_set.drop(columns=['target'])\n",
    "y_test = test_set['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "39328147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the columns to encode and scale(min-max)\n",
    "one_hot_cols = ['artist', 'city_auction', 'currency', 'medium', 'surface', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
    "        ('num', continuous_transformer, continuous_cols)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "903bc23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'estimator__max_depth': 15, 'estimator__n_estimators': 200}\n",
      "Best MSE: 5580775573.4155245\n",
      "Cross-validation scores: [0.00513161 0.14058398 0.20803055 0.31804429 0.35717368]\n",
      "Mean CV R-squared: 0.2057928192875381\n",
      "Train R-squared: 0.9077085867837241\n",
      "Train MSE: 647449870.8368822\n",
      "Train RMSE: 25445.036271086003\n",
      "Train MAE: 14513.494467642173\n"
     ]
    }
   ],
   "source": [
    "# define the model that we are going to use\n",
    "# we use the same random_state\n",
    "# we are going to look what the best n_estimators is\n",
    "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# define the grid of hyperparamters to look at\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
    "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
    "}\n",
    "\n",
    "# define the grid search object\n",
    "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# fit the grid search object to the training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# print the best hyperparameters and the corresponding mean squared error\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best MSE:\", -grid_search.best_score_)\n",
    "\n",
    "# calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# fit the pipeline to the train data\n",
    "grid_search.best_estimator_.fit(x_train, y_train)\n",
    "\n",
    "# make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# print the R-squared score of the model on the train data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# print the mean squared error of the model on the train data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Train MSE:\", mse_train)\n",
    "\n",
    "# print the root mean squared error of the model on the train data\n",
    "rmse_train = mse_train ** 0.5\n",
    "print(\"Train RMSE:\", rmse_train)\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "print(\"Train MAE:\", mae_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5da99f47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'estimator__max_depth': 7, 'estimator__max_features': 'sqrt', 'estimator__n_estimators': 50}\n",
      "Best MSE: 5173978968.048487\n",
      "Cross-validation scores: [0.0232486  0.19824775 0.35358996 0.33317138 0.41144309]\n",
      "Mean CV R-squared: 0.2639401581021722\n",
      "training MAE: 8775.14169667045\n",
      "Train R-squared: 0.9684955091143105\n",
      "Training MSE: 221012744.7818106\n",
      "Training RMSE: 14866.497394538184\n"
     ]
    }
   ],
   "source": [
    "# Define the estimator for Gradient Boosting\n",
    "estimator = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_depth': [7, 10, 20],\n",
    "    'estimator__max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "# Create a grid search object\n",
    "time_series_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the best MSE and corresponding negative value\n",
    "best_mse = -grid_search.best_score_\n",
    "print(\"Best MSE:\", best_mse)\n",
    "\n",
    "# Calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# calculate and print MAE\n",
    "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
    "print('training MAE:', mae)\n",
    "\n",
    "# Make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# Print the R-squared score of the model on the training data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# Print the mean squared error of the model on the training data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Training MSE:\", mse_train)\n",
    "\n",
    "# Print the root mean squared error of the model on the training data\n",
    "rmse_train = sqrt(mse_train)\n",
    "print(\"Training RMSE:\", rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02a2d68",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6f5b8fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 20729596029368.438\n",
      "Test RMSE: 4552976.611994447\n",
      "Test R-squared: -0.1318843057986323\n",
      "Adjusted R2 is -0.2313065759025663\n",
      "Test MAE: 1708753.2941561495\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator with the best parameters\n",
    "gbr = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "37ea4075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 20820597855707.723\n",
      "Test RMSE: 4562959.330928529\n",
      "Test R-squared: -0.13685321782598292\n",
      "Adjusted R2 is -0.23671194641880566\n",
      "Test MAE: 1709708.3450779587\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator with the best parameters\n",
    "gbr = GradientBoostingRegressor(n_estimators=100, max_depth=10, max_features= 'log2',random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05481689",
   "metadata": {},
   "source": [
    "# Model with less features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f848c8e",
   "metadata": {},
   "source": [
    "we are going to make a temporary dataframe to always come back on this dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "022e54d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>target</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>72.213</td>\n",
       "      <td>133.827</td>\n",
       "      <td>1994</td>\n",
       "      <td>London</td>\n",
       "      <td>GBP</td>\n",
       "      <td>40694.870</td>\n",
       "      <td>True</td>\n",
       "      <td>507.800</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>62.101</td>\n",
       "      <td>174.389</td>\n",
       "      <td>1995</td>\n",
       "      <td>New York</td>\n",
       "      <td>USD</td>\n",
       "      <td>9730.240</td>\n",
       "      <td>True</td>\n",
       "      <td>322.600</td>\n",
       "      <td>Watercolour Art</td>\n",
       "      <td>paper</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist  contrast  brightness  year_sold city_auction currency  \\\n",
       "0  Pierre Alechinsky    72.213     133.827       1994       London      GBP   \n",
       "1  Pierre Alechinsky    62.101     174.389       1995     New York      USD   \n",
       "\n",
       "     target signed  circumference           medium surface  year_born   dead  \\\n",
       "0 40694.870   True        507.800          missing  canvas       1927  False   \n",
       "1  9730.240   True        322.600  Watercolour Art   paper       1927  False   \n",
       "\n",
       "   return_sp  \n",
       "0      0.100  \n",
       "1      0.013  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0f8eaaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to drop one of the two columns --> city_auciton or currency due to high correlation\n",
    "# usd --> new york // # euro --> amsterdarm or london // gbp --> london // NLZ --> dutch guilder and actually the euro but before the euro (convert to euro?)\n",
    "# we chose to drop city_auction because here are missing values !!\n",
    "df = df.drop('city_auction', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4f2de114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>currency</th>\n",
       "      <th>target</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>72.213</td>\n",
       "      <td>133.827</td>\n",
       "      <td>1994</td>\n",
       "      <td>GBP</td>\n",
       "      <td>40694.870</td>\n",
       "      <td>True</td>\n",
       "      <td>507.800</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>62.101</td>\n",
       "      <td>174.389</td>\n",
       "      <td>1995</td>\n",
       "      <td>USD</td>\n",
       "      <td>9730.240</td>\n",
       "      <td>True</td>\n",
       "      <td>322.600</td>\n",
       "      <td>Watercolour Art</td>\n",
       "      <td>paper</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist  contrast  brightness  year_sold currency    target  \\\n",
       "0  Pierre Alechinsky    72.213     133.827       1994      GBP 40694.870   \n",
       "1  Pierre Alechinsky    62.101     174.389       1995      USD  9730.240   \n",
       "\n",
       "  signed  circumference           medium surface  year_born   dead  return_sp  \n",
       "0   True        507.800          missing  canvas       1927  False      0.100  \n",
       "1   True        322.600  Watercolour Art   paper       1927  False      0.013  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5a3ece7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the training set into features X and target variable Y\n",
    "x_values = df.drop(columns=['target'])\n",
    "y_values = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68c0462",
   "metadata": {},
   "source": [
    "## 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf374ade",
   "metadata": {},
   "source": [
    "#### Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8dee3d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = ['artist', 'currency', 'medium', 'surface', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
    "        ('num', continuous_transformer, continuous_cols)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1b9d0bea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "pipeline.fit(x_values, y_values)\n",
    "\n",
    "perm_pipe = permutation_importance(pipeline, x_values, y_values, n_repeats=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "feat_import_perm = perm_pipe.importances_mean\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.bar(range(len(feat_import_perm)), feat_import_perm, align=\"center\")\n",
    "ax.set(xticks=range(len(feat_import_perm)), xticklabels=x_values.columns)\n",
    "# Set properties of x axis using setp, we will rotate the labels by 45 degrees\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f0139fdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the indices of the top 8 features\n",
    "top_feature_indices_perm = feat_import_perm.argsort()[-10:][::-1]\n",
    "\n",
    "# Get the names of the top 8 features\n",
    "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
    "\n",
    "# Plotting the permutation importances for the top 10 features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(top_feature_names_perm)), feat_import_perm[top_feature_indices_perm], align=\"center\")\n",
    "plt.xticks(range(len(top_feature_names_perm)), top_feature_names_perm, rotation=45)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Permutation Importance\")\n",
    "plt.title(\"Top 10 Features Based on Permutation Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cd6b987b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['artist', 'circumference', 'contrast', 'brightness', 'year_sold',\n",
      "       'surface', 'return_sp', 'medium', 'currency', 'year_born'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# step 2: define a split point. We opt for 80%\n",
    "split_percentage = 0.80\n",
    "split_point = int(len(df) * split_percentage)\n",
    "\n",
    "# step 3: Split the data in a training and test set\n",
    "train_set = df[:split_point]\n",
    "test_set = df[split_point:]\n",
    "\n",
    "# Get the indices of the top 8 features\n",
    "top_feature_indices_perm = perm_pipe.importances_mean.argsort()[-10:][::-1]\n",
    "\n",
    "# Get the names of the top 8 features\n",
    "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
    "print(top_feature_names_perm)\n",
    "\n",
    "# splitting in training set X and training set y but now only with the features we want.\n",
    "x_train = train_set[top_feature_names_perm]\n",
    "y_train = train_set['target']\n",
    "\n",
    "x_test = test_set[top_feature_names_perm]\n",
    "y_test = test_set['target']\n",
    "\n",
    "one_hot_cols = ['artist', 'currency', 'medium', 'surface', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the columns to encode and scale (standard)\n",
    "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
    "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
    "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "688be855",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'estimator__max_depth': 10, 'estimator__n_estimators': 10}\n",
      "Best MSE: 1340115713455.3887\n",
      "Cross-validation scores: [-0.19161707  0.09165377  0.42177579  0.50170218  0.35524329]\n",
      "Mean CV R-squared: 0.235751590859706\n",
      "Train R-squared: 0.8585319134102684\n",
      "Train MSE: 258772608306.9713\n",
      "Train RMSE: 508696.9710023555\n",
      "Train MAE: 136758.58666204358\n"
     ]
    }
   ],
   "source": [
    "# define the model that we are going to use\n",
    "# we use the same random_state\n",
    "# we are going to look what the best n_estimators is\n",
    "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# define the grid of hyperparamters to look at\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
    "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
    "}\n",
    "\n",
    "# define the grid search object\n",
    "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# fit the grid search object to the training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# print the best hyperparameters and the corresponding mean squared error\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best MSE:\", -grid_search.best_score_)\n",
    "\n",
    "# calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# fit the pipeline to the train data\n",
    "grid_search.best_estimator_.fit(x_train, y_train)\n",
    "\n",
    "# make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# print the R-squared score of the model on the train data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# print the mean squared error of the model on the train data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Train MSE:\", mse_train)\n",
    "\n",
    "# print the root mean squared error of the model on the train data\n",
    "rmse_train = mse_train ** 0.5\n",
    "print(\"Train RMSE:\", rmse_train)\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "print(\"Train MAE:\", mae_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299b85b4",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3797ba9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 11038621020529.053\n",
      "Test RMSE: 3322442.026661873\n",
      "Test R-squared: 0.3972655389379346\n",
      "Adjusted R2 is 0.3573493494636256\n",
      "Test MAE: 1417378.706057924\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator with the best parameters\n",
    "gbr = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb0aaef",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "00aa3323",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "estimator = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "pipeline.fit(x_values, y_values)\n",
    "\n",
    "perm_pipe = permutation_importance(pipeline, x_values, y_values, n_repeats=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "feat_import_perm = perm_pipe.importances_mean\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.bar(range(len(feat_import_perm)), feat_import_perm, align=\"center\")\n",
    "ax.set(xticks=range(len(feat_import_perm)), xticklabels=x_values.columns)\n",
    "# Set properties of x axis using setp, we will rotate the labels by 45 degrees\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2f86aa83",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the indices of the top 8 features\n",
    "top_feature_indices_perm = feat_import_perm.argsort()[-10:][::-1]\n",
    "\n",
    "# Get the names of the top 8 features\n",
    "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
    "\n",
    "# Plotting the permutation importances for the top 10 features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(top_feature_names_perm)), feat_import_perm[top_feature_indices_perm], align=\"center\")\n",
    "plt.xticks(range(len(top_feature_names_perm)), top_feature_names_perm, rotation=45)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Permutation Importance\")\n",
    "plt.title(\"Top 10 Features Based on Permutation Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0e91f4",
   "metadata": {},
   "source": [
    "* higher importance score\n",
    "    * higher score = larger impact on the target, more influential in making predictions\n",
    "* lower score\n",
    "    * their permuation does not significantly affect the model's accuracy\n",
    "* relative importance\n",
    "    * the order of features in sorted list gives you an idea of which features arre most crucial for your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "03d0674b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['artist', 'circumference', 'contrast', 'year_sold', 'brightness',\n",
      "       'surface', 'return_sp', 'medium', 'currency', 'year_born'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# step 2: define a split point. We opt for 80%\n",
    "split_percentage = 0.80\n",
    "split_point = int(len(df) * split_percentage)\n",
    "\n",
    "# step 3: Split the data in a training and test set\n",
    "train_set = df[:split_point]\n",
    "test_set = df[split_point:]\n",
    "\n",
    "# Get the indices of the top 8 features\n",
    "top_feature_indices_perm = perm_pipe.importances_mean.argsort()[-10:][::-1]\n",
    "\n",
    "# Get the names of the top 8 features\n",
    "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
    "print(top_feature_names_perm)\n",
    "\n",
    "# splitting in training set X and training set y but now only with the features we want.\n",
    "x_train = train_set[top_feature_names_perm]\n",
    "y_train = train_set['target']\n",
    "\n",
    "x_test = test_set[top_feature_names_perm]\n",
    "y_test = test_set['target']\n",
    "\n",
    "one_hot_cols = ['artist', 'currency', 'medium', 'surface', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the columns to encode and scale (standard)\n",
    "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
    "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
    "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d09c1b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'estimator__max_depth': 10, 'estimator__max_features': 'sqrt', 'estimator__n_estimators': 200}\n",
      "Best MSE: 1315173851286.0574\n",
      "Cross-validation scores: [0.38499667 0.1497098  0.40659377 0.58708858 0.34645882]\n",
      "Mean CV R-squared: 0.3749695311915306\n",
      "training MAE: 21.015075048394472\n",
      "Train R-squared: 0.9999999992333405\n",
      "Training MSE: 1402.3691091528694\n",
      "Training RMSE: 37.448219038465226\n"
     ]
    }
   ],
   "source": [
    "# Define the estimator for Gradient Boosting\n",
    "estimator = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_depth': [7, 10, 20],\n",
    "    'estimator__max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "# Create a grid search object\n",
    "time_series_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the best MSE and corresponding negative value\n",
    "best_mse = -grid_search.best_score_\n",
    "print(\"Best MSE:\", best_mse)\n",
    "\n",
    "# Calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# calculate and print MAE\n",
    "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
    "print('training MAE:', mae)\n",
    "\n",
    "# Make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# Print the R-squared score of the model on the training data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# Print the mean squared error of the model on the training data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Training MSE:\", mse_train)\n",
    "\n",
    "# Print the root mean squared error of the model on the training data\n",
    "rmse_train = sqrt(mse_train)\n",
    "print(\"Training RMSE:\", rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de737229",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "491eaf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 12708659195145.51\n",
      "Test RMSE: 3564920.6435972047\n",
      "Test R-squared: 0.3060775583687564\n",
      "Adjusted R2 is 0.26012242978390576\n",
      "Test MAE: 1634988.280813204\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator with the best parameters\n",
    "gbr = GradientBoostingRegressor(n_estimators=200, max_depth=20, max_features= 'sqrt',random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04be097",
   "metadata": {},
   "source": [
    "## 8 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0462ea3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>currency</th>\n",
       "      <th>target</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>72.213</td>\n",
       "      <td>133.827</td>\n",
       "      <td>1994</td>\n",
       "      <td>GBP</td>\n",
       "      <td>40694.870</td>\n",
       "      <td>True</td>\n",
       "      <td>507.800</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>62.101</td>\n",
       "      <td>174.389</td>\n",
       "      <td>1995</td>\n",
       "      <td>USD</td>\n",
       "      <td>9730.240</td>\n",
       "      <td>True</td>\n",
       "      <td>322.600</td>\n",
       "      <td>Watercolour Art</td>\n",
       "      <td>paper</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist  contrast  brightness  year_sold currency    target  \\\n",
       "0  Pierre Alechinsky    72.213     133.827       1994      GBP 40694.870   \n",
       "1  Pierre Alechinsky    62.101     174.389       1995      USD  9730.240   \n",
       "\n",
       "  signed  circumference           medium surface  year_born   dead  return_sp  \n",
       "0   True        507.800          missing  canvas       1927  False      0.100  \n",
       "1   True        322.600  Watercolour Art   paper       1927  False      0.013  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d871f9c7",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "aa6b18fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "pipeline.fit(x_values, y_values)\n",
    "\n",
    "perm_pipe = permutation_importance(pipeline, x_values, y_values, n_repeats=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "feat_import_perm = perm_pipe.importances_mean\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.bar(range(len(feat_import_perm)), feat_import_perm, align=\"center\")\n",
    "ax.set(xticks=range(len(feat_import_perm)), xticklabels=x_values.columns)\n",
    "# Set properties of x axis using setp, we will rotate the labels by 45 degrees\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "413b4188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the indices of the top 8 features\n",
    "top_feature_indices_perm = feat_import_perm.argsort()[-8:][::-1]\n",
    "\n",
    "# Get the names of the top 8 features\n",
    "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
    "\n",
    "# Plotting the permutation importances for the top 8 features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(top_feature_names_perm)), feat_import_perm[top_feature_indices_perm], align=\"center\")\n",
    "plt.xticks(range(len(top_feature_names_perm)), top_feature_names_perm, rotation=45)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Permutation Importance\")\n",
    "plt.title(\"Top 8 Features Based on Permutation Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0b32798c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['artist', 'circumference', 'contrast', 'year_sold', 'brightness',\n",
      "       'surface', 'return_sp', 'medium'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# step 2: define a split point. We opt for 80%\n",
    "split_percentage = 0.80\n",
    "split_point = int(len(df) * split_percentage)\n",
    "\n",
    "# step 3: Split the data in a training and test set\n",
    "train_set = df[:split_point]\n",
    "test_set = df[split_point:]\n",
    "\n",
    "# Get the indices of the top 8 features\n",
    "top_feature_indices_perm = perm_pipe.importances_mean.argsort()[-8:][::-1]\n",
    "\n",
    "# Get the names of the top 8 features\n",
    "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
    "print(top_feature_names_perm)\n",
    "\n",
    "# splitting in training set X and training set y but now only with the features we want.\n",
    "x_train = train_set[top_feature_names_perm]\n",
    "y_train = train_set['target']\n",
    "\n",
    "one_hot_cols = ['artist', 'currency', 'medium', 'surface', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the columns to encode and scale (standard)\n",
    "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
    "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
    "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "834f902f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'estimator__max_depth': 20, 'estimator__n_estimators': 150}\n",
      "Best MSE: 1373198030392.9392\n",
      "Cross-validation scores: [-0.30366215  0.09283886  0.48285026  0.54405315  0.31266293]\n",
      "Mean CV R-squared: 0.22574861224253717\n",
      "Train R-squared: 0.9131693583907646\n",
      "Train MSE: 158830108979.65024\n",
      "Train RMSE: 398534.9532721694\n",
      "Train MAE: 115424.88705614912\n"
     ]
    }
   ],
   "source": [
    "# define the model that we are going to use\n",
    "# we use the same random_state\n",
    "# we are going to look what the best n_estimators is\n",
    "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# define the grid of hyperparamters to look at\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
    "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
    "}\n",
    "\n",
    "# define the grid search object\n",
    "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# fit the grid search object to the training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# print the best hyperparameters and the corresponding mean squared error\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best MSE:\", -grid_search.best_score_)\n",
    "\n",
    "# calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# fit the pipeline to the train data\n",
    "grid_search.best_estimator_.fit(x_train, y_train)\n",
    "\n",
    "# make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# print the R-squared score of the model on the train data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# print the mean squared error of the model on the train data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Train MSE:\", mse_train)\n",
    "\n",
    "# print the root mean squared error of the model on the train data\n",
    "rmse_train = mse_train ** 0.5\n",
    "print(\"Train RMSE:\", rmse_train)\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "print(\"Train MAE:\", mae_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3216e435",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "20ae0078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 11424257889586.299\n",
      "Test RMSE: 3379978.977684077\n",
      "Test R-squared: 0.376208866188267\n",
      "Adjusted R2 is 0.33489819507490715\n",
      "Test MAE: 1409083.276109454\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator with the best parameters\n",
    "gbr = RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ea29d",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d8bb2046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "estimator = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "pipeline.fit(x_values, y_values)\n",
    "\n",
    "perm_pipe = permutation_importance(pipeline, x_values, y_values, n_repeats=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "feat_import_perm = perm_pipe.importances_mean\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.bar(range(len(feat_import_perm)), feat_import_perm, align=\"center\")\n",
    "ax.set(xticks=range(len(feat_import_perm)), xticklabels=x_values.columns)\n",
    "# Set properties of x axis using setp, we will rotate the labels by 45 degrees\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a2c336f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAGzCAYAAABn68DyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA+n0lEQVR4nO3debyt9dz/8de7SYOSlGhyQma3kMw3oTRokEpJKZJQZM50l+E2zzKFzGQKUe64+clNogwhY6WU0iAaNX9+f3yvrdV29jnrnPba11lrv56Px36cva51nbU+17XWXutzfYfPN1WFJEmS5tZyfQcgSZI0H5mESZIk9cAkTJIkqQcmYZIkST0wCZMkSeqBSZgkSVIPTMIkjZUk30uyX99xjLMkr0jykb7jkOY7kzCNrSRXDPzcmOSfA7f3nKXnWCvJ55Nc3P18JskaM+z76C6Owbi+fguf/9FJzr0ljzFbkhyW5LqBY/ttkif1HdeodMne1d2xXpzk6CR3XAbiOizJp5dg/397D1XVG6pq1hPZJPsk+cFsP+7SWJb+dqSZmIRpbFXVrad+gD8D2w9s+8wsPc3rgdsCdwbuAqwLHLaI/c8bjKuqtp+lOJZKkhVm+SE/P3DODwY+nWTdWX6OZcmB3bHeDVgTeOeSPkCS5Wc7KC3aCN730kiYhGniJLlVknclOa/7eVeSW3X3PTrJuV13zMVJzlpMq9nGwFer6rKquhT4CnDvpYjpIUlOTPKPJKcmefTAfft2rUqXJzkzybO67asB3wTWG2h9Wi/Jx5O8fuD/3+yKvzumlyX5JXBlkhUW8/z7dM97eZI/DduKWFXHA5fTklOS3DbJN5JclOTv3e8bDPM8SZ7enYO/Jzk+yZ0G7tsyye+SXJrkcCCLOM/DvPYvSnJhkvOT7DvksV4CfBm4T/dY90jy7SSXJPl9kt0GYvh4kg8kOS7JlcAW3WvykiS/THJlko8mWTfJN7vz8b9JbjsY57TjOivJ45JsDbwCeHL3fji1u39J30M3a01LskOS07r3x/eS3HPac7+4i/3StJbhlYc5b0t43AuSVJL9u9fu/CQvWsLX9mVJ/gp8bobj3jzJj7rjPD/J4UlWGniOSnJAkj9278X3JcnA/c8cOM+/SfKAbvt6Sb6c9t7/U5LnDXN+JKrKH3/G/gc4C3hc9/trgZOA2wPrACcCr+vuezRwPfAO4FbAo4ArgbvP8LhPAI6jtYbdFvgucPAM+z4aOHch29cH/gZsS7vw2bK7vU53/3a0RCZdPFcBD5jpMYGPA6+f6Xm7c/ELYENglUU9P7AacNnU8QN3BO49w/EdBny6+z1d3P8A1uy23Q54ErAqsDrwRVoCy6KeB9gJOB24J7AC8CrgxO6+tbv/twuwIvCC7vXbb4YYh3ntX9s91rbdub7tDI/1vann6eL4LvCp7ljOAfbt4n0AcPHA8XwcuBR4eHe+V+5ek5NoLanrAxcCPwPuT3sffhc4dBGv+Vnc9P7+1+swcP+SvocGX8u70f4GtuzOy0u712Olgef+CbAesBbwW+CAGc7ZPsAPpsU97HEvAIqWQK0G3Be4iCX7u35z97irzHDcDwQe0r1uC7pjOXjg/gK+QWv13Kh7/q27+3YF/gI8qDvPdwXu1L3GPwX+C1iJ1mp+JvD4vj8X/Vn2f2wJ0yTaE3htVV1YVRcBrwH2mrbPq6vqmqo6ATgW2G36g3R+Rvtg/Vv3cwPw/kU893rdVfbUz27AU4Hjquq4qrqxqr4NnEJLAqiqY6vqjGpOAL4FPHKpjvwm76mqc6rqn4t7fuBG4D5JVqmq86vqtEU87m5J/kH70j4GeENV/aM7jr9V1Zer6qqquhz4b1pCMGWm53kW8Maq+m1VXQ+8Adg0rTVsW+A3VfWlqroOeBfw10XEt7jX/rru/uuq6jjgCuDui3i893THeypwPvBCWmJ+VlV9rKqur6qf0VrJdhn4f1+rqh925/vqbtt7q+qCqvoL8H/Aj6vq51V1Da2F9f6LiGORbuF76MnAsVX17e4cv42WxDxsYJ/3VNV51VoEvw5sugThLelxv6aqrqyqXwEfA/boti/utb2RltBd073v/01V/bSqTupet7OAD3Hz9yjAm6rqH1X1Z+D/DRzrfsBbqurk7jyfXlVn05KydarqtVV1bVWdCXwY2H0JzpHmKZMwTaL1gLMHbp/dbZvy96q6chH3D/oi8Aday84awBnAogZFn1dVaw78fIF2tbzrYHIGPILWGkSSbZKc1HVt/YOWeKw95LHO5JyB32d8/u48PBk4ADg/ybFJ7rGIx/1Cd1yr0lpe9h7o+lo1yYeSnJ3kMuD7wJpJll/M89wJePdAbJfQWhrWp70u/zqWqqppxzbd4l77v3WJ3pSrgFsv4vGe1x3v+lW1Z/flfyfgwdPO557AHQb+38JivGDg938u5Pai4likW/geutk5q6obafGvP7DPYOK7uHM23ZIe9+C5G3z9FvfaXjSQ8C5UkruldZP/tXuPvoF/P08zHeuGtL//6e7EtIsvWpfxJI+V1CwxCdMkOo/2wThlo27blNt2Y2Vmun/Q/YAPdVfmVwAf5KYWpGGdA3xqWnK2WlW9qRvT8mVa68O6VbUmrftzahxKLeTxrqR1+U25w0L2Gfx/Mz4/tLFdVbUlLSn8He0qfrG6loRvAlOTD15Ea1V6cFWtAfxntz2LeZ5zgGdNi2+VqjqR1vq04dRzduNz/nV7IRb32s+Gc4ATpsV766p69sA+C3vdhnWz1zdtYP86Mz32Ur6HBt3snA2c478sXfi32ODrO/j6Le61nX6cCzvuD9Dee5t079FXsIgxhtOcQzf+cSHb/zTt/bB6VS3p54TmIZMwTaLPAa9Ksk6StWljNaa3Xr0myUpJHknrXvriDI91MrBfklWSrALsT+uaWhKfBrZP8vgkyydZuRtIvAGtq/NWtLEn1yfZBthq4P9eANwuyW0Gtv0C2DatfMYdaLMUl+r5u0HSO3RJ6TW07rkbhjmoLv6tgaluxdVpLRv/SLIWcOjAvot6ng8CL09y727f2yTZtbvvWODeSXZOm/H2PBaedE4Z5rW/pb4B3C3JXklW7H4elIHB7LfQH4CVk2yXZEXaGLlbDdx/AbAgydTn99K8hwZ9AdguyWO753sR7TU6cZaOZ0m9umtVvTdt3N3nu+1L+tou7LhXp40xvKJriX32Qv/nwn0EeHGSB6a5a9dl/hPgsrRJAat0f2P3SfKgJXhszVMmYZpEr6eNefol8CvauK7XD9z/V+DvtKvoz9AGGf9uhsd6Om0A77m0loE70wYfD62qzgF2pF11X0S7cn4JsFw3dup5tC/CvwNPoY21mvq/v6N9+ZzZdXWsRxscfipt0PO3uOlLaomfv/t5Ee1cXEIbH/OcRTzc1Ky8K2gJ6g9pY3OgjddahTZI/STgfwb+34zPU1VfoQ2oPqrrIvo1sE1338W0AdFvoo3J26R7zpks7rW/xbrXbCvamJ/zaO+nqQHhs/H4l9LOzUdo77krae+/KVMXDH9L8rOlfA8NPt/vaeMG30t77banlXu5djaOZymcQJsY8B3gbVX1rW77Er22Mxz3i2nn53JaS+wi/3amPd4XaeMcP9v9/68Ca1XVDbRztinwJ9o5/AgwU9Ir/UvaEAtpfkgrzfDpqtpgMbtKmkNJFtCSmBWnjduTJpYtYZIkST0wCZMkSeqB3ZGSJEk9sCVMkiSpByZhkiRJPRi7lebXXnvtWrBgQd9hSJIkLdZPf/rTi6tqnYXdN3ZJ2IIFCzjllFP6DkOSJGmxkpw90312R0qSJPXAJEySJKkHJmGSJEk9MAmTJEnqgUmYJElSD0zCJEmSemASJkmS1AOTMEmSpB6YhEmSJPXAJEySJKkHJmGSJEk9MAmTJEnqgUmYJElSD0zCJEmSerBC3wEsqxYccmzfIcyqs960Xd8hSJKkAbaESZIk9cAkTJIkqQcmYZIkST0wCZMkSeqBSZgkSVIPTMIkSZJ6MLIkLMmRSS5M8usZ7k+S9yQ5PckvkzxgVLFIkiQta0bZEvZxYOtF3L8NsEn3sz/wgRHGIkmStEwZWRJWVd8HLlnELjsCn6zmJGDNJHccVTySJEnLkj7HhK0PnDNw+9xumyRJ0sTrMwnLQrbVQndM9k9ySpJTLrroohGHJUmSNHp9JmHnAhsO3N4AOG9hO1bVEVW1WVVtts4668xJcJIkSaPUZxJ2DLB3N0vyIcClVXV+j/FIkiTNmRVG9cBJPgc8Glg7ybnAocCKAFX1QeA4YFvgdOAqYN9RxSJJkrSsGVkSVlV7LOb+Ap47queXJElallkxX5IkqQcmYZIkST0wCZMkSeqBSZgkSVIPTMIkSZJ6YBImSZLUA5MwSZKkHpiESZIk9cAkTJIkqQcmYZIkST0wCZMkSeqBSZgkSVIPTMIkSZJ6YBImSZLUA5MwSZKkHpiESZIk9cAkTJIkqQcmYZIkST0wCZMkSeqBSZgkSVIPTMIkSZJ6YBImSZLUA5MwSZKkHpiESZIk9cAkTJIkqQcmYZIkST0wCZMkSeqBSZgkSVIPTMIkSZJ6YBImSZLUA5MwSZKkHpiESZIk9cAkTJIkqQcmYZIkST0wCZMkSeqBSZgkSVIPTMIkSZJ6YBImSZLUA5MwSZKkHpiESZIk9cAkTJIkqQcmYZIkST0wCZMkSeqBSZgkSVIPTMIkSZJ6YBImSZLUA5MwSZKkHpiESZIk9cAkTJIkqQcmYZIkST0wCZMkSerBSJOwJFsn+X2S05McspD7b5Pk60lOTXJakn1HGY8kSdKyYmRJWJLlgfcB2wD3AvZIcq9puz0X+E1V3Q94NPD2JCuNKiZJkqRlxShbwjYHTq+qM6vqWuAoYMdp+xSwepIAtwYuAa4fYUySJEnLhFEmYesD5wzcPrfbNuhw4J7AecCvgOdX1Y0jjEmSJGmZMMokLAvZVtNuPx74BbAesClweJI1/u2Bkv2TnJLklIsuumi245QkSZpzo0zCzgU2HLi9Aa3Fa9C+wNHVnA78CbjH9AeqqiOqarOq2mydddYZWcCSJElzZZRJ2MnAJkk27gbb7w4cM22fPwOPBUiyLnB34MwRxiRJkrRMWGFUD1xV1yc5EDgeWB44sqpOS3JAd/8HgdcBH0/yK1r35cuq6uJRxSRJkrSsGFkSBlBVxwHHTdv2wYHfzwO2GmUMkiRJyyIr5kuSJPXAJEySJKkHJmGSJEk9MAmTJEnqgUmYJElSD0zCJEmSemASJkmS1AOTMEmSpB6YhEmSJPXAJEySJKkHJmGSJEk9MAmTJEnqwVBJWJI7JXlc9/sqSVYfbViSJEmTbbFJWJJnAl8CPtRt2gD46ghjkiRJmnjDtIQ9F3g4cBlAVf0RuP0og5IkSZp0wyRh11TVtVM3kqwA1OhCkiRJmnzDJGEnJHkFsEqSLYEvAl8fbViSJEmTbZgk7BDgIuBXwLOA44BXjTIoSZKkSbfCEPusAhxZVR8GSLJ8t+2qUQYmSZI0yYZpCfsOLemasgrwv6MJR5IkaX4YJglbuaqumLrR/b7q6EKSJEmafMMkYVcmecDUjSQPBP45upAkSZIm3zBjwg4GvpjkvO72HYEnjywiSZKkeWCxSVhVnZzkHsDdgQC/q6rrRh6ZJEnSBBumJQzgQcCCbv/7J6GqPjmyqCRJkibcYpOwJJ8C7gL8Arih21yASZgkSdJSGqYlbDPgXlXlUkWSJEmzZJjZkb8G7jDqQCRJkuaTYVrC1gZ+k+QnwDVTG6tqh5FFJUmSNOGGScIOG3UQkiRJ880wJSpOmItAJEmS5pPFjglL8pAkJye5Ism1SW5IctlcBCdJkjSphhmYfziwB/BH2uLd+3XbJEmStJSGKtZaVacnWb6qbgA+luTEEcclSZI00YZJwq5KshLwiyRvAc4HVhttWJIkSZNtmO7Ivbr9DgSuBDYEdh5lUJIkSZNumCRsp6q6uqouq6rXVNULgSeMOjBJkqRJNkwS9rSFbNtnluOQJEmaV2YcE5ZkD+ApwJ2THDNw1+rA30YdmCRJ0iRb1MD8E2mD8NcG3j6w/XLgl6MMSpIkadLNmIRV1dlJzgWutGq+JEnS7FrkmLCuLthVSW4zR/FIkiTNC8PUCbsa+FWSb9NKVABQVc8bWVSSJEkTbpgk7NjuR5IkSbNksUlYVX2iq5h/t27T76vqutGGJUmSNNkWm4QleTTwCeAsIMCGSZ5WVd8faWSSJEkTbJjuyLcDW1XV7wGS3A34HPDAUQYmSZI0yYapmL/iVAIGUFV/AFYcXUiSJEmTb5iWsFOSfBT4VHd7T+CnowtJkiRp8g2ThD0beC7wPNqYsO8D7x9lUJIkSZNumNmR1yQ5HPgOcCNtduS1I49MkiRpgi12TFiS7YAzgHcDhwOnJ9lmmAdPsnWS3yc5PckhM+zz6CS/SHJaEpdHkiRJ88KwsyO3qKrTAZLchVa89ZuL+k9JlgfeB2wJnAucnOSYqvrNwD5r0ro2t66qPye5/VIdhSRJ0pgZZnbkhVMJWOdM4MIh/t/mwOlVdWbXfXkUsOO0fZ4CHF1VfwaoqmEeV5IkaewN0xJ2WpLjgC8ABexKa9XaGaCqjp7h/60PnDNw+1zgwdP2uRuwYpLvAasD766qTw4fviRJ0ngaJglbGbgAeFR3+yJgLWB7WlI2UxKWhWyrhTz/A4HHAqsAP0pyUleL7KYHSvYH9gfYaKONhghZkiRp2TbM7Mh9l/KxzwU2HLi9AXDeQva5uKquBK5M8n3gfsDNkrCqOgI4AmCzzTabnshJkiSNnWHWjtwYOAhYMLh/Ve2wmP96MrBJ9///AuxOGwM26GvA4UlWAFaidVe+c9jgJUmSxtUw3ZFfBT4KfJ1WJ2woVXV9kgOB44HlgSOr6rQkB3T3f7Cqfpvkf4Bfdo/9kar69RIegyRJ0tgZJgm7uqreszQPXlXHAcdN2/bBabffCrx1aR5fkiRpXA2ThL07yaHAt4BrpjZW1c9GFpUkSdKEGyYJuy+wF/AYbuqOrO62JEmSlsIwSdgTgTu7XqQkSdLsGaZi/qnAmiOOQ5IkaV4ZpiVsXeB3SU7m5mPCFleiQpIkSTMYJgk7dORRSJIkzTPDVMw/YS4CkSRJmk9mTMKSXM6/r/UIbU3Iqqo1RhaVJEnShJsxCauq1ecyEC17FhxybN8hzKqz3rRd3yFIkvQvw8yOlCRJ0iwzCZMkSeqBSZgkSVIPTMIkSZJ6sNgkLMnOSf6Y5NIklyW5PMllcxGcJEnSpBqmWOtbgO2r6rejDkaSJGm+GKY78gITMEmSpNk1TEvYKUk+D3yVm68defSogpIkSZp0wyRhawBXAVsNbCvAJEySJGkpDbN25L5zEYgkSdJ8MszsyA2SfCXJhUkuSPLlJBvMRXCSJEmTapiB+R8DjgHWA9YHvt5tkyRJ0lIaJglbp6o+VlXXdz8fB9YZcVySJEkTbZgk7OIkT02yfPfzVOBvow5MkiRpkg2ThD0d2A34K3A+sEu3TZIkSUtpmNmRfwZ2mINYJEmS5o0Zk7AkL62qtyR5L60u2M1U1fNGGpkkSdIEW1RL2NRSRafMRSCSJEnzyYxJWFV9vfv1qqr64uB9SXYdaVSSJEkTbpiB+S8fcpskSZKGtKgxYdsA2wLrJ3nPwF1rANePOjBJkqRJtqgxYefRxoPtAPx0YPvlwAtGGZQkSdKkW9SYsFOBU5N8tqqum8OYJEmSJt5i64QBC5K8EbgXsPLUxqq688iikiRJmnDDLuD9Ado4sC2ATwKfGmVQkiRJk26YJGyVqvoOkKo6u6oOAx4z2rAkSZIm2zDdkVcnWQ74Y5IDgb8Atx9tWJIkSZNtmJawg4FVgecBDwSeCuw9wpgkSZIm3jBJ2IKquqKqzq2qfavqScBGow5MkiRpklkxX5IkqQdWzJckSeqBFfMlSZJ6MEzF/M9UlS1fkiRJs2iYEhV/TFLTN1oxX5IkaekNk4RtNvD7ysCuwFqjCUeSJGl+WOzsyKr628DPX6rqXVgxX5Ik6RZZbEtYkgcM3FyO1jK2+sgikiRJmgeG6Y58+8Dv1wNnAbuNJBpJkqR5YrFJWFVtMReBSJIkzSfDdEeuSVsrcsHg/lX1vJFFJUmSNOGG6Y48DjgJ+BVw42jDkSRJmh+GScJWrqoXjjwSSZKkeWSYBbw/leSZSe6YZK2pn2EePMnWSX6f5PQkhyxivwcluSHJLkNHLkmSNMaGaQm7Fngr8EpgqnJ+AYusmJ9keeB9wJbAucDJSY6pqt8sZL83A8cvWeiSJEnja5gk7IXAXavq4iV87M2B06vqTIAkRwE7Ar+Ztt9BwJeBBy3h40uSJI2tYbojTwOuWorHXh84Z+D2ud22f0myPvBE4IOLeqAk+yc5JckpF1100VKEIkmStGwZpiXsBuAXSf4fcM3UxiFKVGQh26YvBP4u4GVVdUOysN3/9VxHAEcAbLbZZv+2mLgkSdK4GSYJ+2r3s6TOBTYcuL0BcN60fTYDjuoSsLWBbZNcX1VL83ySJEljY5FJWDdofq+qetxSPPbJwCZJNgb+AuwOPGVwh6raeOC5Pg58wwRMkiTNB4tMwrpuwquS3KaqLl2SB66q65McSJv1uDxwZFWdluSA7v5FjgOTJEmaZMN0R14N/CrJt4ErpzYOs2xRVR1Hq7g/uG2hyVdV7TNELJIkSRNhmCTs2O5HkiRJs2SxSVhVfSLJKsBGVfX7OYhJkiRp4i22TliS7YFfAP/T3d40yTEjjkuSJGmiDVOs9TBa9ft/AFTVL4CNZ95dkiRJizNMEnb9QmZGWjBVkiTpFhhmYP6vkzwFWD7JJsDzgBNHG5YkSdJkG6Yl7CDg3rQliz4LXAocPMKYJEmSJt6MLWFJVgYOAO4K/Ap4aFVdP1eBSZIkTbJFtYR9gra246+AbYC3zUlEkiRJ88CixoTdq6ruC5Dko8BP5iYkSZKkybeolrDrpn6xG1KSJGl2Laol7H5JLut+D7BKdztAVdUaI49OkiRpQs2YhFXV8nMZiCRJ0nwyTIkKSZIkzTKTMEmSpB6YhEmSJPXAJEySJKkHJmGSJEk9MAmTJEnqgUmYJElSD0zCJEmSemASJkmS1AOTMEmSpB6YhEmSJPXAJEySJKkHJmGSJEk9MAmTJEnqwQp9ByAtyxYccmzfIcyqs960Xd8hSJI6toRJkiT1wCRMkiSpByZhkiRJPTAJkyRJ6oFJmCRJUg9MwiRJknpgEiZJktQDkzBJkqQemIRJkiT1wCRMkiSpByZhkiRJPTAJkyRJ6oFJmCRJUg9MwiRJknpgEiZJktQDkzBJkqQemIRJkiT1wCRMkiSpByZhkiRJPTAJkyRJ6oFJmCRJUg9MwiRJknow0iQsydZJfp/k9CSHLOT+PZP8svs5Mcn9RhmPJEnSsmJkSViS5YH3AdsA9wL2SHKvabv9CXhUVf0H8DrgiFHFI0mStCwZZUvY5sDpVXVmVV0LHAXsOLhDVZ1YVX/vbp4EbDDCeCRJkpYZo0zC1gfOGbh9brdtJs8AvjnCeCRJkpYZK4zwsbOQbbXQHZMtaEnYI2a4f39gf4CNNtpotuKTNIQFhxzbdwiz6qw3bdd3CJIEjLYl7Fxgw4HbGwDnTd8pyX8AHwF2rKq/LeyBquqIqtqsqjZbZ511RhKsJEnSXBplEnYysEmSjZOsBOwOHDO4Q5KNgKOBvarqDyOMRZIkaZkysu7Iqro+yYHA8cDywJFVdVqSA7r7Pwj8F3A74P1JAK6vqs1GFZMkSdKyYpRjwqiq44Djpm374MDv+wH7jTIGSZKkZZEV8yVJknpgEiZJktQDkzBJkqQemIRJkiT1wCRMkiSpByZhkiRJPTAJkyRJ6oFJmCRJUg9MwiRJknpgEiZJktQDkzBJkqQemIRJkiT1wCRMkiSpByZhkiRJPTAJkyRJ6oFJmCRJUg9MwiRJknpgEiZJktQDkzBJkqQemIRJkiT1wCRMkiSpByZhkiRJPTAJkyRJ6oFJmCRJUg9MwiRJknqwQt8BSNKybsEhx/Ydwqw6603b9R2CJGwJkyRJ6oVJmCRJUg9MwiRJknpgEiZJktQDkzBJkqQemIRJkiT1wCRMkiSpByZhkiRJPTAJkyRJ6oFJmCRJUg9MwiRJknpgEiZJktQDkzBJkqQerNB3AJKkZd+CQ47tO4RZddabtus7BMmWMEmSpD6YhEmSJPXAJEySJKkHJmGSJEk9MAmTJEnqgbMjJUkagjNENdtsCZMkSeqBSZgkSVIPTMIkSZJ6YBImSZLUA5MwSZKkHox0dmSSrYF3A8sDH6mqN027P9392wJXAftU1c9GGZMkSVo6zhCdXSNrCUuyPPA+YBvgXsAeSe41bbdtgE26n/2BD4wqHkmSpGXJKLsjNwdOr6ozq+pa4Chgx2n77Ah8spqTgDWT3HGEMUmSJC0TRpmErQ+cM3D73G7bku4jSZI0cUY5JiwL2VZLsQ9J9qd1VwJckeT3tzC2ZcnawMWjfpK8edTPcIt4DjwH4DkAzwF4DsBzAJN1Du400x2jTMLOBTYcuL0BcN5S7ENVHQEcMdsBLguSnFJVm/UdR588B54D8ByA5wA8B+A5gPlzDkbZHXkysEmSjZOsBOwOHDNtn2OAvdM8BLi0qs4fYUySJEnLhJG1hFXV9UkOBI6nlag4sqpOS3JAd/8HgeNo5SlOp5Wo2HdU8UiSJC1LRlonrKqOoyVag9s+OPB7Ac8dZQxjYCK7WZeQ58BzAJ4D8ByA5wA8BzBPzkFaHiRJkqS55LJFkiRJPTAJkyRJ6oFJ2DKsW1tTuhnfFzfxXEgaZyZhy4gk6yZZr/t9uyTLlwP21OnWYp2yem+BLCOS3A7a5B4TsfnB1/nfzedzMinHbhK27FgAfC7JW4HDgNv1Gs0YmumPctz/WJMsBzwnyZZJ9gM+lGSFcT+updXVHfxEknfC/E7Epo47yb37jmWUkmTqojTJZknWS7Ju33H1ado52TnJQ5LMWJl9kkw79rX7jueWcHZkz6a9md4LPAvYpaqOSbJiVV03uI8Wbtp53AO4Bli5qj7bb2SzI8mmwA+AC4DNq+pv/UbUryQbA58EvllVb+i2zcu/kyTbAO8HnlRVP+s7nlFK8kJgO+B3tBJLb66qM/uNql9JDgfuC1wL/AH4flV9vt+o5kaS59FqjV4MvKCqLuo5pCVmS1iPpiUO9wS+BbwCeEOSh1bVdb0GOEYGzuOBtNpz1wAfTrJ9r4HNnr8AH6V98Txi+p1da9nEG2jxui1tVY79k7wC5meLWJL/AN5Fl4AlWT/JbSbx/dCtqrJNVT0WWA1YA/hTkhX7jaw/SV4KrFZVj6IVO/9/wH8muVu/kY3G4Pu6O8adaZ/3ywNvSbJJX7EtrYn7Qx0nA4nDi4HXAD+rqrcBHwQ+meQ+SZ4OvK3HMMdCkuWS3B54FPBY4O60D6Tjktyq1+Buoa4Lcvuqej6wG/DOJE/r7ntCkvWq6sZegxyxqeSqS7QeDXwB+C7wVmDbJK8buH+iE7Fpx1fA0cCGSV4FHAt8Drh/H7HNphlex58leRGwLrBP9xm6eZKV5za6fgyek+7zbjNgiySrVdW5wEm09Zgnslty6nMuyS7ApsD3quqMqprq/XhFknv0GOISMwnrwbRsfg9gJ+DpVfWXJLevqsOBVwHvBJ5B63bRNNM+pFcE/g5cBrwReCSwW1XdAOyTZCy/lNKW+XoOLeGgqn4MPBn4ryTvp3VDrdJfhKOXZB3gaUnW7DbdAfhYVX2DdsFyALBDklfDTRc3k2iq9TzJFkl2Bs4F1gf2Bs4AHg/8CXhAj2HeYtN6CbbsxjqdQUs69gC2q6prkjwbeCXt73+iTTsnewN/Aw6hDVN410Aidi1wl/4iHa0kuwJvALakrT39ZICqOoD2Pjh4nFpHTcLmWJcMvGtg061pVy+PSnIo8KUkXwe+CexD+7A5da7jXNZN+0DaCzig6769EjgQ2KOqrkryFGB/YKzGCqRZC9iVNk7woiRPT/IOWuvHY4EfAVtU1Rk9hjoXHtn97JZkddoV715JVu2S7N8ApwB7JLlrj3GOXJeA7US7QLu6qv4OPJM2jvRztAk9D6WNmRpbA3/bzwXe3m2+gtYC+iNaa/BBtL+Nl1bV5b0EOocGzsmHgKcCy3fj4V5DG6ZwapI3AjcCH+st0BHq3vuPAXasqmfSktC9kuwGUFVPBQ4bp6E8I107Uv+uqn6e5K9JHgH8FPghsDnwUuA9tLU2nwKsV1Vj/UE6SgMfSM8B9gP27LY/L8ltgBOSnEI7t0/rrhDHRnd8lyT5X9oaan+gXfleSOuGOTDJ2ZPc6jOlqo5OmxH5cODGqvpIkgcD3+0+fDegXQFvP+kJaZeYPwd4AnB+kgcCD66q9yd5FPAm4DVV9X99xjkb0iaj7AVsXVXndduOAjYBnkgbF/aUqvpNb0HOsST7AutU1VZJlk+yHfBb4C20i7N7AU/tWglXHKdkZEj3oQ05+Q7tuL/RbT8oyfVVdXRV/bW36JaCsyPnSJJbVdU1A7e/QKv39KSuxeZW3R/OzrQrm22r6py+4h0HXbL1IeDVVfXHwXOc5HHA1cC5VXVWj2EusSSPAVYC/g+4gdbq9dOq+mvXDbELreXj2h7DHLnB1s7u9k7ANrQB+Z+hddk/gNb684aq+moPYc6p7j3/LVrr+eq0L97tad2ybwQ2rqrfTD9342Ahr/fGtL/tp3djvq6rqhuS3G6+zg7uut7uA6wJXE9Lxn8OvIT2mXEQcHvahdrVPYU565L8J3CPqjqiG0P9cODQqvplktWArYBTxvE70+7IOZBkVeCAJHdOsn+S11XVbsDltO7HVYDrkzwJeD2w+zi+mUZt+kDdqrqU9h7eIslyAwnYw4CTquoHY5iAHUT7Mn0c7cP1LlV1bJeA7Qe8CHjFfEnAkjwqyTOT7NUlWV+mjQvavapeWVXbAFtV1Venvz8mwdQxJdk8yYOAtWhjApcDPlFVzwB2AO4IXDvVKjSGCdhyA63bUz00VwIPTrJrVV3dJWB7Ay8epzE/s+x7QIC/Au+qqk2AWwF3q6o/0lrNjx33BGzgfb9c2hjqTYAHdp8Db6P1Ih2a5AFVdWVVfWVcvzNtCRuxgS+T3Wj99H8CHltVF3T3f4HWlbIXsA7tam+sus7mwrQxYPcAluuu+J8ObAwcX1U/6K4U9wb2raoLewx5iXVd1G+nNbc/C3gxbbLB3sCfaVPQ/6eqTustyDmUZCvazOAv0Vq81qaNDdsK2B34CfBh4IZxSzqWRJInAK8FPkEb37h/Vf1w4L43Ai/vJiqMtST708a0/YI26/P2tBmfn6AlH1sBe1XVr/qKsS9donrj1L/dttfRLkq2r6rrp+0/dq2h0yVZUFVnpc1w35U2vOSUqvpkN/5tI9pn/dhelNoSNkLT/gjOoX2orMZANfyuRWx54EjgLBOwfzctAXsB7Tx+LMlbq+pIWrP8S9MmNLwCOGQME7BtaF88O9C6G7erqg1pXW/H076M3j0fErDcNHt4F+CtVfXaqtoJOBM4qqqOB/4XOKGqrh/3L5pFSVue6QW0bthLu58/pq2YsDptEsorq+ob49gSmFaGZ+Pu9+fQBpx/AngSbYzstcDDaK/932gznuddAgY3lWeYSsSSPIvWQrR9VV2fmy9tNnatoQBJHp1u9Yckd6GN7X1i18vxJeBU4KlJ9qmqlwPPH+cEDByYP1IDicMWwH9V1RZJ9gG+1r2JfpjkgVW1Q5I7juMfzVwYOI8PoX0gP5Q2Fubn3WDMl3dfVncD/jR2AzNbzZvn08Z5XZBkAXBCd/f3aSUIrph+pTtpBpLt1WnJxuXAqgO7vBB4e7ffZ/qIca4MnIuiTcp4Am229D5VdWHagOyfADt3Y0rHrtUjrd7bG4AnJtmAdqGxHe04b6CNiXwd8I6q+lA/Uc6tmV7HwdYv+Fci9lngw93vK0zI58M6tAK8a1bVGUkOoZXjuaGqjgE+mmR3YNMkt6mqi/sN95YzCRuxtPIJz6d1LVFVH0+b6XVkki/T6h892BawRUurjnwo7Utp5S5ZeQDwk7RipU+jTV0fK0nuR2vNeH13TMsBf6TVvfoo7Up3z0l/fwx0228F7JTk+bRiu59I8seq+i5wT+AewO2TXDhuSccwBr6EbwtcUlWXdC0c7wXuWVVnd93Wr6PNgrsIxq/Vo2u12wI4jVZYdA3a5IINgR26C9ZNaLOe907yM+DKcTvOJTVwwfl62ioZf+3GO03vhly+urIcSVaegDFg9weoqi+m1YT7Y5Ltq+pzSW6grSKzEq1l9CraclWX9hjyrLE7cpYtpEvge8Cdaf3ZAFTVEcDBtMGVW0z6F+zSmH4eq+oPtOro19Jqqt2++yN8MHCfJHcYh+6YJCt2Xy5TLXv3pLX6HJBk7e5D9vvAp2nvjwPGdcDpkugSsC2B99G6HK/rxjjtDnwgrTbSB4DXVtUFk/pl3J2HbYFjkhyRNhj/LcDHaRduB9HO0WE1pqUZctMg/P+mtXx9Czixa8Feg1Y7EVq5hZ/RxrtdMamv+XRJXk4bF7oy8My0pdgGuyFTrT7eVOHSF2X8l6l6EvDWJJtW1dm098ZHk2xeVV8AXk7rlj+INmP2/B5jnVUOzJ9F08YuHUibSvxrWiHJ42mtHW9d2P5auO48bkz7YH41bWDmbrR6at+rNmtwbM5jkvvQPkxCO6b9aUss7QJcR+t6Gfsm9iXVXeW+HfhuVX2l63LYlTZW8v9oVfJvVVW/GqfXe0kl2Rz4L+DdwNa03orv0MbA7UNbEeLcqvreOJ6HaZ+Ru9C+XG8Avjj12Zjkf2jd0OvSSvj8uq9458K0c/JaWiJ6SFVdnVaa4RXA16vqfdP+35602dJPqTGtKTmtde8IWpf0a6rV03wOrbFi76o6Ka08y3VVdVV/Ec8+uyNn0cAf0nNoXyB7Ar+kNbPvAxyetrTEYYP7a+G687gTbabgV2gfTC9Mcmva0iXXJfkqrUL0uPgdbTbsE2jH848kJ9OWHtqGNv7hNTXP6iBV1bXdeTgibcbrr2mtyG8GtuxaQqf2nci/myRr00rU/Kmqvp3ke7SEfUtaovLhGii+OY7nYeAzck/acW3T3fWVbhzQK6tq6+5i5YKp7tZJNS0B24rW3f5g4FO0Mgw/os1+fXuSC6rqS92+e9OK9j51XBMwuNlakM+gTVpbnzYE4WnVChDfCHwjydZVdUqfsY7KuDdhLnOSrEGbTr87bYX3k4EFtC/dg2lLLKw1Dl1nc23wnHS/r0pr9dqJNrv05WkDUI+i1cP5UVUt8+UJBo+rGzz7BdqX7TZJnlRVN1bV94ATgfNos2Xnnar6JO3v5uBqM5++DlxCm/06cZKsmuSx3e//QSu/8VXgsUme0CVcb6OtkrA9bZzY2Eur4/ck4G1VdWG1mcz7AQ9P8k6Aqvr1pCdgcLOkdH/aWLjdgM/TLtjX794DP6ItTXV0t++DaBem+41rl/SgtLG9zwOeU1UPAo4B3tZ1TX6QtprM3/uMcZRsCZtlVXVZ2npn9wCe2A0wXY72JjoF2LTmwTpnS2raFeEzaE3y96GtoXkGsFNVXZfkoCRXVdVHewx3iQwc15NoLV6nVCsp8Hfg6d2/19Nq3ry/qi7rL9p+VdV34F/V8V9PG/8xqV/GAXZM8iraBceetJpYVwLPSnJjVR2X5A3AnWrMyq4swn1pg/F3TfKHqrq2qn7bjXd7S9qC7Rcv6xdXsyXJW2nfF68DqKqXdsnoF5M8uRsT+vOB/3IJbSb1WI6LWkg3+vm0EiS3By6tqlcl+RqtkPnO1coQTSxbwkagWk2Tq4AVktyXNrbj68BxJmALN5CobE67InwnbWzMBsBPugRsH+DZtDFCY6WL/c3A/YCT0mbEfgw4ijZN/8O0grPzIgFLcrckC23ZSauYvgrwkm582ES2GlfVlbSLjP8ALqqq06vVPDoO+CKtMvyOXWvvmX3GOhuSbJvksGrlJt5Bq5e4c7r6VtXqf+1YVRfNowQstMT7PrSleACoqhcAv6d9Bt5MVZ0xCQlY2mSqO9Jaei8FNusScGifi7/t7ptoDswfkbQKvwfTlp9Zl1ZkcGz77udC1yXzJtr4lz2q6oqu6f1jtPERd6FVCx+rJvi0hZWfRlvf8PRuzNM7gMdX1Y/TaiTdWN0ixZNq6gO4G+/zYdrV/F/6jmuuTRuMfHvaDNmDaSUpntFt3wS4P3DmuI6Fmd7ikWQzWuvmd6vqLd3fwf1orTyfqm7G33yRthj3HWkXZw+ljQM7pKo+P7DPzeqDTYq09R//k1YX7GO0YRjPBM6lDce4L23Cwdm9BTlHTMJGKG19szvQvmDn3ZfN4ixsdlduWnboA7SK6Jd3LSbX0mbHXdJDqEul64ZenlZa45HAO4EvdIPQ9wU+Cjyiqk7sMcw51SWkrwQOr6pj0uod3TBtn+WrrRO4MrB2TUgJl+59vHJVnZ/k8cBjaEnWh5KsR1uM/nzg/bTagq+chMQ8yVp1U72z/wAOA37YJWLPpXVNvn7SW4EXkpTuDGxLqwJ/OC0p+Qjw31X18YH9JioR64YaPLuqHp/kU8DqVbVT2nJ0m9BaBb9cA5NxJplJmHqX5Nm08QCr0MpQ7EVrmv8K8P1x/XBOq2V2YZeMvZx2jJ8HftwlGU8FTq6q3/ca6BxKck/ajOEjq+pZ3bbBLoqpBGxN2iD1Z1TVGX3FO1uSrEYrNXAZbebnW2gFWF8GfKYbB7MWLTFfQBsLN5ZrQU57PbegtXTsVFW/6LqaHwi8Czi6qt6aVvl8IgpvDiPJLnXTLMdtgR2B31bVu7rk/JlVtUuvQc6i6UlkWj3ANWnj4B5BG35yTZK7VtXpPYXZG5Mwzbm0JZrO735/Lm2m1EG0sRFHVNUbuu1b0KblH99ftEsnrbzG7sAFtDVBX5LkNcBtaMnl/03S1e1MBrog16J93vwtyb2Ak2gFR9/R7bdcd/9UAvYFWovACTM++JhJq4v1EGAtWkvQR7uu6M8D/6+qXtXtd8eutWzc64A9h5Z03odWlHXPqvpld9/HaBcle41T6/bSyMCSQl0385toSdfU670zrUvyk7T3/ER+LnQtYFfRLrDvR5uY8qRq614eBDyeNhv+n+P2vr8lHJivOdVd+b21GwsDrStiR9of4K+5aW3A99EmM4zdYr1pi3E/q/t5CW3q/Yeq6lBa9+RWwK16DHFODCRgOwGfAT6T5CndmL7NaZW+XwGtXtBAAvZl4HWTkoANDDz/Eq3MwOrAlkkWdF2tuwBPSPK2br/zu3/H7otoIAF7FvB0WnJ5CPA5WgX0RyY5AFiJtg7mpCdgqwEv6wahH0KrAfYW4E5phVmpqqOB39BmSI/daz6TwQk1acWXP0Br+doa2JSblmd7IW082Muq6qpxfN/fEpao0JxJq3j8Atrg3FsluSutON8XaSU8dumapZ+X5Jyq+kSP4S6VJHcG/gEcU1W/7TY/LMn/pdXDeTmwalX9s68Y50qXgD2O1g23HfAaWgmC21bV+9KKU/4gyeeAP3djw55BayEbuxmwC9MlojekrRH6HNpYrzfTijfvlOToqvpzd3Fypx5DnTVJpgoPv5JWUPlZtKRrVVrCeX/guTW5pUf+paquTHIFbabjj6tqK/hXgvKCtEW4/wpcQVsPscaxBXS6aS2id6Ill4+otij3T4HXApsBp9OWp3rywOflvGISpjlTVZemVbj/DHB5Vd0zyZG0sT97V1umYy9aC9KO/UW6dLqxbdsCX6LVQDq8qi7o7v4NcNuquoL2gTvRBj6E16XN/HsorQvi5cBh3TigNyTZoFqpBgCq6u29BDwCAy2BW9AKNz+K1gryUuCzwJOBpyT5bFX9mTZDbOxV1T+THEer9H4O8AfgbFrL9htoS89M9EXItETqdFq5hdsmWa+bbPETWkL+HFql+KfVtEW6x9W0BOy5tDG+awDvSPKXqvpal4S+F/hptYKs85ZJmObEwB/mn2njoi5IsnJVfSdtpuBbk+xAG6y527gN0OxifzbwhK5l4860emAvoLVwbE5rAZloA6/z6sBlVfWZtFnCn6VVwj+5S0q2SvKJGpg1PAktAHDT5IIuAduMtvj2U2nj4B5M+/I5kNY6tBuTuULCJ2mlJ86oNjNyT9rYz+vnUwKW5O7A92mzo58JfC3JrlV1VpK7V9V/Dfy/f5spPI4Gjn1HWqvnXrRjvy/wkCQ/qKqvps1+nlfLsy2MA/M1UtO/WLsroFvTrgK3oyVc53RJy2XAcjWGlcG7cS5rda07UzP8DqDVAdqItkTLaf1GOTeSbEdb2/McWmHd42l10VagTUo4iFYz7ce9BTkiaaUmHg58rVopkscAO1fVgV0yejfgPbTxjy8BVqgJW5B4UNqEi31praF71IQvxj0oySdpYz9XAL5NuxA5kJaU/ISWhD9lEi48pkuyPm25pW9V1X5dwvVK2qzIY2hjBSdyObIl5cB8jdTAVdHBST4MvKOqLq+q19OuED+b5E5VdWZVXTyOCVjnbOCR3dXt1NXshbQSFPvOowTsQbQut9cADwOeQvuy+RIwtRbihycxAeusR+t6Xi2tGvg5wPZpCxBf170Pfg6sDTwXuGZwAPMEWhm4kXaxNdEJ2LSB6PsBV1TVk2mzQ1epqsuq6g20v42/0GaG1iS+/l0L98HAtkn2qKqracd9HW0S1ko9hrdMsSVMIzGtSf7etO6JF3U/t6mq/+zuO5xWoG/bcW6KT1u4/aW0C5sTaV2uB9OudP/YY2hzJslGtMXWL6Qlpe+mffmeNTUWJsm6VXXBpHQ9DhoYA7Y+bTzUL2krA2xJ6475FG1G2BtpyxXdvqpe0le8c2USX+vppn3evZNW8/DHtLGQ13YtoSsDGw5+HkxKF+RMulbxNwJvrKrPpdWJu+18mJQxLJMwjVRa8cE1aFWRj+y2HUebIfjo7vbtx7gF7F+6lo8dgR1oa6G9sbq6SJMuybq0BPsXwH605Ui2rqq/pNXHejBtUP4Nk/yFnOSxtLEv5wJPoH0Rfwe4M+34L6PNFt0QOIBWS25e1UWaZN0Y0A1o3Y9vprWE79fddyRwQVW9vMcQ51xayZ4jgBdW1Rf7jmdZYxKmkUlbgui1tCnYV9KWJjmxu++HtIHb2/QY4kgkWQmg2mLM80JaLawv02odXURrCfsabfzfR2hL8IxlBfhhJdmUllQdU1UndgnZ02hjYz4OXE0bhP+ftKWJdq22aLUmQNpqED+mJRwvAY6kzXj9K23d27sD28/HsVBpVfLPqAlYiH62mYRpJJI8g9YicChtMOYzaF11x1bVj7p9Nqyqc3oLUrdYNxD91lX1h6478sW0kgS3o614cAVtDNjXJrFbamASRmiLzF9NS7xO77omt6ANxj6BtjbkcrSZkifUPFkbbz5J8kTaOpD70BKy7WitwJfSChBfP+ldkFoyJmEaiSQfonVL3aUbE7QpbYr6rYHPVdVP+oxPt1xaNfDX0+p/HUVr8XkO8KmuJWh1YMWuRMFEJWBJVq+qy7vfH0krybEuravxPVX13oF9HwtcXFWndrfHvhaUZpbkCcB/A4dW1Ven3WcCppuxTphmVTcl/69V9axuevr/JLlf3bR479bAn/qNUrOhWjXwl9MqXr+MNg5sF2CzJDsPtnJOWAK2KnBsknfTltV6X/fvubSu2Fd3OefhAFX1ne7/pRoTsAlWVd9IciNwZJIrq+rbA/eZgOlmbAnTLTIwI2zq34/QZga9puui+gitUOnm1Sri36qqruk3as22tCWpbkVb7WBTWl20H01aC9iUrtvpEOBy4FVVdVLaMlyPp5XmmFp8/tAew1SPkjwU+ImJlxbFOmG6RQa+YO/Y3d6PVqLg5V3NrP1odZOmFmOeN4PV55OqurSqLqyq1wE/oxXonKgWsEFV9RXgVcCDgMd1m8+m1QU7g1aw9dsL/9+aD6rqR914wUlcEUGzxCRMS2VaYcL70xZm3gKgql5AG6D8oST3qKrdafWjJvZLWTd7T5wB3CltIeeJ1XUz7QPs0xWkvI62ePsTgEuq6geTWIhTS8aWMC2K3ZFaYtMKE65Dq378VGABcFRVndCNBzuDVin9lfOpXMN81iUdTwD+VBNeIX1Kku2BTwDfoyVhR096OQ5Js8MkTEstydT6j9vRFqnekbY23lG0ekhPoyVgf+4tSGkOJNkZOAx4RrVFyidyLJyk2WUSpqWSZA9ahfTdq+r0btvGwFa0BWpXBvauqt/0F6U0d5KsVVWX9B2HpPFhEqahTOuCXIu2NM/VVXVUktWq6sqBfW8HLOf6YJIkzcwkTIs1LQF7BrA+rbtxK+CRU8twJNkb+HVV/ay3YCVJGhPOjtQida1cUwnYI4CH0iqCH0pbpuXTSTZK8jTgpbRlaiRJ0mLYEqYZJbkHbbHhTwCrAscD1wDPpK0PuA7wGuAOtAKtL6yq0/qJVpKk8WISphkluTdwAW0x5itoidj7gK8DH62qq7r9VqK9l6yEL0nSkEzC9G8GFxhO8nBaodVrgXfSFil+L/Bl4DNV9Y+ewpQkaaw5Jkz/ZiABezZwIHAibbH3g2gtYwcCTwd2tSK4JElLx5YwLVSSHYD/Brarqj8neTCwC23B4g8BtwX+WVVn9ximJEljy5YwzWQ94HNdArZCVf0Y+AJtfNjewB9NwCRJWnomYZrJ2cAjk9x9qg4YLTG7HPiYi9JKknTL2B2phUqyBq3u13K0MWG3AZ5PW6bozD5jkyRpEpiEaUZJ7khblHsH4FLgjVX1y36jkiRpMpiEabG6OmBU1bV9xyJJ0qQwCZMkSeqBA/MlSZJ6YBImSZLUA5MwSZKkHpiESZIk9cAkTNJYS3JDkl8M/CxYisfYKcm9RhCeJM1ohb4DkKRb6J9VtektfIydgG8Avxn2P3TLeV2/+D0laeFsCZM0cZI8MMkJSX6a5Piu8DBJnpnk5CSnJvlyklWTPIxWkPitXUvaXZJ8L8lm3f9ZO8lZ3e/7JPlikq8D30qyWpIju8f8eZId+zpmSePHJEzSuFtloCvyK0lWBN4L7FJVDwSOBP672/foqnpQVd0P+C3wjKo6ETgGeElVbVpVZyzm+R4KPK2qHgO8EvhuVT0I2IKWyK02gmOUNIHsjpQ07m7WHZnkPsB9gG8nAVgeOL+7+z5JXg+sCdwaOH4pnu/bVXVJ9/tWwA5JXtzdXhnYiJbgSdIimYRJmjQBTquqhy7kvo8DO1XVqUn2AR49w2Ncz009BStPu+/Kac/1pKr6/VJHK2nesjtS0qT5PbBOkocCJFkxyb27+1YHzu+6LPcc+D+Xd/dNOQt4YPf7Lot4ruOBg9I1uSW5/y0PX9J8YRImaaJ0C83vArw5yanAL4CHdXe/Gvgx8G3gdwP/7SjgJd3g+rsAbwOeneREYO1FPN3rgBWBXyb5dXdbkobiAt6SJEk9sCVMkiSpByZhkiRJPTAJkyRJ6oFJmCRJUg9MwiRJknpgEiZJktQDkzBJkqQemIRJkiT14P8DAslAxV7oz58AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the indices of the top 8 features\n",
    "top_feature_indices_perm = feat_import_perm.argsort()[-8:][::-1]\n",
    "\n",
    "# Get the names of the top 8 features\n",
    "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
    "\n",
    "# Plotting the permutation importances for the top 8 features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(top_feature_names_perm)), feat_import_perm[top_feature_indices_perm], align=\"center\")\n",
    "plt.xticks(range(len(top_feature_names_perm)), top_feature_names_perm, rotation=45)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Permutation Importance\")\n",
    "plt.title(\"Top 8 Features Based on Permutation Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "758962dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['artist', 'circumference', 'contrast', 'year_sold', 'brightness',\n",
      "       'surface', 'return_sp', 'medium'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "split_percentage = 0.80\n",
    "split_point = int(len(df) * split_percentage)\n",
    "\n",
    "# step 3: Split the data in a training and test set\n",
    "train_set = df[:split_point]\n",
    "test_set = df[split_point:]\n",
    "\n",
    "# Get the indices of the top 8 features\n",
    "top_feature_indices_perm = perm_pipe.importances_mean.argsort()[-8:][::-1]\n",
    "\n",
    "# Get the names of the top 8 features\n",
    "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
    "print(top_feature_names_perm)\n",
    "\n",
    "# splitting in training set X and training set y but now only with the features we want.\n",
    "x_train = train_set[top_feature_names_perm]\n",
    "y_train = train_set['target']\n",
    "\n",
    "one_hot_cols = ['artist', 'currency', 'medium', 'surface', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the columns to encode and scale (standard)\n",
    "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
    "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
    "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "57d4ab06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'estimator__max_depth': 20, 'estimator__max_features': 'sqrt', 'estimator__n_estimators': 200}\n",
      "Best MSE: 1394175578467.1743\n",
      "Cross-validation scores: [0.30978833 0.06487539 0.38611091 0.53533244 0.3119405 ]\n",
      "Mean CV R-squared: 0.32160951372315905\n",
      "training MAE: 0.00039416477676918545\n",
      "Train R-squared: 1.0\n",
      "Training MSE: 9.189006710903663e-07\n",
      "Training RMSE: 0.0009585930685595251\n"
     ]
    }
   ],
   "source": [
    "# Define the estimator for Gradient Boosting\n",
    "estimator = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_depth': [7, 10, 20],\n",
    "    'estimator__max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "# Create a grid search object\n",
    "time_series_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the best MSE and corresponding negative value\n",
    "best_mse = -grid_search.best_score_\n",
    "print(\"Best MSE:\", best_mse)\n",
    "\n",
    "# Calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# calculate and print MAE\n",
    "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
    "print('training MAE:', mae)\n",
    "\n",
    "# Make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# Print the R-squared score of the model on the training data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# Print the mean squared error of the model on the training data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Training MSE:\", mse_train)\n",
    "\n",
    "# Print the root mean squared error of the model on the training data\n",
    "rmse_train = sqrt(mse_train)\n",
    "print(\"Training RMSE:\", rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1043e850",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5efd841f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 12992850941333.16\n",
      "Test RMSE: 3604559.743066157\n",
      "Test R-squared: 0.2905600260014307\n",
      "Adjusted R2 is 0.24357724626642618\n",
      "Test MAE: 2485534.274295622\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator with the best parameters\n",
    "gbr = GradientBoostingRegressor(n_estimators=100, max_depth=2, max_features= 'sqrt',random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d303bb96",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ce795",
   "metadata": {},
   "source": [
    "## default dataset with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c9ee527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f5f0190f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>price_EUR</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>52.601</td>\n",
       "      <td>101.140</td>\n",
       "      <td>2018</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>EUR</td>\n",
       "      <td>87500.000</td>\n",
       "      <td>True</td>\n",
       "      <td>536.000</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Theo Van Rysselberghe</td>\n",
       "      <td>49.258</td>\n",
       "      <td>136.516</td>\n",
       "      <td>2010</td>\n",
       "      <td>Paris</td>\n",
       "      <td>EUR</td>\n",
       "      <td>79000.000</td>\n",
       "      <td>True</td>\n",
       "      <td>243.600</td>\n",
       "      <td>Oil-Based Paintings</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1862</td>\n",
       "      <td>True</td>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  artist  contrast  brightness  year_sold city_auction  \\\n",
       "0      Pierre Alechinsky    52.601     101.140       2018    Amsterdam   \n",
       "1  Theo Van Rysselberghe    49.258     136.516       2010        Paris   \n",
       "\n",
       "  currency  price_EUR signed  circumference               medium surface  \\\n",
       "0      EUR  87500.000   True        536.000              missing  canvas   \n",
       "1      EUR  79000.000   True        243.600  Oil-Based Paintings  canvas   \n",
       "\n",
       "   year_born   dead  return_sp  \n",
       "0       1927  False      0.216  \n",
       "1       1862   True      0.259  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0925b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'price_EUR': 'target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5dc85172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>target</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>52.601</td>\n",
       "      <td>101.140</td>\n",
       "      <td>2018</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>EUR</td>\n",
       "      <td>87500.000</td>\n",
       "      <td>True</td>\n",
       "      <td>536.000</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Theo Van Rysselberghe</td>\n",
       "      <td>49.258</td>\n",
       "      <td>136.516</td>\n",
       "      <td>2010</td>\n",
       "      <td>Paris</td>\n",
       "      <td>EUR</td>\n",
       "      <td>79000.000</td>\n",
       "      <td>True</td>\n",
       "      <td>243.600</td>\n",
       "      <td>Oil-Based Paintings</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1862</td>\n",
       "      <td>True</td>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  artist  contrast  brightness  year_sold city_auction  \\\n",
       "0      Pierre Alechinsky    52.601     101.140       2018    Amsterdam   \n",
       "1  Theo Van Rysselberghe    49.258     136.516       2010        Paris   \n",
       "\n",
       "  currency    target signed  circumference               medium surface  \\\n",
       "0      EUR 87500.000   True        536.000              missing  canvas   \n",
       "1      EUR 79000.000   True        243.600  Oil-Based Paintings  canvas   \n",
       "\n",
       "   year_born   dead  return_sp  \n",
       "0       1927  False      0.216  \n",
       "1       1862   True      0.259  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "725ad9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: sort your data in ascending order 'year_sold'\n",
    "df = df.sort_values(by='year_sold')\n",
    "\n",
    "# step 2: define a split point. We opt for 80%\n",
    "split_percentage = 0.80\n",
    "split_point = int(len(df) * split_percentage)\n",
    "\n",
    "# step 3: Split the data in a training and test set\n",
    "train_set = df[:split_point]\n",
    "test_set = df[split_point:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "60a49c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the training set into features X and target variable Y\n",
    "x_train = train_set.drop(columns=['target'])\n",
    "y_train = train_set['target']\n",
    "\n",
    "#splitting the test set into  features X and target variable Y\n",
    "x_test = test_set.drop(columns=['target'])\n",
    "y_test = test_set['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7aaef445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the columns to encode and scale(min-max)\n",
    "one_hot_cols = ['artist', 'city_auction', 'currency', 'medium', 'surface', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
    "        ('num', continuous_transformer, continuous_cols)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "395e8a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "\n",
      "Test MSE: 11003321795361.916\n",
      "Test RMSE: 3317125.5320475763\n",
      "Test R-squared: 0.3991929589859148\n",
      "Adjusted R2 is 0.3464193675454883\n",
      "Test MAE: 1534310.1636480307\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator with the best parameters\n",
    "gbr = RandomForestRegressor(n_estimators=100, max_depth=20,random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('Random Forest')\n",
    "print('')\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0f2a9e",
   "metadata": {},
   "source": [
    "### interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e1c13513",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = ['artist', 'currency', 'medium', 'surface', 'signed', 'dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
    "        ('num', continuous_transformer, continuous_cols)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "93bc486c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimator = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "perm_pipe = permutation_importance(pipeline, x_test, y_test, n_repeats=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "feat_import_perm = perm_pipe.importances_mean\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.bar(range(len(feat_import_perm)), feat_import_perm, align=\"center\")\n",
    "ax.set(xticks=range(len(feat_import_perm)), xticklabels=x_test.columns)\n",
    "# Set properties of x axis using setp, we will rotate the labels by 45 degrees\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3219ede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Feature  Importance\n",
      "0          artist       0.598\n",
      "7   circumference       0.258\n",
      "1        contrast       0.041\n",
      "2      brightness       0.010\n",
      "12      return_sp       0.006\n",
      "8          medium       0.004\n",
      "5        currency       0.002\n",
      "9         surface       0.001\n",
      "6          signed       0.000\n",
      "11           dead       0.000\n",
      "3       year_sold       0.000\n",
      "4    city_auction       0.000\n",
      "10      year_born      -0.002\n"
     ]
    }
   ],
   "source": [
    "perm_importance_df = pd.DataFrame({'Feature': x_test.columns, 'Importance': perm_pipe.importances_mean})\n",
    "\n",
    "# Sort the DataFrame by importance score in descending order\n",
    "perm_importance_df = perm_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(perm_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e3a9a",
   "metadata": {},
   "source": [
    "#### correlation with target/price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa9f9db",
   "metadata": {},
   "source": [
    "##### numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c38f3119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered Features by Correlation with Price:\n",
      "         Feature  Correlation with Price\n",
      "0      year_sold                   0.217\n",
      "1      year_born                   0.124\n",
      "2  circumference                   0.109\n",
      "5      return_sp                   0.040\n",
      "4       contrast                  -0.053\n",
      "3     brightness                  -0.109\n"
     ]
    }
   ],
   "source": [
    "numerical_features = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "data_numerical = df[numerical_features]\n",
    "\n",
    "# Calculate correlations with the target variable (\"price\")\n",
    "correlation_with_price = data_numerical.corr()['target'].drop('target')\n",
    "\n",
    "# Create a list of features ordered by their correlation with the target variable\n",
    "ordered_features = correlation_with_price.abs().sort_values(ascending=False).index.tolist()\n",
    "\n",
    "ordered_features_df = pd.DataFrame({\n",
    "    'Feature': ordered_features,\n",
    "    'Correlation with Price': [correlation_with_price[feature] for feature in ordered_features]\n",
    "})\n",
    "\n",
    "ordered_features_df_num = ordered_features_df.sort_values(by='Correlation with Price', ascending=False)\n",
    "\n",
    "# Display the ordered list of features with correlation scores\n",
    "print(\"Ordered Features by Correlation with Price:\")\n",
    "print(ordered_features_df_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4e1014",
   "metadata": {},
   "source": [
    "##### categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "db70c64e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered Features by Correlation with Price:\n",
      "                            Feature  Correlation with Price\n",
      "9              artist_Rene Magritte                   0.418\n",
      "24                   surface_canvas                   0.233\n",
      "30                        year_sold                   0.217\n",
      "20       medium_Oil-Based Paintings                   0.188\n",
      "32                        year_born                   0.124\n",
      "31                    circumference                   0.109\n",
      "12              city_auction_London                   0.100\n",
      "13            city_auction_New York                   0.091\n",
      "19                     currency_USD                   0.072\n",
      "17                     currency_GBP                   0.054\n",
      "33                        return_sp                   0.040\n",
      "22           medium_Watercolour Art                   0.037\n",
      "5     artist_Jan Breughel the elder                  -0.012\n",
      "10     artist_Theo Van Rysselberghe                  -0.022\n",
      "14               city_auction_Paris                  -0.042\n",
      "3             artist_Jacob Jordaens                  -0.045\n",
      "6   artist_Jan Breughel the younger                  -0.046\n",
      "28                         contrast                  -0.053\n",
      "1       artist_Eugene Verboeckhoven                  -0.056\n",
      "7               artist_Paul Delvaux                  -0.057\n",
      "2              artist_Felicien Rops                  -0.058\n",
      "26                    surface_other                  -0.058\n",
      "18                     currency_NLG                  -0.064\n",
      "0           artist_Anthony Van Dyck                  -0.075\n",
      "23                   medium_missing                  -0.081\n",
      "4                artist_James Ensor                  -0.087\n",
      "25                  surface_missing                  -0.095\n",
      "11           city_auction_Amsterdam                  -0.101\n",
      "16                     currency_EUR                  -0.101\n",
      "15             city_auction_unknown                  -0.102\n",
      "29                       brightness                  -0.109\n",
      "8          artist_Pierre Alechinsky                  -0.116\n",
      "27                    surface_paper                  -0.126\n",
      "21      medium_Pen and Ink Drawings                  -0.172\n"
     ]
    }
   ],
   "source": [
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "data_categorical = df[categorical_features]\n",
    "\n",
    "# One-hot encode categorical features\n",
    "data_encoded = pd.get_dummies(data_categorical)\n",
    "\n",
    "# Concatenate the encoded categorical features with numerical features\n",
    "data_combined = pd.concat([data_encoded, data_numerical], axis=1)\n",
    "\n",
    "# Calculate correlations with the target variable (\"price\")\n",
    "correlation_with_price = data_combined.corr()['target'].drop('target')\n",
    "\n",
    "# Create a DataFrame with feature names and their correlation scores\n",
    "ordered_features_df = pd.DataFrame({\n",
    "    'Feature': correlation_with_price.index,\n",
    "    'Correlation with Price': correlation_with_price.values\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by correlation scores in descending order\n",
    "ordered_features_df_cat = ordered_features_df.sort_values(by='Correlation with Price', ascending=False)\n",
    "\n",
    "# Display the ordered list of features with correlation scores\n",
    "print(\"Ordered Features by Correlation with Price:\")\n",
    "print(ordered_features_df_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fc6def",
   "metadata": {},
   "source": [
    "###### cat by cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "78cb964f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered Features by Correlation with Target for Categorical Feature 'artist':\n",
      "                            Feature  Correlation with Target\n",
      "9              artist_Rene Magritte                    0.418\n",
      "5     artist_Jan Breughel the elder                   -0.012\n",
      "10     artist_Theo Van Rysselberghe                   -0.022\n",
      "3             artist_Jacob Jordaens                   -0.045\n",
      "6   artist_Jan Breughel the younger                   -0.046\n",
      "1       artist_Eugene Verboeckhoven                   -0.056\n",
      "7               artist_Paul Delvaux                   -0.057\n",
      "2              artist_Felicien Rops                   -0.058\n",
      "0           artist_Anthony Van Dyck                   -0.075\n",
      "4                artist_James Ensor                   -0.087\n",
      "8          artist_Pierre Alechinsky                   -0.116\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame, and 'target' is the target variable\n",
    "categorical_feature = 'artist'\n",
    "\n",
    "# Select the specific categorical feature and the target variable\n",
    "data_subset = df[[categorical_feature, 'target']]\n",
    "\n",
    "# One-hot encode the categorical feature\n",
    "data_encoded = pd.get_dummies(data_subset)\n",
    "\n",
    "# Calculate correlations with the target variable (\"target\")\n",
    "correlation_with_target = data_encoded.corr()['target'].drop('target')\n",
    "\n",
    "# Create a DataFrame with feature names and their correlation scores\n",
    "ordered_features_df_cat = pd.DataFrame({\n",
    "    'Feature': correlation_with_target.index,\n",
    "    'Correlation with Target': correlation_with_target.values\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by correlation scores in descending order\n",
    "ordered_features_df_cat = ordered_features_df_cat.sort_values(by='Correlation with Target', ascending=False)\n",
    "\n",
    "# Display the ordered list of features with correlation scores\n",
    "print(\"Ordered Features by Correlation with Target for Categorical Feature '{}':\".format(categorical_feature))\n",
    "print(ordered_features_df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0ccf7219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered Features by Correlation with Target for Categorical Feature 'city_auction':\n",
      "                  Feature  Correlation with Target\n",
      "1     city_auction_London                    0.100\n",
      "2   city_auction_New York                    0.091\n",
      "3      city_auction_Paris                   -0.042\n",
      "0  city_auction_Amsterdam                   -0.101\n",
      "4    city_auction_unknown                   -0.102\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame, and 'target' is the target variable\n",
    "categorical_feature = 'city_auction'\n",
    "\n",
    "# Select the specific categorical feature and the target variable\n",
    "data_subset = df[[categorical_feature, 'target']]\n",
    "\n",
    "# One-hot encode the categorical feature\n",
    "data_encoded = pd.get_dummies(data_subset)\n",
    "\n",
    "# Calculate correlations with the target variable (\"target\")\n",
    "correlation_with_target = data_encoded.corr()['target'].drop('target')\n",
    "\n",
    "# Create a DataFrame with feature names and their correlation scores\n",
    "ordered_features_df_cat = pd.DataFrame({\n",
    "    'Feature': correlation_with_target.index,\n",
    "    'Correlation with Target': correlation_with_target.values\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by correlation scores in descending order\n",
    "ordered_features_df_cat = ordered_features_df_cat.sort_values(by='Correlation with Target', ascending=False)\n",
    "\n",
    "# Display the ordered list of features with correlation scores\n",
    "print(\"Ordered Features by Correlation with Target for Categorical Feature '{}':\".format(categorical_feature))\n",
    "print(ordered_features_df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ae16c9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered Features by Correlation with Target for Categorical Feature 'currency':\n",
      "        Feature  Correlation with Target\n",
      "3  currency_USD                    0.072\n",
      "1  currency_GBP                    0.054\n",
      "2  currency_NLG                   -0.064\n",
      "0  currency_EUR                   -0.101\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame, and 'target' is the target variable\n",
    "categorical_feature = 'currency'\n",
    "\n",
    "# Select the specific categorical feature and the target variable\n",
    "data_subset = df[[categorical_feature, 'target']]\n",
    "\n",
    "# One-hot encode the categorical feature\n",
    "data_encoded = pd.get_dummies(data_subset)\n",
    "\n",
    "# Calculate correlations with the target variable (\"target\")\n",
    "correlation_with_target = data_encoded.corr()['target'].drop('target')\n",
    "\n",
    "# Create a DataFrame with feature names and their correlation scores\n",
    "ordered_features_df_cat = pd.DataFrame({\n",
    "    'Feature': correlation_with_target.index,\n",
    "    'Correlation with Target': correlation_with_target.values\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by correlation scores in descending order\n",
    "ordered_features_df_cat = ordered_features_df_cat.sort_values(by='Correlation with Target', ascending=False)\n",
    "\n",
    "# Display the ordered list of features with correlation scores\n",
    "print(\"Ordered Features by Correlation with Target for Categorical Feature '{}':\".format(categorical_feature))\n",
    "print(ordered_features_df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "27178b06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered Features by Correlation with Target for Categorical Feature 'signed':\n",
      "        Feature  Correlation with Target\n",
      "1   signed_True                    0.135\n",
      "0  signed_False                   -0.135\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame, and 'target' is the target variable\n",
    "categorical_feature = 'signed'\n",
    "\n",
    "# Select the specific categorical feature and the target variable\n",
    "data_subset = df[[categorical_feature, 'target']]\n",
    "\n",
    "# One-hot encode the categorical feature\n",
    "data_encoded = pd.get_dummies(data_subset)\n",
    "\n",
    "# Calculate correlations with the target variable (\"target\")\n",
    "correlation_with_target = data_encoded.corr()['target'].drop('target')\n",
    "\n",
    "# Create a DataFrame with feature names and their correlation scores\n",
    "ordered_features_df_cat = pd.DataFrame({\n",
    "    'Feature': correlation_with_target.index,\n",
    "    'Correlation with Target': correlation_with_target.values\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by correlation scores in descending order\n",
    "ordered_features_df_cat = ordered_features_df_cat.sort_values(by='Correlation with Target', ascending=False)\n",
    "\n",
    "# Display the ordered list of features with correlation scores\n",
    "print(\"Ordered Features by Correlation with Target for Categorical Feature '{}':\".format(categorical_feature))\n",
    "print(ordered_features_df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a5ad160d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>target</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>72.213</td>\n",
       "      <td>133.827</td>\n",
       "      <td>1994</td>\n",
       "      <td>London</td>\n",
       "      <td>GBP</td>\n",
       "      <td>40694.870</td>\n",
       "      <td>True</td>\n",
       "      <td>507.800</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>62.101</td>\n",
       "      <td>174.389</td>\n",
       "      <td>1995</td>\n",
       "      <td>New York</td>\n",
       "      <td>USD</td>\n",
       "      <td>9730.240</td>\n",
       "      <td>True</td>\n",
       "      <td>322.600</td>\n",
       "      <td>Watercolour Art</td>\n",
       "      <td>paper</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                artist  contrast  brightness  year_sold city_auction currency  \\\n",
       "481  Pierre Alechinsky    72.213     133.827       1994       London      GBP   \n",
       "627  Pierre Alechinsky    62.101     174.389       1995     New York      USD   \n",
       "\n",
       "       target signed  circumference           medium surface  year_born  \\\n",
       "481 40694.870   True        507.800          missing  canvas       1927   \n",
       "627  9730.240   True        322.600  Watercolour Art   paper       1927   \n",
       "\n",
       "      dead  return_sp  \n",
       "481  False      0.100  \n",
       "627  False      0.013  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a6d4b16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered Features by Correlation with Target for Categorical Feature 'medium':\n",
      "                       Feature  Correlation with Target\n",
      "0   medium_Oil-Based Paintings                    0.188\n",
      "2       medium_Watercolour Art                    0.037\n",
      "3               medium_missing                   -0.081\n",
      "1  medium_Pen and Ink Drawings                   -0.172\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame, and 'target' is the target variable\n",
    "categorical_feature = 'medium'\n",
    "\n",
    "# Select the specific categorical feature and the target variable\n",
    "data_subset = df[[categorical_feature, 'target']]\n",
    "\n",
    "# One-hot encode the categorical feature\n",
    "data_encoded = pd.get_dummies(data_subset)\n",
    "\n",
    "# Calculate correlations with the target variable (\"target\")\n",
    "correlation_with_target = data_encoded.corr()['target'].drop('target')\n",
    "\n",
    "# Create a DataFrame with feature names and their correlation scores\n",
    "ordered_features_df_cat = pd.DataFrame({\n",
    "    'Feature': correlation_with_target.index,\n",
    "    'Correlation with Target': correlation_with_target.values\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by correlation scores in descending order\n",
    "ordered_features_df_cat = ordered_features_df_cat.sort_values(by='Correlation with Target', ascending=False)\n",
    "\n",
    "# Display the ordered list of features with correlation scores\n",
    "print(\"Ordered Features by Correlation with Target for Categorical Feature '{}':\".format(categorical_feature))\n",
    "print(ordered_features_df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5c68045e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered Features by Correlation with Target for Categorical Feature 'surface':\n",
      "           Feature  Correlation with Target\n",
      "0   surface_canvas                    0.233\n",
      "2    surface_other                   -0.058\n",
      "1  surface_missing                   -0.095\n",
      "3    surface_paper                   -0.126\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame, and 'target' is the target variable\n",
    "categorical_feature = 'surface'\n",
    "\n",
    "# Select the specific categorical feature and the target variable\n",
    "data_subset = df[[categorical_feature, 'target']]\n",
    "\n",
    "# One-hot encode the categorical feature\n",
    "data_encoded = pd.get_dummies(data_subset)\n",
    "\n",
    "# Calculate correlations with the target variable (\"target\")\n",
    "correlation_with_target = data_encoded.corr()['target'].drop('target')\n",
    "\n",
    "# Create a DataFrame with feature names and their correlation scores\n",
    "ordered_features_df_cat = pd.DataFrame({\n",
    "    'Feature': correlation_with_target.index,\n",
    "    'Correlation with Target': correlation_with_target.values\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by correlation scores in descending order\n",
    "ordered_features_df_cat = ordered_features_df_cat.sort_values(by='Correlation with Target', ascending=False)\n",
    "\n",
    "# Display the ordered list of features with correlation scores\n",
    "print(\"Ordered Features by Correlation with Target for Categorical Feature '{}':\".format(categorical_feature))\n",
    "print(ordered_features_df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8f5e0556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered Features by Correlation with Target for Categorical Feature 'dead':\n",
      "      Feature  Correlation with Target\n",
      "1   dead_True                    0.116\n",
      "0  dead_False                   -0.116\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame, and 'target' is the target variable\n",
    "categorical_feature = 'dead'\n",
    "\n",
    "# Select the specific categorical feature and the target variable\n",
    "data_subset = df[[categorical_feature, 'target']]\n",
    "\n",
    "# One-hot encode the categorical feature\n",
    "data_encoded = pd.get_dummies(data_subset)\n",
    "\n",
    "# Calculate correlations with the target variable (\"target\")\n",
    "correlation_with_target = data_encoded.corr()['target'].drop('target')\n",
    "\n",
    "# Create a DataFrame with feature names and their correlation scores\n",
    "ordered_features_df_cat = pd.DataFrame({\n",
    "    'Feature': correlation_with_target.index,\n",
    "    'Correlation with Target': correlation_with_target.values\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by correlation scores in descending order\n",
    "ordered_features_df_cat = ordered_features_df_cat.sort_values(by='Correlation with Target', ascending=False)\n",
    "\n",
    "# Display the ordered list of features with correlation scores\n",
    "print(\"Ordered Features by Correlation with Target for Categorical Feature '{}':\".format(categorical_feature))\n",
    "print(ordered_features_df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9742998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf11481e",
   "metadata": {},
   "source": [
    "#### all in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4816d0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered Features by Correlation with Price (Numerical + Categorical):\n",
      "                            Feature  Correlation with Price\n",
      "9              artist_Rene Magritte                   0.418\n",
      "24                   surface_canvas                   0.233\n",
      "0                         year_sold                   0.217\n",
      "30                        year_sold                   0.217\n",
      "20       medium_Oil-Based Paintings                   0.188\n",
      "32                        year_born                   0.124\n",
      "1                         year_born                   0.124\n",
      "2                     circumference                   0.109\n",
      "31                    circumference                   0.109\n",
      "12              city_auction_London                   0.100\n",
      "13            city_auction_New York                   0.091\n",
      "19                     currency_USD                   0.072\n",
      "17                     currency_GBP                   0.054\n",
      "33                        return_sp                   0.040\n",
      "5                         return_sp                   0.040\n",
      "22           medium_Watercolour Art                   0.037\n",
      "5     artist_Jan Breughel the elder                  -0.012\n",
      "10     artist_Theo Van Rysselberghe                  -0.022\n",
      "14               city_auction_Paris                  -0.042\n",
      "3             artist_Jacob Jordaens                  -0.045\n",
      "6   artist_Jan Breughel the younger                  -0.046\n",
      "4                          contrast                  -0.053\n",
      "28                         contrast                  -0.053\n",
      "1       artist_Eugene Verboeckhoven                  -0.056\n",
      "7               artist_Paul Delvaux                  -0.057\n",
      "2              artist_Felicien Rops                  -0.058\n",
      "26                    surface_other                  -0.058\n",
      "18                     currency_NLG                  -0.064\n",
      "0           artist_Anthony Van Dyck                  -0.075\n",
      "23                   medium_missing                  -0.081\n",
      "4                artist_James Ensor                  -0.087\n",
      "25                  surface_missing                  -0.095\n",
      "11           city_auction_Amsterdam                  -0.101\n",
      "16                     currency_EUR                  -0.101\n",
      "15             city_auction_unknown                  -0.102\n",
      "29                       brightness                  -0.109\n",
      "3                        brightness                  -0.109\n",
      "8          artist_Pierre Alechinsky                  -0.116\n",
      "27                    surface_paper                  -0.126\n",
      "21      medium_Pen and Ink Drawings                  -0.172\n"
     ]
    }
   ],
   "source": [
    "ordered_features_df_all = pd.concat([ordered_features_df_num, ordered_features_df])\n",
    "\n",
    "# Sort the merged DataFrame by correlation scores in descending order\n",
    "ordered_features_df_all = ordered_features_df_all.sort_values(by='Correlation with Price', ascending=False)\n",
    "\n",
    "# Display the ordered list of features with correlation scores\n",
    "print(\"Ordered Features by Correlation with Price (Numerical + Categorical):\")\n",
    "print(ordered_features_df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810895b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e81b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381fb72f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87f43290",
   "metadata": {},
   "source": [
    "## outlier-removed dataset (10 oultiers dropped) and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d9ed60fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1c4ee611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>target</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>72.213</td>\n",
       "      <td>133.827</td>\n",
       "      <td>1994</td>\n",
       "      <td>London</td>\n",
       "      <td>GBP</td>\n",
       "      <td>40694.870</td>\n",
       "      <td>True</td>\n",
       "      <td>507.800</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>62.101</td>\n",
       "      <td>174.389</td>\n",
       "      <td>1995</td>\n",
       "      <td>New York</td>\n",
       "      <td>USD</td>\n",
       "      <td>9730.240</td>\n",
       "      <td>True</td>\n",
       "      <td>322.600</td>\n",
       "      <td>Watercolour Art</td>\n",
       "      <td>paper</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist  contrast  brightness  year_sold city_auction currency  \\\n",
       "0  Pierre Alechinsky    72.213     133.827       1994       London      GBP   \n",
       "1  Pierre Alechinsky    62.101     174.389       1995     New York      USD   \n",
       "\n",
       "     target signed  circumference           medium surface  year_born   dead  \\\n",
       "0 40694.870   True        507.800          missing  canvas       1927  False   \n",
       "1  9730.240   True        322.600  Watercolour Art   paper       1927  False   \n",
       "\n",
       "   return_sp  \n",
       "0      0.100  \n",
       "1      0.013  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "82c644ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_values_indices = df['target'].nlargest(10).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1592669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_percentage = 0.80\n",
    "split_point = int(len(df) * split_percentage)\n",
    "\n",
    "train_set = df[:split_point]\n",
    "test_set = df[split_point:]\n",
    "\n",
    "range_train = len(train_set)\n",
    "\n",
    "filtered_indices = [index for index in top_values_indices if index <= range_train]\n",
    "\n",
    "# splitting the training set into features X and target variable Y\n",
    "x_train = train_set.drop(columns=['target'])\n",
    "y_train = train_set['target']\n",
    "\n",
    "# dropping the rows based on the indices\n",
    "x_train = x_train.drop(index=filtered_indices)\n",
    "y_train = y_train.drop(index=filtered_indices)\n",
    "\n",
    "#splitting the test set into  features X and target variable Y\n",
    "x_test = test_set.drop(columns=['target'])\n",
    "y_test = test_set['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e8b0d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = ['artist', 'city_auction', 'currency', 'medium', 'surface', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
    "        ('num', continuous_transformer, continuous_cols)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "323db5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 13009079939596.207\n",
      "Test RMSE: 3606810.2167422404\n",
      "Test R-squared: 0.2896738848336651\n",
      "Adjusted R2 is 0.22728037471770324\n",
      "Test MAE: 1765253.0979899238\n"
     ]
    }
   ],
   "source": [
    "gbr = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe5bed1",
   "metadata": {},
   "source": [
    "## feature-selected dataset (10 features) and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f618f759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>target</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>72.213</td>\n",
       "      <td>133.827</td>\n",
       "      <td>1994</td>\n",
       "      <td>London</td>\n",
       "      <td>GBP</td>\n",
       "      <td>40694.870</td>\n",
       "      <td>True</td>\n",
       "      <td>507.800</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>62.101</td>\n",
       "      <td>174.389</td>\n",
       "      <td>1995</td>\n",
       "      <td>New York</td>\n",
       "      <td>USD</td>\n",
       "      <td>9730.240</td>\n",
       "      <td>True</td>\n",
       "      <td>322.600</td>\n",
       "      <td>Watercolour Art</td>\n",
       "      <td>paper</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist  contrast  brightness  year_sold city_auction currency  \\\n",
       "0  Pierre Alechinsky    72.213     133.827       1994       London      GBP   \n",
       "1  Pierre Alechinsky    62.101     174.389       1995     New York      USD   \n",
       "\n",
       "     target signed  circumference           medium surface  year_born   dead  \\\n",
       "0 40694.870   True        507.800          missing  canvas       1927  False   \n",
       "1  9730.240   True        322.600  Watercolour Art   paper       1927  False   \n",
       "\n",
       "   return_sp  \n",
       "0      0.100  \n",
       "1      0.013  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "8c71d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['signed','dead']\n",
    "x_values = df.drop(columns=['target'] + features_to_drop)\n",
    "y_values = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2d51970b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>72.213</td>\n",
       "      <td>133.827</td>\n",
       "      <td>1994</td>\n",
       "      <td>London</td>\n",
       "      <td>GBP</td>\n",
       "      <td>507.800</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>62.101</td>\n",
       "      <td>174.389</td>\n",
       "      <td>1995</td>\n",
       "      <td>New York</td>\n",
       "      <td>USD</td>\n",
       "      <td>322.600</td>\n",
       "      <td>Watercolour Art</td>\n",
       "      <td>paper</td>\n",
       "      <td>1927</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist  contrast  brightness  year_sold city_auction currency  \\\n",
       "0  Pierre Alechinsky    72.213     133.827       1994       London      GBP   \n",
       "1  Pierre Alechinsky    62.101     174.389       1995     New York      USD   \n",
       "\n",
       "   circumference           medium surface  year_born  return_sp  \n",
       "0        507.800          missing  canvas       1927      0.100  \n",
       "1        322.600  Watercolour Art   paper       1927      0.013  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_values.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b2939fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_percentage = 0.80\n",
    "split_point = int(len(df) * split_percentage) \n",
    "\n",
    "# Split the data in a training and test set\n",
    "x_train = x_values[:split_point]\n",
    "x_test = x_values[split_point:]\n",
    "\n",
    "y_train = y_values[:split_point]\n",
    "y_test = y_values[split_point:]\n",
    "\n",
    "one_hot_cols = ['artist', 'currency', 'medium', 'surface']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
    "        ('num', continuous_transformer, continuous_cols)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "dcccf18a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 11038621020529.053\n",
      "Test RMSE: 3322442.026661873\n",
      "Test R-squared: 0.3972655389379346\n",
      "Adjusted R2 is 0.3530650117933831\n",
      "Test MAE: 1417378.706057924\n"
     ]
    }
   ],
   "source": [
    "gbr = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca76ff1a",
   "metadata": {},
   "source": [
    "### interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f6f966cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = ['artist', 'currency', 'medium', 'surface']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
    "        ('num', continuous_transformer, continuous_cols)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "275afdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimator = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "perm_pipe = permutation_importance(pipeline, x_test, y_test, n_repeats=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "feat_import_perm = perm_pipe.importances_mean\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.bar(range(len(feat_import_perm)), feat_import_perm, align=\"center\")\n",
    "ax.set(xticks=range(len(feat_import_perm)), xticklabels=x_test.columns)\n",
    "# Set properties of x axis using setp, we will rotate the labels by 45 degrees\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e5a81745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Feature  Importance\n",
      "0          artist       0.590\n",
      "6   circumference       0.287\n",
      "1        contrast       0.034\n",
      "7          medium       0.007\n",
      "10      return_sp       0.007\n",
      "5        currency       0.005\n",
      "2      brightness       0.005\n",
      "8         surface       0.000\n",
      "3       year_sold       0.000\n",
      "4    city_auction       0.000\n",
      "9       year_born      -0.001\n"
     ]
    }
   ],
   "source": [
    "perm_importance_df = pd.DataFrame({'Feature': x_test.columns, 'Importance': perm_pipe.importances_mean})\n",
    "\n",
    "# Sort the DataFrame by importance score in descending order\n",
    "perm_importance_df = perm_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(perm_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272b34f0",
   "metadata": {},
   "source": [
    "#### correlation with target / price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca7c794",
   "metadata": {},
   "source": [
    "##### numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f214e995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered Features by Correlation with Price:\n",
      "         Feature  Correlation with Price\n",
      "0      year_sold                   0.217\n",
      "1      year_born                   0.124\n",
      "2  circumference                   0.109\n",
      "5      return_sp                   0.040\n",
      "4       contrast                  -0.053\n",
      "3     brightness                  -0.109\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([x_values, y_values], axis=1)\n",
    "\n",
    "# Select non-categorical features (assuming numerical features)\n",
    "numerical_features = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "data_numerical = data[numerical_features]\n",
    "\n",
    "# Calculate correlations with the target variable (\"price\")\n",
    "correlation_with_price = data_numerical.corr()['target'].drop('target')\n",
    "\n",
    "# Create a list of features ordered by their correlation with the target variable\n",
    "ordered_features = correlation_with_price.abs().sort_values(ascending=False).index.tolist()\n",
    "\n",
    "ordered_features_df = pd.DataFrame({\n",
    "    'Feature': ordered_features,\n",
    "    'Correlation with Price': [correlation_with_price[feature] for feature in ordered_features]\n",
    "})\n",
    "\n",
    "ordered_features_df = ordered_features_df.sort_values(by='Correlation with Price', ascending=False)\n",
    "\n",
    "# Display the ordered list of features with correlation scores\n",
    "print(\"Ordered Features by Correlation with Price:\")\n",
    "print(ordered_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f937e84d",
   "metadata": {},
   "source": [
    "##### categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8f6ee5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered Features by Correlation with Price:\n",
      "                            Feature  Correlation with Price\n",
      "9              artist_Rene Magritte                   0.418\n",
      "24                   surface_canvas                   0.233\n",
      "30                        year_sold                   0.217\n",
      "20       medium_Oil-Based Paintings                   0.188\n",
      "32                        year_born                   0.124\n",
      "31                    circumference                   0.109\n",
      "12              city_auction_London                   0.100\n",
      "13            city_auction_New York                   0.091\n",
      "19                     currency_USD                   0.072\n",
      "17                     currency_GBP                   0.054\n",
      "33                        return_sp                   0.040\n",
      "22           medium_Watercolour Art                   0.037\n",
      "5     artist_Jan Breughel the elder                  -0.012\n",
      "10     artist_Theo Van Rysselberghe                  -0.022\n",
      "14               city_auction_Paris                  -0.042\n",
      "3             artist_Jacob Jordaens                  -0.045\n",
      "6   artist_Jan Breughel the younger                  -0.046\n",
      "28                         contrast                  -0.053\n",
      "1       artist_Eugene Verboeckhoven                  -0.056\n",
      "7               artist_Paul Delvaux                  -0.057\n",
      "2              artist_Felicien Rops                  -0.058\n",
      "26                    surface_other                  -0.058\n",
      "18                     currency_NLG                  -0.064\n",
      "0           artist_Anthony Van Dyck                  -0.075\n",
      "23                   medium_missing                  -0.081\n",
      "4                artist_James Ensor                  -0.087\n",
      "25                  surface_missing                  -0.095\n",
      "11           city_auction_Amsterdam                  -0.101\n",
      "16                     currency_EUR                  -0.101\n",
      "15             city_auction_unknown                  -0.102\n",
      "29                       brightness                  -0.109\n",
      "8          artist_Pierre Alechinsky                  -0.116\n",
      "27                    surface_paper                  -0.126\n",
      "21      medium_Pen and Ink Drawings                  -0.172\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([x_values, y_values], axis=1)\n",
    "\n",
    "# Select categorical features (assuming object type)\n",
    "categorical_features = data.select_dtypes(include=['object']).columns\n",
    "data_categorical = data[categorical_features]\n",
    "\n",
    "# One-hot encode categorical features\n",
    "data_encoded = pd.get_dummies(data_categorical)\n",
    "\n",
    "# Concatenate the encoded categorical features with numerical features\n",
    "data_combined = pd.concat([data_encoded, data_numerical], axis=1)\n",
    "\n",
    "# Calculate correlations with the target variable (\"price\")\n",
    "correlation_with_price = data_combined.corr()['target'].drop('target')\n",
    "\n",
    "# Create a DataFrame with feature names and their correlation scores\n",
    "ordered_features_df = pd.DataFrame({\n",
    "    'Feature': correlation_with_price.index,\n",
    "    'Correlation with Price': correlation_with_price.values\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by correlation scores in descending order\n",
    "ordered_features_df = ordered_features_df.sort_values(by='Correlation with Price', ascending=False)\n",
    "\n",
    "# Display the ordered list of features with correlation scores\n",
    "print(\"Ordered Features by Correlation with Price:\")\n",
    "print(ordered_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c45eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b0e1b0b",
   "metadata": {},
   "source": [
    "# Not important anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad132b",
   "metadata": {},
   "source": [
    "## Feature painting or drawing instead of surface and medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ea41c3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>target</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>52.601</td>\n",
       "      <td>101.140</td>\n",
       "      <td>2018</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>EUR</td>\n",
       "      <td>87500.000</td>\n",
       "      <td>True</td>\n",
       "      <td>536.000</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Theo Van Rysselberghe</td>\n",
       "      <td>49.258</td>\n",
       "      <td>136.516</td>\n",
       "      <td>2010</td>\n",
       "      <td>Paris</td>\n",
       "      <td>EUR</td>\n",
       "      <td>79000.000</td>\n",
       "      <td>True</td>\n",
       "      <td>243.600</td>\n",
       "      <td>Oil-Based Paintings</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1862</td>\n",
       "      <td>True</td>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  artist  contrast  brightness  year_sold city_auction  \\\n",
       "0      Pierre Alechinsky    52.601     101.140       2018    Amsterdam   \n",
       "1  Theo Van Rysselberghe    49.258     136.516       2010        Paris   \n",
       "\n",
       "  currency    target signed  circumference               medium surface  \\\n",
       "0      EUR 87500.000   True        536.000              missing  canvas   \n",
       "1      EUR 79000.000   True        243.600  Oil-Based Paintings  canvas   \n",
       "\n",
       "   year_born   dead  return_sp  \n",
       "0       1927  False      0.216  \n",
       "1       1862   True      0.259  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx = dataframe\n",
    "dfx = dfx.rename(columns={'price_EUR': 'target'})\n",
    "dfx.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "35b158b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>target</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "      <th>painting_drawing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>52.601</td>\n",
       "      <td>101.140</td>\n",
       "      <td>2018</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>EUR</td>\n",
       "      <td>87500.000</td>\n",
       "      <td>True</td>\n",
       "      <td>536.000</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.216</td>\n",
       "      <td>painting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Theo Van Rysselberghe</td>\n",
       "      <td>49.258</td>\n",
       "      <td>136.516</td>\n",
       "      <td>2010</td>\n",
       "      <td>Paris</td>\n",
       "      <td>EUR</td>\n",
       "      <td>79000.000</td>\n",
       "      <td>True</td>\n",
       "      <td>243.600</td>\n",
       "      <td>Oil-Based Paintings</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1862</td>\n",
       "      <td>True</td>\n",
       "      <td>0.259</td>\n",
       "      <td>painting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  artist  contrast  brightness  year_sold city_auction  \\\n",
       "0      Pierre Alechinsky    52.601     101.140       2018    Amsterdam   \n",
       "1  Theo Van Rysselberghe    49.258     136.516       2010        Paris   \n",
       "\n",
       "  currency    target signed  circumference               medium surface  \\\n",
       "0      EUR 87500.000   True        536.000              missing  canvas   \n",
       "1      EUR 79000.000   True        243.600  Oil-Based Paintings  canvas   \n",
       "\n",
       "   year_born   dead  return_sp painting_drawing  \n",
       "0       1927  False      0.216         painting  \n",
       "1       1862   True      0.259         painting  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making from medium and surface one boolean --> drawing or painting\n",
    "dfx['painting_drawing'] = 0\n",
    "dfx.loc[(dfx['medium'] == 'Pen and Ink Drawings') | (dfx['surface'] == 'paper'), 'painting_drawing'] = 'drawing'\n",
    "dfx.loc[dfx['medium'] == 'Oil-Based Paintings', 'painting_drawing'] = 'painting'\n",
    "for index, row in dfx.iterrows():\n",
    "    if row['painting_drawing']==0:\n",
    "        dfx.at[index, 'painting_drawing'] = 'painting'\n",
    "dfx.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "0f51335f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences of 0 in 'painting_drawing': 0\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'dfx' is your DataFrame\n",
    "# Count the occurrences of the value 0 in the 'painting_drawing' column\n",
    "count_0 = (dfx['painting_drawing'] == 0).sum()\n",
    "\n",
    "# Display the count of occurrences of the value 0\n",
    "print(\"Number of occurrences of 0 in 'painting_drawing':\", count_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "5231b8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  count   total_spent    average\n",
      "painting_drawing                                \n",
      "painting            471 451180920.260 957921.274\n",
      "drawing             338  73591598.350 217726.622\n"
     ]
    }
   ],
   "source": [
    "painting_drawing_stats = dfx.groupby('painting_drawing').agg({'painting_drawing': 'count', 'target': 'sum'})\n",
    "\n",
    "# Renaming columns for clarity\n",
    "painting_drawing_stats = painting_drawing_stats.rename(columns={'painting_drawing': 'count', 'target': 'total_spent'})\n",
    "painting_drawing_stats['average'] = painting_drawing_stats['total_spent']/painting_drawing_stats['count']\n",
    "painting_drawing_stats = painting_drawing_stats.sort_values(by='average', ascending=False)\n",
    "print(painting_drawing_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "21e7b7a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 809 entries, 0 to 810\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   artist            809 non-null    object  \n",
      " 1   contrast          809 non-null    float64 \n",
      " 2   brightness        809 non-null    float64 \n",
      " 3   year_sold         809 non-null    int64   \n",
      " 4   city_auction      809 non-null    object  \n",
      " 5   currency          809 non-null    object  \n",
      " 6   target            809 non-null    float64 \n",
      " 7   signed            809 non-null    category\n",
      " 8   circumference     809 non-null    float64 \n",
      " 9   year_born         809 non-null    int64   \n",
      " 10  dead              809 non-null    category\n",
      " 11  return_sp         809 non-null    float64 \n",
      " 12  painting_drawing  809 non-null    object  \n",
      "dtypes: category(2), float64(5), int64(2), object(4)\n",
      "memory usage: 109.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dfx = dfx.drop(['medium','surface'], axis=1)\n",
    "dfx.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "18775d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Time Range: 1994 2019\n",
      "Testing Set Time Range: 2019 2023\n"
     ]
    }
   ],
   "source": [
    "dfx = dfx.sort_values(by='year_sold')\n",
    "\n",
    "split_percentage = 0.80\n",
    "split_point = int(len(dfx) * split_percentage)\n",
    "\n",
    "# step 3: Split the data in a training and test set\n",
    "train_set = dfx[:split_point]\n",
    "test_set = dfx[split_point:]\n",
    "\n",
    "# Check the time range in each set\n",
    "print(\"Training Set Time Range:\", train_set['year_sold'].min(), train_set['year_sold'].max())\n",
    "print(\"Testing Set Time Range:\", test_set['year_sold'].min(), test_set['year_sold'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1a7e5843",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_set.drop(columns=['target'])\n",
    "y_train = train_set['target']\n",
    "\n",
    "#splitting the test set into  features X and target variable Y\n",
    "x_test = test_set.drop(columns=['target'])\n",
    "y_test = test_set['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8f2a0e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = ['artist', 'city_auction', 'currency', 'painting_drawing', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
    "        ('num', continuous_transformer, continuous_cols)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d0900d",
   "metadata": {},
   "source": [
    "##### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "fac4bbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Best hyperparameters: {'estimator__max_depth': None, 'estimator__n_estimators': 100}\n",
      "Best MSE: 1365738151089.2837\n",
      "Cross-validation scores: [-0.66363448  0.11147638  0.44058487  0.56848465  0.3276824 ]\n",
      "Mean CV R-squared: 0.15691876490421822\n",
      "Train R-squared: 0.9083418701817938\n",
      "Train MSE: 167660522576.9541\n",
      "Train RMSE: 409463.7011713665\n",
      "Train MAE: 121249.35655239565\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest')\n",
    "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# define the grid of hyperparamters to look at\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
    "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
    "}\n",
    "\n",
    "# define the grid search object\n",
    "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# fit the grid search object to the training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# print the best hyperparameters and the corresponding mean squared error\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best MSE:\", -grid_search.best_score_)\n",
    "\n",
    "# calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# fit the pipeline to the train data\n",
    "grid_search.best_estimator_.fit(x_train, y_train)\n",
    "\n",
    "# make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# print the R-squared score of the model on the train data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# print the mean squared error of the model on the train data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Train MSE:\", mse_train)\n",
    "\n",
    "# print the root mean squared error of the model on the train data\n",
    "rmse_train = mse_train ** 0.5\n",
    "print(\"Train RMSE:\", rmse_train)\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "print(\"Train MAE:\", mae_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e476ed4b",
   "metadata": {},
   "source": [
    "##### gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3ac4ed8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "Best Hyperparameters: {'estimator__max_depth': 7, 'estimator__max_features': 'sqrt', 'estimator__n_estimators': 200}\n",
      "Best MSE: 1387808718665.7866\n",
      "Cross-validation scores: [0.37753583 0.06764133 0.33369454 0.53298568 0.32696073]\n",
      "Mean CV R-squared: 0.3277636223740895\n",
      "training MAE: 3774.4446323530237\n",
      "Train R-squared: 0.9999789811546217\n",
      "Training MSE: 38447550.774699755\n",
      "Training RMSE: 6200.608903543244\n"
     ]
    }
   ],
   "source": [
    "estimator = GradientBoostingRegressor(random_state=42)\n",
    "print('Gradient Boosting')\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_depth': [1,3,5 ,7, 10],\n",
    "    'estimator__max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "# Create a grid search object\n",
    "time_series_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the best MSE and corresponding negative value\n",
    "best_mse = -grid_search.best_score_\n",
    "print(\"Best MSE:\", best_mse)\n",
    "\n",
    "# Calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# calculate and print MAE\n",
    "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
    "print('training MAE:', mae)\n",
    "\n",
    "# Make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# Print the R-squared score of the model on the training data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# Print the mean squared error of the model on the training data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Training MSE:\", mse_train)\n",
    "\n",
    "# Print the root mean squared error of the model on the training data\n",
    "rmse_train = sqrt(mse_train)\n",
    "print(\"Training RMSE:\", rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4b59e6",
   "metadata": {},
   "source": [
    "###### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f93a81fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Random Forest\n",
      "\n",
      "Test MSE: 10831572686651.879\n",
      "Test RMSE: 3291135.4707231177\n",
      "Test R-squared: 0.4085708610158617\n",
      "Adjusted R2 is 0.36093898405069624\n",
      "Test MAE: 1519436.0995665775\n"
     ]
    }
   ],
   "source": [
    "gbr = RandomForestRegressor(n_estimators=100, max_depth=20,random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('test Random Forest')\n",
    "print('')\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1d3937ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Gradient Boosting\n",
      "\n",
      "Test MSE: 14098741249734.092\n",
      "Test RMSE: 3754829.057325259\n",
      "Test R-squared: 0.23017583509677275\n",
      "Adjusted R2 is 0.1681765734938283\n",
      "Test MAE: 1501586.5081748643\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(n_estimators=50, max_depth=7, max_features= 'sqrt',random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('test Gradient Boosting')\n",
    "print('')\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa76e47",
   "metadata": {},
   "source": [
    "# combination model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ba16d6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>target</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>medium</th>\n",
       "      <th>surface</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>72.213</td>\n",
       "      <td>133.827</td>\n",
       "      <td>1994</td>\n",
       "      <td>London</td>\n",
       "      <td>GBP</td>\n",
       "      <td>40694.870</td>\n",
       "      <td>True</td>\n",
       "      <td>507.800</td>\n",
       "      <td>missing</td>\n",
       "      <td>canvas</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>62.101</td>\n",
       "      <td>174.389</td>\n",
       "      <td>1995</td>\n",
       "      <td>New York</td>\n",
       "      <td>USD</td>\n",
       "      <td>9730.240</td>\n",
       "      <td>True</td>\n",
       "      <td>322.600</td>\n",
       "      <td>Watercolour Art</td>\n",
       "      <td>paper</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist  contrast  brightness  year_sold city_auction currency  \\\n",
       "0  Pierre Alechinsky    72.213     133.827       1994       London      GBP   \n",
       "1  Pierre Alechinsky    62.101     174.389       1995     New York      USD   \n",
       "\n",
       "     target signed  circumference           medium surface  year_born   dead  \\\n",
       "0 40694.870   True        507.800          missing  canvas       1927  False   \n",
       "1  9730.240   True        322.600  Watercolour Art   paper       1927  False   \n",
       "\n",
       "   return_sp  \n",
       "0      0.100  \n",
       "1      0.013  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combination of all these models: --> drop 10 outlier and 8 features \n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "eb9cfb47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Time Range: 1994 2019\n",
      "Testing Set Time Range: 2019 2023\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values(by='year_sold')\n",
    "\n",
    "split_percentage = 0.80\n",
    "split_point = int(len(df) * split_percentage)\n",
    "\n",
    "# step 3: Split the data in a training and test set\n",
    "train_set = df[:split_point]\n",
    "test_set = df[split_point:]\n",
    "\n",
    "# Check the time range in each set\n",
    "print(\"Training Set Time Range:\", train_set['year_sold'].min(), train_set['year_sold'].max())\n",
    "print(\"Testing Set Time Range:\", test_set['year_sold'].min(), test_set['year_sold'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e03b76c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ee8f0694",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_values_indices = df['target'].nlargest(10).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7c6c59bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_train = len(train_set)\n",
    "\n",
    "filtered_indices = [index for index in top_values_indices if index < range_train]\n",
    "\n",
    "# splitting the training set into features X and target variable Y\n",
    "x_train = train_set.drop(columns=['target'])\n",
    "y_train = train_set['target']\n",
    "\n",
    "# dropping the rows based on the indices\n",
    "x_train = x_train.drop(index=filtered_indices)\n",
    "y_train = y_train.drop(index=filtered_indices)\n",
    "\n",
    "#splitting the test set into  features X and target variable Y\n",
    "x_test = test_set.drop(columns=['target'])\n",
    "y_test = test_set['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "51571eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = ['artist', 'currency', 'medium', 'surface', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the columns to encode and scale (standard)\n",
    "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
    "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
    "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "99163021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'estimator__max_depth': None, 'estimator__n_estimators': 100}\n",
      "Best MSE: 1293851254761.2239\n",
      "Cross-validation scores: [0.01290975 0.08789117 0.51473599 0.58185512 0.29168481]\n",
      "Mean CV R-squared: 0.2978153702217027\n",
      "Train R-squared: 0.9063797666990207\n",
      "Train MSE: 161731687360.20584\n",
      "Train RMSE: 402158.7837660715\n",
      "Train MAE: 117660.39956728685\n"
     ]
    }
   ],
   "source": [
    "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# define the grid of hyperparamters to look at\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
    "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
    "}\n",
    "\n",
    "# define the grid search object\n",
    "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# fit the grid search object to the training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# print the best hyperparameters and the corresponding mean squared error\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best MSE:\", -grid_search.best_score_)\n",
    "\n",
    "# calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# fit the pipeline to the train data\n",
    "grid_search.best_estimator_.fit(x_train, y_train)\n",
    "\n",
    "# make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# print the R-squared score of the model on the train data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# print the mean squared error of the model on the train data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Train MSE:\", mse_train)\n",
    "\n",
    "# print the root mean squared error of the model on the train data\n",
    "rmse_train = mse_train ** 0.5\n",
    "print(\"Train RMSE:\", rmse_train)\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "print(\"Train MAE:\", mae_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e5be6cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Random Forest\n",
      "Test MSE: 12036041912156.088\n",
      "Test RMSE: 3469299.9167203875\n",
      "Test R-squared: 0.3527018115239764\n",
      "Adjusted R2 is 0.29584453821189327\n",
      "Test MAE: 1460007.1512764744\n"
     ]
    }
   ],
   "source": [
    "gbr = RandomForestRegressor(n_estimators=25, max_depth=15, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('test Random Forest')\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "26d1d1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "Best Hyperparameters: {'estimator__max_depth': 10, 'estimator__max_features': 'sqrt', 'estimator__n_estimators': 100}\n",
      "Best MSE: 1282233808182.0813\n",
      "Cross-validation scores: [0.26427453 0.06583477 0.42044698 0.59963287 0.31617049]\n",
      "Mean CV R-squared: 0.3332719276892556\n",
      "training MAE: 1433.5125013533993\n",
      "Train R-squared: 0.99999658106246\n",
      "Training MSE: 5906314.4559074165\n",
      "Training RMSE: 2430.2910228833534\n"
     ]
    }
   ],
   "source": [
    "estimator = GradientBoostingRegressor(random_state=42)\n",
    "print('Gradient Boosting')\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_depth': [7, 10, 20],\n",
    "    'estimator__max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "# Create a grid search object\n",
    "time_series_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the best MSE and corresponding negative value\n",
    "best_mse = -grid_search.best_score_\n",
    "print(\"Best MSE:\", best_mse)\n",
    "\n",
    "# Calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# calculate and print MAE\n",
    "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
    "print('training MAE:', mae)\n",
    "\n",
    "# Make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# Print the R-squared score of the model on the training data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# Print the mean squared error of the model on the training data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Training MSE:\", mse_train)\n",
    "\n",
    "# Print the root mean squared error of the model on the training data\n",
    "rmse_train = sqrt(mse_train)\n",
    "print(\"Training RMSE:\", rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "98b3d7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Gradient Boosting\n",
      "Test MSE: 15057081288228.207\n",
      "Test RMSE: 3880345.511449748\n",
      "Test R-squared: 0.19023035041422398\n",
      "Adjusted R2 is 0.11910193524790569\n",
      "Test MAE: 1611369.0021174154\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator with the best parameters\n",
    "gbr = GradientBoostingRegressor(n_estimators=200, max_depth=10, max_features= 'sqrt',random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('Test Gradient Boosting')\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7e09e9",
   "metadata": {},
   "source": [
    "# feature painting _ drawing and 10 dropping features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "9d5c082c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>target</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "      <th>painting_drawing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>72.213</td>\n",
       "      <td>133.827</td>\n",
       "      <td>1994</td>\n",
       "      <td>London</td>\n",
       "      <td>GBP</td>\n",
       "      <td>40694.870</td>\n",
       "      <td>True</td>\n",
       "      <td>507.800</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100</td>\n",
       "      <td>painting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                artist  contrast  brightness  year_sold city_auction currency  \\\n",
       "481  Pierre Alechinsky    72.213     133.827       1994       London      GBP   \n",
       "\n",
       "       target signed  circumference  year_born   dead  return_sp  \\\n",
       "481 40694.870   True        507.800       1927  False      0.100   \n",
       "\n",
       "    painting_drawing  \n",
       "481         painting  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "b719f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = dfx.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "929ea708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>contrast</th>\n",
       "      <th>brightness</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_auction</th>\n",
       "      <th>currency</th>\n",
       "      <th>target</th>\n",
       "      <th>signed</th>\n",
       "      <th>circumference</th>\n",
       "      <th>year_born</th>\n",
       "      <th>dead</th>\n",
       "      <th>return_sp</th>\n",
       "      <th>painting_drawing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre Alechinsky</td>\n",
       "      <td>72.213</td>\n",
       "      <td>133.827</td>\n",
       "      <td>1994</td>\n",
       "      <td>London</td>\n",
       "      <td>GBP</td>\n",
       "      <td>40694.870</td>\n",
       "      <td>True</td>\n",
       "      <td>507.800</td>\n",
       "      <td>1927</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100</td>\n",
       "      <td>painting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist  contrast  brightness  year_sold city_auction currency  \\\n",
       "0  Pierre Alechinsky    72.213     133.827       1994       London      GBP   \n",
       "\n",
       "     target signed  circumference  year_born   dead  return_sp  \\\n",
       "0 40694.870   True        507.800       1927  False      0.100   \n",
       "\n",
       "  painting_drawing  \n",
       "0         painting  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a28ed493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Time Range: 1994 2019\n",
      "Testing Set Time Range: 2019 2023\n"
     ]
    }
   ],
   "source": [
    "split_percentage = 0.80\n",
    "split_point = int(len(dfx) * split_percentage)\n",
    "\n",
    "# step 3: Split the data in a training and test set\n",
    "train_set = dfx[:split_point]\n",
    "test_set = dfx[split_point:]\n",
    "\n",
    "# Check the time range in each set\n",
    "print(\"Training Set Time Range:\", train_set['year_sold'].min(), train_set['year_sold'].max())\n",
    "print(\"Testing Set Time Range:\", test_set['year_sold'].min(), test_set['year_sold'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "250c08bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_values_indices = dfx['target'].nlargest(10).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b23251b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_train = len(train_set)\n",
    "\n",
    "filtered_indices = [index for index in top_values_indices if index < range_train]\n",
    "\n",
    "# splitting the training set into features X and target variable Y\n",
    "x_train = train_set.drop(columns=['target'])\n",
    "y_train = train_set['target']\n",
    "\n",
    "# dropping the rows based on the indices\n",
    "x_train = x_train.drop(index=filtered_indices)\n",
    "y_train = y_train.drop(index=filtered_indices)\n",
    "\n",
    "#splitting the test set into  features X and target variable Y\n",
    "x_test = test_set.drop(columns=['target'])\n",
    "y_test = test_set['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e17d1cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = ['artist', 'currency', 'painting_drawing', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the columns to encode and scale (standard)\n",
    "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
    "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
    "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "0c4ad900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest\n",
      "Best hyperparameters: {'estimator__max_depth': 10, 'estimator__n_estimators': 200}\n",
      "Best MSE: 557186490150.9854\n",
      "Cross-validation scores: [-0.62919442  0.05313063  0.50760975  0.57468912  0.37328018]\n",
      "Mean CV R-squared: 0.17590305354726932\n",
      "Train R-squared: 0.9232996688564543\n",
      "Train MSE: 64563812317.339355\n",
      "Train RMSE: 254094.10130370865\n",
      "Train MAE: 111250.12461783602\n"
     ]
    }
   ],
   "source": [
    "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "print('random forest')\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# define the grid of hyperparamters to look at\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
    "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
    "}\n",
    "\n",
    "# define the grid search object\n",
    "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# fit the grid search object to the training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# print the best hyperparameters and the corresponding mean squared error\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best MSE:\", -grid_search.best_score_)\n",
    "\n",
    "# calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# fit the pipeline to the train data\n",
    "grid_search.best_estimator_.fit(x_train, y_train)\n",
    "\n",
    "# make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# print the R-squared score of the model on the train data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# print the mean squared error of the model on the train data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Train MSE:\", mse_train)\n",
    "\n",
    "# print the root mean squared error of the model on the train data\n",
    "rmse_train = mse_train ** 0.5\n",
    "print(\"Train RMSE:\", rmse_train)\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "print(\"Train MAE:\", mae_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "d2e91786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Random Forest\n",
      "Test MSE: 13164963160883.643\n",
      "Test RMSE: 3628355.434750521\n",
      "Test R-squared: 0.2811622972724501\n",
      "Adjusted R2 is 0.22326932792526488\n",
      "Test MAE: 1948115.6631609227\n"
     ]
    }
   ],
   "source": [
    "gbr = RandomForestRegressor(n_estimators=50, max_depth=20, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('test Random Forest')\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c695c64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "Best Hyperparameters: {'estimator__max_depth': 20, 'estimator__max_features': 'sqrt', 'estimator__n_estimators': 200}\n",
      "Best MSE: 548230724587.79755\n",
      "Cross-validation scores: [0.32429918 0.01916662 0.45849791 0.62196203 0.34195492]\n",
      "Mean CV R-squared: 0.35317613176178997\n",
      "training MAE: 1.877208442899388\n",
      "Train R-squared: 0.9999999986503768\n",
      "Training MSE: 1136.0683322809832\n",
      "Training RMSE: 33.70561277118372\n"
     ]
    }
   ],
   "source": [
    "estimator = GradientBoostingRegressor(random_state=42)\n",
    "print('Gradient Boosting')\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_depth': [7, 10, 20],\n",
    "    'estimator__max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "# Create a grid search object\n",
    "time_series_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the best MSE and corresponding negative value\n",
    "best_mse = -grid_search.best_score_\n",
    "print(\"Best MSE:\", best_mse)\n",
    "\n",
    "# Calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# calculate and print MAE\n",
    "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
    "print('training MAE:', mae)\n",
    "\n",
    "# Make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# Print the R-squared score of the model on the training data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# Print the mean squared error of the model on the training data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Training MSE:\", mse_train)\n",
    "\n",
    "# Print the root mean squared error of the model on the training data\n",
    "rmse_train = sqrt(mse_train)\n",
    "print(\"Training RMSE:\", rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a70bacda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Gradient Boosting\n",
      "Test MSE: 13685095856004.938\n",
      "Test RMSE: 3699337.218476431\n",
      "Test R-squared: 0.25276183863801926\n",
      "Adjusted R2 is 0.19258158403168524\n",
      "Test MAE: 2025520.7734119936\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator with the best parameters\n",
    "gbr = GradientBoostingRegressor(n_estimators=100, max_depth=10, max_features= 'sqrt',random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('Test Gradient Boosting')\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3ca013",
   "metadata": {},
   "source": [
    "## less features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d6addf",
   "metadata": {},
   "source": [
    "#### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "9e30dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = ['artist', 'painting_drawing', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
    "        ('num', continuous_transformer, continuous_cols)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "92b52aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data in X and y dataset \n",
    "x_values = dfx.drop(columns=['target'])\n",
    "y_values = dfx['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "2ff62f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "pipeline.fit(x_values, y_values)\n",
    "\n",
    "perm_pipe = permutation_importance(pipeline, x_values, y_values, n_repeats=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "feat_import_perm = perm_pipe.importances_mean\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.bar(range(len(feat_import_perm)), feat_import_perm, align=\"center\")\n",
    "ax.set(xticks=range(len(feat_import_perm)), xticklabels=x_values.columns)\n",
    "# Set properties of x axis using setp, we will rotate the labels by 45 degrees\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "5f8f5af9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the indices of the top 8 features\n",
    "top_feature_indices_perm = feat_import_perm.argsort()[-10:][::-1]\n",
    "\n",
    "# Get the names of the top 8 features\n",
    "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
    "\n",
    "# Plotting the permutation importances for the top 10 features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(top_feature_names_perm)), feat_import_perm[top_feature_indices_perm], align=\"center\")\n",
    "plt.xticks(range(len(top_feature_names_perm)), top_feature_names_perm, rotation=45)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Permutation Importance\")\n",
    "plt.title(\"Top 10 Features Based on Permutation Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "896eadd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['artist', 'circumference', 'brightness', 'contrast', 'year_sold',\n",
      "       'return_sp', 'painting_drawing', 'year_born', 'signed', 'dead'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "split_percentage = 0.80\n",
    "split_point = int(len(dfx) * split_percentage)\n",
    "\n",
    "# step 3: Split the data in a training and test set\n",
    "train_set = dfx[:split_point]\n",
    "test_set = dfx[split_point:]\n",
    "\n",
    "# Get the indices of the top 8 features\n",
    "top_feature_indices_perm = perm_pipe.importances_mean.argsort()[-10:][::-1]\n",
    "\n",
    "# Get the names of the top 8 features\n",
    "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
    "print(top_feature_names_perm)\n",
    "\n",
    "# splitting in training set X and training set y but now only with the features we want.\n",
    "x_train = train_set[top_feature_names_perm]\n",
    "y_train = train_set['target']\n",
    "\n",
    "x_test = test_set[top_feature_names_perm]\n",
    "y_test = test_set['target']\n",
    "\n",
    "one_hot_cols = ['artist', 'currency', 'painting_drawing', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the columns to encode and scale (standard)\n",
    "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
    "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
    "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "783d12aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'estimator__max_depth': 20, 'estimator__n_estimators': 10}\n",
      "Best MSE: 1380499277846.7234\n",
      "Cross-validation scores: [-1.21476911  0.05565081  0.35772474  0.49528961  0.36233966]\n",
      "Mean CV R-squared: 0.011247140666900579\n",
      "Train R-squared: 0.8506930803080323\n",
      "Train MSE: 273111356620.09003\n",
      "Train RMSE: 522600.5708187564\n",
      "Train MAE: 131721.017604793\n"
     ]
    }
   ],
   "source": [
    "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# define the grid of hyperparamters to look at\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
    "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
    "}\n",
    "\n",
    "# define the grid search object\n",
    "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# fit the grid search object to the training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# print the best hyperparameters and the corresponding mean squared error\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best MSE:\", -grid_search.best_score_)\n",
    "\n",
    "# calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# fit the pipeline to the train data\n",
    "grid_search.best_estimator_.fit(x_train, y_train)\n",
    "\n",
    "# make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# print the R-squared score of the model on the train data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# print the mean squared error of the model on the train data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Train MSE:\", mse_train)\n",
    "\n",
    "# print the root mean squared error of the model on the train data\n",
    "rmse_train = mse_train ** 0.5\n",
    "print(\"Train RMSE:\", rmse_train)\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "print(\"Train MAE:\", mae_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "1d53251d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test random forest\n",
      "Test MSE: 10677366571921.754\n",
      "Test RMSE: 3267623.9948809524\n",
      "Test R-squared: 0.4169908746463218\n",
      "Adjusted R2 is 0.3783809987950848\n",
      "Test MAE: 1481245.603236021\n"
     ]
    }
   ],
   "source": [
    "gbr = RandomForestRegressor(n_estimators=200, max_depth=15, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('test random forest')\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141abc34",
   "metadata": {},
   "source": [
    "# 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "56833a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['artist', 'circumference', 'brightness', 'contrast', 'year_sold',\n",
      "       'return_sp', 'painting_drawing', 'year_born'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "split_percentage = 0.80\n",
    "split_point = int(len(dfx) * split_percentage)\n",
    "\n",
    "# step 3: Split the data in a training and test set\n",
    "train_set = dfx[:split_point]\n",
    "test_set = dfx[split_point:]\n",
    "\n",
    "# Get the indices of the top 8 features\n",
    "top_feature_indices_perm = perm_pipe.importances_mean.argsort()[-8:][::-1]\n",
    "\n",
    "# Get the names of the top 8 features\n",
    "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
    "print(top_feature_names_perm)\n",
    "\n",
    "# splitting in training set X and training set y but now only with the features we want.\n",
    "x_train = train_set[top_feature_names_perm]\n",
    "y_train = train_set['target']\n",
    "\n",
    "x_test = test_set[top_feature_names_perm]\n",
    "y_test = test_set['target']\n",
    "\n",
    "one_hot_cols = ['artist', 'currency', 'painting_drawing', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the columns to encode and scale (standard)\n",
    "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
    "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
    "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "ddd17ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'estimator__max_depth': 10, 'estimator__n_estimators': 150}\n",
      "Best MSE: 1386208295100.3652\n",
      "Cross-validation scores: [-0.59459221  0.06931713  0.46711942  0.53537825  0.31528748]\n",
      "Mean CV R-squared: 0.1585020150185372\n",
      "Train R-squared: 0.909626400574294\n",
      "Train MSE: 165310866989.39508\n",
      "Train RMSE: 406584.39098100545\n",
      "Train MAE: 131167.9166542725\n"
     ]
    }
   ],
   "source": [
    "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# define the grid of hyperparamters to look at\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
    "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
    "}\n",
    "\n",
    "# define the grid search object\n",
    "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# fit the grid search object to the training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# print the best hyperparameters and the corresponding mean squared error\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best MSE:\", -grid_search.best_score_)\n",
    "\n",
    "# calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# fit the pipeline to the train data\n",
    "grid_search.best_estimator_.fit(x_train, y_train)\n",
    "\n",
    "# make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# print the R-squared score of the model on the train data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# print the mean squared error of the model on the train data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Train MSE:\", mse_train)\n",
    "\n",
    "# print the root mean squared error of the model on the train data\n",
    "rmse_train = mse_train ** 0.5\n",
    "print(\"Train RMSE:\", rmse_train)\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "print(\"Train MAE:\", mae_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "95aba50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test random forest\n",
      "Test MSE: 10990242774005.59\n",
      "Test RMSE: 3315153.5068538818\n",
      "Test R-squared: 0.39990710406560936\n",
      "Adjusted R2 is 0.36852969774224253\n",
      "Test MAE: 1451499.2023874428\n"
     ]
    }
   ],
   "source": [
    "gbr = RandomForestRegressor(n_estimators=200, max_depth=5, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('test random forest')\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fe33d2",
   "metadata": {},
   "source": [
    "### gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "55b7e70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimator = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "pipeline.fit(x_values, y_values)\n",
    "\n",
    "perm_pipe = permutation_importance(pipeline, x_values, y_values, n_repeats=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "feat_import_perm = perm_pipe.importances_mean\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.bar(range(len(feat_import_perm)), feat_import_perm, align=\"center\")\n",
    "ax.set(xticks=range(len(feat_import_perm)), xticklabels=x_values.columns)\n",
    "# Set properties of x axis using setp, we will rotate the labels by 45 degrees\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "eb9ad760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_feature_indices_perm = feat_import_perm.argsort()[-10:][::-1]\n",
    "\n",
    "# Get the names of the top 8 features\n",
    "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
    "\n",
    "# Plotting the permutation importances for the top 10 features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(top_feature_names_perm)), feat_import_perm[top_feature_indices_perm], align=\"center\")\n",
    "plt.xticks(range(len(top_feature_names_perm)), top_feature_names_perm, rotation=45)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Permutation Importance\")\n",
    "plt.title(\"Top 10 Features Based on Permutation Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "8e0fbe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['artist', 'circumference', 'contrast', 'year_sold', 'brightness',\n",
      "       'return_sp', 'painting_drawing', 'year_born', 'dead', 'signed'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "split_percentage = 0.80\n",
    "split_point = int(len(dfx) * split_percentage)\n",
    "\n",
    "# step 3: Split the data in a training and test set\n",
    "train_set = dfx[:split_point]\n",
    "test_set = dfx[split_point:]\n",
    "\n",
    "# Get the indices of the top 8 features\n",
    "top_feature_indices_perm = perm_pipe.importances_mean.argsort()[-10:][::-1]\n",
    "\n",
    "# Get the names of the top 8 features\n",
    "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
    "print(top_feature_names_perm)\n",
    "\n",
    "# splitting in training set X and training set y but now only with the features we want.\n",
    "x_train = train_set[top_feature_names_perm]\n",
    "y_train = train_set['target']\n",
    "\n",
    "x_test = test_set[top_feature_names_perm]\n",
    "y_test = test_set['target']\n",
    "\n",
    "one_hot_cols = ['artist', 'currency', 'painting_drawing', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the columns to encode and scale (standard)\n",
    "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
    "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
    "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "f27b52a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'estimator__max_depth': 20, 'estimator__max_features': 'sqrt', 'estimator__n_estimators': 200}\n",
      "Best MSE: 1306616438186.4478\n",
      "Cross-validation scores: [0.02935968 0.08649929 0.45286066 0.52633709 0.36429123]\n",
      "Mean CV R-squared: 0.29186959075874214\n",
      "training MAE: 0.00038902389825103584\n",
      "Train R-squared: 1.0\n",
      "Training MSE: 9.116887079148081e-07\n",
      "Training RMSE: 0.000954823914611908\n"
     ]
    }
   ],
   "source": [
    "# Define the estimator for Gradient Boosting\n",
    "estimator = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_depth': [7, 10, 20],\n",
    "    'estimator__max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "# Create a grid search object\n",
    "time_series_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the best MSE and corresponding negative value\n",
    "best_mse = -grid_search.best_score_\n",
    "print(\"Best MSE:\", best_mse)\n",
    "\n",
    "# Calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# calculate and print MAE\n",
    "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
    "print('training MAE:', mae)\n",
    "\n",
    "# Make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# Print the R-squared score of the model on the training data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# Print the mean squared error of the model on the training data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Training MSE:\", mse_train)\n",
    "\n",
    "# Print the root mean squared error of the model on the training data\n",
    "rmse_train = sqrt(mse_train)\n",
    "print(\"Training RMSE:\", rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "ddf42d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tets gradient boosting\n",
      "Test MSE: 10944990389993.062\n",
      "Test RMSE: 3308321.3855357314\n",
      "Test R-squared: 0.4023779898074824\n",
      "Adjusted R2 is 0.3628003732384415\n",
      "Test MAE: 1570933.1485898958\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator with the best parameters\n",
    "gbr = GradientBoostingRegressor(n_estimators=200, max_depth=10, max_features= 'sqrt',random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('tets gradient boosting')\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5de38e7",
   "metadata": {},
   "source": [
    "# 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "c586f6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['artist', 'circumference', 'contrast', 'year_sold', 'brightness',\n",
      "       'return_sp', 'painting_drawing', 'year_born'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "split_percentage = 0.80\n",
    "split_point = int(len(dfx) * split_percentage)\n",
    "\n",
    "# step 3: Split the data in a training and test set\n",
    "train_set = dfx[:split_point]\n",
    "test_set = dfx[split_point:]\n",
    "\n",
    "# Get the indices of the top 8 features\n",
    "top_feature_indices_perm = perm_pipe.importances_mean.argsort()[-8:][::-1]\n",
    "\n",
    "# Get the names of the top 8 features\n",
    "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
    "print(top_feature_names_perm)\n",
    "\n",
    "# splitting in training set X and training set y but now only with the features we want.\n",
    "x_train = train_set[top_feature_names_perm]\n",
    "y_train = train_set['target']\n",
    "\n",
    "x_test = test_set[top_feature_names_perm]\n",
    "y_test = test_set['target']\n",
    "\n",
    "one_hot_cols = ['artist', 'currency', 'painting_drawing', 'signed','dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# define the columns to encode and scale (standard)\n",
    "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
    "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
    "\n",
    "# define the transformers for each column type\n",
    "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
    "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
    "    )\n",
    "\n",
    "# define the feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d055057f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'estimator__max_depth': 7, 'estimator__max_features': 'sqrt', 'estimator__n_estimators': 200}\n",
      "Best MSE: 1370961587645.0222\n",
      "Cross-validation scores: [-0.36726615  0.04846453  0.38345372  0.50431102  0.3476067 ]\n",
      "Mean CV R-squared: 0.18331396271695\n",
      "training MAE: 3461.4295716698825\n",
      "Train R-squared: 0.9999851181206624\n",
      "Training MSE: 27221847.877848923\n",
      "Training RMSE: 5217.4560733990775\n"
     ]
    }
   ],
   "source": [
    "# Define the estimator for Gradient Boosting\n",
    "estimator = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_depth': [7, 10, 20],\n",
    "    'estimator__max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "# Create a grid search object\n",
    "time_series_split = TimeSeriesSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the best MSE and corresponding negative value\n",
    "best_mse = -grid_search.best_score_\n",
    "print(\"Best MSE:\", best_mse)\n",
    "\n",
    "# Calculate and print the cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
    "\n",
    "# calculate and print MAE\n",
    "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
    "print('training MAE:', mae)\n",
    "\n",
    "# Make predictions using the fitted pipeline on the train data\n",
    "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
    "\n",
    "# Print the R-squared score of the model on the training data\n",
    "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
    "\n",
    "# Print the mean squared error of the model on the training data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Training MSE:\", mse_train)\n",
    "\n",
    "# Print the root mean squared error of the model on the training data\n",
    "rmse_train = sqrt(mse_train)\n",
    "print(\"Training RMSE:\", rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "9e28cd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tets gradient boosting\n",
      "Test MSE: 11682967524751.102\n",
      "Test RMSE: 3418035.6236808156\n",
      "Test R-squared: 0.3620827165331041\n",
      "Adjusted R2 is 0.3287275644564036\n",
      "Test MAE: 1504138.0660284592\n"
     ]
    }
   ],
   "source": [
    "# define the final estimator with the best parameters\n",
    "gbr = GradientBoostingRegressor(n_estimators=200, max_depth=20, max_features= 'sqrt',random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('estimator', gbr)])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "r2 = pipeline.score(x_test, y_test)\n",
    "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('tets gradient boosting')\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R-squared:\", r2)\n",
    "print('Adjusted R2 is', adj_r2)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc440f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea14ec2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4766bcf",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "b19934ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, layers, initializers, regularizers, losses, callbacks, optimizers\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "0a3d81bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = ['artist', 'currency', 'medium', 'surface', 'signed', 'dead']\n",
    "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
    "\n",
    "# Create preprocessing transformers\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, continuous_cols),\n",
    "        ('cat', categorical_transformer, one_hot_cols)\n",
    "    ])\n",
    "\n",
    "split_percentage = 0.80\n",
    "split_point = int(len(df) * split_percentage)\n",
    "\n",
    "# step 3: Split the data in a training and test set\n",
    "train_set = df[:split_point]\n",
    "test_set = df[split_point:]\n",
    "\n",
    "x_train = train_set.drop(columns=['target'])\n",
    "y_train = train_set['target']\n",
    "\n",
    "x_test = test_set.drop(columns=['target'])\n",
    "y_test = test_set['target']\n",
    "\n",
    "# create a scaler for the target feature\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "y_train_array = np.array(y_train).reshape(-1, 1)\n",
    "y_test_array = np.array(y_test).reshape(-1, 1)\n",
    "\n",
    "y_train_scaled = scaler.fit_transform(y_train_array).flatten()\n",
    "y_test_scaled = scaler.transform(y_test_array).flatten()\n",
    "\n",
    "# Apply the preprocessing pipeline to your data\n",
    "x_train_processed = preprocessor.fit_transform(x_train)\n",
    "x_test_processed = preprocessor.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "88d4f7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 1s 12ms/step - loss: 5.0570 - mae: 0.5079 - val_loss: 5.0119 - val_mae: 0.4532\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.0581 - mae: 0.5089 - val_loss: 5.0119 - val_mae: 0.4532\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.0576 - mae: 0.5084 - val_loss: 5.0119 - val_mae: 0.4532\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.0583 - mae: 0.5092 - val_loss: 5.0119 - val_mae: 0.4532\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.0570 - mae: 0.5081 - val_loss: 5.0119 - val_mae: 0.4532\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.0601 - mae: 0.5112 - val_loss: 5.0119 - val_mae: 0.4532\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgU0lEQVR4nO3deXhV9b3v8fc3O5skkIBKFJQogRZCpZTBSOtYnO514IgDKug5lWOvU1vHp1Xbp61Wr32OT72t9RytxfG25SFqrVzrwfnqsdVjS1DaIwpKaarRMohXkkBCssP3/rFXNjubXxISs9iQfF7Pkydr/dZvrf3dDOuz5mXujoiISK6CfBcgIiJ7JgWEiIgEKSBERCRIASEiIkEKCBERCSrMdwH9qby83CsrK/NdhojIXmP58uUfufv+oWkDKiAqKyupra3NdxkiInsNM/tbV9N0iElERIIUECIiEqSAEBGRIAWEiIgEKSBERCRIASEiIkEKCBERCRpQ90GIiAwWm5vbeGd9I6vWNdLUkuLyWZ/p989QQIiI7MFa2tpZs6GJ1esaWb2+kdXrGnlnfSN/39yS6XNAWRGXfXk8Ztavnx1rQJjZycBPgQRwn7v/S870WcD/Af4aNf3G3W+Opj0AzAY2uPvn46xTRCTfUu3b+dvHW9NBEIXA6nWN1G3awvbovW5DEgV85oBSvjR+JBNHlVE1upSq0cM5aERxv4cDxBgQZpYA7gJOAuqBZWb2hLu/ldP1d+4+O7CIh4B/A34RV40iIrubu7OuoYVV6xp5JwqD1esbeXdDE62p7QCYQeXIYUwcVcrsLxxI1ejhVI0upXLkMAoTu+/UcZx7EDOBNe6+FsDMaoA5QG5ABLn7y2ZWGV95IiLx+mRra6dDQx3DjS2pTJ9Rw4uoGj2cIz+T3iuYNHo4nz2glJIhiTxWnhZnQIwB3s8arwe+GOh3hJn9CfgQ+Ka7r+zNh5jZJcAlAIccckgfSxUR6bvm1nbe3dA5BFava2RD47ZMn7LiQiaNLmPOtIOoGlUWHSIqY5+hQ/JYeffiDIjQATHPGX8dGOvuTWZ2KrAEmNCbD3H3hcBCgOrq6tzli4j0m1T7duo2bckcHloVnSv428db8WjtU1RYwIRRpRw9oZxJo3cEwejh8ZwniFOcAVEPHJw1XkF6LyHD3Ruyhpea2d1mVu7uH8VYl8gerX27s7U1RXNrO1tb29mSNZz+SbG1tT2rLZWZ1tyWYsu2aFpbitbUdkqLChlRkmR4SZLhxcloOGorTrfvGC6krDhJomDvWpH1N3fng0+aM5eRvrOukdXrm/jLhiZa29PnCQoMKsuHcehBwzlj+hiqoiAYO3LYgPnzizMglgETzGwc8AEwDzg/u4OZjQbWu7ub2UzSN+5tirGmAWn7dqepNUVDcxuNLanopy3zuyGnraGljS3bUpgZRYUFJBMFDEkUMKQw/ZNMFFAUDXe0J7OmFyUKSBYaQxKJrHnSy8ptS/dPZMZ35wm2OG3f7rSk2jutjLe2trN1W3qF3dwWrdy3RSv3tnS/LdtSmeGOENjSumN8a2s726ITlbuqqLCAoUMSDB1SSMmQBMOGJCgZkuCAsmKSCaNpW4qPmlpZ+9EWNje30dDclrkqpitlRYXpQClJMrx4FwOmpJDhxUmGDknsVVvKH29pZdW6higEOq4gaqJp247zBAeNKGbi6DKOnVieOTz02QNKKU7m/zxBnGILCHdPmdk3gGdIX+b6gLuvNLPLoun3AHOBy80sBTQD89zTO2pmthiYBZSbWT1wo7vfH1e9+dKxcs9dqadX5NEKvnnnadnDTa2pzO5tV5IJo6w4SVlxIWXFhZQWFeIOTdvSW5mtqe20tad/t7ZvZ1vWeE8rk94oMDoFT3YwDckJq6LsYEqEwyuZs4zuAq8wYbS0be+0dd5p67unrfW2VBQA7TS3tffqeycTRkkywbCi9Ep86JAEQ5OF7DN0CGP2TVCSLIxW8ukV/dBoJZ893tE2rNP0wl5vrbo7TdvS/74amtsyodHQksoMb25uoyH6t9fQ3MZ7H2/NtG9p7f67FxbYzsGStYey855L5wAaUhjPRsSWbSne3dDE6nUNrF7XlNk7+Khpx3mCfYYmqRpVxlkzxlA1uoyqUWVMGFXGiJJkLDXt6cx7WrPsRaqrq313vlFu+3ZnS2bl3nkLvSGwws8dbmhu26WVe2GBRSv26BBAUTIzXlZcyPCs4UxbyY4wGF6cpKiwoM9bdan2dGi0pZxt7e1ZgeJRoLRHgeKZaa3t7VH/7TvaOkInassOoY5gaovCKdS/o0/H7/7+p5soMIYmd14xh1fU6eFhWcM7r7x3zJMcIHtOkP730BEuDS0dAZPKGu5oTwXDpuMQTVdKkonM3siIwF5M9uGwzns1ScqKCml3Z+3GLdHewI4weO/jrZnPKE4WpM8NRIeFOsJg/7KivWrvpz+Y2XJ3rw5N053UwDvrGzOHZxqCK/OdpzW0tNG0rXcr944V9sH7Dc2suLNX4tl9yoqTmRV/cbLvK/f+UJgoSB8aGgKwZ2xJuTup7d4pYLZ1Fyip7aS2O8XJgszW+rCiaOUehcKnCdHBpDBRwH7DhrDfsN5ffePubEtt7xQcnQJm644w6Zi+vqGFdzfs6NPd/zkzKDCjPdrtTRQY48uHMaViBOccVsHEKAgO3m/ogDlPECcFBPAP//r74HHfRGblvmOrvWLfoQzP2ULfaes9a7gkuXcdj91bmBnJhJFMFLAHXyUoOcyM4mSC4mSCA4YX93r+7PNtHcGyYw9lx/mVCaNKmTiqjPH7D6OocGCfJ4iTAgK4c/50igoLKCtOMqJEK3eRPVVBgaUPLxUnqdg339UMfAoI4L9PHp3vEkRE9jgD58yZiIj0KwWEiIgEKSBERCRIASEiIkEKCBERCVJAiIhIkAJCRESCFBAiIhKkgBARkSAFhIiIBCkgREQkSAEhIiJBCggREQlSQIiISJACQkREghQQIiISpIAQEZEgBYSIiAQpIEREJEgBISIiQQoIEREJijUgzOxkM1ttZmvM7IbA9FlmttnMVkQ/39/VeUVEJF6FcS3YzBLAXcBJQD2wzMyecPe3crr+zt1n93FeERGJSZx7EDOBNe6+1t1bgRpgzm6YV0RE+kGcATEGeD9rvD5qy3WEmf3JzJ4ys8m9nBczu8TMas2sduPGjf1Rt4iIEG9AWKDNc8ZfB8a6+1TgX4ElvZg33ei+0N2r3b16//3372utIiKSI86AqAcOzhqvAD7M7uDuDe7eFA0vBZJmVr4r84qISLziDIhlwAQzG2dmQ4B5wBPZHcxstJlZNDwzqmfTrswrIiLxiu0qJndPmdk3gGeABPCAu680s8ui6fcAc4HLzSwFNAPz3N2B4Lxx1SoiIjuz9Pp4YKiurvba2tp8lyEistcws+XuXh2apjupRUQkSAEhIiJBCggREQlSQIiISJACQkREghQQIiISpIAQEZEgBYSIiAQpIEREJEgBISIiQQoIEREJUkCIiEiQAkJERIIUECIiEqSAEBGRIAWEiIgEKSBERCRIASEiIkEKCBERCVJAiIhIkAJCRESCFBAiIhKkgBARkSAFhIiIBCkgREQkKNaAMLOTzWy1ma0xsxu66Xe4mbWb2dystqvM7E0zW2lmV8dZp4iI7Cy2gDCzBHAXcApwKDDfzA7tot9twDNZbZ8HLgZmAlOB2WY2Ia5aRURkZ3HuQcwE1rj7WndvBWqAOYF+VwCPARuy2j4HvObuW909BfwHcGaMtYqISI44A2IM8H7WeH3UlmFmY0iv+O/JmfdN4FgzG2lmQ4FTgYNDH2Jml5hZrZnVbty4sd+KFxEZ7OIMCAu0ec74HcD17t7eqZP726QPOz0HPA38CUiFPsTdF7p7tbtX77///p+6aBERSSuMcdn1dN7qrwA+zOlTDdSYGUA5cKqZpdx9ibvfD9wPYGY/jJYnIiK7SZwBsQyYYGbjgA+AecD52R3cfVzHsJk9BDzp7kui8QPcfYOZHQKcBRwRY60iIpIjtoBw95SZfYP01UkJ4AF3X2lml0XTc8875HrMzEYCbcDX3f3/xVWriIjsLM49CNx9KbA0py0YDO6+IGf8mPgqExGRnuhOahERCVJAiIhIkAJCRESCFBAiIhKkgBARkaBYr2ISkYGpra2N+vp6Wlpa8l2K7KLi4mIqKipIJpO7PI8CQkR6rb6+nrKyMiorK4mehCB7MHdn06ZN1NfXM27cuJ5niOgQk4j0WktLCyNHjlQ47CXMjJEjR/Z6j08BISJ9onDYu/Tl70sBISJ7nU2bNjFt2jSmTZvG6NGjGTNmTGa8tbW123lra2u58sore/yMI488sl9qfemllzAz7r///kzbG2+8gZlx++23Z9pSqRTl5eV8+9vf7jT/rFmzqKqqyny/uXPnsrvoHISI7HVGjhzJihUrALjpppsoLS3lm9/8ZmZ6KpWisDC8equurqa6urrHz3j11Vf7pVaAKVOm8PDDD/PVr34VgJqaGqZOndqpz7PPPktVVRWPPPIIP/zhDztt8S9atGiXau5v2oMQkQFhwYIFXHvttRx33HFcf/31/PGPf+TII49k+vTpHHnkkaxevRpIb9HPnj0bSIfLRRddxKxZsxg/fjx33nlnZnmlpaWZ/rNmzWLu3LlMmjSJCy64APf0q22WLl3KpEmTOProo7nyyiszy811yCGH0NLSwvr163F3nn76aU455ZROfRYvXsxVV13FIYccwmuvvdbvfz59oT0IEflUfvDblbz1YUO/LvPQg4Zz4z9M7vV877zzDs8//zyJRIKGhgZefvllCgsLef755/nOd77DY489ttM8q1at4sUXX6SxsZGqqiouv/zynS4FfeONN1i5ciUHHXQQRx11FK+88grV1dVceumlvPzyy4wbN4758+d3W9vcuXN59NFHmT59OjNmzKCoqCgzrbm5mRdeeIGf//znfPLJJyxevJgjjtjxhoMLLriAkpISAE466SR+9KMf9frPpi+6DQgzG+7uwb95MzvE3d+LpywRkd4755xzSCQSAGzevJkLL7yQd999FzOjra0tOM9pp51GUVERRUVFHHDAAaxfv56KiopOfWbOnJlpmzZtGnV1dZSWljJ+/PjMZaPz589n4cKFXdZ27rnnct5557Fq1Srmz5/f6RDWk08+yXHHHcfQoUM5++yzueWWW/jJT36S+S75OsTU0x7ES8AMADN7wd1PyJq2pGOaiAxefdnSj8uwYcMyw9/73vc47rjjePzxx6mrq2PWrFnBebK35BOJBKnUzm83DvXpOMy0q0aPHk0ymeS5557jpz/9aaeAWLx4Ma+88gqVlZVA+iT8iy++yIknntirz+hvPQVE9nVR+3UzTURkj7J582bGjBkDwEMPPdTvy580aRJr166lrq6OyspKHn744R7nufnmm9mwYUNmzwCgoaGB3//+97z//vuZIHrwwQdZvHjxHh8Q3sVwaFxEZI9x3XXXceGFF/LjH/+Y448/vt+XX1JSwt13383JJ59MeXk5M2fO7HGe0KWzv/nNbzj++OM77aXMmTOH6667jm3btgGdz0GUl5fz/PPP99O36J51t5tkZvXAj0nvLVwTDRONX+3uB8deYS9UV1d7bW1tvssQGfDefvttPve5z+W7jLxramqitLQUd+frX/86EyZM4Jprrsl3WV0K/b2Z2XJ3D57g6Oky13uBMqA0a7hj/L5PXa2IyF7s3nvvZdq0aUyePJnNmzdz6aWX5rukftXtISZ3/0FX08zs8P4vR0Rk73HNNdfs0XsMn1av7oMws0OBecB8YDOw+6+7EhGR3aLHgDCzsaQDYT6QAsYC1e5eF29pIiKST92egzCzV4GlQBKY6+6HAY0KBxGRga+nk9QbSZ+UHgXsH7Xp8lYRkUGg24Bw9znAFOB14Adm9ldgXzPr+YJfEZGYzJo1i2eeeaZT2x133MHXvva1bufpuAz+1FNP5ZNPPtmpz0033dTpEdwhS5Ys4a233sqMf//73++X+xL2xMeC9/g0V3ff7O4PuPtJwJeAG4E7zOz9nuY1s5PNbLWZrTGzG7rpd7iZtZvZ3Ky2a8xspZm9aWaLzax4F7+TiAxw8+fPp6amplNbTU1Njw/M67B06VL22WefPn12bkDcfPPN/XbHc8djwTv09Fjw3PvYFi1axIoVK1ixYgW//vWvP3U9vXrct7uvd/c73f1I4Oju+ppZArgLOAU4FJgfXQUV6ncb8ExW2xjgStInwz8PJEhfPSUiwty5c3nyySczdxrX1dXx4YcfcvTRR3P55ZdTXV3N5MmTufHGG4PzV1ZW8tFHHwFw6623UlVVxYknnph5JDik73E4/PDDmTp1KmeffTZbt27l1Vdf5YknnuBb3/oW06ZN4y9/+QsLFizIrIxfeOEFpk+fzpQpU7jooosy9VVWVnLjjTcyY8YMpkyZwqpVq4J17WmPBe/paa5P9DD/6d1Mmwmscfe10bJqgDnAWzn9rgAeA3LvqygESsysDRgKfNhDLSKSD0/dAOv+q3+XOXoKnPIvXU4eOXIkM2fO5Omnn2bOnDnU1NRw3nnnYWbceuut7LfffrS3t3PCCSfw5z//mS984QvB5SxfvpyamhreeOMNUqkUM2bM4LDDDgPgrLPO4uKLLwbgu9/9Lvfffz9XXHEFp59+OrNnz97pEE5LSwsLFizghRdeYOLEiXzlK1/hZz/7GVdffTWQfkTG66+/zt13383tt9/OffeF7zXekx4L3tMexBFABfA74Hbgf+X8dGcMkH0Yqj5qy4j2FM4E7slud/cPos97D/g7sNndnw19iJldYma1Zla7cePGHkoSkYEi+zBT9uGlRx55hBkzZjB9+nRWrlzZ6XBQrt/97neceeaZDB06lOHDh3P66Tu2ed98802OOeYYpkyZwqJFi1i5cmW39axevZpx48YxceJEAC688EJefvnlzPSzzjoLgMMOO4y6uroul3Puuefy6KOPsnjx4p0OmeU+Fvzxxx+nvb09Mz37EFN/vDOip/sgRgMnkb4H4nzg34HF7t79n1Ra6GmvuVdA3QFc7+7t2a/XM7N9Se9tjAM+AR41s39091/ttED3hcBCSD+LaRfqEpH+1M2WfpzOOOMMrr32Wl5//XWam5uZMWMGf/3rX7n99ttZtmwZ++67LwsWLKClpaXb5WSve7ItWLCAJUuWMHXqVB566CFeeumlbpfT0+O/O/YEunqkeIc96bHgPV3F1O7uT7v7haRPUK8BXjKzK3Zh2fVA9sP8Ktj5MFE1UGNmdcBc4G4zOwM4Efiru2909zbgN0D/vEFcRAaE0tJSZs2axUUXXZTZ0m5oaGDYsGGMGDGC9evX89RTT3W7jGOPPZbHH3+c5uZmGhsb+e1vf5uZ1tjYyIEHHkhbWxuLFi3KtJeVldHY2LjTsiZNmkRdXR1r1qwB4Je//CVf/vKX+/Tdbr75Zm677bbgY8Hfe+896urqqKur46677mLx4sV9+oxdsSt3UhcBp5Hei6gE7iS9wu7JMmCCmY0DPiB9kvn87A7uPi7rcx4CnnT3JWb2ReBLZjYUaAZOAPSYVhHpZP78+Zx11lmZQ01Tp05l+vTpTJ48mfHjx3PUUUd1O/+MGTM477zzmDZtGmPHjuWYY47JTLvlllv44he/yNixY5kyZUomFObNm8fFF1/MnXfe2elKoeLiYh588EHOOeccUqkUhx9+OJdddlmfvtee8ljwnh73/b+BzwNPATXu/mavFm52KunDSAngAXe/1cwuA3D3e3L6PkQ6IH4djf8AOI/04z3eAP6Hu2/r7vP0uG+R3UOP+9479fZx3z3tQfwTsAWYCFyZdazOAHf34d3N7O5LST+qI7vtni76LsgZv5H0PRciIpIHPT3uu1f3SYiIyMChABARkSAFhIj0SU+XdcqepS9/XwoIEem14uJiNm3apJDYS7g7mzZtori4d4+069Ub5UREACoqKqivr0dPL9h7FBcXU1FR0at5FBAi0mvJZJJx48b13FH2ajrEJCIiQQoIEREJUkCIiEiQAkJERIIUECIiEqSAEBGRIAWEiIgEKSBERCRIASEiIkEKCBERCVJAiIhIkAJCRESCFBAiIhKkgBARkSAFhIiIBCkgREQkSAEhIiJBCggREQlSQIiISFCsAWFmJ5vZajNbY2Y3dNPvcDNrN7O50XiVma3I+mkws6vjrFVERDorjGvBZpYA7gJOAuqBZWb2hLu/Feh3G/BMR5u7rwamZU3/AHg8rlpFRGRnce5BzATWuPtad28FaoA5gX5XAI8BG7pYzgnAX9z9b/GUKSIiIXEGxBjg/azx+qgtw8zGAGcC93SznHnA4n6vTkREuhVnQFigzXPG7wCud/f24ALMhgCnA492+SFml5hZrZnVbty4sa+1iohIjtjOQZDeYzg4a7wC+DCnTzVQY2YA5cCpZpZy9yXR9FOA1919fVcf4u4LgYUA1dXVuQEkIiJ9FGdALAMmmNk40ieZ5wHnZ3dw93Edw2b2EPBkVjgAzEeHl0RE8iK2gHD3lJl9g/TVSQngAXdfaWaXRdO7O++AmQ0lfQXUpXHVKCIiXYtzDwJ3XwoszWkLBoO7L8gZ3wqMjK04ERHplu6kFhGRIAWEiIgEKSBERCRIASEiIkEKCBERCVJAiIhIkAJCRESCFBAiIhKkgBARkSAFhIiIBCkgREQkSAEhIiJBCggREQlSQIiISJACQkREghQQIiISpIAQEZEgBYSIiAQpIEREJEgBISIiQQoIEREJUkCIiEiQAkJERIIUECIiEqSAEBGRoFgDwsxONrPVZrbGzG7opt/hZtZuZnOz2vYxs1+b2Soze9vMjoizVhER6Sy2gDCzBHAXcApwKDDfzA7tot9twDM5k34KPO3uk4CpwNtx1SoiIjuLcw9iJrDG3de6eytQA8wJ9LsCeAzY0NFgZsOBY4H7Ady91d0/ibFWERHJEWdAjAHezxqvj9oyzGwMcCZwT86844GNwINm9oaZ3Wdmw2KsVUREcsQZEBZo85zxO4Dr3b09p70QmAH8zN2nA1uA4DkMM7vEzGrNrHbjxo2fsmQREelQGOOy64GDs8YrgA9z+lQDNWYGUA6camYp4DWg3t3/EPX7NV0EhLsvBBYCVFdX5waQiIj0UZwBsQyYYGbjgA+AecD52R3cfVzHsJk9BDzp7kui8ffNrMrdVwMnAG/FWKuIiOSILSDcPWVm3yB9dVICeMDdV5rZZdH03PMOua4AFpnZEGAt8M9x1SoiIjsz94FzVKa6utpra2vzXYaIyF7DzJa7e3Vomu6kFhGRIAWEiIgEKSBERCRIASEiIkEKCBERCVJAiIhIkAJCRESCFBAiIhKkgBARkSAFhIiIBCkgREQkSAEhIiJBCggREQlSQIiISJACQkREghQQIiISpIAQEZGgON9Jvff4+Zch1ZLvKkRE+qZkP7joqX5frAICoHwitG/LdxUiIn1TPCKWxSogAM6+N98ViIjscXQOQkREghQQIiISpIAQEZEgBYSIiAQpIEREJEgBISIiQQoIEREJUkCIiEiQuXu+a+g3ZrYR+FsfZy8HPurHcvYG+s4D32D7vqDv3Ftj3X3/0IQBFRCfhpnVunt1vuvYnfSdB77B9n1B37k/6RCTiIgEKSBERCRIAbHDwnwXkAf6zgPfYPu+oO/cb3QOQkREgrQHISIiQQoIEREJGvQBYWYnm9lqM1tjZjfku57dwcweMLMNZvZmvmvZHczsYDN70czeNrOVZnZVvmuKm5kVm9kfzexP0Xf+Qb5r2l3MLGFmb5jZk/muZXcwszoz+y8zW2Fmtf267MF8DsLMEsA7wElAPbAMmO/ub+W1sJiZ2bFAE/ALd/98vuuJm5kdCBzo7q+bWRmwHDhjIP89m5kBw9y9ycySwO+Bq9z9tTyXFjszuxaoBoa7++x81xM3M6sDqt29328OHOx7EDOBNe6+1t1bgRpgTp5rip27vwx8nO86dhd3/7u7vx4NNwJvA2PyW1W8PK0pGk1GPwN+a9DMKoDTgPvyXctAMNgDYgzwftZ4PQN8xTHYmVklMB34Q55LiV10qGUFsAF4zt0H/HcG7gCuA7bnuY7dyYFnzWy5mV3Snwse7AFhgbYBv5U1WJlZKfAYcLW7N+S7nri5e7u7TwMqgJlmNqAPJ5rZbGCDuy/Pdy272VHuPgM4Bfh6dAi5Xwz2gKgHDs4arwA+zFMtEqPoOPxjwCJ3/02+69md3P0T4CXg5PxWErujgNOjY/I1wPFm9qv8lhQ/d/8w+r0BeJz0ofN+MdgDYhkwwczGmdkQYB7wRJ5rkn4WnbC9H3jb3X+c73p2BzPb38z2iYZLgBOBVXktKmbu/m13r3D3StL/l/+vu/9jnsuKlZkNiy68wMyGAf8N6LerEwd1QLh7CvgG8AzpE5ePuPvK/FYVPzNbDPwnUGVm9Wb21XzXFLOjgH8ivUW5Ivo5Nd9FxexA4EUz+zPpDaHn3H1QXPY5yIwCfm9mfwL+CPy7uz/dXwsf1Je5iohI1wb1HoSIiHRNASEiIkEKCBERCVJAiIhIkAJCRESCFBAiPTCz9qzLY1f051N/zaxysDxVV/Y+hfkuQGQv0Bw9skJkUNEehEgfRc/hvy1678IfzeyzUftYM3vBzP4c/T4kah9lZo9H72j4k5kdGS0qYWb3Ru9teDa68xkzu9LM3oqWU5OnrymDmAJCpGclOYeYzsua1uDuM4F/I/0kUaLhX7j7F4BFwJ1R+53Af7j7VGAG0HHX/gTgLnefDHwCnB213wBMj5ZzWTxfTaRrupNapAdm1uTupYH2OuB4d18bPQxwnbuPNLOPSL+gqC1q/7u7l5vZRqDC3bdlLaOS9GMwJkTj1wNJd/+fZvY06Rc7LQGWZL3fQWS30B6EyKfjXQx31SdkW9ZwOzvODZ4G3AUcBiw3M50zlN1KASHy6ZyX9fs/o+FXST9NFOAC0q/7BHgBuBwyL/MZ3tVCzawAONjdXyT9Apx9gJ32YkTipC0SkZ6VRG9m6/C0u3dc6lpkZn8gvbE1P2q7EnjAzL4FbAT+OWq/ClgYPT23nXRY/L2Lz0wAvzKzEaRfbPWT6L0OIruNzkGI9FGcL4sX2RPoEJOIiARpD0JERIK0ByEiIkEKCBERCVJAiIhIkAJCRESCFBAiIhL0/wFgSF2MBx+cMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    layers.Input(shape=(33,)),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Set your desired learning rate\n",
    "learning_rate = 0.0000000001  # You can adjust this value\n",
    "\n",
    "# Create an instance of the Adam optimizer with the specified learning rate\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "# Train the model with MAE monitoring and early stopping\n",
    "history = model.fit(\n",
    "    x_train_processed, y_train_scaled,\n",
    "    epochs=50,\n",
    "    validation_data=(x_test_processed, y_test_scaled),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Get MAE values from the training history\n",
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "\n",
    "# Plot MAE values over epochs\n",
    "plt.plot(mae, label='Training MAE')\n",
    "plt.plot(val_mae, label='Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fa50eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9890fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14a5152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2307736b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce5e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c764aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6768d322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda8a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ca9155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eec6fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de67f238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbb32a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6498268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d96dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c699895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9abcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689d4b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a0895e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cb0fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c8f2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efffa8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f03706a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db400878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe8e26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87424bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f015d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cf86b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedd78f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "c4a433c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "import re\n",
      "import warnings\n",
      "import requests\n",
      "warnings.filterwarnings(\"ignore\")\n",
      "   2:\n",
      "df = pd.read_csv('dataset_twee.csv')\n",
      "df.head(2)\n",
      "   3:\n",
      "# dropping the duplicates\n",
      "df = df.drop_duplicates()\n",
      "   4:\n",
      "# looking how much different artists we have to work with\n",
      "artist_freq = df['artist'].value_counts()\n",
      "print(f\"There are {len(artist_freq)} different artists in {len(df)} samples and the frequency of each different artist is:\")\n",
      "print(artist_freq)\n",
      "   5:\n",
      "# some painters are the same and we are going to put them under one name \n",
      "replace_artists = {'Jan Breughel I': 'Jan Breughel the elder', 'Jan Breughel II': 'Jan Breughel the younger', 'Rysselberghe': 'Theo Van Rysselberghe'}\n",
      "df['artist'] = df['artist'].replace(replace_artists)\n",
      "\n",
      "# drop all the columns with Breughel because we dont know which one it is ( there are more Breughels such as Pieter B. the younger and elder, ...)\n",
      "df = df[df['artist'] != 'Breughel']\n",
      "\n",
      "# print frequention of the artists \n",
      "artist_freq = df['artist'].value_counts()\n",
      "print(f\"There are {len(artist_freq)} different artists in {len(df)} samples and the frequency of each different artist is:\")\n",
      "print(artist_freq)\n",
      "   6: df.info()\n",
      "   7:\n",
      "# drop the nan values of price_realized because these rows are useless\n",
      "df.dropna(subset=['price_realized'], inplace=True)\n",
      "   8: print(f\"The data contains {df.shape[0]} instances and {df.shape[1]} features.\")\n",
      "   9:\n",
      "# creating new feature: year_sold \n",
      "df['year_sold'] = pd.to_numeric(df['img_name'].str[:4], errors='coerce').astype('Int64')\n",
      "  10:\n",
      "# creating new feature: city_auction\n",
      "df['city_auction'] = df['img_name'].str[5:8]\n",
      "\n",
      "# changing some values of this column\n",
      "df['city_auction'] = np.where( df['city_auction'].isnull(), 'unknown', df['city_auction'])\n",
      "print(df['city_auction'].unique())\n",
      "  11:\n",
      "# dropping the duplicate paintings, it is perfect possible that the exact row is not the same \n",
      "# but the most that a painting is taken twice with an error or difference in a one feature\n",
      "\n",
      "# first we look at the different titles which is the perfect reference point to look at duplicates\n",
      "duplicate_titles = df['title'].duplicated().sum()\n",
      "print('The amount of duplicate titles is:', duplicate_titles)\n",
      "\n",
      "# secondly, we look at the different title, artist and year_sold\n",
      "duplicates_3features = df.duplicated(subset=['artist', 'title', 'year_sold'])\n",
      "df_duplicates = df[duplicates_3features]\n",
      "num_duplicates = duplicates_3features.sum()\n",
      "print(f\"Number of duplicates across features title, arist and year_sold: {num_duplicates}\")\n",
      "  12:\n",
      "# dropping the duplicate rows BUT keeping the ones with the least nan_values\n",
      "df['nan_count'] = df.isnull().sum(axis=1)\n",
      "df_sorted = df.sort_values(by='nan_count')\n",
      "df_no_triple_duplicates = df_sorted.drop_duplicates(subset=['title','artist','year_sold'])\n",
      "df_no_triple_duplicates = df_no_triple_duplicates.drop('nan_count',axis=1)\n",
      "  13:\n",
      "artist_freq = df_no_triple_duplicates['artist'].value_counts()\n",
      "df = df_no_triple_duplicates\n",
      "print(f\"There are {len(artist_freq)} different artists in {len(df_no_triple_duplicates)} samples and the frequency of each different artist is:\\n\")\n",
      "print(artist_freq)\n",
      "  14:\n",
      "# resetting the index of the dataframe\n",
      "df.reset_index(drop=True, inplace=True)\n",
      "df.head(2)\n",
      "  15:\n",
      "city_mapping = {\n",
      "    'AMS': 'Amsterdam',\n",
      "    'PAR': 'Paris',\n",
      "    'NYR': 'New York',\n",
      "    'CKS': 'London',\n",
      "    'HGK': 'Hong Kong',\n",
      "    'NYP': 'New York',\n",
      "    'CSK': 'London',\n",
      "    'RMA': 'Milan',\n",
      "    'NYE': 'New York',\n",
      "    'ECO': 'unknown',\n",
      "    'unknown': 'unknown'\n",
      "}\n",
      "\n",
      "# Use the replace function to map the values\n",
      "df['city_auction'] = df['city_auction'].replace(city_mapping)\n",
      "  16:\n",
      "# splitsing the realized_price to currency and price\n",
      "df[['currency','price']] = df['price_realized'].str.split(' ', n=1, expand=True)\n",
      "df['price'] = df['price'].str.replace(',','')\n",
      "  17:\n",
      "# splitsing the estimate_price to a low-price and high-price estimate\n",
      "df[['low_estimate','high_estimate']] = df['estimated_price'].str.split(' – ', expand=True)\n",
      "df['low_estimate'] = df['low_estimate'].str.replace(r'\\D','',regex=True)\n",
      "df['high_estimate'] = df['high_estimate'].str.replace(r'\\D','',regex=True)\n",
      "  18:\n",
      "# Assuming df['price'], df['low_estimate'], and df['high_estimate'] may have missing values\n",
      "valid_rows = df.dropna(subset=['price', 'low_estimate', 'high_estimate'])\n",
      "\n",
      "correct_valuation = sum(\n",
      "    (valid_rows['price'] >= valid_rows['low_estimate']) &\n",
      "    (valid_rows['price'] <= valid_rows['high_estimate'])\n",
      ")\n",
      "\n",
      "over_valuation = sum(valid_rows['price'] > valid_rows['high_estimate'])\n",
      "under_valuation = sum(valid_rows['price'] < valid_rows['low_estimate'])\n",
      "\n",
      "print('The correct number of estimations are:', correct_valuation)\n",
      "print('The number of over estimations are: ', over_valuation)\n",
      "print('The number of under estimations are: ', under_valuation)\n",
      "print(' ')\n",
      "\n",
      "# the ratio of correct, over and under valuations\n",
      "share_right = correct_valuation/len(valid_rows)\n",
      "share_over = over_valuation/len(valid_rows)\n",
      "share_under = under_valuation/len(valid_rows)\n",
      "\n",
      "print(f'{share_right:.2f}% of the estimations are correct.')\n",
      "print(f'{share_over:.2f}% of the estimations are too high.')\n",
      "print(f'{share_under:.2f}% of the estimations are too low.')\n",
      "  19:\n",
      "# making a new variable average_estimate to use for the sum of residuals\n",
      "# first we need to make floats and ignore the strings with NaN\n",
      "df['low_estimate'] = df['low_estimate'].replace('', np.nan)\n",
      "df['low_estimate'] = df['low_estimate'].astype(float)\n",
      "df['high_estimate'] = df['high_estimate'].replace('', np.nan)\n",
      "df['high_estimate'] = df['high_estimate'].astype(float)\n",
      "df['average_estimate'] = (df['low_estimate'] + df['high_estimate'])/2\n",
      "\n",
      "# we keep it in a variable so we can drop these columns due to human-induced bias and the risk of overfitting\n",
      "average_estimates = df['average_estimate'] \n",
      "average_estimates.head(2)\n",
      "  20:\n",
      "# test with the package\n",
      "from datetime import datetime\n",
      "from forex_python.converter import CurrencyRates\n",
      "\n",
      "c = CurrencyRates()\n",
      "date_string = \"2000-01-01\"\n",
      "target_currency = \"EUR\"\n",
      "base_currency = \"HKD\"\n",
      "\n",
      "target_date = datetime.strptime(date_string, \"%Y-%m-%d\")\n",
      "\n",
      "historical_rate = c.get_rate(base_currency, target_currency, target_date)\n",
      "\n",
      "print(f\"The exchange rate on {date_string} from {base_currency} to {target_currency} was: {historical_rate:.4f}\")\n",
      "  21:\n",
      "# making a function to extract the historical rate between currencies \n",
      "# this package can only go to 2000 so all the years between 1994 and 1999 are changed to 2000 to extract the rate\n",
      "from forex_python.converter import CurrencyRates\n",
      "from datetime import datetime\n",
      "\n",
      "# create a CurrencyRates object\n",
      "c = CurrencyRates()\n",
      "\n",
      "# this package can only go to 2000 so all the years between 1994 and 1999 are changed to 2000 to extract the rate\n",
      "# making a new temporary column 'year_temp' with all the years 2000 or more\n",
      "# function adjust_year to make this happen\n",
      "def adjust_years(year):\n",
      "    if pd.notna(year):\n",
      "        return max(year, 2000)\n",
      "    else:\n",
      "        return pd.NA\n",
      "\n",
      "# Apply the function to create the new 'year_temp' column\n",
      "df['year_temp'] = df['year_sold'].apply(adjust_years)\n",
      "\n",
      "# making a new column called date_string with the date always the first of the year\n",
      "df['year_string'] = pd.to_datetime(df['year_temp'], format='%Y').dt.to_period('Y').dt.start_time.astype(str)\n",
      "  22:\n",
      "# calculating the average exchange rates to fill in the nan values\n",
      "\n",
      "date_string_average = [datetime(year, 1, 1).strftime(\"%Y-%m-%d\") for year in range(2000, 2023 + 1)]\n",
      "\n",
      "# Euro to Euro\n",
      "average_rate_EUR = 1\n",
      "print(average_rate_EUR)\n",
      "\n",
      "# USD to Euro\n",
      "USD_to_EUR = []\n",
      "for date in date_string_average:\n",
      "    base_currency = 'USD'\n",
      "    target_currency = 'EUR'\n",
      "    target_date = datetime.strptime(date, \"%Y-%m-%d\")\n",
      "    historical_rate = c.get_rate(base_currency, target_currency, target_date)\n",
      "    USD_to_EUR.append(historical_rate)\n",
      "average_rate_USD = np.mean(USD_to_EUR)    \n",
      "print(average_rate_USD)\n",
      "\n",
      "# GBP to Euro\n",
      "GBP_to_EUR = []\n",
      "for date in date_string_average:\n",
      "    base_currency = 'GBP'\n",
      "    target_currency = 'EUR'\n",
      "    target_date = datetime.strptime(date, \"%Y-%m-%d\")\n",
      "    historical_rate = c.get_rate(base_currency, target_currency, target_date)\n",
      "    GBP_to_EUR.append(historical_rate)\n",
      "average_rate_GBP = np.mean(GBP_to_EUR)    \n",
      "print(average_rate_GBP)\n",
      "\n",
      "# NLG to Euro\n",
      "average_rate_NLG = 0.45378\n",
      "print(average_rate_NLG)\n",
      "\n",
      "# HKD to Euro\n",
      "HKD_to_EUR = []\n",
      "for date in date_string_average:\n",
      "    base_currency = 'HKD'\n",
      "    target_currency = 'EUR'\n",
      "    target_date = datetime.strptime(date, \"%Y-%m-%d\")\n",
      "    historical_rate = c.get_rate(base_currency, target_currency, target_date)\n",
      "    HKD_to_EUR.append(historical_rate)\n",
      "average_rate_HKD = np.mean(HKD_to_EUR)    \n",
      "print(average_rate_HKD)\n",
      "  23:\n",
      "# making it through working in blocks instead of with a function\n",
      "df['exchange_rate'] = None # initialization of the new column\n",
      "for index, row in df.iterrows(): # iterating\n",
      "    c = CurrencyRates() # creating a CurrencyRates object\n",
      "    date_string = df['year_string'][index]\n",
      "    target_currency = 'EUR'\n",
      "    base_currency = df['currency'][index]\n",
      "\n",
      "    \n",
      "    if pd.isna(date_string) or date_string == 'NaT':\n",
      "        if base_currency == 'EUR':\n",
      "            historical_rate = average_rate_EUR\n",
      "        elif base_currency == 'USD':\n",
      "            historical_rate = average_rate_USD\n",
      "        elif base_currency == 'GBP':\n",
      "            historical_rate = average_rate_GBP\n",
      "        elif base_currency == 'NLG':\n",
      "            historical_rate = average_rate_NLG\n",
      "        else:\n",
      "            historical_rate = average_rate_HKD\n",
      "    else:\n",
      "        # converting date string to datetime object\n",
      "        target_date = datetime.strptime(date_string, \"%Y-%m-%d\")\n",
      "\n",
      "        if base_currency == 'NLG':\n",
      "            historical_rate =  0.45378\n",
      "        else:\n",
      "            historical_rate = c.get_rate(base_currency, target_currency, target_date)\n",
      "\n",
      "    df['exchange_rate'][index] = historical_rate\n",
      "df.head(2)\n",
      "  24:\n",
      "# making a new column price_EUR which is the price in euro\n",
      "# convert exchange_rate and price to float\n",
      "df['exchange_rate'] = df['exchange_rate'].astype(float)\n",
      "df['price'] = df['price'].astype(float)\n",
      "\n",
      "df['price_EUR'] = (df['price'] * df['exchange_rate']).round(2)\n",
      "df['low_estimate_EUR'] = (df['low_estimate'] * df['exchange_rate']).round(2)\n",
      "df['high_estimate_EUR'] = (df['high_estimate'] * df['exchange_rate']).round(2)\n",
      "df['average_estimate_EUR'] = (df['average_estimate'] * df['exchange_rate']).round(2)\n",
      "\n",
      "df.head(1)\n",
      "  25:\n",
      "price_zero_count = (df['price_EUR'] == 0).sum()\n",
      "print(price_zero_count)\n",
      "  26: df = df[df['price_EUR'] != 0]\n",
      "  27:\n",
      "price_zero_count = (df['price_EUR'] == 0).sum()\n",
      "print(price_zero_count)\n",
      "  28:\n",
      "# we are going to calculate the sum of residuals\n",
      "\n",
      "residuals = df['price_EUR'].dropna() - df['average_estimate_EUR'].dropna()\n",
      "sum_of_residuals = np.sum(residuals)\n",
      "average_residual = sum_of_residuals / len(residuals.dropna())\n",
      "\n",
      "# printing\n",
      "print(\"The sum of residuals is equal to:\", sum_of_residuals)\n",
      "print(len(residuals.dropna()))\n",
      "print('The average residual is equal to:', average_residual) # without the nan vlues of the avearge\n",
      "  29: df.info()\n",
      "  30:\n",
      "# making a new column called 'signed' from output of the column 'details'\n",
      "df['signed'] = df['details'].str.contains(r'signed|signé', case=False, na=False, regex=True).astype(bool)\n",
      "  31:\n",
      "# making a new column called 'Dimensions' from output of the column 'details'\n",
      "def extract_dimensions(text):\n",
      "    matches = re.findall(r'(\\d+\\.\\d+\\s?[xX]\\s?\\d+\\.\\d+\\s?cm\\.|\\d+\\.\\d+\\s?[xX]\\s?\\d+\\.\\d+\\s?mm\\.)', text)\n",
      "    return matches[0] if matches else None\n",
      "\n",
      "# Apply the function to the 'details' column to create the new 'dimension' column\n",
      "df['dimension'] = df['details'].apply(extract_dimensions)\n",
      "df['dimension'].head(3)\n",
      "  32:\n",
      "# making a new column called 'dimension' from output of the column 'details'\n",
      "def extract_information(text):\n",
      "    matches = re.findall(r'(.{15}\\s?(?:cm\\.|mm\\.))', text)\n",
      "    return matches[0] if matches else None\n",
      "\n",
      "# Apply the function to the 'details' column to create the new 'X' column\n",
      "df['dimension'] = df['details'].apply(extract_information)\n",
      "df['dimension']\n",
      "  33:\n",
      "# splitsing and creating\n",
      "\n",
      "# makign a column with the unit of length of the dimensions\n",
      "df['unit_of_length'] = df['dimension'].str[-3:-1]\n",
      "\n",
      "# Handling 'None' values in 'dimension'\n",
      "df.loc[df['dimension'].isna(), ['l', 'w']] = [None, None]\n",
      "\n",
      "# Splitting 'dimension' into 'length' and 'width' using str.extract\n",
      "df[['l', 'w']] = df['dimension'].str.extract(r'([\\d.]+)\\s*x\\s*([\\d.]+)')\n",
      "\n",
      "# Removing non-numeric characters and converting to float\n",
      "df['l'] = pd.to_numeric(df['l'], errors='coerce')\n",
      "df['w'] = pd.to_numeric(df['w'], errors='coerce')\n",
      "\n",
      "# Display the updated DataFrame\n",
      "print(df[['dimension', 'unit_of_length', 'l', 'w']])\n",
      "  34:\n",
      "# creating the Area and Circumference\n",
      "\n",
      "# first we need to put all in the same unit of length and we use 'cm'\n",
      "for index, row in df.iterrows():\n",
      "    if df['unit_of_length'][index] == 'mm':\n",
      "        df['l'][index] = df['l'][index]/10\n",
      "        df['w'][index] = df['w'][index]/10 \n",
      "        df['unit_of_length'][index] = 'cm'\n",
      "\n",
      "df['area'] = df['l'] * df['w']\n",
      "df['circumference'] = df['l']*2 + df['w']*2\n",
      "\n",
      "print(df[['unit_of_length', 'l', 'w','area','circumference']])\n",
      "  35:\n",
      "# making a new column called 'year_painted' from output of the column 'details'\n",
      "def extract_last_5_characters(text):\n",
      "    return text[-5:]\n",
      "\n",
      "# Apply the function to the 'details' column to create the new 'year_painted' column\n",
      "df['year_painted_temp'] = df['details'].apply(extract_last_5_characters)\n",
      "def extract_numeric_year(text):\n",
      "    # Use regular expression to find numeric values\n",
      "    matches = re.findall(r'\\b\\d+\\b', text)\n",
      "    \n",
      "    # Return the first match if found, otherwise return None\n",
      "    return matches[0] if matches else None\n",
      "\n",
      "# Apply the function to the 'year_painted' column to create a new 'real_year' column\n",
      "df['year_painted'] = df['year_painted_temp'].apply(extract_numeric_year)\n",
      "  36:\n",
      "# print for the medium and surface\n",
      "for i in range(200,300):\n",
      "    print(df['details'][i])\n",
      "    print('')\n",
      "  37:\n",
      "# Define the lists for each category of medium\n",
      "# we made this manuel by looking at the first 100 paintings and taking these values and put them in these categories\n",
      "\n",
      "oil_based_paintings = [\n",
      "    'huile',\n",
      "    'oil'\n",
      "]\n",
      "\n",
      "pen_and_ink_drawings = [\n",
      "    'pencil',\n",
      "    'ballpoint',\n",
      "    'pen',\n",
      "    'India ink',\n",
      "    'crayons',\n",
      "    'encre',\n",
      "    'fusain',\n",
      "    'coal',\n",
      "    'pastel',\n",
      "    'graphite',\n",
      "    'charcoal'\n",
      "]\n",
      "\n",
      "acrylic = [\n",
      "    'acrylic'\n",
      "    'acrylic paint',\n",
      "    'acrylic medium',\n",
      "    'gesso',\n",
      "    'palette knife',\n",
      "    'pouring medium',\n",
      "    'impasto gel',\n",
      "    'fluid acrylics'\n",
      "]\n",
      "\n",
      "watercolour_art = [\n",
      "    'watercolour',\n",
      "    'wash',\n",
      "    'watercolor',\n",
      "    'gouache',\n",
      "    'aquarelle',\n",
      "    'tempera',\n",
      "    'casein',\n",
      "    'Chinese watercolor',\n",
      "    'Japanese watercolor',\n",
      "    'ink wash',\n",
      "    'bodycolor',\n",
      "    'poster color'\n",
      "]\n",
      "  38:\n",
      "# Create a function to categorize the 'medium' with partial matches\n",
      "def categorize_medium(details):\n",
      "    details_lower = details.lower()  # Convert to lowercase for case-insensitive matching\n",
      "    for category, category_list in zip(['Oil-Based Paintings','Pen and Ink Drawings', 'acrylic', 'Watercolour Art'],\n",
      "                                      [oil_based_paintings, pen_and_ink_drawings, acrylic, watercolour_art ]):\n",
      "        for keyword in category_list:\n",
      "            if keyword.lower() in details_lower or details_lower in keyword.lower():\n",
      "                return category\n",
      "    return 'missing'\n",
      "\n",
      "# Apply the function to create the 'medium' column\n",
      "df['medium'] = df['details'].apply(categorize_medium)\n",
      "  39:\n",
      "# watching the different values of medium\n",
      "medium_counts = df['medium'].value_counts()\n",
      "print(medium_counts)\n",
      "  40:\n",
      "# Define the lists for each category of surface\n",
      "# we made this manuel by looking at the first 100 paintings and taking these values and put them in these categories\n",
      "\n",
      "canvas = [\n",
      "    'canvas',\n",
      "    'toile',\n",
      "    'map',\n",
      "    'linen',\n",
      "    'canvas board'\n",
      "]\n",
      "\n",
      "paper = [\n",
      "    'paper',\n",
      "    'papier',\n",
      "    'card',\n",
      "    'simili-japan',\n",
      "    'carton',\n",
      "    'cartonpapier',\n",
      "    'vellum',\n",
      "    'newsprint',\n",
      "    'canvas paper'\n",
      "]\n",
      "\n",
      "other = [\n",
      "    'wood',\n",
      "    'panel', \n",
      "    'glass',\n",
      "    'copper',\n",
      "    'metal',\n",
      "    'masonite',\n",
      "    'hardboard',\n",
      "    'plywood',\n",
      "    'paperboard',\n",
      "    'leather',\n",
      "    'fabric'    \n",
      "]\n",
      "# other is for all the others such as wood, ... as a surface\n",
      "  41:\n",
      "def categorize_surface(details):\n",
      "    details_lower = details.lower()  # Convert to lowercase for case-insensitive matching\n",
      "    for category, category_list in zip(['canvas','paper','other'],\n",
      "                                      [canvas, paper, other]):\n",
      "        for keyword in category_list:\n",
      "            if keyword.lower() in details_lower or details_lower in keyword.lower():\n",
      "                return category\n",
      "    return 'missing'\n",
      "\n",
      "# Apply the function to create the 'medium' column\n",
      "df['surface'] = df['details'].apply(categorize_surface)\n",
      "  42:\n",
      "# watching the different values of medium\n",
      "surface_counts = df['surface'].value_counts()\n",
      "print(surface_counts)\n",
      "  43:\n",
      "# dominantcolor_hex --> '#RRGGBB' and we are going to split it to red, green and blue\n",
      "# Convert the hexadecimal strings to integers for each color component\n",
      "df['red_hex'] = df['dominant_color_hex'].apply(lambda x: int(x[1:3], 16) if pd.notnull(x) else None)\n",
      "df['green_hex'] = df['dominant_color_hex'].apply(lambda x: int(x[3:5], 16) if pd.notnull(x) else None)\n",
      "df['blue_hex'] = df['dominant_color_hex'].apply(lambda x: int(x[5:7], 16) if pd.notnull(x) else None)\n",
      "  44: df.head(2)\n",
      "  45:\n",
      "# adding the artists year of birth and if they are dead yes or no\n",
      "unique_artists = df['artist'].unique()\n",
      "print(unique_artists)\n",
      "# Creating a DataFrame with 'artist' column\n",
      "df_y = pd.DataFrame(unique_artists, columns=['artist'])\n",
      "\n",
      "# Adding columns 'year_born' and 'dead' with manuallu\n",
      "df_y['year_born'] = [1927, 1862, 1568, 1898, 1599, 1897, 1860, 1601, 1593, 1833, 1798] \n",
      "df_y['dead'] = [False, True, True, True, True, True, True, True, True, True, True,]  \n",
      "\n",
      "# merging of the 2 dataframe that the data corespondents \n",
      "df = pd.merge(df, df_y[['artist', 'year_born', 'dead']], on='artist', how='left')\n",
      "\n",
      "# we only took the year of birth because if we would have taken death as well, these two would correlate. the feature dead (Yes or No) does not do this\n",
      "  46: df_y\n",
      "  47:\n",
      "# looking for the most expensive and least expensive paintings\n",
      "max_price_index = df['price_EUR'].idxmax()\n",
      "min_price_index = df['price_EUR'].idxmin()\n",
      "most_expensive_painting_title = df.loc[max_price_index, 'title']\n",
      "least_expensive_painting_title = df.loc[min_price_index, 'title']\n",
      "print(f\"The title of the most expensive painting is: {most_expensive_painting_title}, {df.loc[max_price_index, 'price_EUR']}\")\n",
      "print(f\"The title of the least expensive painting is: {least_expensive_painting_title}, {df.loc[min_price_index, 'price_EUR']}\")\n",
      "\n",
      "# looking for the biggest painting\n",
      "biggest_painting_circum_index = df['circumference'].idxmax()\n",
      "biggest_painting_area_index = df['area'].idxmax()\n",
      "largest_painting_title = df.loc[biggest_painting_circum_index, 'title']\n",
      "biggest_painting_title = df.loc[biggest_painting_area_index, 'title']\n",
      "print(f\"The title of the biggest painting circumferencewise is: {largest_painting_title}, {df.loc[biggest_painting_circum_index, 'circumference']}\")\n",
      "print(f\"The title of the biggest painting areawise is: {biggest_painting_title}, {df.loc[biggest_painting_area_index, 'area']}\")\n",
      "  48:\n",
      "# dropping some columns \n",
      "    # due to splitting\n",
      "    # too few values\n",
      "    # no meaninfull value\n",
      "\n",
      "df.drop(['Unnamed: 0','index','img_name','collection','details','provenance','exhibit','further_details','price_realized',\n",
      "         'estimated_price','year_string','year_temp','exchange_rate','heigth','width','dominant_color_hex','hue','price','low_estimate',\n",
      "         'high_estimate','average_estimate','dimension','unit_of_length','l','w','year_painted_temp','average_estimate_EUR','low_estimate_EUR','high_estimate_EUR'], axis=1, inplace=True)\n",
      "  49:\n",
      "# looking at the different features, their non-null count and datatype\n",
      "print(f\"The data contains {df.shape[0]} instances and {df.shape[1]} features.\")\n",
      "  50:\n",
      "df.duplicated().sum()\n",
      "print(\"Number of duplicate rows: \", df.duplicated().sum())\n",
      "  51:\n",
      "print(f\"It contains {df.shape[1]} features. \\n\")\n",
      "print(\"These are the features and its types: \\n\", df.dtypes)\n",
      "  52:\n",
      "# change the values to the right type\n",
      "df['year_painted'] = pd.to_numeric(df['year_painted'], errors='coerce').astype('float')\n",
      "  53: df.describe().round(2).T\n",
      "  54:\n",
      "for column in df.columns:    \n",
      "    if df[column].dtype.name == 'object': \n",
      "        \n",
      "        categories = df[column].value_counts() \n",
      "\n",
      "        print(f\"Column '{column}' is categorical with {len(categories)} categories;\")\n",
      "  55:\n",
      "numerical_columns = df.select_dtypes(include=['float64','int64']).columns\n",
      "numerical_columns = numerical_columns[numerical_columns != 'price_EUR']\n",
      "df[numerical_columns].hist(bins=20, figsize=(15,10))\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "  56: print(df.isnull().sum())\n",
      "  57:\n",
      "# going to put the visual characteristics to the mean of that feature for each individual artist\n",
      "# numerical features --> normal distributed and no outliers --> mean\n",
      "df['contrast'] = df.groupby('artist')['contrast'].transform(lambda x: x.fillna(x.mean()))\n",
      "df['brightness'] = df.groupby('artist')['brightness'].transform(lambda x: x.fillna(x.mean()))\n",
      "df['red_hex'] = df.groupby('artist')['red_hex'].transform(lambda x: x.fillna(x.mean()))\n",
      "df['green_hex'] = df.groupby('artist')['green_hex'].transform(lambda x: x.fillna(x.mean()))\n",
      "df['blue_hex'] = df.groupby('artist')['blue_hex'].transform(lambda x: x.fillna(x.mean()))\n",
      "\n",
      "# boolean feature --> no impact on outliers, simple, intuitive, did the same for the other categories\n",
      "#                     however, we will lose variability\n",
      "df['faces'] = df.groupby('artist')['faces'].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else df['faces'].mode()[0]))\n",
      "  58:\n",
      "# putting 'missing' when the value of 'title' is nan\n",
      "df['title'].fillna('missing', inplace=True)\n",
      "  59:\n",
      "# missing value of year_sold\n",
      "frequency = df['year_sold'].value_counts()\n",
      "weight_dict = dict(zip(frequency.index, frequency))\n",
      "result_df = pd.DataFrame(list(weight_dict.items()), columns=['year_sold', 'frequency'])\n",
      "result_df['weight'] = result_df['frequency'] / result_df['frequency'].sum()\n",
      "print(result_df.head(2))\n",
      "\n",
      "# function to fill NaN values in Year_sold based on the weight\n",
      "def fill_nan_based_on_weight(row):\n",
      "    if pd.isna(row['year_sold']):\n",
      "        return np.random.choice(result_df['year_sold'], p=result_df['weight'])\n",
      "    else:\n",
      "        return row['year_sold']\n",
      "\n",
      "df['year_sold'] = df.apply(fill_nan_based_on_weight, axis=1)\n",
      "print(df['year_sold'].isna().sum())\n",
      "  60:\n",
      "# area and circumference --> because skewed we do the median of each artist\n",
      "df['area'] = df.groupby('artist')['area'].transform(lambda x: x.fillna(x.median()))\n",
      "df['circumference'] = df.groupby('artist')['circumference'].transform(lambda x: x.fillna(x.median()))\n",
      "  61:\n",
      "# year painted --> we take a standardization of the last x years the artist lived an then random numbers\n",
      "# Define a function to fill missing values\n",
      "\n",
      "def fill_year_painted(row):\n",
      "    if np.isnan(row['year_painted']):\n",
      "        # Calculate the range based on 'year_born_x' + 50\n",
      "        lower_bound = row['year_born'] + 50 - 20\n",
      "        upper_bound = row['year_born'] + 50 + 20\n",
      "\n",
      "        # Generate a random number in the defined range\n",
      "        random_year = np.random.randint(lower_bound, upper_bound + 1)\n",
      "\n",
      "        return random_year\n",
      "    else:\n",
      "        return row['year_painted']\n",
      "\n",
      "# Apply the function to fill missing values in 'year_painted'\n",
      "df['year_painted'] = df.apply(fill_year_painted, axis=1)\n",
      "print(df['year_painted'].isna().sum())\n",
      "  62: print(df.isnull().sum())\n",
      "  63:\n",
      "# first we are going to make a dataframe with a column year and a column with the value\n",
      "# making a dataframe for each year when it was sold\n",
      "unique_years = sorted(df['year_sold'].unique())\n",
      "return_sp500 = [0.0997,0.0133,0.2268,0.3310,0.2834,0.2089,-0.0903,-0.1185,-0.2197,0.2836,0.1074,0.0483,0.1561,0.0548,-0.3655,0.2594,0.1482,0.0210,0.1589,0.3215,0.1352,0.0138,0.1177,0.2161,-0.0423,0.3121,0.1802,0.2847,-0.1801,]\n",
      "\n",
      "# creating df\n",
      "df_sp = pd.DataFrame({\n",
      "    'year' : unique_years,\n",
      "    'return_sp' : return_sp500\n",
      "})\n",
      "\n",
      "df_sp.head(2)\n",
      "  64:\n",
      "merged_df = pd.merge(df, df_sp, left_on='year_sold', right_on='year', how='left')\n",
      "merged_df = merged_df.drop('year', axis=1)\n",
      "df = merged_df\n",
      "df.head(2)\n",
      "  65:\n",
      "# descriptive statistics\n",
      "stats = df['price_EUR'].describe()\n",
      "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
      "print(stats)\n",
      "\n",
      "# gives an overall sense of the central tendency and variability of the prices\n",
      "  66:\n",
      "# boxplots\n",
      "sns.boxplot(x = df['price_EUR'])\n",
      "plt.show()\n",
      "\n",
      "# outliers can be easily identified in a box plots\n",
      "  67:\n",
      "# histogram\n",
      "plt.figure(figsize=(10, 6))\n",
      "plt.hist(df['price_EUR'].dropna(), bins=50, color='skyblue', edgecolor='black')\n",
      "plt.title('Distribution of Prices in EURO')\n",
      "plt.xlabel('price_EUR')\n",
      "plt.ylabel('Frequency')\n",
      "plt.show()\n",
      "\n",
      "# insights in shape of distribution (skewed!!!)\n",
      "  68:\n",
      "# percentiles\n",
      "percentiles = np.percentile(df['price_EUR'], [25, 50, 75])\n",
      "print(percentiles)\n",
      "\n",
      "# outliers may have a significant impact on the mean, but percentiles provide a more robust measure of the spread\n",
      "  69:\n",
      "# outliers both sides\n",
      "Q1 = df['price_EUR'].quantile(0.25)\n",
      "Q3 = df['price_EUR'].quantile(0.75)\n",
      "\n",
      "# Calculate IQR\n",
      "IQR = Q3 - Q1\n",
      "\n",
      "# Define the lower and upper bounds for outliers\n",
      "lower_bound = Q1 - 1.5 * IQR\n",
      "upper_bound = Q3 + 1.5 * IQR\n",
      "\n",
      "# Count the number of outliers\n",
      "num_outliers = ((df['price_EUR'] < lower_bound) | (df['price_EUR'] > upper_bound)).sum()\n",
      "\n",
      "print(f\"The number of outliers in 'price_EUR' is: {num_outliers}\")\n",
      "  70:\n",
      "# Calculate Q3\n",
      "Q3 = df['price_EUR'].quantile(0.75)\n",
      "\n",
      "# Define the upper bound for outliers (above Q3)\n",
      "upper_bound = Q3 + 1.5 * IQR\n",
      "\n",
      "# Count the number of outliers above Q3\n",
      "num_outliers_above_Q3 = (df['price_EUR'] > upper_bound).sum()\n",
      "\n",
      "print(f\"The number of outliers above Q3 in 'price_EUR' is: {num_outliers_above_Q3}\")\n",
      "  71:\n",
      "# outlier detection (Z-score)\n",
      "from scipy.stats import zscore\n",
      "z_score = zscore(df['price_EUR'])\n",
      "outliers = np.where(np.abs(z_score)>3)\n",
      "print(outliers)\n",
      "# help detect observation that deviate significantl from the norm\n",
      "  72:\n",
      "# separate analysis\n",
      "without_outliers = df[df['price_EUR'] < 0.9 * df['price_EUR'].max()]\n",
      "# one outlier that is dropped here\n",
      "  73:\n",
      "numerical_columns = df.select_dtypes(include=['float64','int64']).columns\n",
      "numerical_columns = numerical_columns[numerical_columns != 'price_EUR']\n",
      "df[numerical_columns].hist(bins=20, figsize=(15,10))\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "  74:\n",
      "# looking at the unique values of year_painted becaus this needs to be in between the year of birth of the first artist and 2023.\n",
      "# we are putting nan's everywhere where the year painted is outside the possible range\n",
      "low_bound = min(df['year_born'].unique())\n",
      "high_bound = 2023\n",
      "\n",
      "for index, row in df.iterrows():\n",
      "    if df['year_painted'][index] <= low_bound or df['year_painted'][index] > high_bound:\n",
      "        df.loc[index, 'year_painted'] = np.nan\n",
      "# fill in the average of that artist\n",
      "df['year_painted'] = df.groupby('artist')['year_painted'].transform(lambda x: x.fillna(x.mean()))\n",
      "\n",
      "# new histogram\n",
      "df['year_painted'].hist(bins=20, figsize=(5,2))\n",
      "  75:\n",
      "# new histogram to look at year_born\n",
      "df_y['year_born'].hist(bins=20, figsize=(5,2))\n",
      "  76:\n",
      "# the number of paintings per painter\n",
      "# print frequention of the artists \n",
      "artist_freq = df['artist'].value_counts()\n",
      "print(f\"There are {len(artist_freq)} different artists in {len(df)} samples and the frequency of each different artist is:\")\n",
      "print(artist_freq)\n",
      "  77:\n",
      "# In which year was the first painting sold in this dataset\n",
      "min_year = df['year_sold'].min()\n",
      "max_year = df['year_sold'].max()\n",
      "print(f'The earliest painting in this dataset was sold in {min_year} and the last one in {max_year} which has {max_year-min_year} years between them.')\n",
      "  78:\n",
      "# making a dataframe with all the important information of the artist\n",
      "# Group by 'artist' and aggregate the desired statistics\n",
      "df_artist = df.groupby('artist').agg({\n",
      "    'artist': 'count',\n",
      "    'price_EUR': ['min', 'mean', 'max', 'sum']\n",
      "})\n",
      "\n",
      "# Rename the columns for clarity\n",
      "df_artist.columns = ['count', 'min', 'mean', 'max', 'total']\n",
      "\n",
      "# Reset index to make 'artist' a regular column\n",
      "df_artist.reset_index(inplace=True)\n",
      "\n",
      "# Display the new DataFrame\n",
      "df_artist.head(2)\n",
      "  79: df.dtypes\n",
      "  80:\n",
      "# correlationmatrix, Pearson correlation, only for numeric features\n",
      "numeric_features = df.select_dtypes(include=['float64','int64'])\n",
      "\n",
      "corr_matrix = numeric_features.corr()\n",
      "\n",
      "plt.figure(figsize=(12,8))\n",
      "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
      "plt.title('Pearson Correlation Matrix (Numeric Features)')\n",
      "plt.show()\n",
      "  81:\n",
      "# univariate testing, to see the relationship of all features seperately with the output\n",
      "from scipy.stats import ttest_ind, f_oneway\n",
      "\n",
      "# List of numeric columns\n",
      "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
      "\n",
      "# Perform t-test for each numeric column\n",
      "for column in numeric_columns:\n",
      "    statistic, p_value = ttest_ind(df[column], df['price_EUR'])\n",
      "    print(f\"T-test for {column}: p-value = {p_value}\")\n",
      "    \n",
      "# List of categorical columns\n",
      "categorical_columns = df.select_dtypes(include=['object','bool']).columns\n",
      "\n",
      "# Perform ANOVA for each categorical column\n",
      "for column in categorical_columns:\n",
      "    groups = df.groupby(column)['price_EUR'].apply(list)\n",
      "    statistic, p_value = f_oneway(*groups)\n",
      "    print(f\"ANOVA for {column}: p-value = {p_value}\")\n",
      "  82:\n",
      "# dropping the features that have no significant influence or are correlated with others.\n",
      "df.drop(['year_painted','red_hex','green_hex','blue_hex','title','faces','area'], axis=1, inplace=True)\n",
      "df.head(2)\n",
      "  83: df.dtypes\n",
      "  84:\n",
      "# create a figure with subplots for each column\n",
      "# Convert boolean columns to categorical ( help maintain consistency in the encoding process. \n",
      "# It makes the interpretation of the encoded features more straightforward)\n",
      "df['signed'] = df['signed'].astype('category')\n",
      "df['dead'] = df['dead'].astype('category')\n",
      "\n",
      "df.info()\n",
      "  85: df.head(2)\n",
      "  86: df = df[~df['city_auction'].isin(['Hong Kong','Milan'])]\n",
      "  87: print(f'the dataset had {df.shape[0]} features and {df.shape[1]} columns.')\n",
      "  88:\n",
      "# Information about the samples\n",
      "samples = len(df)\n",
      "print(samples)\n",
      "min_date = df['year_sold'].min()\n",
      "max_date = df['year_sold'].max()\n",
      "print(min_date)\n",
      "print(max_date)\n",
      "  89:\n",
      "# Target feature\n",
      "min_price = df[df['price_EUR'] > 0]['price_EUR'].min()\n",
      "max_price = df['price_EUR'].max()\n",
      "total = sum(df['price_EUR'])\n",
      "print(total)\n",
      "print(min_price)\n",
      "print(max_price)\n",
      "number = len(df[df['price_EUR']==0])\n",
      "print(number)\n",
      "  90:\n",
      "# artist\n",
      "import pandas as pd\n",
      "\n",
      "# Assuming df is your original DataFrame\n",
      "# Grouping by 'artist' and aggregating price statistics\n",
      "grouped_data = df.groupby('artist')['price_EUR'].describe()\n",
      "\n",
      "# Creating the new DataFrame\n",
      "result_df = pd.DataFrame({\n",
      "    'artist': grouped_data.index,\n",
      "    'count': grouped_data['count'],\n",
      "    'average': grouped_data['mean'],\n",
      "    'std dev': grouped_data['std'],\n",
      "    'min': grouped_data['min'],\n",
      "    '25%': grouped_data['25%'],\n",
      "    '50%': grouped_data['50%'],\n",
      "    '75%': grouped_data['75%'],\n",
      "    'max': grouped_data['max'],\n",
      "    'total': grouped_data['count'] * grouped_data['mean']  # Total = count * average\n",
      "})\n",
      "\n",
      "# Displaying the result DataFrame\n",
      "print(result_df)\n",
      "  91:\n",
      "# location and most money per location\n",
      "import pandas as pd\n",
      "\n",
      "# Assuming df is your original DataFrame\n",
      "# Grouping by 'city_auction' and aggregating count and sum\n",
      "city_stats = df.groupby('city_auction').agg({'city_auction': 'count', 'price_EUR': 'sum'})\n",
      "\n",
      "# Renaming columns for clarity\n",
      "city_stats = city_stats.rename(columns={'city_auction': 'count', 'price_EUR': 'total_spent'})\n",
      "city_stats['average'] = city_stats['total_spent'] / city_stats['count']\n",
      "city_stats = city_stats.sort_values(by='average', ascending=False)\n",
      "\n",
      "# Displaying the result DataFrame\n",
      "print(city_stats)\n",
      "  92: # we dropped the rows of 'milan' and 'hong kong' because there were only 1 row each and it was 'annoying' the code\n",
      "  93:\n",
      "# currency and most money per currency\n",
      "\n",
      "# Assuming df is your original DataFrame\n",
      "# Grouping by 'city_auction' and aggregating count and sum\n",
      "currency_stats = df.groupby('currency').agg({'currency': 'count', 'price_EUR': 'sum'})\n",
      "\n",
      "# Renaming columns for clarity\n",
      "currency_stats = currency_stats.rename(columns={'currency': 'count', 'price_EUR': 'total_spent'})\n",
      "currency_stats['average'] = currency_stats['total_spent'] / currency_stats['count']\n",
      "currency_stats = currency_stats.sort_values(by='average', ascending=False)\n",
      "\n",
      "# Displaying the result DataFrame\n",
      "print(currency_stats)\n",
      "  94:\n",
      "# currency and most money per currency\n",
      "\n",
      "# Assuming df is your original DataFrame\n",
      "# Grouping by 'city_auction' and aggregating count and sum\n",
      "surface_stats = df.groupby('surface').agg({'surface': 'count', 'price_EUR': 'sum'})\n",
      "\n",
      "# Renaming columns for clarity\n",
      "surface_stats = surface_stats.rename(columns={'surface': 'count', 'price_EUR': 'total_spent'})\n",
      "surface_stats['average'] = surface_stats['total_spent'] / surface_stats['count']\n",
      "surface_stats = surface_stats.sort_values(by='average', ascending=False)\n",
      "\n",
      "# Displaying the result DataFrame\n",
      "print(surface_stats)\n",
      "  95:\n",
      "# currency and most money per currency\n",
      "\n",
      "# Assuming df is your original DataFrame\n",
      "# Grouping by 'city_auction' and aggregating count and sum\n",
      "medium_stats = df.groupby('medium').agg({'medium': 'count', 'price_EUR': 'sum'})\n",
      "\n",
      "# Renaming columns for clarity\n",
      "medium_stats = medium_stats.rename(columns={'medium': 'count', 'price_EUR': 'total_spent'})\n",
      "medium_stats['average'] = medium_stats['total_spent'] / medium_stats['count']\n",
      "medium_stats = medium_stats.sort_values(by='average', ascending=False)\n",
      "\n",
      "# Displaying the result DataFrame\n",
      "print(medium_stats)\n",
      "  96:\n",
      "# currency and most money per currency\n",
      "\n",
      "# Assuming df is your original DataFrame\n",
      "# Grouping by 'city_auction' and aggregating count and sum\n",
      "signed_stats = df.groupby('signed').agg({'signed': 'count', 'price_EUR': 'sum'})\n",
      "\n",
      "# Renaming columns for clarity\n",
      "signed_stats = signed_stats.rename(columns={'signed': 'count', 'price_EUR': 'total_spent'})\n",
      "signed_stats['average'] = signed_stats['total_spent']/signed_stats['count']\n",
      "signed_stats = signed_stats.sort_values(by='average', ascending=False)\n",
      "\n",
      "# Displaying the result DataFrame\n",
      "print(signed_stats)\n",
      "  97: df.head(2)\n",
      "  98:\n",
      "### here we are making feature called dataframe with df as dataframe to always have the standard df somewhere\n",
      "dataframe = df\n",
      "dataframe.head(2)\n",
      "  99: df.head(2)\n",
      " 100: df = df.rename(columns={'price_EUR': 'target'})\n",
      " 101: df.head(2)\n",
      " 102:\n",
      "#  When dealing with time series data, it's important to split the dataset in a way that respects the temporal\n",
      "# order to avoid data leakage and to simulate a more realistic scenario where you train on past data and \n",
      "# evaluate on future data.\n",
      "\n",
      "# step 1: sort your data in ascending order 'year_sold'\n",
      "df = df.sort_values(by='year_sold')\n",
      "\n",
      "# step 2: define a split point. We opt for 80%\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(df) * split_percentage)\n",
      "\n",
      "# step 3: Split the data in a training and test set\n",
      "train_set = df[:split_point]\n",
      "test_set = df[split_point:]\n",
      "\n",
      "# Check the time range in each set\n",
      "print(\"Training Set Time Range:\", train_set['year_sold'].min(), train_set['year_sold'].max())\n",
      "print(\"Testing Set Time Range:\", test_set['year_sold'].min(), test_set['year_sold'].max())\n",
      " 103: df.head(2)\n",
      " 104:\n",
      "# splitting training and test into X features and Y\n",
      "\n",
      "# splitting the training set into features X and target variable Y\n",
      "x_train = train_set.drop(columns=['target'])\n",
      "y_train = train_set['target']\n",
      "\n",
      "#splitting the test set into  features X and target variable Y\n",
      "x_test = test_set.drop(columns=['target'])\n",
      "y_test = test_set['target']\n",
      " 105:\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
      "from sklearn.impute import SimpleImputer\n",
      "from sklearn.feature_selection import SelectKBest, f_regression\n",
      "import category_encoders as ce\n",
      "from category_encoders import OneHotEncoder\n",
      " 106:\n",
      "# define the columns to encode and scale(min-max)\n",
      "one_hot_cols = ['artist', 'city_auction', 'currency', 'medium', 'surface', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
      "        ('num', continuous_transformer, continuous_cols)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 107:\n",
      "# libraries for the models\n",
      "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
      "from sklearn.model_selection import GridSearchCV, cross_val_score, TimeSeriesSplit\n",
      "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.impute import SimpleImputer\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.model_selection import TimeSeriesSplit\n",
      "from math import sqrt\n",
      " 108:\n",
      "# define the models\n",
      "linear = LinearRegression()\n",
      "# alpha is the regularization term, the larger the stronger the regularization. If 0 you have a linear regression\n",
      "# choosing the right alpha is crucial: to small --> overfitting, to large --> shrinkage of coefficient #underfitting\n",
      "ridge = Ridge(alpha=0.5)\n",
      "lasso = Lasso(alpha=0.5)\n",
      "\n",
      "# define the pipelines\n",
      "pipeline_linear = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', linear)\n",
      "])\n",
      "\n",
      "pipeline_ridge = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', ridge)\n",
      "])\n",
      "\n",
      "pipeline_lasso = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', lasso)\n",
      "])\n",
      "\n",
      "# define the hyperparameters to search\n",
      "# purpose = explore different combinations of these hyperparameters to find the \n",
      "# set that results in the best model performance. \n",
      "param_grid = [{'estimator': [Ridge()],\n",
      "              'estimator__alpha': [0.01, 0.1, 1, 10, 100]\n",
      "              },\n",
      "              {'estimator': [Lasso()],\n",
      "              'estimator__alpha': [0.01, 0.1, 1, 10, 100]\n",
      "              }\n",
      "]\n",
      "\n",
      "# create gridsearchcv to perform this lookout for the best hyperparameters\n",
      "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline_linear, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# git the grid search to the training data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# evaluate each model using cross-validation\n",
      "scores_linear = cross_val_score(pipeline_linear, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
      "scores_ridge = cross_val_score(pipeline_ridge, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
      "scores_lasso = cross_val_score(pipeline_lasso, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
      "\n",
      "# compute the mean squared error of each model\n",
      "mse_linear = -cross_val_score(pipeline_linear, x_train, y_train, cv=time_serie_split, scoring='neg_mean_squared_error').mean()\n",
      "mse_ridge = -cross_val_score(pipeline_ridge, x_train, y_train, cv=time_serie_split, scoring='neg_mean_squared_error').mean()\n",
      "mse_lasso = -cross_val_score(pipeline_lasso, x_train, y_train, cv=time_serie_split, scoring='neg_mean_squared_error').mean()\n",
      "\n",
      "# compute the root mean squared error of each model\n",
      "rmse_linear = sqrt(mse_linear)\n",
      "rmse_ridge = sqrt(mse_ridge)\n",
      "rmse_lasso = sqrt(mse_lasso)\n",
      "\n",
      "# Ensure the entire pipeline is fitted before predicting\n",
      "grid_search.best_estimator_.fit(x_train, y_train)\n",
      "pipeline_ridge.fit(x_train, y_train)\n",
      "pipeline_lasso.fit(x_train, y_train)\n",
      "\n",
      "# Compute the mean absolute error of each model\n",
      "mae_linear = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
      "mae_ridge = mean_absolute_error(y_train, pipeline_ridge.predict(x_train))\n",
      "mae_lasso = mean_absolute_error(y_train, pipeline_lasso.predict(x_train))\n",
      "\n",
      "# printing all\n",
      "# print best parameters and best score\n",
      "print('Best parameters:', grid_search.best_params_)\n",
      "print('Best score:', -grid_search.best_score_)\n",
      "print('Best R2:', grid_search.best_estimator_.score(x_train, y_train))\n",
      "print(' ')\n",
      "\n",
      "# printing all for linear regression\n",
      "print('All the metrics for Linear Regression.')\n",
      "print(\"Linear Regression CV R-squared:\", scores_linear.mean())\n",
      "print(\"Linear Regression CV MSE:\", mse_linear)\n",
      "print(\"Linear Regression CV RMSE:\", rmse_linear)\n",
      "print(\"Linear Regression CV MAE:\", mae_linear)\n",
      "print(' ')\n",
      "\n",
      "# printing all for Ridge regression\n",
      "print('All the metrics for the Ridge Regression.')\n",
      "print(\"Ridge Regression CV R-squared:\", scores_ridge.mean())\n",
      "print(\"Ridge Regression CV MSE:\", mse_ridge)\n",
      "print(\"Ridge Regression CV RMSE:\", rmse_ridge)\n",
      "print(\"Ridge Regression CV MAE:\", mae_ridge)\n",
      "print(' ')\n",
      "\n",
      "\n",
      "# printing all for Lasso regression\n",
      "print('All the metrics for the Lasso Regression.')\n",
      "print(\"Lasso Regression CV R-squared:\", scores_lasso.mean())\n",
      "print(\"Lasso Regression CV MSE:\", mse_lasso)\n",
      "print(\"Lasso Regression CV RMSE:\", rmse_lasso)\n",
      "print(\"Lasso Regression CV MAE:\", mae_lasso)\n",
      " 109:\n",
      "# import libraries for the decision tree model\n",
      "from sklearn.tree import DecisionTreeRegressor\n",
      "from math import sqrt\n",
      "from sklearn.tree import DecisionTreeRegressor\n",
      "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
      "from math import sqrt\n",
      " 110:\n",
      "# define the final estimator\n",
      "print('Decision Tree')\n",
      "estimator = DecisionTreeRegressor(random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# define the grid of hyperparameters to search\n",
      "param_grid = {\n",
      "    'estimator__max_depth': [None,1, 2,3, 5, 10],\n",
      "    'estimator__min_samples_leaf': [1, 2, 4],\n",
      "    'estimator__max_features': ['auto', 'sqrt', 'log2']\n",
      "}\n",
      "\n",
      "# define the grid search object\n",
      "time_series_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# fit the pipeline to the data using cross-validation\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# Get the best estimator from the grid search\n",
      "best_estimator = grid_search.best_estimator_\n",
      "\n",
      "# Get cross-validated R-squared scores\n",
      "cv_r2_scores = cross_val_score(best_estimator, x_train, y_train, cv=time_series_split, scoring='r2')\n",
      "\n",
      "# Print the R-squared scores for each fold\n",
      "print(\"CV R-squared scores for each fold:\", cv_r2_scores)\n",
      "print(\"Average CV R-squared:\", cv_r2_scores.mean())\n",
      "print('\\n')\n",
      "\n",
      "# Predict on the entire training set\n",
      "y_train_pred = best_estimator.predict(x_train)\n",
      "\n",
      "# print the R-squared score of the model using cross-validation\n",
      "r2 = grid_search.best_estimator_.score(x_train, y_train)\n",
      "print(\"CV R-squared:\", r2)\n",
      "\n",
      "# print the mean squared error of the model using cross-validation\n",
      "mse = -grid_search.best_score_\n",
      "print(\"CV MSE:\", mse)\n",
      "\n",
      "# print the root mean squared error of the model using cross-validation\n",
      "rmse = sqrt(mse)\n",
      "print(\"CV RMSE:\", rmse)\n",
      "print(' ')\n",
      "\n",
      "# Print the Mean Absolute Error (MAE) of the model using cross-validation\n",
      "mae = mean_absolute_error(y_train, y_train_pred)\n",
      "print(\"CV MAE:\", mae)\n",
      "print(' ')\n",
      "\n",
      "# Print the R-squared score on the entire training set\n",
      "r2_train = r2_score(y_train, y_train_pred)\n",
      "print(\"Training Set R-squared:\", r2_train)\n",
      "\n",
      "# Print the mean squared error on the entire training set\n",
      "mse_train = mean_squared_error(y_train, y_train_pred)\n",
      "print(\"Training Set MSE:\", mse_train)\n",
      "\n",
      "# Print the root mean squared error on the entire training set\n",
      "rmse_train = sqrt(mse_train)\n",
      "print(\"Training Set RMSE:\", rmse_train)\n",
      "print(' ')\n",
      "\n",
      "# Print the Mean Absolute Error (MAE) on the entire training set\n",
      "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
      "print(\"Training Set MAE:\", mae_train)\n",
      "print(' ')\n",
      "\n",
      "# print the best hyperparameters and the corresponding mean squared error\n",
      "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
      "print(' ')\n",
      "print(\"Best MSE:\", mse)\n",
      " 111:\n",
      "# import libraries for the RandomForestRegressor\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      " 112:\n",
      "# define the model that we are going to use\n",
      "# we use the same random_state\n",
      "# we are going to look what the best n_estimators is\n",
      "print('Random Forest')\n",
      "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# define the grid of hyperparamters to look at\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
      "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
      "}\n",
      "\n",
      "# define the grid search object\n",
      "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# fit the grid search object to the training data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# print the best hyperparameters and the corresponding mean squared error\n",
      "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
      "print(\"Best MSE:\", -grid_search.best_score_)\n",
      "\n",
      "# calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# fit the pipeline to the train data\n",
      "grid_search.best_estimator_.fit(x_train, y_train)\n",
      "\n",
      "# make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# print the R-squared score of the model on the train data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# print the mean squared error of the model on the train data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Train MSE:\", mse_train)\n",
      "\n",
      "# print the root mean squared error of the model on the train data\n",
      "rmse_train = mse_train ** 0.5\n",
      "print(\"Train RMSE:\", rmse_train)\n",
      "\n",
      "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
      "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
      "print(\"Train MAE:\", mae_train)\n",
      " 113:\n",
      "# import libraries for the Gradient Boosting Regressor\n",
      "from sklearn.ensemble import GradientBoostingRegressor\n",
      " 114:\n",
      "# Define the estimator for Gradient Boosting\n",
      "estimator = GradientBoostingRegressor(random_state=42)\n",
      "print('Gradient Boosting')\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# Define the hyperparameters to tune\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [50, 100, 200],\n",
      "    'estimator__max_depth': [1,3,5 ,7, 10],\n",
      "    'estimator__max_features': ['sqrt', 'log2'],\n",
      "}\n",
      "\n",
      "# Create a grid search object\n",
      "time_series_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# Fit the grid search object to the data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# Print the best hyperparameters\n",
      "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
      "\n",
      "# Print the best MSE and corresponding negative value\n",
      "best_mse = -grid_search.best_score_\n",
      "print(\"Best MSE:\", best_mse)\n",
      "\n",
      "# Calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# calculate and print MAE\n",
      "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
      "print('training MAE:', mae)\n",
      "\n",
      "# Make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# Print the R-squared score of the model on the training data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# Print the mean squared error of the model on the training data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Training MSE:\", mse_train)\n",
      "\n",
      "# Print the root mean squared error of the model on the training data\n",
      "rmse_train = sqrt(mse_train)\n",
      "print(\"Training RMSE:\", rmse_train)\n",
      " 115:\n",
      "# import of the libraries\n",
      "from sklearn.ensemble import GradientBoostingRegressor\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.metrics import mean_squared_error\n",
      "from math import sqrt\n",
      " 116:\n",
      "# define the final estimator with the best parameters\n",
      "gbr = RandomForestRegressor(n_estimators=200, max_depth=7,random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print('Random Forest')\n",
      "print('')\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 117:\n",
      "# define the final estimator with the best parameters\n",
      "gbr = GradientBoostingRegressor(n_estimators=100, max_depth=10, max_features= 'log2',random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print('Gradient Boosting')\n",
      "print('')\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 118:\n",
      "# reindex\n",
      "df = df.reset_index(drop=True)\n",
      " 119: df.head(2)\n",
      " 120:\n",
      "# Define the number of outliers to drop for each scenario\n",
      "outlier_counts = [10, 25, 75, 146]\n",
      "\n",
      "# Visual inspection for different outlier removal scenarios\n",
      "plt.figure(figsize=(15, 8))\n",
      "\n",
      "# Before outlier removal\n",
      "plt.subplot(3, 3, 1)\n",
      "plt.hist(df['target'].dropna(), bins=30, color='skyblue', edgecolor='black')\n",
      "plt.title('Original Distribution of Target Variable')\n",
      "plt.xlabel('target')\n",
      "plt.ylabel('Frequency')\n",
      "\n",
      "# Iterate through different outlier removal scenarios\n",
      "for i, outlier_count in enumerate(outlier_counts):\n",
      "    # Remove the top outliers based on the specified count\n",
      "    target_without_outliers = df['target'].sort_values().iloc[:-outlier_count]\n",
      "    \n",
      "    # Visualize the distribution after outlier removal\n",
      "    plt.subplot(3, 3, i + 2)\n",
      "    plt.hist(target_without_outliers, bins=30, color='skyblue', edgecolor='black')\n",
      "    plt.title(f'Distribution (Remove {outlier_count} Outliers)')\n",
      "    plt.xlabel('target')\n",
      "    plt.ylabel('Frequency')\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      " 121: top_values_indices = df['target'].nlargest(10).index\n",
      " 122: df.head(2)\n",
      " 123:\n",
      "## splitsing in 80% and then you are going to look at the indexes of the outliers --> later we are going to drop the outliers but only out of the training set\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(df) * split_percentage)\n",
      "\n",
      "train_set = df[:split_point]\n",
      "test_set = df[split_point:]\n",
      "\n",
      "range_train = len(train_set)\n",
      "\n",
      "filtered_indices = [index for index in top_values_indices if index <= range_train]\n",
      "\n",
      "# splitting the training set into features X and target variable Y\n",
      "x_train = train_set.drop(columns=['target'])\n",
      "y_train = train_set['target']\n",
      "\n",
      "# dropping the rows based on the indices\n",
      "x_train = x_train.drop(index=filtered_indices)\n",
      "y_train = y_train.drop(index=filtered_indices)\n",
      "\n",
      "#splitting the test set into  features X and target variable Y\n",
      "x_test = test_set.drop(columns=['target'])\n",
      "y_test = test_set['target']\n",
      " 124:\n",
      "# define the columns to encode and scale(min-max)\n",
      "one_hot_cols = ['artist', 'city_auction', 'currency', 'medium', 'surface', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
      "        ('num', continuous_transformer, continuous_cols)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 125:\n",
      "# define the model that we are going to use\n",
      "# we use the same random_state\n",
      "# we are going to look what the best n_estimators is\n",
      "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
      "print('Random Forst')\n",
      "print('')\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# define the grid of hyperparamters to look at\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
      "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
      "}\n",
      "\n",
      "# define the grid search object\n",
      "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# fit the grid search object to the training data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# print the best hyperparameters and the corresponding mean squared error\n",
      "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
      "print(\"Best MSE:\", -grid_search.best_score_)\n",
      "\n",
      "# calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# fit the pipeline to the train data\n",
      "grid_search.best_estimator_.fit(x_train, y_train)\n",
      "\n",
      "# make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# print the R-squared score of the model on the train data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# print the mean squared error of the model on the train data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Train MSE:\", mse_train)\n",
      "\n",
      "# print the root mean squared error of the model on the train data\n",
      "rmse_train = mse_train ** 0.5\n",
      "print(\"Train RMSE:\", rmse_train)\n",
      "\n",
      "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
      "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
      "print(\"Train MAE:\", mae_train)\n",
      " 126:\n",
      "# Define the estimator for Gradient Boosting\n",
      "estimator = GradientBoostingRegressor(random_state=42)\n",
      "print('Gradient Boosting')\n",
      "print('')\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# Define the hyperparameters to tune\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [50, 100, 200],\n",
      "    'estimator__max_depth': [7, 10, 20],\n",
      "    'estimator__max_features': ['sqrt', 'log2'],\n",
      "}\n",
      "\n",
      "# Create a grid search object\n",
      "time_series_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# Fit the grid search object to the data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# Print the best hyperparameters\n",
      "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
      "\n",
      "# Print the best MSE and corresponding negative value\n",
      "best_mse = -grid_search.best_score_\n",
      "print(\"Best MSE:\", best_mse)\n",
      "\n",
      "# Calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# calculate and print MAE\n",
      "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
      "print('training MAE:', mae)\n",
      "\n",
      "# Make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# Print the R-squared score of the model on the training data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# Print the mean squared error of the model on the training data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Training MSE:\", mse_train)\n",
      "\n",
      "# Print the root mean squared error of the model on the training data\n",
      "rmse_train = sqrt(mse_train)\n",
      "print(\"Training RMSE:\", rmse_train)\n",
      " 127:\n",
      "# define the final estimator with the best parameters\n",
      "gbr = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 128:\n",
      "# define the final estimator with the best parameters\n",
      "gbr = GradientBoostingRegressor(n_estimators=200, max_depth=7, max_features= 'sqrt',random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 129: top_values_indices = df['target'].nlargest(25).index\n",
      " 130:\n",
      "## splitsing in 80% and then you are going to look at the indexes of the outliers --> later we are going to drop the outliers but only out of the training set\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(df) * split_percentage)\n",
      "\n",
      "train_set = df[:split_point]\n",
      "test_set = df[split_point:]\n",
      "\n",
      "range_train = len(train_set)\n",
      "\n",
      "filtered_indices = [index for index in top_values_indices if index <= range_train]\n",
      "\n",
      "# splitting the training set into features X and target variable Y\n",
      "x_train = train_set.drop(columns=['target'])\n",
      "y_train = train_set['target']\n",
      "\n",
      "# dropping the rows based on the indices\n",
      "x_train = x_train.drop(index=filtered_indices)\n",
      "y_train = y_train.drop(index=filtered_indices)\n",
      "\n",
      "#splitting the test set into  features X and target variable Y\n",
      "x_test = test_set.drop(columns=['target'])\n",
      "y_test = test_set['target']\n",
      "\n",
      "\n",
      "# define the columns to encode and scale(min-max)\n",
      "one_hot_cols = ['artist', 'city_auction', 'currency', 'medium', 'surface', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
      "        ('num', continuous_transformer, continuous_cols)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 131:\n",
      "# define the model that we are going to use\n",
      "# we use the same random_state\n",
      "# we are going to look what the best n_estimators is\n",
      "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
      "print('Random Forest')\n",
      "print('')\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# define the grid of hyperparamters to look at\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
      "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
      "}\n",
      "\n",
      "# define the grid search object\n",
      "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# fit the grid search object to the training data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# print the best hyperparameters and the corresponding mean squared error\n",
      "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
      "print(\"Best MSE:\", -grid_search.best_score_)\n",
      "\n",
      "# calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# fit the pipeline to the train data\n",
      "grid_search.best_estimator_.fit(x_train, y_train)\n",
      "\n",
      "# make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# print the R-squared score of the model on the train data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# print the mean squared error of the model on the train data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Train MSE:\", mse_train)\n",
      "\n",
      "# print the root mean squared error of the model on the train data\n",
      "rmse_train = mse_train ** 0.5\n",
      "print(\"Train RMSE:\", rmse_train)\n",
      "\n",
      "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
      "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
      "print(\"Train MAE:\", mae_train)\n",
      " 132:\n",
      "# Define the estimator for Gradient Boosting\n",
      "estimator = GradientBoostingRegressor(random_state=42)\n",
      "print('Gradient Boosting')\n",
      "print('')\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# Define the hyperparameters to tune\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [50, 100, 200],\n",
      "    'estimator__max_depth': [7, 10, 20],\n",
      "    'estimator__max_features': ['sqrt', 'log2'],\n",
      "}\n",
      "\n",
      "# Create a grid search object\n",
      "time_series_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# Fit the grid search object to the data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# Print the best hyperparameters\n",
      "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
      "\n",
      "# Print the best MSE and corresponding negative value\n",
      "best_mse = -grid_search.best_score_\n",
      "print(\"Best MSE:\", best_mse)\n",
      "\n",
      "# Calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# calculate and print MAE\n",
      "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
      "print('training MAE:', mae)\n",
      "\n",
      "# Make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# Print the R-squared score of the model on the training data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# Print the mean squared error of the model on the training data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Training MSE:\", mse_train)\n",
      "\n",
      "# Print the root mean squared error of the model on the training data\n",
      "rmse_train = sqrt(mse_train)\n",
      "print(\"Training RMSE:\", rmse_train)\n",
      " 133:\n",
      "# define the final estimator with the best parameters\n",
      "gbr = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 134:\n",
      "# define the final estimator with the best parameters\n",
      "gbr = GradientBoostingRegressor(n_estimators=200, max_depth=20, max_features= 'log2',random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 135:\n",
      "top_values_indices = df['target'].nlargest(75).index\n",
      "## splitsing in 80% and then you are going to look at the indexes of the outliers --> later we are going to drop the outliers but only out of the training set\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(df) * split_percentage)\n",
      "\n",
      "train_set = df[:split_point]\n",
      "test_set = df[split_point:]\n",
      "\n",
      "range_train = len(train_set)\n",
      "\n",
      "filtered_indices = [index for index in top_values_indices if index < range_train]\n",
      "\n",
      "# splitting the training set into features X and target variable Y\n",
      "x_train = train_set.drop(columns=['target'])\n",
      "y_train = train_set['target']\n",
      "\n",
      "# dropping the rows based on the indices\n",
      "x_train = x_train.drop(index=filtered_indices)\n",
      "y_train = y_train.drop(index=filtered_indices)\n",
      "\n",
      "#splitting the test set into  features X and target variable Y\n",
      "x_test = test_set.drop(columns=['target'])\n",
      "y_test = test_set['target']\n",
      "\n",
      "\n",
      "# define the columns to encode and scale(min-max)\n",
      "one_hot_cols = ['artist', 'city_auction', 'currency', 'medium', 'surface', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
      "        ('num', continuous_transformer, continuous_cols)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 136:\n",
      "# define the model that we are going to use\n",
      "# we use the same random_state\n",
      "# we are going to look what the best n_estimators is\n",
      "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
      "print('Random Forest')\n",
      "print('')\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# define the grid of hyperparamters to look at\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
      "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
      "}\n",
      "\n",
      "# define the grid search object\n",
      "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# fit the grid search object to the training data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# print the best hyperparameters and the corresponding mean squared error\n",
      "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
      "print(\"Best MSE:\", -grid_search.best_score_)\n",
      "\n",
      "# calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# fit the pipeline to the train data\n",
      "grid_search.best_estimator_.fit(x_train, y_train)\n",
      "\n",
      "# make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# print the R-squared score of the model on the train data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# print the mean squared error of the model on the train data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Train MSE:\", mse_train)\n",
      "\n",
      "# print the root mean squared error of the model on the train data\n",
      "rmse_train = mse_train ** 0.5\n",
      "print(\"Train RMSE:\", rmse_train)\n",
      "\n",
      "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
      "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
      "print(\"Train MAE:\", mae_train)\n",
      " 137:\n",
      "# Define the estimator for Gradient Boosting\n",
      "estimator = GradientBoostingRegressor(random_state=42)\n",
      "print('Gradient Boosting')\n",
      "print('')\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# Define the hyperparameters to tune\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [50, 100, 200],\n",
      "    'estimator__max_depth': [7, 10, 20],\n",
      "    'estimator__max_features': ['sqrt', 'log2'],\n",
      "}\n",
      "\n",
      "# Create a grid search object\n",
      "time_series_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# Fit the grid search object to the data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# Print the best hyperparameters\n",
      "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
      "\n",
      "# Print the best MSE and corresponding negative value\n",
      "best_mse = -grid_search.best_score_\n",
      "print(\"Best MSE:\", best_mse)\n",
      "\n",
      "# Calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# calculate and print MAE\n",
      "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
      "print('training MAE:', mae)\n",
      "\n",
      "# Make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# Print the R-squared score of the model on the training data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# Print the mean squared error of the model on the training data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Training MSE:\", mse_train)\n",
      "\n",
      "# Print the root mean squared error of the model on the training data\n",
      "rmse_train = sqrt(mse_train)\n",
      "print(\"Training RMSE:\", rmse_train)\n",
      " 138:\n",
      "# define the final estimator with the best parameters\n",
      "gbr = RandomForestRegressor(n_estimators=20, max_depth=10, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 139:\n",
      "# define the final estimator with the best parameters\n",
      "gbr = GradientBoostingRegressor(n_estimators=50, max_depth=20, max_features= 'log2',random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 140: df.head(2)\n",
      " 141: top_values_indices = df['target'].nlargest(146).index\n",
      " 142: df.info()\n",
      " 143:\n",
      "## splitsing in 80% and then you are going to look at the indexes of the outliers --> later we are going to drop the outliers but only out of the training set\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(df) * split_percentage)\n",
      "\n",
      "train_set = df[:split_point]\n",
      "test_set = df[split_point:]\n",
      "\n",
      "range_train = len(train_set)\n",
      "\n",
      "filtered_indices = [index for index in top_values_indices if index < range_train]\n",
      "\n",
      "# splitting the training set into features X and target variable Y\n",
      "x_train = train_set.drop(columns=['target'])\n",
      "y_train = train_set['target']\n",
      "\n",
      "# dropping the rows based on the indices\n",
      "x_train = x_train.drop(index=filtered_indices)\n",
      "y_train = y_train.drop(index=filtered_indices)\n",
      "\n",
      "#splitting the test set into  features X and target variable Y\n",
      "x_test = test_set.drop(columns=['target'])\n",
      "y_test = test_set['target']\n",
      " 144:\n",
      "# define the columns to encode and scale(min-max)\n",
      "one_hot_cols = ['artist', 'city_auction', 'currency', 'medium', 'surface', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
      "        ('num', continuous_transformer, continuous_cols)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 145:\n",
      "# define the model that we are going to use\n",
      "# we use the same random_state\n",
      "# we are going to look what the best n_estimators is\n",
      "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# define the grid of hyperparamters to look at\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
      "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
      "}\n",
      "\n",
      "# define the grid search object\n",
      "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# fit the grid search object to the training data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# print the best hyperparameters and the corresponding mean squared error\n",
      "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
      "print(\"Best MSE:\", -grid_search.best_score_)\n",
      "\n",
      "# calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# fit the pipeline to the train data\n",
      "grid_search.best_estimator_.fit(x_train, y_train)\n",
      "\n",
      "# make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# print the R-squared score of the model on the train data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# print the mean squared error of the model on the train data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Train MSE:\", mse_train)\n",
      "\n",
      "# print the root mean squared error of the model on the train data\n",
      "rmse_train = mse_train ** 0.5\n",
      "print(\"Train RMSE:\", rmse_train)\n",
      "\n",
      "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
      "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
      "print(\"Train MAE:\", mae_train)\n",
      " 146:\n",
      "# Define the estimator for Gradient Boosting\n",
      "estimator = GradientBoostingRegressor(random_state=42)\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# Define the hyperparameters to tune\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [50, 100, 200],\n",
      "    'estimator__max_depth': [7, 10, 20],\n",
      "    'estimator__max_features': ['sqrt', 'log2'],\n",
      "}\n",
      "\n",
      "# Create a grid search object\n",
      "time_series_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# Fit the grid search object to the data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# Print the best hyperparameters\n",
      "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
      "\n",
      "# Print the best MSE and corresponding negative value\n",
      "best_mse = -grid_search.best_score_\n",
      "print(\"Best MSE:\", best_mse)\n",
      "\n",
      "# Calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# calculate and print MAE\n",
      "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
      "print('training MAE:', mae)\n",
      "\n",
      "# Make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# Print the R-squared score of the model on the training data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# Print the mean squared error of the model on the training data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Training MSE:\", mse_train)\n",
      "\n",
      "# Print the root mean squared error of the model on the training data\n",
      "rmse_train = sqrt(mse_train)\n",
      "print(\"Training RMSE:\", rmse_train)\n",
      " 147:\n",
      "# define the final estimator with the best parameters\n",
      "gbr = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 148:\n",
      "# define the final estimator with the best parameters\n",
      "gbr = GradientBoostingRegressor(n_estimators=100, max_depth=10, max_features= 'log2',random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 149: df.head(2)\n",
      " 150:\n",
      "# we are going to drop one of the two columns --> city_auciton or currency due to high correlation\n",
      "# usd --> new york // # euro --> amsterdarm or london // gbp --> london // NLZ --> dutch guilder and actually the euro but before the euro (convert to euro?)\n",
      "# we chose to drop city_auction because here are missing values !!\n",
      "df = df.drop('city_auction', axis=1)\n",
      " 151: df.head(2)\n",
      " 152:\n",
      "# splitting the training set into features X and target variable Y\n",
      "x_values = df.drop(columns=['target'])\n",
      "y_values = df['target']\n",
      " 153:\n",
      "one_hot_cols = ['artist', 'currency', 'medium', 'surface', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
      "        ('num', continuous_transformer, continuous_cols)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 154:\n",
      "from sklearn.inspection import permutation_importance\n",
      "\n",
      "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "pipeline.fit(x_values, y_values)\n",
      "\n",
      "perm_pipe = permutation_importance(pipeline, x_values, y_values, n_repeats=100, random_state=42, n_jobs=-1)\n",
      "\n",
      "feat_import_perm = perm_pipe.importances_mean\n",
      "fig, ax = plt.subplots(figsize=(20, 5))\n",
      "ax.bar(range(len(feat_import_perm)), feat_import_perm, align=\"center\")\n",
      "ax.set(xticks=range(len(feat_import_perm)), xticklabels=x_values.columns)\n",
      "# Set properties of x axis using setp, we will rotate the labels by 45 degrees\n",
      "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
      "plt.show()\n",
      " 155:\n",
      "# Get the indices of the top 8 features\n",
      "top_feature_indices_perm = feat_import_perm.argsort()[-10:][::-1]\n",
      "\n",
      "# Get the names of the top 8 features\n",
      "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
      "\n",
      "# Plotting the permutation importances for the top 10 features\n",
      "plt.figure(figsize=(10, 6))\n",
      "plt.bar(range(len(top_feature_names_perm)), feat_import_perm[top_feature_indices_perm], align=\"center\")\n",
      "plt.xticks(range(len(top_feature_names_perm)), top_feature_names_perm, rotation=45)\n",
      "plt.xlabel(\"Feature\")\n",
      "plt.ylabel(\"Permutation Importance\")\n",
      "plt.title(\"Top 10 Features Based on Permutation Importance\")\n",
      "plt.show()\n",
      " 156:\n",
      "# step 2: define a split point. We opt for 80%\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(df) * split_percentage)\n",
      "\n",
      "# step 3: Split the data in a training and test set\n",
      "train_set = df[:split_point]\n",
      "test_set = df[split_point:]\n",
      "\n",
      "# Get the indices of the top 8 features\n",
      "top_feature_indices_perm = perm_pipe.importances_mean.argsort()[-10:][::-1]\n",
      "\n",
      "# Get the names of the top 8 features\n",
      "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
      "print(top_feature_names_perm)\n",
      "\n",
      "# splitting in training set X and training set y but now only with the features we want.\n",
      "x_train = train_set[top_feature_names_perm]\n",
      "y_train = train_set['target']\n",
      "\n",
      "x_test = test_set[top_feature_names_perm]\n",
      "y_test = test_set['target']\n",
      "\n",
      "one_hot_cols = ['artist', 'currency', 'medium', 'surface', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the columns to encode and scale (standard)\n",
      "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
      "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
      "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 157:\n",
      "# define the model that we are going to use\n",
      "# we use the same random_state\n",
      "# we are going to look what the best n_estimators is\n",
      "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# define the grid of hyperparamters to look at\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
      "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
      "}\n",
      "\n",
      "# define the grid search object\n",
      "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# fit the grid search object to the training data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# print the best hyperparameters and the corresponding mean squared error\n",
      "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
      "print(\"Best MSE:\", -grid_search.best_score_)\n",
      "\n",
      "# calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# fit the pipeline to the train data\n",
      "grid_search.best_estimator_.fit(x_train, y_train)\n",
      "\n",
      "# make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# print the R-squared score of the model on the train data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# print the mean squared error of the model on the train data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Train MSE:\", mse_train)\n",
      "\n",
      "# print the root mean squared error of the model on the train data\n",
      "rmse_train = mse_train ** 0.5\n",
      "print(\"Train RMSE:\", rmse_train)\n",
      "\n",
      "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
      "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
      "print(\"Train MAE:\", mae_train)\n",
      " 158:\n",
      "# define the final estimator with the best parameters\n",
      "gbr = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 159:\n",
      "from sklearn.inspection import permutation_importance\n",
      "\n",
      "estimator = GradientBoostingRegressor(random_state=42)\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "pipeline.fit(x_values, y_values)\n",
      "\n",
      "perm_pipe = permutation_importance(pipeline, x_values, y_values, n_repeats=100, random_state=42, n_jobs=-1)\n",
      "\n",
      "feat_import_perm = perm_pipe.importances_mean\n",
      "fig, ax = plt.subplots(figsize=(20, 5))\n",
      "ax.bar(range(len(feat_import_perm)), feat_import_perm, align=\"center\")\n",
      "ax.set(xticks=range(len(feat_import_perm)), xticklabels=x_values.columns)\n",
      "# Set properties of x axis using setp, we will rotate the labels by 45 degrees\n",
      "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
      "plt.show()\n",
      " 160:\n",
      "# Get the indices of the top 8 features\n",
      "top_feature_indices_perm = feat_import_perm.argsort()[-10:][::-1]\n",
      "\n",
      "# Get the names of the top 8 features\n",
      "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
      "\n",
      "# Plotting the permutation importances for the top 10 features\n",
      "plt.figure(figsize=(10, 6))\n",
      "plt.bar(range(len(top_feature_names_perm)), feat_import_perm[top_feature_indices_perm], align=\"center\")\n",
      "plt.xticks(range(len(top_feature_names_perm)), top_feature_names_perm, rotation=45)\n",
      "plt.xlabel(\"Feature\")\n",
      "plt.ylabel(\"Permutation Importance\")\n",
      "plt.title(\"Top 10 Features Based on Permutation Importance\")\n",
      "plt.show()\n",
      " 161:\n",
      "# step 2: define a split point. We opt for 80%\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(df) * split_percentage)\n",
      "\n",
      "# step 3: Split the data in a training and test set\n",
      "train_set = df[:split_point]\n",
      "test_set = df[split_point:]\n",
      "\n",
      "# Get the indices of the top 8 features\n",
      "top_feature_indices_perm = perm_pipe.importances_mean.argsort()[-10:][::-1]\n",
      "\n",
      "# Get the names of the top 8 features\n",
      "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
      "print(top_feature_names_perm)\n",
      "\n",
      "# splitting in training set X and training set y but now only with the features we want.\n",
      "x_train = train_set[top_feature_names_perm]\n",
      "y_train = train_set['target']\n",
      "\n",
      "x_test = test_set[top_feature_names_perm]\n",
      "y_test = test_set['target']\n",
      "\n",
      "one_hot_cols = ['artist', 'currency', 'medium', 'surface', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the columns to encode and scale (standard)\n",
      "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
      "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
      "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 162:\n",
      "# Define the estimator for Gradient Boosting\n",
      "estimator = GradientBoostingRegressor(random_state=42)\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# Define the hyperparameters to tune\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [50, 100, 200],\n",
      "    'estimator__max_depth': [7, 10, 20],\n",
      "    'estimator__max_features': ['sqrt', 'log2'],\n",
      "}\n",
      "\n",
      "# Create a grid search object\n",
      "time_series_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# Fit the grid search object to the data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# Print the best hyperparameters\n",
      "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
      "\n",
      "# Print the best MSE and corresponding negative value\n",
      "best_mse = -grid_search.best_score_\n",
      "print(\"Best MSE:\", best_mse)\n",
      "\n",
      "# Calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# calculate and print MAE\n",
      "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
      "print('training MAE:', mae)\n",
      "\n",
      "# Make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# Print the R-squared score of the model on the training data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# Print the mean squared error of the model on the training data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Training MSE:\", mse_train)\n",
      "\n",
      "# Print the root mean squared error of the model on the training data\n",
      "rmse_train = sqrt(mse_train)\n",
      "print(\"Training RMSE:\", rmse_train)\n",
      " 163:\n",
      "# define the final estimator with the best parameters\n",
      "gbr = GradientBoostingRegressor(n_estimators=200, max_depth=20, max_features= 'sqrt',random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 164: df.head(2)\n",
      " 165:\n",
      "from sklearn.inspection import permutation_importance\n",
      "\n",
      "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "pipeline.fit(x_values, y_values)\n",
      "\n",
      "perm_pipe = permutation_importance(pipeline, x_values, y_values, n_repeats=100, random_state=42, n_jobs=-1)\n",
      "\n",
      "feat_import_perm = perm_pipe.importances_mean\n",
      "fig, ax = plt.subplots(figsize=(20, 5))\n",
      "ax.bar(range(len(feat_import_perm)), feat_import_perm, align=\"center\")\n",
      "ax.set(xticks=range(len(feat_import_perm)), xticklabels=x_values.columns)\n",
      "# Set properties of x axis using setp, we will rotate the labels by 45 degrees\n",
      "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
      "plt.show()\n",
      " 166:\n",
      "# Get the indices of the top 8 features\n",
      "top_feature_indices_perm = feat_import_perm.argsort()[-8:][::-1]\n",
      "\n",
      "# Get the names of the top 8 features\n",
      "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
      "\n",
      "# Plotting the permutation importances for the top 8 features\n",
      "plt.figure(figsize=(10, 6))\n",
      "plt.bar(range(len(top_feature_names_perm)), feat_import_perm[top_feature_indices_perm], align=\"center\")\n",
      "plt.xticks(range(len(top_feature_names_perm)), top_feature_names_perm, rotation=45)\n",
      "plt.xlabel(\"Feature\")\n",
      "plt.ylabel(\"Permutation Importance\")\n",
      "plt.title(\"Top 8 Features Based on Permutation Importance\")\n",
      "plt.show()\n",
      " 167:\n",
      "# step 2: define a split point. We opt for 80%\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(df) * split_percentage)\n",
      "\n",
      "# step 3: Split the data in a training and test set\n",
      "train_set = df[:split_point]\n",
      "test_set = df[split_point:]\n",
      "\n",
      "# Get the indices of the top 8 features\n",
      "top_feature_indices_perm = perm_pipe.importances_mean.argsort()[-8:][::-1]\n",
      "\n",
      "# Get the names of the top 8 features\n",
      "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
      "print(top_feature_names_perm)\n",
      "\n",
      "# splitting in training set X and training set y but now only with the features we want.\n",
      "x_train = train_set[top_feature_names_perm]\n",
      "y_train = train_set['target']\n",
      "\n",
      "one_hot_cols = ['artist', 'currency', 'medium', 'surface', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the columns to encode and scale (standard)\n",
      "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
      "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
      "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 168:\n",
      "# define the model that we are going to use\n",
      "# we use the same random_state\n",
      "# we are going to look what the best n_estimators is\n",
      "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# define the grid of hyperparamters to look at\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
      "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
      "}\n",
      "\n",
      "# define the grid search object\n",
      "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# fit the grid search object to the training data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# print the best hyperparameters and the corresponding mean squared error\n",
      "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
      "print(\"Best MSE:\", -grid_search.best_score_)\n",
      "\n",
      "# calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# fit the pipeline to the train data\n",
      "grid_search.best_estimator_.fit(x_train, y_train)\n",
      "\n",
      "# make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# print the R-squared score of the model on the train data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# print the mean squared error of the model on the train data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Train MSE:\", mse_train)\n",
      "\n",
      "# print the root mean squared error of the model on the train data\n",
      "rmse_train = mse_train ** 0.5\n",
      "print(\"Train RMSE:\", rmse_train)\n",
      "\n",
      "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
      "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
      "print(\"Train MAE:\", mae_train)\n",
      " 169:\n",
      "# define the final estimator with the best parameters\n",
      "gbr = RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 170:\n",
      "from sklearn.inspection import permutation_importance\n",
      "\n",
      "estimator = GradientBoostingRegressor(random_state=42)\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "pipeline.fit(x_values, y_values)\n",
      "\n",
      "perm_pipe = permutation_importance(pipeline, x_values, y_values, n_repeats=100, random_state=42, n_jobs=-1)\n",
      "\n",
      "feat_import_perm = perm_pipe.importances_mean\n",
      "fig, ax = plt.subplots(figsize=(20, 5))\n",
      "ax.bar(range(len(feat_import_perm)), feat_import_perm, align=\"center\")\n",
      "ax.set(xticks=range(len(feat_import_perm)), xticklabels=x_values.columns)\n",
      "# Set properties of x axis using setp, we will rotate the labels by 45 degrees\n",
      "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
      "plt.show()\n",
      " 171:\n",
      "# Get the indices of the top 8 features\n",
      "top_feature_indices_perm = feat_import_perm.argsort()[-8:][::-1]\n",
      "\n",
      "# Get the names of the top 8 features\n",
      "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
      "\n",
      "# Plotting the permutation importances for the top 8 features\n",
      "plt.figure(figsize=(10, 6))\n",
      "plt.bar(range(len(top_feature_names_perm)), feat_import_perm[top_feature_indices_perm], align=\"center\")\n",
      "plt.xticks(range(len(top_feature_names_perm)), top_feature_names_perm, rotation=45)\n",
      "plt.xlabel(\"Feature\")\n",
      "plt.ylabel(\"Permutation Importance\")\n",
      "plt.title(\"Top 8 Features Based on Permutation Importance\")\n",
      "plt.show()\n",
      " 172:\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(df) * split_percentage)\n",
      "\n",
      "# step 3: Split the data in a training and test set\n",
      "train_set = df[:split_point]\n",
      "test_set = df[split_point:]\n",
      "\n",
      "# Get the indices of the top 8 features\n",
      "top_feature_indices_perm = perm_pipe.importances_mean.argsort()[-8:][::-1]\n",
      "\n",
      "# Get the names of the top 8 features\n",
      "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
      "print(top_feature_names_perm)\n",
      "\n",
      "# splitting in training set X and training set y but now only with the features we want.\n",
      "x_train = train_set[top_feature_names_perm]\n",
      "y_train = train_set['target']\n",
      "\n",
      "one_hot_cols = ['artist', 'currency', 'medium', 'surface', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the columns to encode and scale (standard)\n",
      "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
      "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
      "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 173:\n",
      "# Define the estimator for Gradient Boosting\n",
      "estimator = GradientBoostingRegressor(random_state=42)\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# Define the hyperparameters to tune\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [50, 100, 200],\n",
      "    'estimator__max_depth': [7, 10, 20],\n",
      "    'estimator__max_features': ['sqrt', 'log2'],\n",
      "}\n",
      "\n",
      "# Create a grid search object\n",
      "time_series_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# Fit the grid search object to the data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# Print the best hyperparameters\n",
      "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
      "\n",
      "# Print the best MSE and corresponding negative value\n",
      "best_mse = -grid_search.best_score_\n",
      "print(\"Best MSE:\", best_mse)\n",
      "\n",
      "# Calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# calculate and print MAE\n",
      "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
      "print('training MAE:', mae)\n",
      "\n",
      "# Make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# Print the R-squared score of the model on the training data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# Print the mean squared error of the model on the training data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Training MSE:\", mse_train)\n",
      "\n",
      "# Print the root mean squared error of the model on the training data\n",
      "rmse_train = sqrt(mse_train)\n",
      "print(\"Training RMSE:\", rmse_train)\n",
      " 174:\n",
      "# define the final estimator with the best parameters\n",
      "gbr = GradientBoostingRegressor(n_estimators=100, max_depth=2, max_features= 'sqrt',random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 175: df = dataframe\n",
      " 176: df.head(2)\n",
      " 177: df.rename(columns={'price_EUR': 'target'}, inplace=True)\n",
      " 178: df.head(2)\n",
      " 179:\n",
      "# step 1: sort your data in ascending order 'year_sold'\n",
      "df = df.sort_values(by='year_sold')\n",
      "\n",
      "# step 2: define a split point. We opt for 80%\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(df) * split_percentage)\n",
      "\n",
      "# step 3: Split the data in a training and test set\n",
      "train_set = df[:split_point]\n",
      "test_set = df[split_point:]\n",
      " 180:\n",
      "# splitting the training set into features X and target variable Y\n",
      "x_train = train_set.drop(columns=['target'])\n",
      "y_train = train_set['target']\n",
      "\n",
      "#splitting the test set into  features X and target variable Y\n",
      "x_test = test_set.drop(columns=['target'])\n",
      "y_test = test_set['target']\n",
      " 181:\n",
      "# define the columns to encode and scale(min-max)\n",
      "one_hot_cols = ['artist', 'city_auction', 'currency', 'medium', 'surface', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
      "        ('num', continuous_transformer, continuous_cols)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 182:\n",
      "# define the final estimator with the best parameters\n",
      "gbr = RandomForestRegressor(n_estimators=100, max_depth=20,random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print('Random Forest')\n",
      "print('')\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 183:\n",
      "one_hot_cols = ['artist', 'currency', 'medium', 'surface', 'signed', 'dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
      "        ('num', continuous_transformer, continuous_cols)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 184:\n",
      "estimator = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42)\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "perm_pipe = permutation_importance(pipeline, x_test, y_test, n_repeats=100, random_state=42, n_jobs=-1)\n",
      "\n",
      "feat_import_perm = perm_pipe.importances_mean\n",
      "fig, ax = plt.subplots(figsize=(20, 5))\n",
      "ax.bar(range(len(feat_import_perm)), feat_import_perm, align=\"center\")\n",
      "ax.set(xticks=range(len(feat_import_perm)), xticklabels=x_test.columns)\n",
      "# Set properties of x axis using setp, we will rotate the labels by 45 degrees\n",
      "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
      "plt.show()\n",
      " 185:\n",
      "perm_importance_df = pd.DataFrame({'Feature': x_test.columns, 'Importance': perm_pipe.importances_mean})\n",
      "\n",
      "# Sort the DataFrame by importance score in descending order\n",
      "perm_importance_df = perm_importance_df.sort_values(by='Importance', ascending=False)\n",
      "\n",
      "# Display the DataFrame\n",
      "print(perm_importance_df)\n",
      " 186:\n",
      "numerical_features = df.select_dtypes(include=['float64', 'int64']).columns\n",
      "data_numerical = df[numerical_features]\n",
      "\n",
      "# Calculate correlations with the target variable (\"price\")\n",
      "correlation_with_price = data_numerical.corr()['target'].drop('target')\n",
      "\n",
      "# Create a list of features ordered by their correlation with the target variable\n",
      "ordered_features = correlation_with_price.abs().sort_values(ascending=False).index.tolist()\n",
      "\n",
      "ordered_features_df = pd.DataFrame({\n",
      "    'Feature': ordered_features,\n",
      "    'Correlation with Price': [correlation_with_price[feature] for feature in ordered_features]\n",
      "})\n",
      "\n",
      "ordered_features_df_num = ordered_features_df.sort_values(by='Correlation with Price', ascending=False)\n",
      "\n",
      "# Display the ordered list of features with correlation scores\n",
      "print(\"Ordered Features by Correlation with Price:\")\n",
      "print(ordered_features_df_num)\n",
      " 187:\n",
      "categorical_features = df.select_dtypes(include=['object']).columns\n",
      "data_categorical = df[categorical_features]\n",
      "\n",
      "# One-hot encode categorical features\n",
      "data_encoded = pd.get_dummies(data_categorical)\n",
      "\n",
      "# Concatenate the encoded categorical features with numerical features\n",
      "data_combined = pd.concat([data_encoded, data_numerical], axis=1)\n",
      "\n",
      "# Calculate correlations with the target variable (\"price\")\n",
      "correlation_with_price = data_combined.corr()['target'].drop('target')\n",
      "\n",
      "# Create a DataFrame with feature names and their correlation scores\n",
      "ordered_features_df = pd.DataFrame({\n",
      "    'Feature': correlation_with_price.index,\n",
      "    'Correlation with Price': correlation_with_price.values\n",
      "})\n",
      "\n",
      "# Sort the DataFrame by correlation scores in descending order\n",
      "ordered_features_df_cat = ordered_features_df.sort_values(by='Correlation with Price', ascending=False)\n",
      "\n",
      "# Display the ordered list of features with correlation scores\n",
      "print(\"Ordered Features by Correlation with Price:\")\n",
      "print(ordered_features_df_cat)\n",
      " 188:\n",
      "# Assuming df is your DataFrame, and 'target' is the target variable\n",
      "categorical_feature = 'artist'\n",
      "\n",
      "# Select the specific categorical feature and the target variable\n",
      "data_subset = df[[categorical_feature, 'target']]\n",
      "\n",
      "# One-hot encode the categorical feature\n",
      "data_encoded = pd.get_dummies(data_subset)\n",
      "\n",
      "# Calculate correlations with the target variable (\"target\")\n",
      "correlation_with_target = data_encoded.corr()['target'].drop('target')\n",
      "\n",
      "# Create a DataFrame with feature names and their correlation scores\n",
      "ordered_features_df_cat = pd.DataFrame({\n",
      "    'Feature': correlation_with_target.index,\n",
      "    'Correlation with Target': correlation_with_target.values\n",
      "})\n",
      "\n",
      "# Sort the DataFrame by correlation scores in descending order\n",
      "ordered_features_df_cat = ordered_features_df_cat.sort_values(by='Correlation with Target', ascending=False)\n",
      "\n",
      "# Display the ordered list of features with correlation scores\n",
      "print(\"Ordered Features by Correlation with Target for Categorical Feature '{}':\".format(categorical_feature))\n",
      "print(ordered_features_df_cat)\n",
      " 189:\n",
      "# Assuming df is your DataFrame, and 'target' is the target variable\n",
      "categorical_feature = 'city_auction'\n",
      "\n",
      "# Select the specific categorical feature and the target variable\n",
      "data_subset = df[[categorical_feature, 'target']]\n",
      "\n",
      "# One-hot encode the categorical feature\n",
      "data_encoded = pd.get_dummies(data_subset)\n",
      "\n",
      "# Calculate correlations with the target variable (\"target\")\n",
      "correlation_with_target = data_encoded.corr()['target'].drop('target')\n",
      "\n",
      "# Create a DataFrame with feature names and their correlation scores\n",
      "ordered_features_df_cat = pd.DataFrame({\n",
      "    'Feature': correlation_with_target.index,\n",
      "    'Correlation with Target': correlation_with_target.values\n",
      "})\n",
      "\n",
      "# Sort the DataFrame by correlation scores in descending order\n",
      "ordered_features_df_cat = ordered_features_df_cat.sort_values(by='Correlation with Target', ascending=False)\n",
      "\n",
      "# Display the ordered list of features with correlation scores\n",
      "print(\"Ordered Features by Correlation with Target for Categorical Feature '{}':\".format(categorical_feature))\n",
      "print(ordered_features_df_cat)\n",
      " 190:\n",
      "# Assuming df is your DataFrame, and 'target' is the target variable\n",
      "categorical_feature = 'currency'\n",
      "\n",
      "# Select the specific categorical feature and the target variable\n",
      "data_subset = df[[categorical_feature, 'target']]\n",
      "\n",
      "# One-hot encode the categorical feature\n",
      "data_encoded = pd.get_dummies(data_subset)\n",
      "\n",
      "# Calculate correlations with the target variable (\"target\")\n",
      "correlation_with_target = data_encoded.corr()['target'].drop('target')\n",
      "\n",
      "# Create a DataFrame with feature names and their correlation scores\n",
      "ordered_features_df_cat = pd.DataFrame({\n",
      "    'Feature': correlation_with_target.index,\n",
      "    'Correlation with Target': correlation_with_target.values\n",
      "})\n",
      "\n",
      "# Sort the DataFrame by correlation scores in descending order\n",
      "ordered_features_df_cat = ordered_features_df_cat.sort_values(by='Correlation with Target', ascending=False)\n",
      "\n",
      "# Display the ordered list of features with correlation scores\n",
      "print(\"Ordered Features by Correlation with Target for Categorical Feature '{}':\".format(categorical_feature))\n",
      "print(ordered_features_df_cat)\n",
      " 191:\n",
      "# Assuming df is your DataFrame, and 'target' is the target variable\n",
      "categorical_feature = 'signed'\n",
      "\n",
      "# Select the specific categorical feature and the target variable\n",
      "data_subset = df[[categorical_feature, 'target']]\n",
      "\n",
      "# One-hot encode the categorical feature\n",
      "data_encoded = pd.get_dummies(data_subset)\n",
      "\n",
      "# Calculate correlations with the target variable (\"target\")\n",
      "correlation_with_target = data_encoded.corr()['target'].drop('target')\n",
      "\n",
      "# Create a DataFrame with feature names and their correlation scores\n",
      "ordered_features_df_cat = pd.DataFrame({\n",
      "    'Feature': correlation_with_target.index,\n",
      "    'Correlation with Target': correlation_with_target.values\n",
      "})\n",
      "\n",
      "# Sort the DataFrame by correlation scores in descending order\n",
      "ordered_features_df_cat = ordered_features_df_cat.sort_values(by='Correlation with Target', ascending=False)\n",
      "\n",
      "# Display the ordered list of features with correlation scores\n",
      "print(\"Ordered Features by Correlation with Target for Categorical Feature '{}':\".format(categorical_feature))\n",
      "print(ordered_features_df_cat)\n",
      " 192: df.head(2)\n",
      " 193:\n",
      "# Assuming df is your DataFrame, and 'target' is the target variable\n",
      "categorical_feature = 'medium'\n",
      "\n",
      "# Select the specific categorical feature and the target variable\n",
      "data_subset = df[[categorical_feature, 'target']]\n",
      "\n",
      "# One-hot encode the categorical feature\n",
      "data_encoded = pd.get_dummies(data_subset)\n",
      "\n",
      "# Calculate correlations with the target variable (\"target\")\n",
      "correlation_with_target = data_encoded.corr()['target'].drop('target')\n",
      "\n",
      "# Create a DataFrame with feature names and their correlation scores\n",
      "ordered_features_df_cat = pd.DataFrame({\n",
      "    'Feature': correlation_with_target.index,\n",
      "    'Correlation with Target': correlation_with_target.values\n",
      "})\n",
      "\n",
      "# Sort the DataFrame by correlation scores in descending order\n",
      "ordered_features_df_cat = ordered_features_df_cat.sort_values(by='Correlation with Target', ascending=False)\n",
      "\n",
      "# Display the ordered list of features with correlation scores\n",
      "print(\"Ordered Features by Correlation with Target for Categorical Feature '{}':\".format(categorical_feature))\n",
      "print(ordered_features_df_cat)\n",
      " 194:\n",
      "# Assuming df is your DataFrame, and 'target' is the target variable\n",
      "categorical_feature = 'surface'\n",
      "\n",
      "# Select the specific categorical feature and the target variable\n",
      "data_subset = df[[categorical_feature, 'target']]\n",
      "\n",
      "# One-hot encode the categorical feature\n",
      "data_encoded = pd.get_dummies(data_subset)\n",
      "\n",
      "# Calculate correlations with the target variable (\"target\")\n",
      "correlation_with_target = data_encoded.corr()['target'].drop('target')\n",
      "\n",
      "# Create a DataFrame with feature names and their correlation scores\n",
      "ordered_features_df_cat = pd.DataFrame({\n",
      "    'Feature': correlation_with_target.index,\n",
      "    'Correlation with Target': correlation_with_target.values\n",
      "})\n",
      "\n",
      "# Sort the DataFrame by correlation scores in descending order\n",
      "ordered_features_df_cat = ordered_features_df_cat.sort_values(by='Correlation with Target', ascending=False)\n",
      "\n",
      "# Display the ordered list of features with correlation scores\n",
      "print(\"Ordered Features by Correlation with Target for Categorical Feature '{}':\".format(categorical_feature))\n",
      "print(ordered_features_df_cat)\n",
      " 195:\n",
      "# Assuming df is your DataFrame, and 'target' is the target variable\n",
      "categorical_feature = 'dead'\n",
      "\n",
      "# Select the specific categorical feature and the target variable\n",
      "data_subset = df[[categorical_feature, 'target']]\n",
      "\n",
      "# One-hot encode the categorical feature\n",
      "data_encoded = pd.get_dummies(data_subset)\n",
      "\n",
      "# Calculate correlations with the target variable (\"target\")\n",
      "correlation_with_target = data_encoded.corr()['target'].drop('target')\n",
      "\n",
      "# Create a DataFrame with feature names and their correlation scores\n",
      "ordered_features_df_cat = pd.DataFrame({\n",
      "    'Feature': correlation_with_target.index,\n",
      "    'Correlation with Target': correlation_with_target.values\n",
      "})\n",
      "\n",
      "# Sort the DataFrame by correlation scores in descending order\n",
      "ordered_features_df_cat = ordered_features_df_cat.sort_values(by='Correlation with Target', ascending=False)\n",
      "\n",
      "# Display the ordered list of features with correlation scores\n",
      "print(\"Ordered Features by Correlation with Target for Categorical Feature '{}':\".format(categorical_feature))\n",
      "print(ordered_features_df_cat)\n",
      " 196:\n",
      "ordered_features_df_all = pd.concat([ordered_features_df_num, ordered_features_df])\n",
      "\n",
      "# Sort the merged DataFrame by correlation scores in descending order\n",
      "ordered_features_df_all = ordered_features_df_all.sort_values(by='Correlation with Price', ascending=False)\n",
      "\n",
      "# Display the ordered list of features with correlation scores\n",
      "print(\"Ordered Features by Correlation with Price (Numerical + Categorical):\")\n",
      "print(ordered_features_df_all)\n",
      " 197: df = df.reset_index(drop=True)\n",
      " 198: df.head(2)\n",
      " 199: top_values_indices = df['target'].nlargest(10).index\n",
      " 200:\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(df) * split_percentage)\n",
      "\n",
      "train_set = df[:split_point]\n",
      "test_set = df[split_point:]\n",
      "\n",
      "range_train = len(train_set)\n",
      "\n",
      "filtered_indices = [index for index in top_values_indices if index <= range_train]\n",
      "\n",
      "# splitting the training set into features X and target variable Y\n",
      "x_train = train_set.drop(columns=['target'])\n",
      "y_train = train_set['target']\n",
      "\n",
      "# dropping the rows based on the indices\n",
      "x_train = x_train.drop(index=filtered_indices)\n",
      "y_train = y_train.drop(index=filtered_indices)\n",
      "\n",
      "#splitting the test set into  features X and target variable Y\n",
      "x_test = test_set.drop(columns=['target'])\n",
      "y_test = test_set['target']\n",
      " 201:\n",
      "one_hot_cols = ['artist', 'city_auction', 'currency', 'medium', 'surface', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
      "        ('num', continuous_transformer, continuous_cols)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 202:\n",
      "gbr = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 203: df.head(2)\n",
      " 204:\n",
      "features_to_drop = ['signed','dead']\n",
      "x_values = df.drop(columns=['target'] + features_to_drop)\n",
      "y_values = df['target']\n",
      " 205: x_values.head(2)\n",
      " 206:\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(df) * split_percentage) \n",
      "\n",
      "# Split the data in a training and test set\n",
      "x_train = x_values[:split_point]\n",
      "x_test = x_values[split_point:]\n",
      "\n",
      "y_train = y_values[:split_point]\n",
      "y_test = y_values[split_point:]\n",
      "\n",
      "one_hot_cols = ['artist', 'currency', 'medium', 'surface']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
      "        ('num', continuous_transformer, continuous_cols)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 207:\n",
      "gbr = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 208:\n",
      "one_hot_cols = ['artist', 'currency', 'medium', 'surface']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
      "        ('num', continuous_transformer, continuous_cols)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 209:\n",
      "estimator = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "perm_pipe = permutation_importance(pipeline, x_test, y_test, n_repeats=100, random_state=42, n_jobs=-1)\n",
      "\n",
      "feat_import_perm = perm_pipe.importances_mean\n",
      "fig, ax = plt.subplots(figsize=(20, 5))\n",
      "ax.bar(range(len(feat_import_perm)), feat_import_perm, align=\"center\")\n",
      "ax.set(xticks=range(len(feat_import_perm)), xticklabels=x_test.columns)\n",
      "# Set properties of x axis using setp, we will rotate the labels by 45 degrees\n",
      "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
      "plt.show()\n",
      " 210:\n",
      "perm_importance_df = pd.DataFrame({'Feature': x_test.columns, 'Importance': perm_pipe.importances_mean})\n",
      "\n",
      "# Sort the DataFrame by importance score in descending order\n",
      "perm_importance_df = perm_importance_df.sort_values(by='Importance', ascending=False)\n",
      "\n",
      "# Display the DataFrame\n",
      "print(perm_importance_df)\n",
      " 211:\n",
      "data = pd.concat([x_values, y_values], axis=1)\n",
      "\n",
      "# Select non-categorical features (assuming numerical features)\n",
      "numerical_features = data.select_dtypes(include=['float64', 'int64']).columns\n",
      "data_numerical = data[numerical_features]\n",
      "\n",
      "# Calculate correlations with the target variable (\"price\")\n",
      "correlation_with_price = data_numerical.corr()['target'].drop('target')\n",
      "\n",
      "# Create a list of features ordered by their correlation with the target variable\n",
      "ordered_features = correlation_with_price.abs().sort_values(ascending=False).index.tolist()\n",
      "\n",
      "ordered_features_df = pd.DataFrame({\n",
      "    'Feature': ordered_features,\n",
      "    'Correlation with Price': [correlation_with_price[feature] for feature in ordered_features]\n",
      "})\n",
      "\n",
      "ordered_features_df = ordered_features_df.sort_values(by='Correlation with Price', ascending=False)\n",
      "\n",
      "# Display the ordered list of features with correlation scores\n",
      "print(\"Ordered Features by Correlation with Price:\")\n",
      "print(ordered_features_df)\n",
      " 212:\n",
      "data = pd.concat([x_values, y_values], axis=1)\n",
      "\n",
      "# Select categorical features (assuming object type)\n",
      "categorical_features = data.select_dtypes(include=['object']).columns\n",
      "data_categorical = data[categorical_features]\n",
      "\n",
      "# One-hot encode categorical features\n",
      "data_encoded = pd.get_dummies(data_categorical)\n",
      "\n",
      "# Concatenate the encoded categorical features with numerical features\n",
      "data_combined = pd.concat([data_encoded, data_numerical], axis=1)\n",
      "\n",
      "# Calculate correlations with the target variable (\"price\")\n",
      "correlation_with_price = data_combined.corr()['target'].drop('target')\n",
      "\n",
      "# Create a DataFrame with feature names and their correlation scores\n",
      "ordered_features_df = pd.DataFrame({\n",
      "    'Feature': correlation_with_price.index,\n",
      "    'Correlation with Price': correlation_with_price.values\n",
      "})\n",
      "\n",
      "# Sort the DataFrame by correlation scores in descending order\n",
      "ordered_features_df = ordered_features_df.sort_values(by='Correlation with Price', ascending=False)\n",
      "\n",
      "# Display the ordered list of features with correlation scores\n",
      "print(\"Ordered Features by Correlation with Price:\")\n",
      "print(ordered_features_df)\n",
      " 213:\n",
      "dfx = dataframe\n",
      "dfx = dfx.rename(columns={'price_EUR': 'target'})\n",
      "dfx.head(2)\n",
      " 214:\n",
      "# making from medium and surface one boolean --> drawing or painting\n",
      "dfx['painting_drawing'] = 0\n",
      "dfx.loc[(dfx['medium'] == 'Pen and Ink Drawings') | (dfx['surface'] == 'paper'), 'painting_drawing'] = 'drawing'\n",
      "dfx.loc[dfx['medium'] == 'Oil-Based Paintings', 'painting_drawing'] = 'painting'\n",
      "for index, row in dfx.iterrows():\n",
      "    if row['painting_drawing']==0:\n",
      "        dfx.at[index, 'painting_drawing'] = 'painting'\n",
      "dfx.head(2)\n",
      " 215:\n",
      "# Assuming 'dfx' is your DataFrame\n",
      "# Count the occurrences of the value 0 in the 'painting_drawing' column\n",
      "count_0 = (dfx['painting_drawing'] == 0).sum()\n",
      "\n",
      "# Display the count of occurrences of the value 0\n",
      "print(\"Number of occurrences of 0 in 'painting_drawing':\", count_0)\n",
      " 216:\n",
      "painting_drawing_stats = dfx.groupby('painting_drawing').agg({'painting_drawing': 'count', 'target': 'sum'})\n",
      "\n",
      "# Renaming columns for clarity\n",
      "painting_drawing_stats = painting_drawing_stats.rename(columns={'painting_drawing': 'count', 'target': 'total_spent'})\n",
      "painting_drawing_stats['average'] = painting_drawing_stats['total_spent']/painting_drawing_stats['count']\n",
      "painting_drawing_stats = painting_drawing_stats.sort_values(by='average', ascending=False)\n",
      "print(painting_drawing_stats)\n",
      " 217:\n",
      "dfx = dfx.drop(['medium','surface'], axis=1)\n",
      "dfx.info()\n",
      " 218:\n",
      "dfx = dfx.sort_values(by='year_sold')\n",
      "\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(dfx) * split_percentage)\n",
      "\n",
      "# step 3: Split the data in a training and test set\n",
      "train_set = dfx[:split_point]\n",
      "test_set = dfx[split_point:]\n",
      "\n",
      "# Check the time range in each set\n",
      "print(\"Training Set Time Range:\", train_set['year_sold'].min(), train_set['year_sold'].max())\n",
      "print(\"Testing Set Time Range:\", test_set['year_sold'].min(), test_set['year_sold'].max())\n",
      " 219:\n",
      "x_train = train_set.drop(columns=['target'])\n",
      "y_train = train_set['target']\n",
      "\n",
      "#splitting the test set into  features X and target variable Y\n",
      "x_test = test_set.drop(columns=['target'])\n",
      "y_test = test_set['target']\n",
      " 220:\n",
      "one_hot_cols = ['artist', 'city_auction', 'currency', 'painting_drawing', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
      "        ('num', continuous_transformer, continuous_cols)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 221:\n",
      "print('Random Forest')\n",
      "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# define the grid of hyperparamters to look at\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
      "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
      "}\n",
      "\n",
      "# define the grid search object\n",
      "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# fit the grid search object to the training data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# print the best hyperparameters and the corresponding mean squared error\n",
      "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
      "print(\"Best MSE:\", -grid_search.best_score_)\n",
      "\n",
      "# calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# fit the pipeline to the train data\n",
      "grid_search.best_estimator_.fit(x_train, y_train)\n",
      "\n",
      "# make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# print the R-squared score of the model on the train data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# print the mean squared error of the model on the train data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Train MSE:\", mse_train)\n",
      "\n",
      "# print the root mean squared error of the model on the train data\n",
      "rmse_train = mse_train ** 0.5\n",
      "print(\"Train RMSE:\", rmse_train)\n",
      "\n",
      "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
      "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
      "print(\"Train MAE:\", mae_train)\n",
      " 222:\n",
      "estimator = GradientBoostingRegressor(random_state=42)\n",
      "print('Gradient Boosting')\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# Define the hyperparameters to tune\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [50, 100, 200],\n",
      "    'estimator__max_depth': [1,3,5 ,7, 10],\n",
      "    'estimator__max_features': ['sqrt', 'log2'],\n",
      "}\n",
      "\n",
      "# Create a grid search object\n",
      "time_series_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# Fit the grid search object to the data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# Print the best hyperparameters\n",
      "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
      "\n",
      "# Print the best MSE and corresponding negative value\n",
      "best_mse = -grid_search.best_score_\n",
      "print(\"Best MSE:\", best_mse)\n",
      "\n",
      "# Calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# calculate and print MAE\n",
      "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
      "print('training MAE:', mae)\n",
      "\n",
      "# Make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# Print the R-squared score of the model on the training data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# Print the mean squared error of the model on the training data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Training MSE:\", mse_train)\n",
      "\n",
      "# Print the root mean squared error of the model on the training data\n",
      "rmse_train = sqrt(mse_train)\n",
      "print(\"Training RMSE:\", rmse_train)\n",
      " 223:\n",
      "gbr = RandomForestRegressor(n_estimators=100, max_depth=20,random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print('test Random Forest')\n",
      "print('')\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 224:\n",
      "gbr = GradientBoostingRegressor(n_estimators=50, max_depth=7, max_features= 'sqrt',random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print('test Gradient Boosting')\n",
      "print('')\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 225:\n",
      "# combination of all these models: --> drop 10 outlier and 8 features \n",
      "df.head(2)\n",
      " 226:\n",
      "df = df.sort_values(by='year_sold')\n",
      "\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(df) * split_percentage)\n",
      "\n",
      "# step 3: Split the data in a training and test set\n",
      "train_set = df[:split_point]\n",
      "test_set = df[split_point:]\n",
      "\n",
      "# Check the time range in each set\n",
      "print(\"Training Set Time Range:\", train_set['year_sold'].min(), train_set['year_sold'].max())\n",
      "print(\"Testing Set Time Range:\", test_set['year_sold'].min(), test_set['year_sold'].max())\n",
      " 227: df = df.reset_index(drop=True)\n",
      " 228: top_values_indices = df['target'].nlargest(10).index\n",
      " 229:\n",
      "range_train = len(train_set)\n",
      "\n",
      "filtered_indices = [index for index in top_values_indices if index < range_train]\n",
      "\n",
      "# splitting the training set into features X and target variable Y\n",
      "x_train = train_set.drop(columns=['target'])\n",
      "y_train = train_set['target']\n",
      "\n",
      "# dropping the rows based on the indices\n",
      "x_train = x_train.drop(index=filtered_indices)\n",
      "y_train = y_train.drop(index=filtered_indices)\n",
      "\n",
      "#splitting the test set into  features X and target variable Y\n",
      "x_test = test_set.drop(columns=['target'])\n",
      "y_test = test_set['target']\n",
      " 230:\n",
      "one_hot_cols = ['artist', 'currency', 'medium', 'surface', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the columns to encode and scale (standard)\n",
      "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
      "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
      "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 231:\n",
      "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# define the grid of hyperparamters to look at\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
      "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
      "}\n",
      "\n",
      "# define the grid search object\n",
      "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# fit the grid search object to the training data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# print the best hyperparameters and the corresponding mean squared error\n",
      "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
      "print(\"Best MSE:\", -grid_search.best_score_)\n",
      "\n",
      "# calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# fit the pipeline to the train data\n",
      "grid_search.best_estimator_.fit(x_train, y_train)\n",
      "\n",
      "# make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# print the R-squared score of the model on the train data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# print the mean squared error of the model on the train data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Train MSE:\", mse_train)\n",
      "\n",
      "# print the root mean squared error of the model on the train data\n",
      "rmse_train = mse_train ** 0.5\n",
      "print(\"Train RMSE:\", rmse_train)\n",
      "\n",
      "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
      "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
      "print(\"Train MAE:\", mae_train)\n",
      " 232:\n",
      "gbr = RandomForestRegressor(n_estimators=25, max_depth=15, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print('test Random Forest')\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 233:\n",
      "estimator = GradientBoostingRegressor(random_state=42)\n",
      "print('Gradient Boosting')\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# Define the hyperparameters to tune\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [50, 100, 200],\n",
      "    'estimator__max_depth': [7, 10, 20],\n",
      "    'estimator__max_features': ['sqrt', 'log2'],\n",
      "}\n",
      "\n",
      "# Create a grid search object\n",
      "time_series_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# Fit the grid search object to the data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# Print the best hyperparameters\n",
      "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
      "\n",
      "# Print the best MSE and corresponding negative value\n",
      "best_mse = -grid_search.best_score_\n",
      "print(\"Best MSE:\", best_mse)\n",
      "\n",
      "# Calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# calculate and print MAE\n",
      "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
      "print('training MAE:', mae)\n",
      "\n",
      "# Make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# Print the R-squared score of the model on the training data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# Print the mean squared error of the model on the training data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Training MSE:\", mse_train)\n",
      "\n",
      "# Print the root mean squared error of the model on the training data\n",
      "rmse_train = sqrt(mse_train)\n",
      "print(\"Training RMSE:\", rmse_train)\n",
      " 234:\n",
      "# define the final estimator with the best parameters\n",
      "gbr = GradientBoostingRegressor(n_estimators=200, max_depth=10, max_features= 'sqrt',random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print('Test Gradient Boosting')\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 235: dfx.head(1)\n",
      " 236: dfx = dfx.reset_index(drop=True)\n",
      " 237: dfx.head(1)\n",
      " 238:\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(dfx) * split_percentage)\n",
      "\n",
      "# step 3: Split the data in a training and test set\n",
      "train_set = dfx[:split_point]\n",
      "test_set = dfx[split_point:]\n",
      "\n",
      "# Check the time range in each set\n",
      "print(\"Training Set Time Range:\", train_set['year_sold'].min(), train_set['year_sold'].max())\n",
      "print(\"Testing Set Time Range:\", test_set['year_sold'].min(), test_set['year_sold'].max())\n",
      " 239: top_values_indices = dfx['target'].nlargest(10).index\n",
      " 240:\n",
      "range_train = len(train_set)\n",
      "\n",
      "filtered_indices = [index for index in top_values_indices if index < range_train]\n",
      "\n",
      "# splitting the training set into features X and target variable Y\n",
      "x_train = train_set.drop(columns=['target'])\n",
      "y_train = train_set['target']\n",
      "\n",
      "# dropping the rows based on the indices\n",
      "x_train = x_train.drop(index=filtered_indices)\n",
      "y_train = y_train.drop(index=filtered_indices)\n",
      "\n",
      "#splitting the test set into  features X and target variable Y\n",
      "x_test = test_set.drop(columns=['target'])\n",
      "y_test = test_set['target']\n",
      " 241:\n",
      "one_hot_cols = ['artist', 'currency', 'painting_drawing', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the columns to encode and scale (standard)\n",
      "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
      "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
      "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 242:\n",
      "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
      "print('random forest')\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# define the grid of hyperparamters to look at\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
      "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
      "}\n",
      "\n",
      "# define the grid search object\n",
      "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# fit the grid search object to the training data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# print the best hyperparameters and the corresponding mean squared error\n",
      "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
      "print(\"Best MSE:\", -grid_search.best_score_)\n",
      "\n",
      "# calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# fit the pipeline to the train data\n",
      "grid_search.best_estimator_.fit(x_train, y_train)\n",
      "\n",
      "# make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# print the R-squared score of the model on the train data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# print the mean squared error of the model on the train data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Train MSE:\", mse_train)\n",
      "\n",
      "# print the root mean squared error of the model on the train data\n",
      "rmse_train = mse_train ** 0.5\n",
      "print(\"Train RMSE:\", rmse_train)\n",
      "\n",
      "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
      "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
      "print(\"Train MAE:\", mae_train)\n",
      " 243:\n",
      "gbr = RandomForestRegressor(n_estimators=50, max_depth=20, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print('test Random Forest')\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 244:\n",
      "estimator = GradientBoostingRegressor(random_state=42)\n",
      "print('Gradient Boosting')\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# Define the hyperparameters to tune\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [50, 100, 200],\n",
      "    'estimator__max_depth': [7, 10, 20],\n",
      "    'estimator__max_features': ['sqrt', 'log2'],\n",
      "}\n",
      "\n",
      "# Create a grid search object\n",
      "time_series_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# Fit the grid search object to the data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# Print the best hyperparameters\n",
      "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
      "\n",
      "# Print the best MSE and corresponding negative value\n",
      "best_mse = -grid_search.best_score_\n",
      "print(\"Best MSE:\", best_mse)\n",
      "\n",
      "# Calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# calculate and print MAE\n",
      "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
      "print('training MAE:', mae)\n",
      "\n",
      "# Make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# Print the R-squared score of the model on the training data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# Print the mean squared error of the model on the training data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Training MSE:\", mse_train)\n",
      "\n",
      "# Print the root mean squared error of the model on the training data\n",
      "rmse_train = sqrt(mse_train)\n",
      "print(\"Training RMSE:\", rmse_train)\n",
      " 245:\n",
      "# define the final estimator with the best parameters\n",
      "gbr = GradientBoostingRegressor(n_estimators=100, max_depth=10, max_features= 'sqrt',random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print('Test Gradient Boosting')\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 246:\n",
      "one_hot_cols = ['artist', 'painting_drawing', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols),\n",
      "        ('num', continuous_transformer, continuous_cols)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 247:\n",
      "# splitting data in X and y dataset \n",
      "x_values = dfx.drop(columns=['target'])\n",
      "y_values = dfx['target']\n",
      " 248:\n",
      "from sklearn.inspection import permutation_importance\n",
      "\n",
      "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "pipeline.fit(x_values, y_values)\n",
      "\n",
      "perm_pipe = permutation_importance(pipeline, x_values, y_values, n_repeats=100, random_state=42, n_jobs=-1)\n",
      "\n",
      "feat_import_perm = perm_pipe.importances_mean\n",
      "fig, ax = plt.subplots(figsize=(20, 5))\n",
      "ax.bar(range(len(feat_import_perm)), feat_import_perm, align=\"center\")\n",
      "ax.set(xticks=range(len(feat_import_perm)), xticklabels=x_values.columns)\n",
      "# Set properties of x axis using setp, we will rotate the labels by 45 degrees\n",
      "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
      "plt.show()\n",
      " 249:\n",
      "# Get the indices of the top 8 features\n",
      "top_feature_indices_perm = feat_import_perm.argsort()[-10:][::-1]\n",
      "\n",
      "# Get the names of the top 8 features\n",
      "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
      "\n",
      "# Plotting the permutation importances for the top 10 features\n",
      "plt.figure(figsize=(10, 6))\n",
      "plt.bar(range(len(top_feature_names_perm)), feat_import_perm[top_feature_indices_perm], align=\"center\")\n",
      "plt.xticks(range(len(top_feature_names_perm)), top_feature_names_perm, rotation=45)\n",
      "plt.xlabel(\"Feature\")\n",
      "plt.ylabel(\"Permutation Importance\")\n",
      "plt.title(\"Top 10 Features Based on Permutation Importance\")\n",
      "plt.show()\n",
      " 250:\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(dfx) * split_percentage)\n",
      "\n",
      "# step 3: Split the data in a training and test set\n",
      "train_set = dfx[:split_point]\n",
      "test_set = dfx[split_point:]\n",
      "\n",
      "# Get the indices of the top 8 features\n",
      "top_feature_indices_perm = perm_pipe.importances_mean.argsort()[-10:][::-1]\n",
      "\n",
      "# Get the names of the top 8 features\n",
      "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
      "print(top_feature_names_perm)\n",
      "\n",
      "# splitting in training set X and training set y but now only with the features we want.\n",
      "x_train = train_set[top_feature_names_perm]\n",
      "y_train = train_set['target']\n",
      "\n",
      "x_test = test_set[top_feature_names_perm]\n",
      "y_test = test_set['target']\n",
      "\n",
      "one_hot_cols = ['artist', 'currency', 'painting_drawing', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the columns to encode and scale (standard)\n",
      "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
      "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
      "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 251:\n",
      "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# define the grid of hyperparamters to look at\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
      "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
      "}\n",
      "\n",
      "# define the grid search object\n",
      "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# fit the grid search object to the training data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# print the best hyperparameters and the corresponding mean squared error\n",
      "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
      "print(\"Best MSE:\", -grid_search.best_score_)\n",
      "\n",
      "# calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# fit the pipeline to the train data\n",
      "grid_search.best_estimator_.fit(x_train, y_train)\n",
      "\n",
      "# make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# print the R-squared score of the model on the train data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# print the mean squared error of the model on the train data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Train MSE:\", mse_train)\n",
      "\n",
      "# print the root mean squared error of the model on the train data\n",
      "rmse_train = mse_train ** 0.5\n",
      "print(\"Train RMSE:\", rmse_train)\n",
      "\n",
      "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
      "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
      "print(\"Train MAE:\", mae_train)\n",
      " 252:\n",
      "gbr = RandomForestRegressor(n_estimators=200, max_depth=15, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print('test random forest')\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 253:\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(dfx) * split_percentage)\n",
      "\n",
      "# step 3: Split the data in a training and test set\n",
      "train_set = dfx[:split_point]\n",
      "test_set = dfx[split_point:]\n",
      "\n",
      "# Get the indices of the top 8 features\n",
      "top_feature_indices_perm = perm_pipe.importances_mean.argsort()[-8:][::-1]\n",
      "\n",
      "# Get the names of the top 8 features\n",
      "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
      "print(top_feature_names_perm)\n",
      "\n",
      "# splitting in training set X and training set y but now only with the features we want.\n",
      "x_train = train_set[top_feature_names_perm]\n",
      "y_train = train_set['target']\n",
      "\n",
      "x_test = test_set[top_feature_names_perm]\n",
      "y_test = test_set['target']\n",
      "\n",
      "one_hot_cols = ['artist', 'currency', 'painting_drawing', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the columns to encode and scale (standard)\n",
      "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
      "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
      "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 254:\n",
      "estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# define the grid of hyperparamters to look at\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [10, 25, 50, 100, 150, 200],\n",
      "    'estimator__max_depth': [None,5, 10, 15, 20, 30]\n",
      "}\n",
      "\n",
      "# define the grid search object\n",
      "time_serie_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_serie_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# fit the grid search object to the training data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# print the best hyperparameters and the corresponding mean squared error\n",
      "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
      "print(\"Best MSE:\", -grid_search.best_score_)\n",
      "\n",
      "# calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_serie_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# fit the pipeline to the train data\n",
      "grid_search.best_estimator_.fit(x_train, y_train)\n",
      "\n",
      "# make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# print the R-squared score of the model on the train data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# print the mean squared error of the model on the train data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Train MSE:\", mse_train)\n",
      "\n",
      "# print the root mean squared error of the model on the train data\n",
      "rmse_train = mse_train ** 0.5\n",
      "print(\"Train RMSE:\", rmse_train)\n",
      "\n",
      "# Calculate and print the Mean Absolute Error (MAE) of the model on the train data\n",
      "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
      "print(\"Train MAE:\", mae_train)\n",
      " 255:\n",
      "gbr = RandomForestRegressor(n_estimators=200, max_depth=5, random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print('test random forest')\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 256:\n",
      "estimator = GradientBoostingRegressor(random_state=42)\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "pipeline.fit(x_values, y_values)\n",
      "\n",
      "perm_pipe = permutation_importance(pipeline, x_values, y_values, n_repeats=100, random_state=42, n_jobs=-1)\n",
      "\n",
      "feat_import_perm = perm_pipe.importances_mean\n",
      "fig, ax = plt.subplots(figsize=(20, 5))\n",
      "ax.bar(range(len(feat_import_perm)), feat_import_perm, align=\"center\")\n",
      "ax.set(xticks=range(len(feat_import_perm)), xticklabels=x_values.columns)\n",
      "# Set properties of x axis using setp, we will rotate the labels by 45 degrees\n",
      "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
      "plt.show()\n",
      " 257:\n",
      "top_feature_indices_perm = feat_import_perm.argsort()[-10:][::-1]\n",
      "\n",
      "# Get the names of the top 8 features\n",
      "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
      "\n",
      "# Plotting the permutation importances for the top 10 features\n",
      "plt.figure(figsize=(10, 6))\n",
      "plt.bar(range(len(top_feature_names_perm)), feat_import_perm[top_feature_indices_perm], align=\"center\")\n",
      "plt.xticks(range(len(top_feature_names_perm)), top_feature_names_perm, rotation=45)\n",
      "plt.xlabel(\"Feature\")\n",
      "plt.ylabel(\"Permutation Importance\")\n",
      "plt.title(\"Top 10 Features Based on Permutation Importance\")\n",
      "plt.show()\n",
      " 258:\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(dfx) * split_percentage)\n",
      "\n",
      "# step 3: Split the data in a training and test set\n",
      "train_set = dfx[:split_point]\n",
      "test_set = dfx[split_point:]\n",
      "\n",
      "# Get the indices of the top 8 features\n",
      "top_feature_indices_perm = perm_pipe.importances_mean.argsort()[-10:][::-1]\n",
      "\n",
      "# Get the names of the top 8 features\n",
      "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
      "print(top_feature_names_perm)\n",
      "\n",
      "# splitting in training set X and training set y but now only with the features we want.\n",
      "x_train = train_set[top_feature_names_perm]\n",
      "y_train = train_set['target']\n",
      "\n",
      "x_test = test_set[top_feature_names_perm]\n",
      "y_test = test_set['target']\n",
      "\n",
      "one_hot_cols = ['artist', 'currency', 'painting_drawing', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the columns to encode and scale (standard)\n",
      "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
      "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
      "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 259:\n",
      "# Define the estimator for Gradient Boosting\n",
      "estimator = GradientBoostingRegressor(random_state=42)\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# Define the hyperparameters to tune\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [50, 100, 200],\n",
      "    'estimator__max_depth': [7, 10, 20],\n",
      "    'estimator__max_features': ['sqrt', 'log2'],\n",
      "}\n",
      "\n",
      "# Create a grid search object\n",
      "time_series_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# Fit the grid search object to the data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# Print the best hyperparameters\n",
      "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
      "\n",
      "# Print the best MSE and corresponding negative value\n",
      "best_mse = -grid_search.best_score_\n",
      "print(\"Best MSE:\", best_mse)\n",
      "\n",
      "# Calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# calculate and print MAE\n",
      "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
      "print('training MAE:', mae)\n",
      "\n",
      "# Make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# Print the R-squared score of the model on the training data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# Print the mean squared error of the model on the training data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Training MSE:\", mse_train)\n",
      "\n",
      "# Print the root mean squared error of the model on the training data\n",
      "rmse_train = sqrt(mse_train)\n",
      "print(\"Training RMSE:\", rmse_train)\n",
      " 260:\n",
      "# define the final estimator with the best parameters\n",
      "gbr = GradientBoostingRegressor(n_estimators=200, max_depth=10, max_features= 'sqrt',random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print('tets gradient boosting')\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 261:\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(dfx) * split_percentage)\n",
      "\n",
      "# step 3: Split the data in a training and test set\n",
      "train_set = dfx[:split_point]\n",
      "test_set = dfx[split_point:]\n",
      "\n",
      "# Get the indices of the top 8 features\n",
      "top_feature_indices_perm = perm_pipe.importances_mean.argsort()[-8:][::-1]\n",
      "\n",
      "# Get the names of the top 8 features\n",
      "top_feature_names_perm = x_values.columns[top_feature_indices_perm]\n",
      "print(top_feature_names_perm)\n",
      "\n",
      "# splitting in training set X and training set y but now only with the features we want.\n",
      "x_train = train_set[top_feature_names_perm]\n",
      "y_train = train_set['target']\n",
      "\n",
      "x_test = test_set[top_feature_names_perm]\n",
      "y_test = test_set['target']\n",
      "\n",
      "one_hot_cols = ['artist', 'currency', 'painting_drawing', 'signed','dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# define the columns to encode and scale (standard)\n",
      "one_hot_cols_less_features = [col for col in one_hot_cols if col in top_feature_names_perm]\n",
      "continuous_cols_less_features = [col for col in continuous_cols if col in top_feature_names_perm]\n",
      "\n",
      "# define the transformers for each column type\n",
      "one_hot_transformer = ce.OneHotEncoder(cols=one_hot_cols_less_features)\n",
      "continuous_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())])\n",
      "\n",
      "# combine the transformers using ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('one_hot', one_hot_transformer, one_hot_cols_less_features),\n",
      "        ('num', continuous_transformer, continuous_cols_less_features)],\n",
      "    )\n",
      "\n",
      "# define the feature selector\n",
      "selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
      " 262:\n",
      "# Define the estimator for Gradient Boosting\n",
      "estimator = GradientBoostingRegressor(random_state=42)\n",
      "\n",
      "# Define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', estimator)\n",
      "])\n",
      "\n",
      "# Define the hyperparameters to tune\n",
      "param_grid = {\n",
      "    'estimator__n_estimators': [50, 100, 200],\n",
      "    'estimator__max_depth': [7, 10, 20],\n",
      "    'estimator__max_features': ['sqrt', 'log2'],\n",
      "}\n",
      "\n",
      "# Create a grid search object\n",
      "time_series_split = TimeSeriesSplit(n_splits=5)\n",
      "grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_split, scoring='neg_mean_squared_error')\n",
      "\n",
      "# Fit the grid search object to the data\n",
      "grid_search.fit(x_train, y_train)\n",
      "\n",
      "# Print the best hyperparameters\n",
      "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
      "\n",
      "# Print the best MSE and corresponding negative value\n",
      "best_mse = -grid_search.best_score_\n",
      "print(\"Best MSE:\", best_mse)\n",
      "\n",
      "# Calculate and print the cross-validation scores\n",
      "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=time_series_split, scoring='r2')\n",
      "print(\"Cross-validation scores:\", cv_scores)\n",
      "print(\"Mean CV R-squared:\", cv_scores.mean())\n",
      "\n",
      "# calculate and print MAE\n",
      "mae = mean_absolute_error(y_train, grid_search.best_estimator_.predict(x_train))\n",
      "print('training MAE:', mae)\n",
      "\n",
      "# Make predictions using the fitted pipeline on the train data\n",
      "y_pred_train = grid_search.best_estimator_.predict(x_train)\n",
      "\n",
      "# Print the R-squared score of the model on the training data\n",
      "print(\"Train R-squared:\", grid_search.best_estimator_.score(x_train, y_train))\n",
      "\n",
      "# Print the mean squared error of the model on the training data\n",
      "mse_train = mean_squared_error(y_train, y_pred_train)\n",
      "print(\"Training MSE:\", mse_train)\n",
      "\n",
      "# Print the root mean squared error of the model on the training data\n",
      "rmse_train = sqrt(mse_train)\n",
      "print(\"Training RMSE:\", rmse_train)\n",
      " 263:\n",
      "# define the final estimator with the best parameters\n",
      "gbr = GradientBoostingRegressor(n_estimators=200, max_depth=20, max_features= 'sqrt',random_state=42)\n",
      "\n",
      "# define the pipeline\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('selector', selector),\n",
      "    ('estimator', gbr)])\n",
      "\n",
      "# fit the pipeline to the training data\n",
      "pipeline.fit(x_train, y_train)\n",
      "\n",
      "# make predictions on the test set\n",
      "y_pred = pipeline.predict(x_test)\n",
      "\n",
      "# evaluate the model on the test set\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "rmse = sqrt(mse)\n",
      "r2 = pipeline.score(x_test, y_test)\n",
      "adj_r2 = 1 - ((1 - r2) * (x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1))\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "\n",
      "print('tets gradient boosting')\n",
      "print(\"Test MSE:\", mse)\n",
      "print(\"Test RMSE:\", rmse)\n",
      "print(\"Test R-squared:\", r2)\n",
      "print('Adjusted R2 is', adj_r2)\n",
      "print(\"Test MAE:\", mae)\n",
      " 264:\n",
      "import tensorflow as tf\n",
      "from tensorflow import keras\n",
      "from tensorflow.keras import Sequential, layers, initializers, regularizers, losses, callbacks, optimizers\n",
      "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
      "from tensorflow.keras.optimizers import Adam\n",
      "from tensorflow.keras.regularizers import l2\n",
      "import matplotlib.pyplot as plt\n",
      "from keras.callbacks import EarlyStopping\n",
      " 265:\n",
      "one_hot_cols = ['artist', 'currency', 'medium', 'surface', 'signed', 'dead']\n",
      "continuous_cols = ['contrast', 'brightness', 'year_sold', 'circumference', 'year_born', 'return_sp']\n",
      "\n",
      "# Create preprocessing transformers\n",
      "numeric_transformer = Pipeline(steps=[\n",
      "    ('scaler', StandardScaler())\n",
      "])\n",
      "\n",
      "categorical_transformer = Pipeline(steps=[\n",
      "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
      "])\n",
      "\n",
      "# Combine transformers into a ColumnTransformer\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('num', numeric_transformer, continuous_cols),\n",
      "        ('cat', categorical_transformer, one_hot_cols)\n",
      "    ])\n",
      "\n",
      "split_percentage = 0.80\n",
      "split_point = int(len(df) * split_percentage)\n",
      "\n",
      "# step 3: Split the data in a training and test set\n",
      "train_set = df[:split_point]\n",
      "test_set = df[split_point:]\n",
      "\n",
      "x_train = train_set.drop(columns=['target'])\n",
      "y_train = train_set['target']\n",
      "\n",
      "x_test = test_set.drop(columns=['target'])\n",
      "y_test = test_set['target']\n",
      "\n",
      "# create a scaler for the target feature\n",
      "scaler = MinMaxScaler()\n",
      "\n",
      "y_train_array = np.array(y_train).reshape(-1, 1)\n",
      "y_test_array = np.array(y_test).reshape(-1, 1)\n",
      "\n",
      "y_train_scaled = scaler.fit_transform(y_train_array).flatten()\n",
      "y_test_scaled = scaler.transform(y_test_array).flatten()\n",
      "\n",
      "# Apply the preprocessing pipeline to your data\n",
      "x_train_processed = preprocessor.fit_transform(x_train)\n",
      "x_test_processed = preprocessor.transform(x_test)\n",
      " 266:\n",
      "# Build the neural network model\n",
      "model = Sequential([\n",
      "    layers.Input(shape=(33,)),\n",
      "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
      "    layers.Dropout(0.3),\n",
      "    layers.Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
      "    layers.Dropout(0.3),\n",
      "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
      "    layers.Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
      "    layers.Dense(1, activation='sigmoid')\n",
      "])\n",
      "\n",
      "# Set your desired learning rate\n",
      "learning_rate = 0.0000000001  # You can adjust this value\n",
      "\n",
      "# Create an instance of the Adam optimizer with the specified learning rate\n",
      "optimizer = Adam(learning_rate=learning_rate)\n",
      "\n",
      "# Define early stopping callback\n",
      "early_stopping = EarlyStopping(\n",
      "    monitor='val_loss',\n",
      "    patience=5,\n",
      "    restore_best_weights=True\n",
      ")\n",
      "\n",
      "# Compile the model\n",
      "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
      "\n",
      "# Train the model\n",
      "# Train the model with MAE monitoring and early stopping\n",
      "history = model.fit(\n",
      "    x_train_processed, y_train_scaled,\n",
      "    epochs=50,\n",
      "    validation_data=(x_test_processed, y_test_scaled),\n",
      "    callbacks=[early_stopping]\n",
      ")\n",
      "\n",
      "# Get MAE values from the training history\n",
      "mae = history.history['mae']\n",
      "val_mae = history.history['val_mae']\n",
      "\n",
      "# Plot MAE values over epochs\n",
      "plt.plot(mae, label='Training MAE')\n",
      "plt.plot(val_mae, label='Validation MAE')\n",
      "plt.xlabel('Epochs')\n",
      "plt.ylabel('MAE')\n",
      "plt.legend()\n",
      "plt.show()\n",
      " 267:\n",
      "%lsmagic\n",
      "%history -n\n"
     ]
    }
   ],
   "source": [
    "%lsmagic\n",
    "%history -n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac1e4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fefabf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391ea12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5512b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ac95e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4463240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64efd4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec3938f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dce7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2207c164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c5cbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65b3d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216b7ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05447826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfdc51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ab3c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad2310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc475d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1246667d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163eeb40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f8632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e387f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf0c1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cf6885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1986ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e37ed86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302628c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f353b092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4216f628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f201a33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c722da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d22b388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549cfe61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a218b1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d239ee7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5262349c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b297c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0755a797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecce679a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f611526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a68689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6615f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59fcc75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c63f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bf4801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ee2ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c2a219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ba645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c8354a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f16692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a201ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a2d57b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84166f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd702a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475b34a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac4ddd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c773a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5464057a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633e5d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978af7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6103dec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b8a31c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193dee92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2988de61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2199495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea00ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b747c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17672aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d919445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
